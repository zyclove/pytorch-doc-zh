
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>torch.nn · Pytorch 中文文档</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="ApacheCN">
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-insert-logo/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-pageview-count/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-emphasize/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-alerts/style.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-auto-scroll-table/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-page-toc-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-tbfed-pagefooter/footer.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-advanced-emoji/emoji-website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="optim.html" />
    
    
    <link rel="prev" href="storage.html" />
    

    <style>
    @media only screen and (max-width: 640px) {
        .book-header .hidden-mobile {
            display: none;
        }
    }
    </style>
    <script>
        window["gitbook-plugin-github-buttons"] = {"buttons":[{"user":"apachecn","repo":"pytorch-doc-zh","type":"star","count":true,"size":"small"}]};
    </script>

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    PyTorch 0.3 中文文档 & 教程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="tut.html">
            
                <a href="tut.html">
            
                    
                    中文教程
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="beginner_tutorials.html">
            
                <a href="beginner_tutorials.html">
            
                    
                    初学者教程
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.1" data-path="deep_learning_60min_blitz.html">
            
                <a href="deep_learning_60min_blitz.html">
            
                    
                    PyTorch 深度学习: 60 分钟极速入门教程
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.1.1" data-path="blitz_tensor_tutorial.html">
            
                <a href="blitz_tensor_tutorial.html">
            
                    
                    PyTorch 是什么？
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.1.2" data-path="blitz_autograd_tutorial.html">
            
                <a href="blitz_autograd_tutorial.html">
            
                    
                    自动求导: 自动微分
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.1.3" data-path="blitz_neural_networks_tutorial.html">
            
                <a href="blitz_neural_networks_tutorial.html">
            
                    
                    神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.1.4" data-path="blitz_cifar10_tutorial.html">
            
                <a href="blitz_cifar10_tutorial.html">
            
                    
                    训练一个分类器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.1.5" data-path="blitz_data_parallel_tutorial.html">
            
                <a href="blitz_data_parallel_tutorial.html">
            
                    
                    可选: 数据并行
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.1.2" data-path="former_torchies_tutorial.html">
            
                <a href="former_torchies_tutorial.html">
            
                    
                    PyTorch for former Torch users
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.2.1" data-path="former_torchies_tensor_tutorial.html">
            
                <a href="former_torchies_tensor_tutorial.html">
            
                    
                    Tensors
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.2.2" data-path="former_torchies_autograd_tutorial.html">
            
                <a href="former_torchies_autograd_tutorial.html">
            
                    
                    Autograd (自动求导)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.2.3" data-path="former_torchies_nn_tutorial.html">
            
                <a href="former_torchies_nn_tutorial.html">
            
                    
                    nn package
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.2.4" data-path="former_torchies_parallelism_tutorial.html">
            
                <a href="former_torchies_parallelism_tutorial.html">
            
                    
                    Multi-GPU examples
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.1.3" data-path="pytorch_with_examples.html">
            
                <a href="pytorch_with_examples.html">
            
                    
                    跟着例子学习 PyTorch
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.3.1" data-path="pytorch_with_examples_warm-up-numpy.html">
            
                <a href="pytorch_with_examples_warm-up-numpy.html">
            
                    
                    Warm-up: numpy
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3.2" data-path="pytorch_with_examples_pytorch-tensors.html">
            
                <a href="pytorch_with_examples_pytorch-tensors.html">
            
                    
                    PyTorch: Tensors
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3.3" data-path="pytorch_with_examples_pytorch-variables-and-autograd.html">
            
                <a href="pytorch_with_examples_pytorch-variables-and-autograd.html">
            
                    
                    PyTorch: 变量和autograd
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3.4" data-path="pytorch_with_examples_pytorch-defining-new-autograd-functions.html">
            
                <a href="pytorch_with_examples_pytorch-defining-new-autograd-functions.html">
            
                    
                    PyTorch: 定义新的autograd函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3.5" data-path="pytorch_with_examples_tensorflow-static-graphs.html">
            
                <a href="pytorch_with_examples_tensorflow-static-graphs.html">
            
                    
                    TensorFlow: 静态图
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3.6" data-path="pytorch_with_examples_pytorch-nn.html">
            
                <a href="pytorch_with_examples_pytorch-nn.html">
            
                    
                    PyTorch: nn包
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3.7" data-path="pytorch_with_examples_pytorch-optim.html">
            
                <a href="pytorch_with_examples_pytorch-optim.html">
            
                    
                    PyTorch: optim包
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3.8" data-path="pytorch_with_examples_pytorch-custom-nn-modules.html">
            
                <a href="pytorch_with_examples_pytorch-custom-nn-modules.html">
            
                    
                    PyTorch: 定制化nn模块
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3.9" data-path="pytorch_with_examples_pytorch-control-flow-weight-sharing.html">
            
                <a href="pytorch_with_examples_pytorch-control-flow-weight-sharing.html">
            
                    
                    PyTorch: 动态控制流程 + 权重共享
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.1.4" data-path="transfer_learning_tutorial.html">
            
                <a href="transfer_learning_tutorial.html">
            
                    
                    迁移学习教程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.5" data-path="data_loading_tutorial.html">
            
                <a href="data_loading_tutorial.html">
            
                    
                    数据加载和处理教程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.6" data-path="deep_learning_nlp_tutorial.html">
            
                <a href="deep_learning_nlp_tutorial.html">
            
                    
                    针对NLP的Pytorch深度学习
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.6.1" data-path="nlp_pytorch_tutorial.html">
            
                <a href="nlp_pytorch_tutorial.html">
            
                    
                    PyTorch介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.6.2" data-path="nlp_deep_learning_tutorial.html">
            
                <a href="nlp_deep_learning_tutorial.html">
            
                    
                    PyTorch深度学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.6.3" data-path="nlp_word_embeddings_tutorial.html">
            
                <a href="nlp_word_embeddings_tutorial.html">
            
                    
                    词汇嵌入:编码词汇语义
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.6.4" data-path="nlp_sequence_models_tutorial.html">
            
                <a href="nlp_sequence_models_tutorial.html">
            
                    
                    序列模型和 LSTM 网络（长短记忆网络）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.6.5" data-path="nlp_advanced_tutorial.html">
            
                <a href="nlp_advanced_tutorial.html">
            
                    
                    高级教程: 作出动态决策和 Bi-LSTM CRF
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="intermediate_tutorials.html">
            
                <a href="intermediate_tutorials.html">
            
                    
                    中级教程
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.2.1" data-path="char_rnn_classification_tutorial.html">
            
                <a href="char_rnn_classification_tutorial.html">
            
                    
                    用字符级RNN分类名称
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.2" data-path="char_rnn_generation_tutorial.html">
            
                <a href="char_rnn_generation_tutorial.html">
            
                    
                    基与字符级RNN（Char-RNN）的人名生成
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.3" data-path="seq2seq_translation_tutorial.html">
            
                <a href="seq2seq_translation_tutorial.html">
            
                    
                    用基于注意力机制的seq2seq神经网络进行翻译
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.4" data-path="reinforcement_q_learning.html">
            
                <a href="reinforcement_q_learning.html">
            
                    
                    强化学习（DQN）教程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.5" data-path="dist_tuto.html">
            
                <a href="dist_tuto.html">
            
                    
                    Writing Distributed Applications with PyTorch
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.6" data-path="spatial_transformer_tutorial.html">
            
                <a href="spatial_transformer_tutorial.html">
            
                    
                    空间转换网络 (Spatial Transformer Networks) 教程
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="advanced_tutorials.html">
            
                <a href="advanced_tutorials.html">
            
                    
                    高级教程
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.3.1" data-path="neural_style_tutorial.html">
            
                <a href="neural_style_tutorial.html">
            
                    
                    用 PyTorch 做 神经转换 (Neural Transfer)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.2" data-path="numpy_extensions_tutorial.html">
            
                <a href="numpy_extensions_tutorial.html">
            
                    
                    使用 numpy 和 scipy 创建扩展
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.3" data-path="super_resolution_with_caffe2.html">
            
                <a href="super_resolution_with_caffe2.html">
            
                    
                    使用 ONNX 将模型从 PyTorch 迁移到 Caffe2 和 Mobile
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.4" data-path="c_extension.html">
            
                <a href="c_extension.html">
            
                    
                    为 pytorch 自定义 C 扩展
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="doc.html">
            
                <a href="doc.html">
            
                    
                    中文文档
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="notes.html">
            
                <a href="notes.html">
            
                    
                    介绍
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1.1" data-path="notes_autograd.html">
            
                <a href="notes_autograd.html">
            
                    
                    自动求导机制
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.2" data-path="notes_broadcasting.html">
            
                <a href="notes_broadcasting.html">
            
                    
                    广播语义
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.3" data-path="notes_cuda.html">
            
                <a href="notes_cuda.html">
            
                    
                    CUDA 语义
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.4" data-path="notes_extending.html">
            
                <a href="notes_extending.html">
            
                    
                    扩展 PyTorch
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.5" data-path="notes_multiprocessing.html">
            
                <a href="notes_multiprocessing.html">
            
                    
                    多进程的最佳实践
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.6" data-path="notes_serialization.html">
            
                <a href="notes_serialization.html">
            
                    
                    序列化语义
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="package_reference.html">
            
                <a href="package_reference.html">
            
                    
                    Package 参考
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.2.1" data-path="torch.html">
            
                <a href="torch.html">
            
                    
                    torch
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.2" data-path="tensors.html">
            
                <a href="tensors.html">
            
                    
                    torch.Tensor
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.3" data-path="sparse.html">
            
                <a href="sparse.html">
            
                    
                    torch.sparse
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.4" data-path="storage.html">
            
                <a href="storage.html">
            
                    
                    torch.Storage
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.2.5" data-path="nn.html">
            
                <a href="nn.html">
            
                    
                    torch.nn
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.6" data-path="optim.html">
            
                <a href="optim.html">
            
                    
                    torch.optim
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.7" data-path="autograd.html">
            
                <a href="autograd.html">
            
                    
                    Automatic differentiation package - torch.autograd
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.8" data-path="distributions.html">
            
                <a href="distributions.html">
            
                    
                    Probability distributions - torch.distributions
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.9" data-path="multiprocessing.html">
            
                <a href="multiprocessing.html">
            
                    
                    Multiprocessing package - torch.multiprocessing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.10" data-path="distributed.html">
            
                <a href="distributed.html">
            
                    
                    Distributed communication package - torch.distributed
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.11" data-path="legacy.html">
            
                <a href="legacy.html">
            
                    
                    Legacy package - torch.legacy
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.12" data-path="cuda.html">
            
                <a href="cuda.html">
            
                    
                    torch.cuda
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.13" data-path="ffi.html">
            
                <a href="ffi.html">
            
                    
                    torch.utils.ffi
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.14" data-path="data.html">
            
                <a href="data.html">
            
                    
                    torch.utils.data
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.15" data-path="model_zoo.html">
            
                <a href="model_zoo.html">
            
                    
                    torch.utils.model_zoo
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.16" data-path="onnx.html">
            
                <a href="onnx.html">
            
                    
                    torch.onnx
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="torchvision_reference.html">
            
                <a href="torchvision_reference.html">
            
                    
                    torchvision 参考
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.3.1" data-path="torchvision.html">
            
                <a href="torchvision.html">
            
                    
                    torchvision
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.2" data-path="datasets.html">
            
                <a href="datasets.html">
            
                    
                    torchvision.datasets
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.3" data-path="models.html">
            
                <a href="models.html">
            
                    
                    torchvision.models
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.4" data-path="transforms.html">
            
                <a href="transforms.html">
            
                    
                    torchvision.transforms
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.5" data-path="utils.html">
            
                <a href="utils.html">
            
                    
                    torchvision.utils
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >torch.nn</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="torchnn">torch.nn</h1>
<blockquote>
<p>&#x8BD1;&#x8005;&#xFF1A;<a href="https://github.com/VPrincekin" target="_blank">@&#x5C0F;&#x738B;&#x5B50;</a>&#x3001;<a href="https://github.com/wangyangting" target="_blank">@&#x90A3;&#x4F0A;&#x62B9;&#x5FAE;&#x7B11;</a>&#x3001;<a href="https://github.com/busyboxs" target="_blank">@Yang Shun</a>&#x3001;<a href="https://github.com/zhuyansen" target="_blank">@Zhu Yansen</a>&#x3001;<a href="https://github.com/woaichipinngguo" target="_blank">@woaichipinngguo</a>&#x3001;<a href="https://github.com/buldajs" target="_blank">@buldajs</a>&#x3001;<a href="https://github.com/swardsman" target="_blank">@&#x5409;&#x601D;&#x96E8;</a>&#x3001;<a href="https://github.com/vra" target="_blank">@&#x738B;&#x4E91;&#x5CF0;</a>&#x3001;<a href="https://github.com/sawyer7246" target="_blank">@&#x674E;&#x96E8;&#x9F99;</a>&#x3001;<a href="https://github.com/Eadral" target="_blank">@Yucong Zhu</a>&#x3001;<a href="https://github.com/garry1ng" target="_blank">@&#x6797;&#x5609;&#x5E94;</a>&#x3001;<a href="https://github.com/QianFanCe" target="_blank">@QianFanCe</a>&#x3001;<a href="https://github.com/dabney777" target="_blank">@dabney777</a>&#x3001;<a href="https://github.com/jizg" target="_blank">@Alex</a>&#x3001;<a href="https://github.com/Mabinogiysk" target="_blank">@SiKai Yao</a>&#x3001;<a href="https://github.com/QiaoXie" target="_blank">@&#x5C0F;&#x4E54;</a> @laihongchang @&#x567C;&#x91CC;&#x556A;&#x5566;&#x5623; <a href="https://github.com/BarrettLi" target="_blank">@BarrettLi</a>&#x3001;<a href="https://github.com/KrokYin" target="_blank">@KrokYin</a>&#x3001;<a href="https://github.com/JoinsenQ" target="_blank">@MUSK1881</a></p>
<p>&#x6821;&#x5BF9;&#x8005;&#xFF1A;<a href="http://community.apachecn.org/?/people/clown9804" target="_blank">@clown9804</a>&#x3001;<a href="https://github.com/wizardforcel" target="_blank">@&#x98DE;&#x9F99;</a></p>
</blockquote>
<h2 id="parameters-&#x53C2;&#x6570;">Parameters (&#x53C2;&#x6570;)</h2>
<pre><code class="lang-py">class torch.nn.Parameter
</code></pre>
<p>Variable &#x7684;&#x4E00;&#x79CD;, &#x5E38;&#x88AB;&#x7528;&#x4E8E; module parameter&#xFF08;&#x6A21;&#x5757;&#x53C2;&#x6570;&#xFF09;.</p>
<p>Parameters &#x662F; <code>Variable</code>](autograd.html#torch.autograd.Variable &quot;torch.autograd.Variable&quot;) &#x7684;&#x5B50;&#x7C7B;, &#x5F53;&#x5B83;&#x548C; [<code>Module</code> &#x4E00;&#x8D77;&#x4F7F;&#x7528;&#x7684;&#x65F6;&#x5019;&#x4F1A;&#x6709;&#x4E00;&#x4E9B;&#x7279;&#x6B8A;&#x7684;&#x5C5E;&#x6027; - &#x5F53;&#x5B83;&#x4EEC;&#x88AB;&#x8D4B;&#x503C;&#x7ED9; Module &#x5C5E;&#x6027;&#x65F6;, &#x5B83;&#x4F1A;&#x81EA;&#x52A8;&#x7684;&#x88AB;&#x52A0;&#x5230; Module &#x7684;&#x53C2;&#x6570;&#x5217;&#x8868;&#x4E2D;, &#x5E76;&#x4E14;&#x4F1A;&#x51FA;&#x73B0;&#x5728; <code>parameters()</code> iterator &#x8FED;&#x4EE3;&#x5668;&#x65B9;&#x6CD5;&#x4E2D;. &#x5C06; Varibale &#x8D4B;&#x503C;&#x7ED9; Module &#x5C5E;&#x6027;&#x5219;&#x4E0D;&#x4F1A;&#x6709;&#x8FD9;&#x6837;&#x7684;&#x5F71;&#x54CD;. &#x8FD9;&#x6837;&#x505A;&#x7684;&#x539F;&#x56E0;&#x662F;: &#x6211;&#x4EEC;&#x6709;&#x65F6;&#x5019;&#x4F1A;&#x9700;&#x8981;&#x7F13;&#x5B58;&#x4E00;&#x4E9B;&#x4E34;&#x65F6;&#x7684; state&#xFF08;&#x72B6;&#x6001;&#xFF09;, &#x4F8B;&#x5982;: &#x6A21;&#x578B; RNN &#x4E2D;&#x7684;&#x6700;&#x540E;&#x4E00;&#x4E2A;&#x9690;&#x85CF;&#x72B6;&#x6001;. &#x5982;&#x679C;&#x6CA1;&#x6709; <code>Parameter</code> &#x8FD9;&#x4E2A;&#x7C7B;&#x7684;&#x8BDD;, &#x90A3;&#x4E48;&#x8FD9;&#x4E9B;&#x4E34;&#x65F6;&#x8868;&#x4E5F;&#x4F1A;&#x6CE8;&#x518C;&#x4E3A;&#x6A21;&#x578B;&#x53D8;&#x91CF;.</p>
<p>Variable &#x4E0E; Parameter &#x7684;&#x53E6;&#x4E00;&#x4E2A;&#x4E0D;&#x540C;&#x4E4B;&#x5904;&#x5728;&#x4E8E;, Parameter &#x4E0D;&#x80FD;&#x88AB; volatile (&#x5373;: &#x65E0;&#x6CD5;&#x8BBE;&#x7F6E; volatile=True) &#x800C;&#x4E14;&#x9ED8;&#x8BA4; requires_grad=True. Variable &#x9ED8;&#x8BA4; requires_grad=False.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>data (Tensor)</code> &#x2013; parameter tensor.</li>
<li><code>requires_grad (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x5982;&#x679C;&#x53C2;&#x6570;&#x9700;&#x8981;&#x68AF;&#x5EA6;. &#x66F4;&#x591A;&#x7EC6;&#x8282;&#x8BF7;&#x53C2;&#x9605; <a href="notes/autograd.html#excluding-subgraphs">&#x53CD;&#x5411;&#x6392;&#x9664; subgraphs (&#x5B50;&#x56FE;)</a>.</li>
</ul>
<h2 id="containers-&#x5BB9;&#x5668;">Containers (&#x5BB9;&#x5668;)</h2>
<h3 id="module">Module</h3>
<pre><code class="lang-py">class torch.nn.Module
</code></pre>
<p>&#x6240;&#x6709;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x57FA;&#x7C7B;.</p>
<p>&#x4F60;&#x7684;&#x6A21;&#x578B;&#x5E94;&#x8BE5;&#x4E5F;&#x662F;&#x8BE5;&#x7C7B;&#x7684;&#x5B50;&#x7C7B;.</p>
<p>Modules &#x4E5F;&#x53EF;&#x4EE5;&#x5305;&#x542B;&#x5176;&#x5B83; Modules, &#x5141;&#x8BB8;&#x4F7F;&#x7528;&#x6811;&#x7ED3;&#x6784;&#x5D4C;&#x5165;&#x5B83;&#x4EEC;. &#x4F60;&#x53EF;&#x4EE5;&#x5C06;&#x5B50;&#x6A21;&#x5757;&#x8D4B;&#x503C;&#x7ED9;&#x6A21;&#x578B;&#x5C5E;&#x6027;</p>
<pre><code class="lang-py"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Model</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">20</span>, <span class="hljs-number">5</span>)
        self.conv2 = nn.Conv2d(<span class="hljs-number">20</span>, <span class="hljs-number">20</span>, <span class="hljs-number">5</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
       x = F.relu(self.conv1(x))
       <span class="hljs-keyword">return</span> F.relu(self.conv2(x))
</code></pre>
<p>&#x4EE5;&#x8FD9;&#x79CD;&#x65B9;&#x5F0F;&#x5206;&#x914D;&#x7684;&#x5B50;&#x6A21;&#x5757;&#x5C06;&#x88AB;&#x6CE8;&#x518C;, &#x5E76;&#x4E14;&#x5728;&#x8C03;&#x7528; .cuda() &#x7B49;&#x7B49;&#x65B9;&#x6CD5;&#x65F6;&#x4E5F;&#x5C06;&#x8F6C;&#x6362;&#x5B83;&#x4EEC;&#x7684;&#x53C2;&#x6570;.</p>
<pre><code class="lang-py">add_module(name, module)
</code></pre>
<p>&#x6DFB;&#x52A0;&#x4E00;&#x4E2A; child module&#xFF08;&#x5B50;&#x6A21;&#x5757;&#xFF09;&#x5230;&#x5F53;&#x524D;&#x7684; module&#xFF08;&#x6A21;&#x5757;&#xFF09;&#x4E2D;.</p>
<p>&#x88AB;&#x6DFB;&#x52A0;&#x7684; module &#x8FD8;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x6307;&#x5B9A;&#x7684; name &#x5C5E;&#x6027;&#x6765;&#x83B7;&#x53D6;&#x5B83;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>name (string)</code> &#x2013; &#x5B50;&#x6A21;&#x5757;&#x7684;&#x540D;&#x79F0;. &#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x6307;&#x5B9A;&#x7684; name &#x4ECE;&#x8BE5;&#x6A21;&#x5757;&#x8BBF;&#x95EE;&#x5B50;&#x6A21;&#x5757;</li>
<li><code>parameter (Module)</code> &#x2013; &#x88AB;&#x6DFB;&#x52A0;&#x5230;&#x6A21;&#x5757;&#x7684;&#x5B50;&#x6A21;&#x5757;.</li>
</ul>
<pre><code class="lang-py">apply(fn)
</code></pre>
<p>&#x5C06; <code>fn</code> &#x51FD;&#x6570;&#x9012;&#x5F52;&#x7684;&#x5E94;&#x7528;&#x5230;&#x6BCF;&#x4E00;&#x4E2A;&#x5B50;&#x6A21;&#x5757; (&#x7531; <code>.children()</code> &#x65B9;&#x6CD5;&#x6240;&#x8FD4;&#x56DE;&#x7684;) &#x4EE5;&#x53CA; self. &#x5178;&#x578B;&#x7684;&#x7528;&#x4E8E;&#x5305;&#x62EC;&#x521D;&#x59CB;&#x5316;&#x6A21;&#x578B;&#x7684;&#x53C2;&#x6570; (&#x4E5F;&#x53EF;&#x53C2;&#x9605; torch-nn-init).</p>
<p>&#x53C2;&#x6570;&#xFF1A;<code>fn (Module -&gt; None)</code> &#x2013; &#x8981;&#x88AB;&#x5E94;&#x7528;&#x5230;&#x6BCF;&#x4E00;&#x4E2A;&#x5B50;&#x6A21;&#x5757;&#x4E0A;&#x7684;&#x51FD;&#x6570;</p>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;<code>self</code></p>
<p>&#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;<code>Module</code></p>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py">&gt;&gt;&gt; def init_weights(m):
&gt;&gt;&gt;     print(m)
&gt;&gt;&gt;     if type(m) == nn.Linear:
&gt;&gt;&gt;         m.weight.data.fill_(1.0)
&gt;&gt;&gt;         print(m.weight)
&gt;&gt;&gt;
&gt;&gt;&gt; net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))
&gt;&gt;&gt; net.apply(init_weights)
Linear (2 -&gt; 2)
Parameter containing:
 1  1
 1  1
[torch.FloatTensor of size 2x2]
Linear (2 -&gt; 2)
Parameter containing:
 1  1
 1  1
[torch.FloatTensor of size 2x2]
Sequential (
 (0): Linear (2 -&gt; 2)
 (1): Linear (2 -&gt; 2)
)
</code></pre>
<pre><code class="lang-py">children()
</code></pre>
<p>&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x6700;&#x8FD1;&#x5B50;&#x6A21;&#x5757;&#x7684; iterator&#xFF08;&#x8FED;&#x4EE3;&#x5668;&#xFF09;.</p>
<p>Yields: <code>Module</code> &#x2013; &#x4E00;&#x4E2A;&#x5B50;&#x6A21;&#x5757;</p>
<pre><code class="lang-py">cpu()
</code></pre>
<p>&#x5C06;&#x6240;&#x6709;&#x7684;&#x6A21;&#x578B;&#x53C2;&#x6570;&#x548C;&#x7F13;&#x51B2;&#x533A;&#x79FB;&#x52A8;&#x5230; CPU.</p>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;<code>self</code></p>
<p>&#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;<code>Module</code></p>
<pre><code class="lang-py">cuda(device=<span class="hljs-keyword">None</span>)
</code></pre>
<p>&#x5C06;&#x6240;&#x6709;&#x7684;&#x6A21;&#x578B;&#x53C2;&#x6570;&#x548C;&#x7F13;&#x51B2;&#x533A;&#x79FB;&#x52A8;&#x5230; GPU.</p>
<p>&#x8FD9;&#x5C06;&#x4F1A;&#x5173;&#x8054;&#x4E00;&#x4E9B;&#x53C2;&#x6570;&#x5E76;&#x4E14;&#x7F13;&#x5B58;&#x4E0D;&#x540C;&#x7684;&#x5BF9;&#x8C61;. &#x6240;&#x4EE5;&#x5728;&#x6784;&#x5EFA;&#x4F18;&#x5316;&#x5668;&#x4E4B;&#x524D;&#x5E94;&#x8BE5;&#x8C03;&#x7528;&#x5B83;, &#x5982;&#x679C;&#x6A21;&#x5757;&#x5728;&#x4F18;&#x5316;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#x4F1A;&#x751F;&#x5B58;&#x5728; GPU &#x4E0A;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;<code>device (int, &#x53EF;&#x9009;)</code> &#x2013; &#x5982;&#x679C;&#x6307;&#x5B9A;, &#x6240;&#x6709;&#x53C2;&#x6570;&#x5C06;&#x88AB;&#x590D;&#x5236;&#x5230;&#x6307;&#x5B9A;&#x7684;&#x8BBE;&#x5907;&#x4E0A;</p>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;<code>self</code></p>
<p>&#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;<code>Module</code></p>
<pre><code class="lang-py">double()
</code></pre>
<p>&#x5C06;&#x6240;&#x6709;&#x7684; parameters &#x548C; buffers &#x7684;&#x6570;&#x636E;&#x7C7B;&#x578B;&#x8F6C;&#x6362;&#x6210; double.</p>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;<code>self</code></p>
<p>&#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;<code>Module</code></p>
<pre><code class="lang-py">eval()
</code></pre>
<p>&#x5C06;&#x6A21;&#x5757;&#x8BBE;&#x7F6E;&#x4E3A;&#x8BC4;&#x4F30;&#x6A21;&#x5F0F;.</p>
<p>&#x8FD9;&#x79CD;&#x65B9;&#x5F0F;&#x53EA;&#x5BF9; Dropout &#x6216; BatchNorm &#x7B49;&#x6A21;&#x5757;&#x6709;&#x6548;.</p>
<pre><code class="lang-py">float()
</code></pre>
<p>&#x5C06;&#x6240;&#x6709;&#x7684; parameters &#x548C; buffers &#x7684;&#x6570;&#x636E;&#x7C7B;&#x578B;&#x8F6C;&#x6362;&#x6210;float.</p>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;<code>self</code></p>
<p>&#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;<code>Module</code></p>
<pre><code class="lang-py">forward(*input)
</code></pre>
<p>&#x5B9A;&#x4E49;&#x6BCF;&#x6B21;&#x8C03;&#x7528;&#x65F6;&#x6267;&#x884C;&#x7684;&#x8BA1;&#x7B97;.</p>
<p>&#x5E94;&#x8BE5;&#x88AB;&#x6240;&#x6709;&#x7684;&#x5B50;&#x7C7B;&#x91CD;&#x5199;.</p>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x5C3D;&#x7BA1;&#x9700;&#x8981;&#x5728;&#x6B64;&#x51FD;&#x6570;&#x4E2D;&#x5B9A;&#x4E49;&#x6B63;&#x5411;&#x4F20;&#x9012;&#x7684;&#x65B9;&#x5F0F;, &#x4F46;&#x662F;&#x5E94;&#x8BE5;&#x4E8B;&#x540E;&#x5C3D;&#x91CF;&#x8C03;&#x7528; <code>Module</code> &#x5B9E;&#x4F8B;, &#x56E0;&#x4E3A;&#x524D;&#x8005;&#x8D1F;&#x8D23;&#x8FD0;&#x884C;&#x5DF2;&#x6CE8;&#x518C;&#x7684;&#x94A9;&#x5B50;, &#x800C;&#x540E;&#x8005;&#x9759;&#x9ED8;&#x7684;&#x5FFD;&#x7565;&#x5B83;&#x4EEC;.</p>
<pre><code class="lang-py">half()
</code></pre>
<p>&#x5C06;&#x6240;&#x6709;&#x7684; parameters &#x548C; buffers &#x7684;&#x6570;&#x636E;&#x7C7B;&#x578B;&#x8F6C;&#x6362;&#x6210; half.</p>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;<code>self</code></p>
<p>&#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;<code>Module</code></p>
<pre><code class="lang-py">load_state_dict(state_dict, strict=<span class="hljs-keyword">True</span>)
</code></pre>
<p>&#x5C06; <code>state_dict</code> &#x4E2D;&#x7684; parameters &#x548C; buffers &#x590D;&#x5236;&#x5230;&#x6B64;&#x6A21;&#x5757;&#x548C;&#x5B83;&#x7684;&#x5B50;&#x540E;&#x4EE3;&#x4E2D;. &#x5982;&#x679C; <code>strict</code> &#x4E3A; <code>True</code>, &#x5219; <code>state_dict</code> &#x7684; key &#x5FC5;&#x987B;&#x548C;&#x6A21;&#x5757;&#x7684; <code>state_dict()</code> &#x51FD;&#x6570;&#x8FD4;&#x56DE;&#x7684; key &#x4E00;&#x81F4;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>state_dict (dict)</code> &#x2013; &#x4E00;&#x4E2A;&#x5305;&#x542B; parameters &#x548C; persistent buffers&#xFF08;&#x6301;&#x4E45;&#x5316;&#x7F13;&#x5B58;&#x7684;&#xFF09;&#x5B57;&#x5178;.</li>
<li><code>strict (bool)</code> &#x2013; &#x4E25;&#x683C;&#x7684;&#x5F3A;&#x5236; <code>state_dict</code> &#x5C5E;&#x6027;&#x4E2D;&#x7684; key &#x4E0E;&#x8BE5;&#x6A21;&#x5757;&#x7684;&#x51FD;&#x6570; <code>state_dict()</code> &#x8FD4;&#x56DE;&#x7684; keys &#x76F8;&#x5339;&#x914D;.</li>
</ul>
<pre><code class="lang-py">modules()
</code></pre>
<p>&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x8986;&#x76D6;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E2D;&#x6240;&#x6709;&#x6A21;&#x5757;&#x7684; iterator&#xFF08;&#x8FED;&#x4EE3;&#x5668;&#xFF09;.</p>
<p>Yields: <code>Module</code> &#x2013; &#x7F51;&#x7EDC;&#x4E2D;&#x7684;&#x4E00;&#x4E2A;&#x6A21;&#x5757;</p>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x91CD;&#x590D;&#x7684;&#x6A21;&#x5757;&#x53EA;&#x8FD4;&#x56DE;&#x4E00;&#x6B21;. &#x5728;&#x4E0B;&#x9762;&#x7684;&#x4F8B;&#x5B50;&#x4E2D;, <code>1</code> &#x53EA;&#x4F1A;&#x88AB;&#x8FD4;&#x56DE;&#x4E00;&#x6B21;. example, <code>l</code> will be returned only once.</p>
<pre><code class="lang-py">&gt;&gt;&gt; l = nn.Linear(2, 2)
&gt;&gt;&gt; net = nn.Sequential(l, l)
&gt;&gt;&gt; for idx, m in enumerate(net.modules()):
&gt;&gt;&gt;     print(idx, &apos;-&gt;&apos;, m)
0 -&gt; Sequential (
 (0): Linear (2 -&gt; 2)
 (1): Linear (2 -&gt; 2)
)
1 -&gt; Linear (2 -&gt; 2)
</code></pre>
<pre><code class="lang-py">named_children()
</code></pre>
<p>&#x8FD4;&#x56DE;&#x4E00;&#x4E2A; iterator&#xFF08;&#x8FED;&#x4EE3;&#x5668;&#xFF09;, &#x800C;&#x4E0D;&#x662F;&#x6700;&#x63A5;&#x8FD1;&#x7684;&#x5B50;&#x6A21;&#x5757;, &#x4EA7;&#x751F;&#x6A21;&#x5757;&#x7684; name &#x4EE5;&#x53CA;&#x6A21;&#x5757;&#x672C;&#x8EAB;.</p>
<p>Yields: <code>(string, Module)</code> &#x2013; &#x5305;&#x542B;&#x540D;&#x79F0;&#x548C;&#x5B50;&#x6A21;&#x5757;&#x7684; Tuple&#xFF08;&#x5143;&#x7EC4;&#xFF09;</p>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> name, module <span class="hljs-keyword">in</span> model.named_children():
<span class="hljs-meta">&gt;&gt;&gt; </span>    <span class="hljs-keyword">if</span> name <span class="hljs-keyword">in</span> [<span class="hljs-string">&apos;conv4&apos;</span>, <span class="hljs-string">&apos;conv5&apos;</span>]:
<span class="hljs-meta">&gt;&gt;&gt; </span>        print(module)
</code></pre>
<pre><code class="lang-py">named_modules(memo=<span class="hljs-keyword">None</span>, prefix=<span class="hljs-string">&apos;&apos;</span>)
</code></pre>
<p>&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E2D;&#x6240;&#x6709;&#x6A21;&#x5757;&#x7684; iterator&#xFF08;&#x8FED;&#x4EE3;&#x5668;&#xFF09;, &#x4EA7;&#x751F;&#x6A21;&#x5757;&#x7684; name &#x4EE5;&#x53CA;&#x6A21;&#x5757;&#x672C;&#x8EAB;.</p>
<p>Yields: <code>(string, Module)</code> &#x2013; &#x540D;&#x5B57;&#x548C;&#x6A21;&#x5757;&#x7684; Tuple&#xFF08;&#x5143;&#x7EC4;&#xFF09;</p>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x91CD;&#x590D;&#x7684;&#x6A21;&#x5757;&#x53EA;&#x8FD4;&#x56DE;&#x4E00;&#x6B21;. &#x5728;&#x4E0B;&#x9762;&#x7684;&#x4F8B;&#x5B50;&#x4E2D;, <code>1</code> &#x53EA;&#x4F1A;&#x88AB;&#x8FD4;&#x56DE;&#x4E00;&#x6B21;.</p>
<pre><code class="lang-py">&gt;&gt;&gt; l = nn.Linear(2, 2)
&gt;&gt;&gt; net = nn.Sequential(l, l)
&gt;&gt;&gt; for idx, m in enumerate(net.named_modules()):
&gt;&gt;&gt;     print(idx, &apos;-&gt;&apos;, m)
0 -&gt; (&apos;&apos;, Sequential (
 (0): Linear (2 -&gt; 2)
 (1): Linear (2 -&gt; 2)
))
1 -&gt; (&apos;0&apos;, Linear (2 -&gt; 2))
</code></pre>
<pre><code class="lang-py">named_parameters(memo=<span class="hljs-keyword">None</span>, prefix=<span class="hljs-string">&apos;&apos;</span>)
</code></pre>
<p>&#x8FD4;&#x56DE;&#x6A21;&#x5757;&#x53C2;&#x6570;&#x7684;&#x8FED;&#x4EE3;&#x5668;, &#x4EA7;&#x751F;&#x53C2;&#x6570;&#x7684;&#x540D;&#x79F0;&#x4EE5;&#x53CA;&#x53C2;&#x6570;&#x672C;&#x8EAB;</p>
<p>Yields: <code>(string, Parameter)</code> &#x2013; Tuple &#x5305;&#x542B;&#x540D;&#x79F0;&#x5F88;&#x53C2;&#x6570;&#x7684; Tuple&#xFF08;&#x5143;&#x7EC4;&#xFF09;</p>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> name, param <span class="hljs-keyword">in</span> self.named_parameters():
<span class="hljs-meta">&gt;&gt;&gt; </span>   <span class="hljs-keyword">if</span> name <span class="hljs-keyword">in</span> [<span class="hljs-string">&apos;bias&apos;</span>]:
<span class="hljs-meta">&gt;&gt;&gt; </span>       print(param.size())
</code></pre>
<pre><code class="lang-py">parameters()
</code></pre>
<p>&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x6A21;&#x5757;&#x53C2;&#x6570;&#x7684;&#x8FED;&#x4EE3;&#x5668;.</p>
<p>&#x8FD9;&#x901A;&#x5E38;&#x4F20;&#x9012;&#x7ED9;&#x4F18;&#x5316;&#x5668;.</p>
<p>Yields: <code>Parameter</code> &#x2013; &#x6A21;&#x578B;&#x53C2;&#x6570;</p>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py">&gt;&gt;&gt; for param in model.parameters():
&gt;&gt;&gt;     print(type(param.data), param.size())
&lt;class &apos;torch.FloatTensor&apos;&gt; (20L,)
&lt;class &apos;torch.FloatTensor&apos;&gt; (20L, 1L, 5L, 5L)
</code></pre>
<pre><code class="lang-py">register_backward_hook(hook)
</code></pre>
<p>&#x5728;&#x6A21;&#x5757;&#x4E0A;&#x6CE8;&#x518C;&#x4E00;&#x4E2A; backward hook&#xFF08;&#x53CD;&#x5411;&#x94A9;&#x5B50;&#xFF09;.</p>
<p>&#x6BCF;&#x6B21;&#x8BA1;&#x7B97;&#x5173;&#x4E8E;&#x6A21;&#x5757;&#x8F93;&#x5165;&#x7684;&#x68AF;&#x5EA6;&#x65F6;, &#x90FD;&#x4F1A;&#x8C03;&#x7528;&#x8BE5;&#x94A9;&#x5B50;. &#x94A9;&#x5B50;&#x5E94;&#x8BE5;&#x6709;&#x4EE5;&#x4E0B;&#x7ED3;&#x6784;:</p>
<pre><code class="lang-py">hook(module, grad_input, grad_output) -&gt; Tensor or None
</code></pre>
<p>&#x5982;&#x679C; module &#x6709;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x6216;&#x8F93;&#x51FA;&#x7684;&#x8BDD;, &#x90A3;&#x4E48; <code>grad_input</code> &#x548C; <code>grad_output</code> &#x5C06;&#x4F1A;&#x662F;&#x4E2A; tuple. hook &#x4E0D;&#x5E94;&#x8BE5;&#x4FEE;&#x6539;&#x5B83;&#x7684;&#x53C2;&#x6570;, &#x4F46;&#x662F;&#x5B83;&#x53EF;&#x4EE5;&#x9009;&#x62E9;&#x6027;&#x5730;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x5173;&#x4E8E;&#x8F93;&#x5165;&#x7684;&#x68AF;&#x5EA6;, &#x8FD9;&#x4E2A;&#x8FD4;&#x56DE;&#x7684;&#x68AF;&#x5EA6;&#x5728;&#x540E;&#x7EED;&#x7684;&#x8BA1;&#x7B97;&#x4E2D;&#x4F1A;&#x66FF;&#x4EE3; <code>grad_input</code>.</p>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;&#x901A;&#x8FC7;&#x8C03;&#x7528; <code>handle.remove()</code> &#x65B9;&#x6CD5;&#x53EF;&#x4EE5;&#x5220;&#x9664;&#x6DFB;&#x52A0;&#x94A9;&#x5B50;&#x7684;&#x53E5;&#x67C4; <code>handle.remove()</code></p>
<p>&#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;<code>torch.utils.hooks.RemovableHandle</code></p>
<pre><code class="lang-py">register_buffer(name, tensor)
</code></pre>
<p>&#x7ED9;&#x6A21;&#x5757;&#x6DFB;&#x52A0;&#x4E00;&#x4E2A;&#x6301;&#x4E45;&#x5316;&#x7684; buffer.</p>
<p>&#x6301;&#x4E45;&#x5316;&#x7684; buffer &#x901A;&#x5E38;&#x88AB;&#x7528;&#x5728;&#x8FD9;&#x4E48;&#x4E00;&#x79CD;&#x60C5;&#x51B5;: &#x6211;&#x4EEC;&#x9700;&#x8981;&#x4FDD;&#x5B58;&#x4E00;&#x4E2A;&#x72B6;&#x6001;, &#x4F46;&#x662F;&#x8FD9;&#x4E2A;&#x72B6;&#x6001;&#x4E0D;&#x80FD;&#x770B;&#x4F5C;&#x6210;&#x4E3A;&#x6A21;&#x578B;&#x53C2;&#x6570;. &#x4F8B;&#x5982;: BatchNorm &#x7684; <code>running_mean</code> &#x4E0D;&#x662F;&#x4E00;&#x4E2A; parameter, &#x4F46;&#x662F;&#x5B83;&#x4E5F;&#x662F;&#x9700;&#x8981;&#x4FDD;&#x5B58;&#x7684;&#x72B6;&#x6001;&#x4E4B;&#x4E00;.</p>
<p>Buffers &#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x6307;&#x5B9A;&#x7684; name &#x4F5C;&#x4E3A;&#x5C5E;&#x6027;&#x8BBF;&#x95EE;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>name (string)</code> &#x2013; buffer &#x7684;&#x540D;&#x79F0;. &#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x6307;&#x5B9A;&#x7684; name &#x4ECE;&#x8BE5;&#x6A21;&#x5757;&#x8BBF;&#x95EE; buffer</li>
<li><code>tensor (Tensor)</code> &#x2013; &#x88AB;&#x6CE8;&#x518C;&#x7684; buffer.</li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>self.register_buffer(<span class="hljs-string">&apos;running_mean&apos;</span>, torch.zeros(num_features))
</code></pre>
<pre><code class="lang-py">register_forward_hook(hook)
</code></pre>
<p>&#x5728;&#x6A21;&#x5757;&#x4E0A;&#x6CE8;&#x518C;&#x4E00;&#x4E2A; forward hook&#xFF08;&#x524D;&#x5411;&#x94A9;&#x5B50;&#xFF09;.</p>
<p>&#x6BCF;&#x4E00;&#x6B21; <code>forward()</code> &#x51FD;&#x6570;&#x8BA1;&#x7B97;&#x51FA;&#x4E00;&#x4E2A;&#x8F93;&#x51FA;&#x540E;, &#x8BE5;&#x94A9;&#x5B50;&#x5C06;&#x4F1A;&#x88AB;&#x8C03;&#x7528;. &#x5B83;&#x5E94;&#x8BE5;&#x5177;&#x6709;&#x4EE5;&#x4E0B;&#x7ED3;&#x6784;</p>
<pre><code class="lang-py">hook(module, input, output) -&gt; None
</code></pre>
<p>&#x8BE5;&#x94A9;&#x5B50;&#x5E94;&#x8BE5;&#x4E0D;&#x4F1A;&#x4FEE;&#x6539;&#x8F93;&#x5165;&#x6216;&#x8F93;&#x51FA;.</p>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;&#x901A;&#x8FC7;&#x8C03;&#x7528; <code>handle.remove()</code> &#x65B9;&#x6CD5;&#x53EF;&#x4EE5;&#x5220;&#x9664;&#x6DFB;&#x52A0;&#x94A9;&#x5B50;&#x7684;&#x53E5;&#x67C4;</p>
<p>&#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;<code>torch.utils.hooks.RemovableHandle</code></p>
<pre><code class="lang-py">register_forward_pre_hook(hook)
</code></pre>
<p>&#x5728;&#x6A21;&#x5757;&#x4E0A;&#x6CE8;&#x518C;&#x4E00;&#x4E2A;&#x9884;&#x524D;&#x5411;&#x94A9;&#x5B50;.</p>
<p>&#x6BCF;&#x4E00;&#x6B21;&#x5728;&#x8C03;&#x7528; <code>forward()</code> &#x51FD;&#x6570;&#x524D;&#x90FD;&#x4F1A;&#x8C03;&#x7528;&#x8BE5;&#x94A9;&#x5B50;. &#x5B83;&#x5E94;&#x8BE5;&#x6709;&#x4EE5;&#x4E0B;&#x7ED3;&#x6784;:</p>
<pre><code class="lang-py">hook(module, input) -&gt; None
</code></pre>
<p>&#x8BE5;&#x94A9;&#x5B50;&#x4E0D;&#x5E94;&#x8BE5;&#x4FEE;&#x6539;&#x8F93;&#x5165;.</p>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;&#x901A;&#x8FC7;&#x8C03;&#x7528; <code>handle.remove()</code> &#x65B9;&#x6CD5;&#x53EF;&#x4EE5;&#x5220;&#x9664;&#x6DFB;&#x52A0;&#x94A9;&#x5B50;&#x7684;&#x53E5;&#x67C4; <code>handle.remove()</code></p>
<p>&#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;<code>torch.utils.hooks.RemovableHandle</code></p>
<pre><code class="lang-py">register_parameter(name, param)
</code></pre>
<p>&#x6DFB;&#x52A0;&#x4E00;&#x4E2A;&#x53C2;&#x6570;&#x5230;&#x6A21;&#x5757;&#x4E2D;.</p>
<p>&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x6307;&#x5B9A;&#x7684; name &#x5C5E;&#x6027;&#x6765;&#x8BBF;&#x95EE;&#x53C2;&#x6570;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>name (string)</code> &#x2013; &#x53C2;&#x6570;&#x540D;. &#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x6307;&#x5B9A;&#x7684; name &#x6765;&#x4ECE;&#x8BE5;&#x6A21;&#x5757;&#x4E2D;&#x8BBF;&#x95EE;&#x53C2;&#x6570;</li>
<li><code>parameter (Parameter)</code> &#x2013; &#x8981;&#x88AB;&#x6DFB;&#x52A0;&#x5230;&#x6A21;&#x5757;&#x7684;&#x53C2;&#x6570;.</li>
</ul>
<pre><code class="lang-py">state_dict(destination=<span class="hljs-keyword">None</span>, prefix=<span class="hljs-string">&apos;&apos;</span>, keep_vars=<span class="hljs-keyword">False</span>)
</code></pre>
<p>&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x5B57;&#x5178;, &#x5B83;&#x5305;&#x542B;&#x6574;&#x4E2A;&#x6A21;&#x5757;&#x7684;&#x72B6;&#x6001;.</p>
<p>&#x5305;&#x62EC;&#x53C2;&#x6570;&#x548C;&#x6301;&#x4E45;&#x5316;&#x7684;&#x7F13;&#x51B2;&#x533A; (&#x4F8B;&#x5982;. &#x8FD0;&#x884C;&#x4E2D;&#x7684;&#x5E73;&#x5747;&#x503C;). Keys &#x662F;&#x4E0E;&#x4E4B;&#x5BF9;&#x5E94;&#x7684;&#x53C2;&#x6570;&#x548C;&#x7F13;&#x51B2;&#x533A;&#x7684; name.</p>
<p>&#x5F53; keep_vars &#x4E3A; <code>True</code> &#x65F6;, &#x5B83;&#x4E3A;&#x6BCF;&#x4E00;&#x4E2A;&#x53C2;&#x6570;&#xFF08;&#x800C;&#x4E0D;&#x662F;&#x4E00;&#x4E2A;&#x5F20;&#x91CF;&#xFF09;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A; Variable.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>destination (dict, &#x53EF;&#x9009;)</code> &#x2013; &#x5982;&#x679C;&#x4E0D;&#x662F; None, &#x8BE5;&#x8FD4;&#x56DE;&#x7684;&#x5B57;&#x5178;&#x5E94;&#x8BE5;&#x88AB;&#x5B58;&#x50A8;&#x5230; destination &#x4E2D;. Default: None</li>
<li><code>prefix (string, &#x53EF;&#x9009;)</code> &#x2013; &#x5411;&#x7ED3;&#x679C;&#x5B57;&#x5178;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x53C2;&#x6570;&#x548C;&#x7F13;&#x51B2;&#x533A;&#x7684; key&#xFF08;&#x540D;&#x79F0;&#xFF09;&#x6DFB;&#x52A0;&#x4E00;&#x4E2A;&#x524D;&#x7F00;. Default: &#x2018;&#x2019;</li>
<li><code>keep_vars (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x5982;&#x679C;&#x4E3A; <code>True</code>, &#x4E3A;&#x6BCF;&#x4E00;&#x4E2A;&#x53C2;&#x6570;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A; Variable. &#x5982;&#x679C;&#x4E3A; <code>False</code>, &#x4E3A;&#x6BCF;&#x4E00;&#x4E2A;&#x53C2;&#x6570;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A; Tensor. Default: <code>False</code></li>
</ul>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;&#x5305;&#x542B;&#x6A21;&#x5757;&#x6574;&#x4F53;&#x72B6;&#x6001;&#x7684;&#x5B57;&#x5178;</p>
<p>&#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;<code>dict</code></p>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>module.state_dict().keys()
[<span class="hljs-string">&apos;bias&apos;</span>, <span class="hljs-string">&apos;weight&apos;</span>]
</code></pre>
<pre><code class="lang-py">train(mode=<span class="hljs-keyword">True</span>)
</code></pre>
<p>&#x8BBE;&#x7F6E;&#x6A21;&#x5757;&#x4E3A;&#x8BAD;&#x7EC3;&#x6A21;&#x5F0F;.</p>
<p>&#x8FD9;&#x53EA;&#x5BF9;&#x8BF8;&#x5982; Dropout &#x6216; BatchNorm &#x7B49;&#x6A21;&#x5757;&#x65F6;&#x624D;&#x4F1A;&#x6709;&#x5F71;&#x54CD;.</p>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;<code>self</code></p>
<p>&#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;<code>Module</code></p>
<pre><code class="lang-py">type(dst_type)
</code></pre>
<p>&#x8F6C;&#x6362;&#x6240;&#x6709;&#x53C2;&#x6570;&#x548C;&#x7F13;&#x51B2;&#x533A;&#x4E3A; dst_type.</p>
<p>&#x53C2;&#x6570;&#xFF1A;<code>dst_type (type &#x6216; string)</code> &#x2013; &#x7406;&#x60F3;&#x7684;&#x7C7B;&#x578B;</p>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;<code>self</code></p>
<p>&#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A;<code>Module</code></p>
<pre><code class="lang-py">zero_grad()
</code></pre>
<p>&#x5C06;&#x6240;&#x6709;&#x6A21;&#x578B;&#x53C2;&#x6570;&#x7684;&#x68AF;&#x5EA6;&#x8BBE;&#x7F6E;&#x4E3A;&#x96F6;.</p>
<h3 id="sequential">Sequential</h3>
<pre><code class="lang-py">class torch.nn.Sequential(*args)
</code></pre>
<p>&#x4E00;&#x4E2A;&#x987A;&#x5E8F;&#x7684;&#x5BB9;&#x5668;. &#x6A21;&#x5757;&#x5C06;&#x6309;&#x7167;&#x5B83;&#x4EEC;&#x5728;&#x6784;&#x9020;&#x51FD;&#x6570;&#x4E2D;&#x4F20;&#x9012;&#x7684;&#x987A;&#x5E8F;&#x6DFB;&#x52A0;&#x5230;&#x5B83;. &#x6216;&#x8005;, &#x4E5F;&#x53EF;&#x4EE5;&#x4F20;&#x5165;&#x6A21;&#x5757;&#x7684;&#x6709;&#x5E8F;&#x5B57;&#x5178;.</p>
<p>&#x4E3A;&#x4E86;&#x66F4;&#x5BB9;&#x6613;&#x7406;&#x89E3;, &#x5217;&#x4E3E;&#x5C0F;&#x4F8B;&#x6765;&#x8BF4;&#x660E;</p>
<pre><code class="lang-py"><span class="hljs-comment"># &#x4F7F;&#x7528; Sequential &#x7684;&#x4F8B;&#x5B50;</span>
model = nn.Sequential(
          nn.Conv2d(<span class="hljs-number">1</span>,<span class="hljs-number">20</span>,<span class="hljs-number">5</span>),
          nn.ReLU(),
          nn.Conv2d(<span class="hljs-number">20</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>),
          nn.ReLU()
        )

<span class="hljs-comment"># &#x4E0E; OrderedDict &#x4E00;&#x8D77;&#x4F7F;&#x7528; Sequential &#x7684;&#x4F8B;&#x5B50;</span>
model = nn.Sequential(OrderedDict([
          (<span class="hljs-string">&apos;conv1&apos;</span>, nn.Conv2d(<span class="hljs-number">1</span>,<span class="hljs-number">20</span>,<span class="hljs-number">5</span>)),
          (<span class="hljs-string">&apos;relu1&apos;</span>, nn.ReLU()),
          (<span class="hljs-string">&apos;conv2&apos;</span>, nn.Conv2d(<span class="hljs-number">20</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>)),
          (<span class="hljs-string">&apos;relu2&apos;</span>, nn.ReLU())
        ]))
</code></pre>
<h3 id="modulelist">ModuleList</h3>
<pre><code class="lang-py">class torch.nn.ModuleList(modules=None)
</code></pre>
<p>&#x5C06;&#x5B50;&#x6A21;&#x5757;&#x653E;&#x5165;&#x4E00;&#x4E2A; list &#x4E2D;.</p>
<p>ModuleList &#x53EF;&#x4EE5;&#x50CF;&#x666E;&#x901A;&#x7684; Python list &#x4E00;&#x6837;&#x88AB;&#x7D22;&#x5F15;, &#x4F46;&#x662F;&#x5B83;&#x5305;&#x542B;&#x7684;&#x6A21;&#x5757;&#x5DF2;&#x7ECF;&#x88AB;&#x6B63;&#x786E;&#x7684;&#x6CE8;&#x518C;&#x4E86;, &#x5E76;&#x4E14;&#x6240;&#x6709;&#x7684; Module &#x65B9;&#x6CD5;&#x90FD;&#x662F;&#x53EF;&#x89C1;&#x7684;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;<code>modules (list, &#x53EF;&#x9009;)</code> &#x2013; &#x8981;&#x6DFB;&#x52A0;&#x7684;&#x6A21;&#x5757;&#x5217;&#x8868;</p>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyModule</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super(MyModule, self).__init__()
        self.linears = nn.ModuleList([nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>)])

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        <span class="hljs-comment"># ModuleList can act as an iterable, or be indexed using ints</span>
        <span class="hljs-keyword">for</span> i, l <span class="hljs-keyword">in</span> enumerate(self.linears):
            x = self.linears[i // <span class="hljs-number">2</span>](x) + l(x)
        <span class="hljs-keyword">return</span> x
</code></pre>
<pre><code class="lang-py">append(module)
</code></pre>
<p>&#x6DFB;&#x52A0;&#x4E00;&#x4E2A;&#x6307;&#x5B9A;&#x7684;&#x6A21;&#x5757;&#x5230; list &#x5C3E;&#x90E8;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;<code>module (nn.Module)</code> &#x2013; &#x8981;&#x88AB;&#x6DFB;&#x52A0;&#x7684;&#x6A21;&#x5757;</p>
<pre><code class="lang-py">extend(modules)
</code></pre>
<p>&#x5728;&#x6700;&#x540E;&#x6DFB;&#x52A0; Python list &#x4E2D;&#x7684;&#x6A21;&#x5757;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;<code>modules (list)</code> &#x2013; &#x8981;&#x88AB;&#x6DFB;&#x52A0;&#x7684;&#x6A21;&#x5757;&#x5217;&#x8868;</p>
<h3 id="parameterlist">ParameterList</h3>
<pre><code class="lang-py">class torch.nn.ParameterList(parameters=None)
</code></pre>
<p>&#x4FDD;&#x5B58; list &#x4E2D;&#x7684; parameter.</p>
<p>ParameterList &#x53EF;&#x4EE5;&#x50CF;&#x666E;&#x901A;&#x7684; Python list &#x90A3;&#x6837;&#x88AB;&#x7D22;&#x5F15;, &#x4F46;&#x662F;&#x5B83;&#x6240;&#x5305;&#x542B;&#x7684;&#x53C2;&#x6570;&#x88AB;&#x6B63;&#x786E;&#x7684;&#x6CE8;&#x518C;&#x4E86;, &#x5E76;&#x4E14;&#x6240;&#x6709;&#x7684; Module &#x65B9;&#x6CD5;&#x90FD;&#x53EF;&#x89C1;&#x7684;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;<code>modules (list, &#x53EF;&#x9009;)</code> &#x2013; &#x8981;&#x88AB;&#x6DFB;&#x52A0;&#x7684; <code>Parameter</code> &#x5217;&#x8868;</p>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyModule</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super(MyModule, self).__init__()
        self.params = nn.ParameterList([nn.Parameter(torch.randn(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>)) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>)])

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        <span class="hljs-comment"># ModuleList &#x53EF;&#x4EE5;&#x5145;&#x5F53; iterable&#xFF08;&#x8FED;&#x4EE3;&#x5668;&#xFF09;, &#x6216;&#x8005;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;&#x6574;&#x6570;&#x8FDB;&#x884C;&#x7D22;&#x5F15;</span>
        <span class="hljs-keyword">for</span> i, p <span class="hljs-keyword">in</span> enumerate(self.params):
            x = self.params[i // <span class="hljs-number">2</span>].mm(x) + p.mm(x)
        <span class="hljs-keyword">return</span> x
</code></pre>
<pre><code class="lang-py">append(parameter)
</code></pre>
<p>&#x6DFB;&#x52A0;&#x4E00;&#x4E2A;&#x6307;&#x5B9A;&#x7684;&#x53C2;&#x6570;&#x5230; list &#x5C3E;&#x90E8;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;<code>parameter (nn.Parameter)</code> &#x2013; parameter to append</p>
<pre><code class="lang-py">extend(parameters)
</code></pre>
<p>&#x5728;&#x6700;&#x540E;&#x6DFB;&#x52A0; Python list &#x4E2D;&#x7684;&#x53C2;&#x6570;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;<code>parameters (list)</code> &#x2013; list of parameters to append</p>
<h2 id="convolution-layers-&#x5377;&#x79EF;&#x5C42;">Convolution Layers (&#x5377;&#x79EF;&#x5C42;)</h2>
<h3 id="conv1d">Conv1d</h3>
<pre><code class="lang-py">class torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)
</code></pre>
<p>&#x4E00;&#x7EF4;&#x5377;&#x79EF;&#x5C42; &#x8F93;&#x5165;&#x77E9;&#x9635;&#x7684;&#x7EF4;&#x5EA6;&#x4E3A; <img src="img/tex-198b2086ddb5510d9fc69c433c3ee55d.gif" alt="(N, C_{in}, L)">, &#x8F93;&#x51FA;&#x77E9;&#x9635;&#x7EF4;&#x5EA6;&#x4E3A; <img src="img/tex-bb2bc07c1c0ec52a2e964a60175aac05.gif" alt="(N, C_{out}, L_{out})">. &#x5176;&#x4E2D;N&#x4E3A;&#x8F93;&#x5165;&#x6570;&#x91CF;, C&#x4E3A;&#x6BCF;&#x4E2A;&#x8F93;&#x5165;&#x6837;&#x672C;&#x7684;&#x901A;&#x9053;&#x6570;&#x91CF;, L&#x4E3A;&#x6837;&#x672C;&#x4E2D;&#x4E00;&#x4E2A;&#x901A;&#x9053;&#x4E0B;&#x7684;&#x6570;&#x636E;&#x7684;&#x957F;&#x5EA6;. &#x7B97;&#x6CD5;&#x5982;&#x4E0B;:</p>
<p><img src="img/tex-b482ae261c2a6c7f51be7da721fe7e54.gif" alt="\begin{array}{ll} out(N_i, C_{out_j}) = bias(C_{out_j}) + \sum_{k=0}^{C_{in}-1} weight(C_{out_j}, k) \star input(N_i, k) \end{array}"></p>
<p><img src="img/tex-4b4efc2fbe82a047fc08c83ea081f1d9.gif" alt="\star"> &#x662F;&#x4E92;&#x76F8;&#x5173;&#x8FD0;&#x7B97;&#x7B26;, &#x4E0A;&#x5F0F;&#x5E26; <img src="img/tex-4b4efc2fbe82a047fc08c83ea081f1d9.gif" alt="\star"> &#x9879;&#x4E3A;&#x5377;&#x79EF;&#x9879;.</p>
<p><code>stride</code> &#x8BA1;&#x7B97;&#x76F8;&#x5173;&#x7CFB;&#x6570;&#x7684;&#x6B65;&#x957F;, &#x53EF;&#x4EE5;&#x4E3A; tuple .<code>padding</code> &#x5904;&#x7406;&#x8FB9;&#x754C;&#x65F6;&#x5728;&#x4E24;&#x4FA7;&#x8865;0&#x6570;&#x91CF;<code>dilation</code> &#x91C7;&#x6837;&#x95F4;&#x9694;&#x6570;&#x91CF;. &#x5927;&#x4E8E;1&#x65F6;&#x4E3A;&#x975E;&#x81F4;&#x5BC6;&#x91C7;&#x6837;, &#x5982;&#x5BF9;(a,b,c,d,e)&#x91C7;&#x6837;&#x65F6;, &#x82E5;&#x6C60;&#x5316;&#x89C4;&#x6A21;&#x4E3A;2,</p>
<p>dilation &#x4E3A;1&#x65F6;, &#x4F7F;&#x7528; (a,b);(b,c)&#x2026; &#x8FDB;&#x884C;&#x6C60;&#x5316;, dilation &#x4E3A;1&#x65F6;, &#x4F7F;&#x7528; (a,c);(b,d)&#x2026; &#x8FDB;&#x884C;&#x6C60;&#x5316;. | <code>groups</code> &#x63A7;&#x5236;&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA;&#x4E4B;&#x95F4;&#x7684;&#x8FDE;&#x63A5;, group=1, &#x8F93;&#x51FA;&#x662F;&#x6240;&#x6709;&#x8F93;&#x5165;&#x7684;&#x5377;&#x79EF;&#xFF1B;group=2, &#x6B64;&#x65F6;&#x76F8;&#x5F53;&#x4E8E; &#x6709;&#x5E76;&#x6392;&#x7684;&#x4E24;&#x4E2A;&#x5377;&#x57FA;&#x5C42;, &#x6BCF;&#x4E2A;&#x5377;&#x79EF;&#x5C42;&#x53EA;&#x5728;&#x5BF9;&#x5E94;&#x7684;&#x8F93;&#x5165;&#x901A;&#x9053;&#x548C;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x4E4B;&#x95F4;&#x8BA1;&#x7B97;, &#x5E76;&#x4E14;&#x8F93;&#x51FA;&#x65F6;&#x4F1A;&#x5C06;&#x6240;&#x6709; &#x8F93;&#x51FA;&#x901A;&#x9053;&#x7B80;&#x5355;&#x7684;&#x9996;&#x5C3E;&#x76F8;&#x63A5;&#x4F5C;&#x4E3A;&#x7ED3;&#x679C;&#x8F93;&#x51FA;.</p>
<blockquote>
<p><code>in_channels</code> &#x548C; <code>out_channels</code>&#x90FD;&#x8981;&#x53EF;&#x4EE5;&#x88AB; groups &#x6574;&#x9664;.</p>
</blockquote>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x6570;&#x636E;&#x7684;&#x6700;&#x540E;&#x4E00;&#x5217;&#x53EF;&#x80FD;&#x4F1A;&#x56E0;&#x4E3A; kernal &#x5927;&#x5C0F;&#x8BBE;&#x5B9A;&#x4E0D;&#x5F53;&#x800C;&#x88AB;&#x4E22;&#x5F03;&#xFF08;&#x5927;&#x90E8;&#x5206;&#x53D1;&#x751F;&#x5728; kernal &#x5927;&#x5C0F;&#x4E0D;&#x80FD;&#x88AB;&#x8F93;&#x5165; &#x6574;&#x9664;&#x7684;&#x65F6;&#x5019;, &#x9002;&#x5F53;&#x7684; padding &#x53EF;&#x4EE5;&#x907F;&#x514D;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF09;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>in_channels (-)</code> &#x2013; &#x8F93;&#x5165;&#x4FE1;&#x53F7;&#x7684;&#x901A;&#x9053;&#x6570;.</li>
<li><code>out_channels (-)</code> &#x2013; &#x5377;&#x79EF;&#x540E;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x7684;&#x901A;&#x9053;&#x6570;.</li>
<li><code>kernel_size (-)</code> &#x2013; &#x5377;&#x79EF;&#x6838;&#x7684;&#x5F62;&#x72B6;.</li>
<li><code>stride (-)</code> &#x2013; &#x5377;&#x79EF;&#x6BCF;&#x6B21;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x4E3A;1.</li>
<li><code>padding (-)</code> &#x2013; &#x5904;&#x7406;&#x8FB9;&#x754C;&#x65F6;&#x586B;&#x5145;0&#x7684;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;0(&#x4E0D;&#x586B;&#x5145;).</li>
<li><code>dilation (-)</code> &#x2013; &#x91C7;&#x6837;&#x95F4;&#x9694;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;1, &#x65E0;&#x95F4;&#x9694;&#x91C7;&#x6837;.</li>
<li><code>groups (-)</code> &#x2013; &#x8F93;&#x5165;&#x4E0E;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x7684;&#x5206;&#x7EC4;&#x6570;&#x91CF;. &#x5F53;&#x4E0D;&#x4E3A;1&#x65F6;, &#x9ED8;&#x8BA4;&#x4E3A;1(&#x5168;&#x8FDE;&#x63A5;).</li>
<li><code>bias (-)</code> &#x2013; &#x4E3A; <code>True</code> &#x65F6;, &#x6DFB;&#x52A0;&#x504F;&#x7F6E;.</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165; Input: <img src="img/tex-1fe4e158f3308cc1b9e22afd6f08957d.gif" alt="(N, C_{in}, L_{in})"></li>
<li>&#x8F93;&#x51FA; Output: <img src="img/tex-bb2bc07c1c0ec52a2e964a60175aac05.gif" alt="(N, C_{out}, L_{out})"> &#x5176;&#x4E2D; <img src="img/tex-1ef60f8e6f123a4369ccdc2117bd3f0d.gif" alt="L_{out} = floor((L_{in} + 2 * padding - dilation * (kernel\_size - 1) - 1) / stride + 1)"></li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li><code>weight (Tensor)</code> &#x2013; &#x5377;&#x79EF;&#x7F51;&#x7EDC;&#x5C42;&#x95F4;&#x8FDE;&#x63A5;&#x7684;&#x6743;&#x91CD;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A; (out_channels, in_channels, kernel_size)</li>
<li><code>bias (Tensor)</code> &#x2013; &#x504F;&#x7F6E;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A; (out_channels)</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Conv1d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">50</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="conv2d">Conv2d</h3>
<pre><code class="lang-py">class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)
</code></pre>
<p>&#x4E8C;&#x7EF4;&#x5377;&#x79EF;&#x5C42; &#x8F93;&#x5165;&#x77E9;&#x9635;&#x7684;&#x7EF4;&#x5EA6;&#x4E3A; <img src="img/tex-120cc675d6ab67bb046f090d7be120a6.gif" alt="(N, C_{in}, H, W)"> , &#x8F93;&#x51FA;&#x77E9;&#x9635;&#x7EF4;&#x5EA6;&#x4E3A; <img src="img/tex-ba3afaecc84f511d8c24e8605d528d35.gif" alt="(N, C_{out}, H_{out}, W_{out})"> . &#x5176;&#x4E2D;N&#x4E3A;&#x8F93;&#x5165;&#x6570;&#x91CF;, C&#x4E3A;&#x6BCF;&#x4E2A;&#x8F93;&#x5165;&#x6837;&#x672C;&#x7684;&#x901A;&#x9053;&#x6570;&#x91CF;, H, W &#x5206;&#x522B;&#x4E3A;&#x6837;&#x672C;&#x4E2D;&#x4E00;&#x4E2A;&#x901A;&#x9053;&#x4E0B;&#x7684;&#x6570;&#x636E;&#x7684;&#x5F62;&#x72B6;. &#x7B97;&#x6CD5;&#x5982;&#x4E0B;:</p>
<p><img src="img/tex-b482ae261c2a6c7f51be7da721fe7e54.gif" alt="%\begin{array}{ll} out(N_i, C_{out_j}) = bias(C_{out_j}) + \sum_{ {k}=0}^{C_{in}-1} weight(C_{out_j}, k) \star input(N_i, k) \end{array}%"></p>
<p><img src="img/tex-4b4efc2fbe82a047fc08c83ea081f1d9.gif" alt="\star"> &#x662F;&#x4E92;&#x76F8;&#x5173;&#x8FD0;&#x7B97;&#x7B26;, &#x4E0A;&#x5F0F;&#x5E26;<code>*</code>&#x9879;&#x4E3A;&#x5377;&#x79EF;&#x9879;.</p>
<p><code>stride</code> &#x8BA1;&#x7B97;&#x76F8;&#x5173;&#x7CFB;&#x6570;&#x7684;&#x6B65;&#x957F;, &#x53EF;&#x4EE5;&#x4E3A; tuple .<code>padding</code> &#x5904;&#x7406;&#x8FB9;&#x754C;&#x65F6;&#x5728;&#x6BCF;&#x4E2A;&#x7EF4;&#x5EA6;&#x9996;&#x5C3E;&#x8865;0&#x6570;&#x91CF;.<code>dilation</code> &#x91C7;&#x6837;&#x95F4;&#x9694;&#x6570;&#x91CF;. &#x5927;&#x4E8E;1&#x65F6;&#x4E3A;&#x975E;&#x81F4;&#x5BC6;&#x91C7;&#x6837;.<code>groups</code> &#x63A7;&#x5236;&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA;&#x4E4B;&#x95F4;&#x7684;&#x8FDE;&#x63A5;, group=1, &#x8F93;&#x51FA;&#x662F;&#x6240;&#x6709;&#x8F93;&#x5165;&#x7684;&#x5377;&#x79EF;&#xFF1B; group=2, &#x6B64;&#x65F6;</p>
<p>&#x76F8;&#x5F53;&#x4E8E;&#x6709;&#x5E76;&#x6392;&#x7684;&#x4E24;&#x4E2A;&#x5377;&#x57FA;&#x5C42;, &#x6BCF;&#x4E2A;&#x5377;&#x79EF;&#x5C42;&#x53EA;&#x5728;&#x5BF9;&#x5E94;&#x7684;&#x8F93;&#x5165;&#x901A;&#x9053;&#x548C;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x4E4B;&#x95F4;&#x8BA1;&#x7B97;, &#x5E76;&#x4E14;&#x8F93;&#x51FA;&#x65F6;&#x4F1A;&#x5C06;&#x6240;&#x6709; &#x8F93;&#x51FA;&#x901A;&#x9053;&#x7B80;&#x5355;&#x7684;&#x9996;&#x5C3E;&#x76F8;&#x63A5;&#x4F5C;&#x4E3A;&#x7ED3;&#x679C;&#x8F93;&#x51FA;.</p>
<blockquote>
<p><code>in_channels</code> &#x548C; <code>out_channels</code>&#x90FD;&#x8981;&#x53EF;&#x4EE5;&#x88AB; groups &#x6574;&#x9664;.</p>
</blockquote>
<p><code>kernel_size</code>, <code>stride</code>, <code>padding</code>, <code>dilation</code> &#x53EF;&#x4EE5;&#x4E3A;:</p>
<blockquote>
<ul>
<li>&#x5355;&#x4E2A; <code>int</code> &#x503C; &#x2013; &#x5BBD;&#x548C;&#x9AD8;&#x5747;&#x88AB;&#x8BBE;&#x5B9A;&#x4E3A;&#x6B64;&#x503C;.</li>
<li>&#x7531;&#x4E24;&#x4E2A; <code>int</code> &#x7EC4;&#x6210;&#x7684; <code>tuple</code> &#x2013; &#x7B2C;&#x4E00;&#x4E2A; <code>int</code> &#x4E3A;&#x9AD8;, &#x7B2C;&#x4E8C;&#x4E2A; <code>int</code> &#x4E3A;&#x5BBD;.</li>
</ul>
</blockquote>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x6570;&#x636E;&#x7684;&#x6700;&#x540E;&#x4E00;&#x5217;&#x53EF;&#x80FD;&#x4F1A;&#x56E0;&#x4E3A; kernal &#x5927;&#x5C0F;&#x8BBE;&#x5B9A;&#x4E0D;&#x5F53;&#x800C;&#x88AB;&#x4E22;&#x5F03;&#xFF08;&#x5927;&#x90E8;&#x5206;&#x53D1;&#x751F;&#x5728; kernal &#x5927;&#x5C0F;&#x4E0D;&#x80FD;&#x88AB;&#x8F93;&#x5165; &#x6574;&#x9664;&#x7684;&#x65F6;&#x5019;, &#x9002;&#x5F53;&#x7684; padding &#x53EF;&#x4EE5;&#x907F;&#x514D;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF09;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>in_channels (-)</code> &#x2013; &#x8F93;&#x5165;&#x4FE1;&#x53F7;&#x7684;&#x901A;&#x9053;&#x6570;.</li>
<li><code>out_channels (-)</code> &#x2013; &#x5377;&#x79EF;&#x540E;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x7684;&#x901A;&#x9053;&#x6570;.</li>
<li><code>kernel_size (-)</code> &#x2013; &#x5377;&#x79EF;&#x6838;&#x7684;&#x5F62;&#x72B6;.</li>
<li><code>stride (-)</code> &#x2013; &#x5377;&#x79EF;&#x6BCF;&#x6B21;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x4E3A;1.</li>
<li><code>padding (-)</code> &#x2013; &#x5904;&#x7406;&#x8FB9;&#x754C;&#x65F6;&#x586B;&#x5145;0&#x7684;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;0(&#x4E0D;&#x586B;&#x5145;).</li>
<li><code>dilation (-)</code> &#x2013; &#x91C7;&#x6837;&#x95F4;&#x9694;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;1, &#x65E0;&#x95F4;&#x9694;&#x91C7;&#x6837;.</li>
<li><code>groups (-)</code> &#x2013; &#x8F93;&#x5165;&#x4E0E;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x7684;&#x5206;&#x7EC4;&#x6570;&#x91CF;. &#x5F53;&#x4E0D;&#x4E3A;1&#x65F6;, &#x9ED8;&#x8BA4;&#x4E3A;1(&#x5168;&#x8FDE;&#x63A5;).</li>
<li><code>bias (-)</code> &#x2013; &#x4E3A; <code>True</code> &#x65F6;, &#x6DFB;&#x52A0;&#x504F;&#x7F6E;.</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165; Input: <img src="img/tex-a821595925aa8f87a7488c9e2b28cbe7.gif" alt="(N, C_{in}, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA; Output: <img src="img/tex-ba3afaecc84f511d8c24e8605d528d35.gif" alt="(N, C_{out}, H_{out}, W_{out})"> &#x5176;&#x4E2D; <img src="img/tex-79b3618ba1cd1e8e6e665aae1b4fc446.gif" alt="H_{out} = floor((H_{in} + 2 * padding[0] - dilation[0] * (kernel\_size[0] - 1) - 1) / stride[0] + 1)"> <img src="img/tex-e9f44b9b5fc42bdb5991cfcd52e2dced.gif" alt="W_{out} = floor((W_{in} + 2 * padding[1] - dilation[1] * (kernel\_size[1] - 1) - 1) / stride[1] + 1)"></li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li><code>weight (Tensor)</code> &#x2013; &#x5377;&#x79EF;&#x7F51;&#x7EDC;&#x5C42;&#x95F4;&#x8FDE;&#x63A5;&#x7684;&#x6743;&#x91CD;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A; (out_channels, in_channels, kernel_size[0], kernel_size[1])</li>
<li><code>bias (Tensor)</code> &#x2013; &#x504F;&#x7F6E;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A; (out_channels)</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With square kernels and equal stride</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># non-square kernels and unequal stride and with padding</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">5</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">4</span>, <span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># non-square kernels and unequal stride and with padding and dilation</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">5</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">4</span>, <span class="hljs-number">2</span>), dilation=(<span class="hljs-number">3</span>, <span class="hljs-number">1</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">50</span>, <span class="hljs-number">100</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="conv3d">Conv3d</h3>
<pre><code class="lang-py">class torch.nn.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)
</code></pre>
<p>&#x4E09;&#x7EF4;&#x5377;&#x57FA;&#x5C42; &#x8F93;&#x5165;&#x77E9;&#x9635;&#x7684;&#x7EF4;&#x5EA6;&#x4E3A; <img src="img/tex-98729c804361218eea500df06cd60c8b.gif" alt="(N, C_{in}, D, H, W)">, &#x8F93;&#x51FA;&#x77E9;&#x9635;&#x7EF4;&#x5EA6;&#x4E3A;:<img src="img/tex-5b2f3f7fabcd6ee5b9f89543b54d71e2.gif" alt="(N, C_{out}, D_{out}, H_{out}, W_{out})">. &#x5176;&#x4E2D;N&#x4E3A;&#x8F93;&#x5165;&#x6570;&#x91CF;, C&#x4E3A;&#x6BCF;&#x4E2A;&#x8F93;&#x5165;&#x6837;&#x672C;&#x7684;&#x901A;&#x9053;&#x6570;&#x91CF;, D, H, W &#x5206;&#x522B;&#x4E3A;&#x6837;&#x672C;&#x4E2D;&#x4E00;&#x4E2A;&#x901A;&#x9053;&#x4E0B;&#x7684;&#x6570;&#x636E;&#x7684;&#x5F62;&#x72B6;. &#x7B97;&#x6CD5;&#x5982;&#x4E0B;:</p>
<p><img src="img/tex-b482ae261c2a6c7f51be7da721fe7e54.gif" alt="\begin{array}{ll} out(N_i, C_{out_j}) = bias(C_{out_j}) + \sum_{k=0}^{C_{in}-1} weight(C_{out_j}, k) \star input(N_i, k) \end{array}"></p>
<p><img src="img/tex-4b4efc2fbe82a047fc08c83ea081f1d9.gif" alt="\star"> &#x662F;&#x4E92;&#x76F8;&#x5173;&#x8FD0;&#x7B97;&#x7B26;, &#x4E0A;&#x5F0F;&#x5E26;<code>*</code>&#x9879;&#x4E3A;&#x5377;&#x79EF;&#x9879;.</p>
<p><code>stride</code> &#x8BA1;&#x7B97;&#x76F8;&#x5173;&#x7CFB;&#x6570;&#x7684;&#x6B65;&#x957F;, &#x53EF;&#x4EE5;&#x4E3A; tuple .<code>padding</code> &#x5904;&#x7406;&#x8FB9;&#x754C;&#x65F6;&#x5728;&#x6BCF;&#x4E2A;&#x7EF4;&#x5EA6;&#x9996;&#x5C3E;&#x8865;0&#x6570;&#x91CF;.<code>dilation</code> &#x91C7;&#x6837;&#x95F4;&#x9694;&#x6570;&#x91CF;. &#x5927;&#x4E8E;1&#x65F6;&#x4E3A;&#x975E;&#x81F4;&#x5BC6;&#x91C7;&#x6837;.<code>groups</code> &#x63A7;&#x5236;&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA;&#x4E4B;&#x95F4;&#x7684;&#x8FDE;&#x63A5;, group=1, &#x8F93;&#x51FA;&#x662F;&#x6240;&#x6709;&#x8F93;&#x5165;&#x7684;&#x5377;&#x79EF;&#xFF1B; group=2, &#x6B64;&#x65F6;</p>
<p>&#x76F8;&#x5F53;&#x4E8E;&#x6709;&#x5E76;&#x6392;&#x7684;&#x4E24;&#x4E2A;&#x5377;&#x57FA;&#x5C42;, &#x6BCF;&#x4E2A;&#x5377;&#x79EF;&#x5C42;&#x53EA;&#x5728;&#x5BF9;&#x5E94;&#x7684;&#x8F93;&#x5165;&#x901A;&#x9053;&#x548C;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x4E4B;&#x95F4;&#x8BA1;&#x7B97;, &#x5E76;&#x4E14;&#x8F93;&#x51FA;&#x65F6;&#x4F1A;&#x5C06;&#x6240;&#x6709; &#x8F93;&#x51FA;&#x901A;&#x9053;&#x7B80;&#x5355;&#x7684;&#x9996;&#x5C3E;&#x76F8;&#x63A5;&#x4F5C;&#x4E3A;&#x7ED3;&#x679C;&#x8F93;&#x51FA;.</p>
<blockquote>
<p><code>in_channels</code> &#x548C; <code>out_channels</code>&#x90FD;&#x8981;&#x53EF;&#x4EE5;&#x88AB; groups &#x6574;&#x9664;.</p>
</blockquote>
<p><code>kernel_size</code>, <code>stride</code>, <code>padding</code>, <code>dilation</code> &#x53EF;&#x4EE5;&#x4E3A;:</p>
<blockquote>
<ul>
<li>&#x5355;&#x4E2A; <code>int</code> &#x503C; &#x2013; &#x5BBD;&#x548C;&#x9AD8;&#x548C;&#x6DF1;&#x5EA6;&#x5747;&#x88AB;&#x8BBE;&#x5B9A;&#x4E3A;&#x6B64;&#x503C;.</li>
<li>&#x7531;&#x4E09;&#x4E2A; <code>int</code> &#x7EC4;&#x6210;&#x7684; <code>tuple</code> &#x2013; &#x7B2C;&#x4E00;&#x4E2A; <code>int</code> &#x4E3A;&#x6DF1;&#x5EA6;, &#x7B2C;&#x4E8C;&#x4E2A; <code>int</code> &#x4E3A;&#x9AD8;&#x5EA6;, &#x7B2C;&#x4E09;&#x4E2A; <code>int</code> &#x4E3A;&#x5BBD;&#x5EA6;.</li>
</ul>
</blockquote>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x6570;&#x636E;&#x7684;&#x6700;&#x540E;&#x4E00;&#x5217;&#x53EF;&#x80FD;&#x4F1A;&#x56E0;&#x4E3A; kernal &#x5927;&#x5C0F;&#x8BBE;&#x5B9A;&#x4E0D;&#x5F53;&#x800C;&#x88AB;&#x4E22;&#x5F03;&#xFF08;&#x5927;&#x90E8;&#x5206;&#x53D1;&#x751F;&#x5728; kernal &#x5927;&#x5C0F;&#x4E0D;&#x80FD;&#x88AB;&#x8F93;&#x5165; &#x6574;&#x9664;&#x7684;&#x65F6;&#x5019;, &#x9002;&#x5F53;&#x7684; padding &#x53EF;&#x4EE5;&#x907F;&#x514D;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF09;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>in_channels (-)</code> &#x2013; &#x8F93;&#x5165;&#x4FE1;&#x53F7;&#x7684;&#x901A;&#x9053;&#x6570;.</li>
<li><code>out_channels (-)</code> &#x2013; &#x5377;&#x79EF;&#x540E;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x7684;&#x901A;&#x9053;&#x6570;.</li>
<li><code>kernel_size (-)</code> &#x2013; &#x5377;&#x79EF;&#x6838;&#x7684;&#x5F62;&#x72B6;.</li>
<li><code>stride (-)</code> &#x2013; &#x5377;&#x79EF;&#x6BCF;&#x6B21;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x4E3A;1.</li>
<li><code>padding (-)</code> &#x2013; &#x5904;&#x7406;&#x8FB9;&#x754C;&#x65F6;&#x586B;&#x5145;0&#x7684;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;0(&#x4E0D;&#x586B;&#x5145;).</li>
<li><code>dilation (-)</code> &#x2013; &#x91C7;&#x6837;&#x95F4;&#x9694;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;1, &#x65E0;&#x95F4;&#x9694;&#x91C7;&#x6837;.</li>
<li><code>groups (-)</code> &#x2013; &#x8F93;&#x5165;&#x4E0E;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x7684;&#x5206;&#x7EC4;&#x6570;&#x91CF;. &#x5F53;&#x4E0D;&#x4E3A;1&#x65F6;, &#x9ED8;&#x8BA4;&#x4E3A;1(&#x5168;&#x8FDE;&#x63A5;).</li>
<li><code>bias (-)</code> &#x2013; &#x4E3A; <code>True</code> &#x65F6;, &#x6DFB;&#x52A0;&#x504F;&#x7F6E;.</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165; Input: <img src="img/tex-3284da09db0303b6608e4bc197b59361.gif" alt="(N, C_{in}, D_{in}, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA; Output: <img src="img/tex-5b2f3f7fabcd6ee5b9f89543b54d71e2.gif" alt="(N, C_{out}, D_{out}, H_{out}, W_{out})"> &#x5176;&#x4E2D; <img src="img/tex-ba168d43ee6e937903b387d0afce9a40.gif" alt="D_{out} = floor((D_{in} + 2 * padding[0] - dilation[0] * (kernel\_size[0] - 1) - 1) / stride[0] + 1)"> <img src="img/tex-89213fb2d0850f4cc41af72bae650bd0.gif" alt="H_{out} = floor((H_{in} + 2 * padding[1] - dilation[1] * (kernel\_size[1] - 1) - 1) / stride[1] + 1)"> <img src="img/tex-397d0048589e3a1a6644d6613e7d4722.gif" alt="W_{out} = floor((W_{in} + 2 * padding[2] - dilation[2] * (kernel\_size[2] - 1) - 1) / stride[2] + 1)"></li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li><code>weight (Tensor)</code> &#x2013; &#x5377;&#x79EF;&#x7F51;&#x7EDC;&#x5C42;&#x95F4;&#x8FDE;&#x63A5;&#x7684;&#x6743;&#x91CD;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A; (out_channels, in_channels, kernel_size[0], kernel_size[1], kernel_size[2])</li>
<li><code>bias (Tensor)</code> &#x2013; &#x504F;&#x7F6E;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A; (out_channels)</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With square kernels and equal stride</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Conv3d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># non-square kernels and unequal stride and with padding</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Conv3d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">2</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">4</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>, <span class="hljs-number">100</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="convtranspose1d">ConvTranspose1d</h3>
<pre><code class="lang-py">class torch.nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)
</code></pre>
<p>&#x4E00;&#x7EF4;&#x53CD;&#x5377;&#x79EF;&#x5C42; &#x53CD;&#x5377;&#x79EF;&#x5C42;&#x53EF;&#x4EE5;&#x7406;&#x89E3;&#x4E3A;&#x8F93;&#x5165;&#x7684;&#x6570;&#x636E;&#x548C;&#x5377;&#x79EF;&#x6838;&#x7684;&#x4F4D;&#x7F6E;&#x53CD;&#x8F6C;&#x7684;&#x5377;&#x79EF;&#x64CD;&#x4F5C;. &#x53CD;&#x5377;&#x79EF;&#x6709;&#x65F6;&#x5019;&#x4E5F;&#x4F1A;&#x88AB;&#x7FFB;&#x8BD1;&#x6210;&#x89E3;&#x5377;&#x79EF;.</p>
<p><code>stride</code> &#x8BA1;&#x7B97;&#x76F8;&#x5173;&#x7CFB;&#x6570;&#x7684;&#x6B65;&#x957F;.<code>padding</code> &#x5904;&#x7406;&#x8FB9;&#x754C;&#x65F6;&#x5728;&#x6BCF;&#x4E2A;&#x7EF4;&#x5EA6;&#x9996;&#x5C3E;&#x8865;0&#x6570;&#x91CF;.<code>output_padding</code> &#x8F93;&#x51FA;&#x65F6;&#x5019;&#x5728;&#x9996;&#x5C3E;&#x8865;0&#x7684;&#x6570;&#x91CF;. &#xFF08;&#x5377;&#x79EF;&#x65F6;, &#x5F62;&#x72B6;&#x4E0D;&#x540C;&#x7684;&#x8F93;&#x5165;&#x6570;&#x636E;</p>
<p>&#x5BF9;&#x76F8;&#x540C;&#x7684;&#x6838;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4EA7;&#x751F;&#x5F62;&#x72B6;&#x76F8;&#x540C;&#x7684;&#x7ED3;&#x679C;&#xFF1B;&#x53CD;&#x5377;&#x79EF;&#x65F6;, &#x540C;&#x4E00;&#x4E2A;&#x8F93;&#x5165;&#x5BF9;&#x76F8;&#x540C;&#x7684;&#x6838;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4EA7;&#x751F;&#x591A; &#x4E2A;&#x5F62;&#x72B6;&#x4E0D;&#x540C;&#x7684;&#x8F93;&#x51FA;, &#x800C;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x53EA;&#x80FD;&#x6709;&#x4E00;&#x4E2A;, &#x56E0;&#x6B64;&#x5FC5;&#x987B;&#x5BF9;&#x8F93;&#x51FA;&#x5F62;&#x72B6;&#x8FDB;&#x884C;&#x7EA6;&#x675F;&#xFF09;. | <code>dilation</code> &#x91C7;&#x6837;&#x95F4;&#x9694;&#x6570;&#x91CF;. &#x5927;&#x4E8E;1&#x65F6;&#x4E3A;&#x975E;&#x81F4;&#x5BC6;&#x91C7;&#x6837;. | <code>groups</code> &#x63A7;&#x5236;&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA;&#x4E4B;&#x95F4;&#x7684;&#x8FDE;&#x63A5;, group=1, &#x8F93;&#x51FA;&#x662F;&#x6240;&#x6709;&#x8F93;&#x5165;&#x7684;&#x5377;&#x79EF;&#xFF1B; group=2, &#x6B64;&#x65F6; &#x76F8;&#x5F53;&#x4E8E;&#x6709;&#x5E76;&#x6392;&#x7684;&#x4E24;&#x4E2A;&#x5377;&#x57FA;&#x5C42;, &#x6BCF;&#x4E2A;&#x5377;&#x79EF;&#x5C42;&#x53EA;&#x5728;&#x5BF9;&#x5E94;&#x7684;&#x8F93;&#x5165;&#x901A;&#x9053;&#x548C;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x4E4B;&#x95F4;&#x8BA1;&#x7B97;, &#x5E76;&#x4E14;&#x8F93;&#x51FA;&#x65F6;&#x4F1A;&#x5C06;&#x6240;&#x6709; &#x8F93;&#x51FA;&#x901A;&#x9053;&#x7B80;&#x5355;&#x7684;&#x9996;&#x5C3E;&#x76F8;&#x63A5;&#x4F5C;&#x4E3A;&#x7ED3;&#x679C;&#x8F93;&#x51FA;.</p>
<blockquote>
<p><code>in_channels</code> &#x548C; <code>out_channels</code>&#x90FD;&#x8981;&#x53EF;&#x4EE5;&#x88AB; groups &#x6574;&#x9664;.</p>
</blockquote>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x6570;&#x636E;&#x7684;&#x6700;&#x540E;&#x4E00;&#x5217;&#x53EF;&#x80FD;&#x4F1A;&#x56E0;&#x4E3A; kernal &#x5927;&#x5C0F;&#x8BBE;&#x5B9A;&#x4E0D;&#x5F53;&#x800C;&#x88AB;&#x4E22;&#x5F03;&#xFF08;&#x5927;&#x90E8;&#x5206;&#x53D1;&#x751F;&#x5728; kernal &#x5927;&#x5C0F;&#x4E0D;&#x80FD;&#x88AB;&#x8F93;&#x5165; &#x6574;&#x9664;&#x7684;&#x65F6;&#x5019;, &#x9002;&#x5F53;&#x7684; padding &#x53EF;&#x4EE5;&#x907F;&#x514D;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF09;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>in_channels (-)</code> &#x2013; &#x8F93;&#x5165;&#x4FE1;&#x53F7;&#x7684;&#x901A;&#x9053;&#x6570;.</li>
<li><code>out_channels (-)</code> &#x2013; &#x5377;&#x79EF;&#x540E;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x7684;&#x901A;&#x9053;&#x6570;.</li>
<li><code>kernel_size (-)</code> &#x2013; &#x5377;&#x79EF;&#x6838;&#x7684;&#x5F62;&#x72B6;.</li>
<li><code>stride (-)</code> &#x2013; &#x5377;&#x79EF;&#x6BCF;&#x6B21;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x4E3A;1.</li>
<li><code>padding (-)</code> &#x2013; &#x5904;&#x7406;&#x8FB9;&#x754C;&#x65F6;&#x586B;&#x5145;0&#x7684;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;0(&#x4E0D;&#x586B;&#x5145;).</li>
<li><code>output_padding (-)</code> &#x2013; &#x8F93;&#x51FA;&#x65F6;&#x5019;&#x5728;&#x9996;&#x5C3E;&#x8865;&#x503C;&#x7684;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;0. &#xFF08;&#x5377;&#x79EF;&#x65F6;, &#x5F62;&#x72B6;&#x4E0D;&#x540C;&#x7684;&#x8F93;&#x5165;&#x6570;&#x636E;</li>
<li><code>&#x540C;&#x4E00;&#x4E2A;&#x8F93;&#x5165;&#x5BF9;&#x76F8;&#x540C;&#x7684;&#x6838;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4EA7;&#x751F;&#x591A; (_&#x5BF9;&#x76F8;&#x540C;&#x7684;&#x6838;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4EA7;&#x751F;&#x5F62;&#x72B6;&#x76F8;&#x540C;&#x7684;&#x7ED3;&#x679C;&#xFF1B;&#x53CD;&#x5377;&#x79EF;&#x65F6;_,)</code> &#x2013;</li>
<li>&#x800C;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x53EA;&#x80FD;&#x6709;&#x4E00;&#x4E2A;, &#x56E0;&#x6B64;&#x5FC5;&#x987B;&#x5BF9;&#x8F93;&#x51FA;&#x5F62;&#x72B6;&#x8FDB;&#x884C;&#x7EA6;&#x675F;&#xFF09; (<em>&#x4E2A;&#x5F62;&#x72B6;&#x4E0D;&#x540C;&#x7684;&#x8F93;&#x51FA;</em>,) &#x2013;</li>
<li><code>groups (-)</code> &#x2013; &#x8F93;&#x5165;&#x4E0E;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x7684;&#x5206;&#x7EC4;&#x6570;&#x91CF;. &#x5F53;&#x4E0D;&#x4E3A;1&#x65F6;, &#x9ED8;&#x8BA4;&#x4E3A;1(&#x5168;&#x8FDE;&#x63A5;).</li>
<li><code>bias (-)</code> &#x2013; &#x4E3A; <code>True</code> &#x65F6;, &#x6DFB;&#x52A0;&#x504F;&#x7F6E;.</li>
<li><code>dilation (-)</code> &#x2013; &#x91C7;&#x6837;&#x95F4;&#x9694;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;1, &#x65E0;&#x95F4;&#x9694;&#x91C7;&#x6837;.</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165; Input: <img src="img/tex-1fe4e158f3308cc1b9e22afd6f08957d.gif" alt="(N, C_{in}, L_{in})"></li>
<li>&#x8F93;&#x51FA; Output: <img src="img/tex-bb2bc07c1c0ec52a2e964a60175aac05.gif" alt="(N, C_{out}, L_{out})"> &#x5176;&#x4E2D; <img src="img/tex-3358a4e917382beb03a6ef2132bb4018.gif" alt="L_{out} = (L_{in} - 1) * stride - 2 * padding + kernel\_size + output\_padding"></li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li><code>weight (Tensor)</code> &#x2013; &#x5377;&#x79EF;&#x7F51;&#x7EDC;&#x5C42;&#x95F4;&#x8FDE;&#x63A5;&#x7684;&#x6743;&#x91CD;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A;weight (Tensor): &#x5377;&#x79EF;&#x7F51;&#x7EDC;&#x5C42;&#x95F4;&#x8FDE;&#x63A5;&#x7684;&#x6743;&#x91CD;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A; (in_channels, out_channels, kernel_size[0], kernel_size[1])</li>
<li><code>bias (Tensor)</code> &#x2013; &#x504F;&#x7F6E;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A; (out_channels)</li>
</ul>
<h3 id="convtranspose2d">ConvTranspose2d</h3>
<pre><code class="lang-py">class torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)
</code></pre>
<p>&#x4E8C;&#x7EF4;&#x53CD;&#x5377;&#x79EF;&#x5C42; &#x53CD;&#x5377;&#x79EF;&#x5C42;&#x53EF;&#x4EE5;&#x7406;&#x89E3;&#x4E3A;&#x8F93;&#x5165;&#x7684;&#x6570;&#x636E;&#x548C;&#x5377;&#x79EF;&#x6838;&#x7684;&#x4F4D;&#x7F6E;&#x53CD;&#x8F6C;&#x7684;&#x5377;&#x79EF;&#x64CD;&#x4F5C;. &#x53CD;&#x5377;&#x79EF;&#x6709;&#x65F6;&#x5019;&#x4E5F;&#x4F1A;&#x88AB;&#x7FFB;&#x8BD1;&#x6210;&#x89E3;&#x5377;&#x79EF;.</p>
<p><code>stride</code> &#x8BA1;&#x7B97;&#x76F8;&#x5173;&#x7CFB;&#x6570;&#x7684;&#x6B65;&#x957F;.<code>padding</code> &#x5904;&#x7406;&#x8FB9;&#x754C;&#x65F6;&#x5728;&#x6BCF;&#x4E2A;&#x7EF4;&#x5EA6;&#x9996;&#x5C3E;&#x8865;0&#x6570;&#x91CF;.<code>output_padding</code> &#x8F93;&#x51FA;&#x65F6;&#x5019;&#x5728;&#x6BCF;&#x4E00;&#x4E2A;&#x7EF4;&#x5EA6;&#x9996;&#x5C3E;&#x8865;0&#x7684;&#x6570;&#x91CF;. &#xFF08;&#x5377;&#x79EF;&#x65F6;, &#x5F62;&#x72B6;&#x4E0D;&#x540C;&#x7684;&#x8F93;&#x5165;&#x6570;&#x636E;</p>
<p>&#x5BF9;&#x76F8;&#x540C;&#x7684;&#x6838;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4EA7;&#x751F;&#x5F62;&#x72B6;&#x76F8;&#x540C;&#x7684;&#x7ED3;&#x679C;&#xFF1B;&#x53CD;&#x5377;&#x79EF;&#x65F6;, &#x540C;&#x4E00;&#x4E2A;&#x8F93;&#x5165;&#x5BF9;&#x76F8;&#x540C;&#x7684;&#x6838;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4EA7;&#x751F;&#x591A; &#x4E2A;&#x5F62;&#x72B6;&#x4E0D;&#x540C;&#x7684;&#x8F93;&#x51FA;, &#x800C;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x53EA;&#x80FD;&#x6709;&#x4E00;&#x4E2A;, &#x56E0;&#x6B64;&#x5FC5;&#x987B;&#x5BF9;&#x8F93;&#x51FA;&#x5F62;&#x72B6;&#x8FDB;&#x884C;&#x7EA6;&#x675F;&#xFF09;. | <code>dilation</code> &#x91C7;&#x6837;&#x95F4;&#x9694;&#x6570;&#x91CF;. &#x5927;&#x4E8E;1&#x65F6;&#x4E3A;&#x975E;&#x81F4;&#x5BC6;&#x91C7;&#x6837;. | <code>groups</code> &#x63A7;&#x5236;&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA;&#x4E4B;&#x95F4;&#x7684;&#x8FDE;&#x63A5;, group=1, &#x8F93;&#x51FA;&#x662F;&#x6240;&#x6709;&#x8F93;&#x5165;&#x7684;&#x5377;&#x79EF;&#xFF1B; group=2, &#x6B64;&#x65F6; &#x76F8;&#x5F53;&#x4E8E;&#x6709;&#x5E76;&#x6392;&#x7684;&#x4E24;&#x4E2A;&#x5377;&#x57FA;&#x5C42;, &#x6BCF;&#x4E2A;&#x5377;&#x79EF;&#x5C42;&#x53EA;&#x5728;&#x5BF9;&#x5E94;&#x7684;&#x8F93;&#x5165;&#x901A;&#x9053;&#x548C;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x4E4B;&#x95F4;&#x8BA1;&#x7B97;, &#x5E76;&#x4E14;&#x8F93;&#x51FA;&#x65F6;&#x4F1A;&#x5C06;&#x6240;&#x6709; &#x8F93;&#x51FA;&#x901A;&#x9053;&#x7B80;&#x5355;&#x7684;&#x9996;&#x5C3E;&#x76F8;&#x63A5;&#x4F5C;&#x4E3A;&#x7ED3;&#x679C;&#x8F93;&#x51FA;.</p>
<blockquote>
<p><code>in_channels</code> &#x548C; <code>out_channels</code>&#x90FD;&#x5E94;&#x5F53;&#x53EF;&#x4EE5;&#x88AB; groups &#x6574;&#x9664;.</p>
</blockquote>
<p><code>kernel_size</code>, <code>stride</code>, <code>padding</code>, <code>output_padding</code> &#x53EF;&#x4EE5;&#x4E3A;:</p>
<blockquote>
<ul>
<li>&#x5355;&#x4E2A; <code>int</code> &#x503C; &#x2013; &#x5BBD;&#x548C;&#x9AD8;&#x5747;&#x88AB;&#x8BBE;&#x5B9A;&#x4E3A;&#x6B64;&#x503C;.</li>
<li>&#x7531;&#x4E24;&#x4E2A; <code>int</code> &#x7EC4;&#x6210;&#x7684; <code>tuple</code> &#x2013; &#x7B2C;&#x4E00;&#x4E2A; <code>int</code> &#x4E3A;&#x9AD8;&#x5EA6;, &#x7B2C;&#x4E8C;&#x4E2A; <code>int</code> &#x4E3A;&#x5BBD;&#x5EA6;.</li>
</ul>
</blockquote>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x6570;&#x636E;&#x7684;&#x6700;&#x540E;&#x4E00;&#x5217;&#x53EF;&#x80FD;&#x4F1A;&#x56E0;&#x4E3A; kernal &#x5927;&#x5C0F;&#x8BBE;&#x5B9A;&#x4E0D;&#x5F53;&#x800C;&#x88AB;&#x4E22;&#x5F03;&#xFF08;&#x5927;&#x90E8;&#x5206;&#x53D1;&#x751F;&#x5728; kernal &#x5927;&#x5C0F;&#x4E0D;&#x80FD;&#x88AB;&#x8F93;&#x5165; &#x6574;&#x9664;&#x7684;&#x65F6;&#x5019;, &#x9002;&#x5F53;&#x7684; padding &#x53EF;&#x4EE5;&#x907F;&#x514D;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF09;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>in_channels (-)</code> &#x2013; &#x8F93;&#x5165;&#x4FE1;&#x53F7;&#x7684;&#x901A;&#x9053;&#x6570;.</li>
<li><code>out_channels (-)</code> &#x2013; &#x5377;&#x79EF;&#x540E;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x7684;&#x901A;&#x9053;&#x6570;.</li>
<li><code>kernel_size (-)</code> &#x2013; &#x5377;&#x79EF;&#x6838;&#x7684;&#x5F62;&#x72B6;.</li>
<li><code>stride (-)</code> &#x2013; &#x5377;&#x79EF;&#x6BCF;&#x6B21;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x4E3A;1.</li>
<li><code>padding (-)</code> &#x2013; &#x5904;&#x7406;&#x8FB9;&#x754C;&#x65F6;&#x586B;&#x5145;0&#x7684;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;0(&#x4E0D;&#x586B;&#x5145;).</li>
<li><code>output_padding (-)</code> &#x2013; &#x8F93;&#x51FA;&#x65F6;&#x5019;&#x5728;&#x9996;&#x5C3E;&#x8865;&#x503C;&#x7684;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;0. &#xFF08;&#x5377;&#x79EF;&#x65F6;, &#x5F62;&#x72B6;&#x4E0D;&#x540C;&#x7684;&#x8F93;&#x5165;&#x6570;&#x636E;</li>
<li><code>&#x540C;&#x4E00;&#x4E2A;&#x8F93;&#x5165;&#x5BF9;&#x76F8;&#x540C;&#x7684;&#x6838;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4EA7;&#x751F;&#x591A; (_&#x5BF9;&#x76F8;&#x540C;&#x7684;&#x6838;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4EA7;&#x751F;&#x5F62;&#x72B6;&#x76F8;&#x540C;&#x7684;&#x7ED3;&#x679C;&#xFF1B;&#x53CD;&#x5377;&#x79EF;&#x65F6;_,)</code> &#x2013;</li>
<li>&#x800C;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x53EA;&#x80FD;&#x6709;&#x4E00;&#x4E2A;, &#x56E0;&#x6B64;&#x5FC5;&#x987B;&#x5BF9;&#x8F93;&#x51FA;&#x5F62;&#x72B6;&#x8FDB;&#x884C;&#x7EA6;&#x675F;&#xFF09; (<em>&#x4E2A;&#x5F62;&#x72B6;&#x4E0D;&#x540C;&#x7684;&#x8F93;&#x51FA;</em>,) &#x2013;</li>
<li><code>groups (-)</code> &#x2013; &#x8F93;&#x5165;&#x4E0E;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x7684;&#x5206;&#x7EC4;&#x6570;&#x91CF;. &#x5F53;&#x4E0D;&#x4E3A;1&#x65F6;, &#x9ED8;&#x8BA4;&#x4E3A;1(&#x5168;&#x8FDE;&#x63A5;).</li>
<li><code>bias (-)</code> &#x2013; &#x4E3A; <code>True</code> &#x65F6;, &#x6DFB;&#x52A0;&#x504F;&#x7F6E;.</li>
<li><code>dilation (-)</code> &#x2013; &#x91C7;&#x6837;&#x95F4;&#x9694;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;1, &#x65E0;&#x95F4;&#x9694;&#x91C7;&#x6837;.</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165; Input: <img src="img/tex-a821595925aa8f87a7488c9e2b28cbe7.gif" alt="(N, C_{in}, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA; Output: <img src="img/tex-ba3afaecc84f511d8c24e8605d528d35.gif" alt="(N, C_{out}, H_{out}, W_{out})"> &#x5176;&#x4E2D; <img src="img/tex-7009a9216729c8c52e70b14ec732620d.gif" alt="H_{out} = (H_{in} - 1) * stride[0] - 2 * padding[0] + kernel\_size[0] + output\_padding[0]"> <img src="img/tex-bc45574b44fdf01856bacfcd4abdeeba.gif" alt="W_{out} = (W_{in} - 1) * stride[1] - 2 * padding[1] + kernel\_size[1] + output\_padding[1]"></li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li><code>weight (Tensor)</code> &#x2013; &#x5377;&#x79EF;&#x7F51;&#x7EDC;&#x5C42;&#x95F4;&#x8FDE;&#x63A5;&#x7684;&#x6743;&#x91CD;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A;weight (Tensor): &#x5377;&#x79EF;&#x7F51;&#x7EDC;&#x5C42;&#x95F4;&#x8FDE;&#x63A5;&#x7684;&#x6743;&#x91CD;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A; (in_channels, out_channels, kernel_size[0], kernel_size[1])</li>
<li><code>bias (Tensor)</code> &#x2013; &#x504F;&#x7F6E;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A; (out_channels)</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With square kernels and equal stride</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ConvTranspose2d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># non-square kernels and unequal stride and with padding</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ConvTranspose2d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">5</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">4</span>, <span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">50</span>, <span class="hljs-number">100</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># exact output size can be also specified as an argument</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>downsample = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>upsample = nn.ConvTranspose2d(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>, <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>h = downsample(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>h.size()
torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, <span class="hljs-number">6</span>, <span class="hljs-number">6</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>output = upsample(h, output_size=input.size())
<span class="hljs-meta">&gt;&gt;&gt; </span>output.size()
torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">16</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>])
</code></pre>
<h3 id="convtranspose3d">ConvTranspose3d</h3>
<pre><code class="lang-py">class torch.nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)
</code></pre>
<p>&#x4E09;&#x7EF4;&#x53CD;&#x5377;&#x79EF;&#x5C42; &#x53CD;&#x5377;&#x79EF;&#x5C42;&#x53EF;&#x4EE5;&#x7406;&#x89E3;&#x4E3A;&#x8F93;&#x5165;&#x7684;&#x6570;&#x636E;&#x548C;&#x5377;&#x79EF;&#x6838;&#x7684;&#x4F4D;&#x7F6E;&#x53CD;&#x8F6C;&#x7684;&#x5377;&#x79EF;&#x64CD;&#x4F5C;. &#x53CD;&#x5377;&#x79EF;&#x6709;&#x65F6;&#x5019;&#x4E5F;&#x4F1A;&#x88AB;&#x7FFB;&#x8BD1;&#x6210;&#x89E3;&#x5377;&#x79EF;.</p>
<p><code>stride</code> &#x8BA1;&#x7B97;&#x76F8;&#x5173;&#x7CFB;&#x6570;&#x7684;&#x6B65;&#x957F;.<code>padding</code> &#x5904;&#x7406;&#x8FB9;&#x754C;&#x65F6;&#x5728;&#x6BCF;&#x4E2A;&#x7EF4;&#x5EA6;&#x9996;&#x5C3E;&#x8865;0&#x6570;&#x91CF;.<code>output_padding</code> &#x8F93;&#x51FA;&#x65F6;&#x5019;&#x5728;&#x6BCF;&#x4E00;&#x4E2A;&#x7EF4;&#x5EA6;&#x9996;&#x5C3E;&#x8865;0&#x7684;&#x6570;&#x91CF;. &#xFF08;&#x5377;&#x79EF;&#x65F6;, &#x5F62;&#x72B6;&#x4E0D;&#x540C;&#x7684;&#x8F93;&#x5165;&#x6570;&#x636E;</p>
<p>&#x5BF9;&#x76F8;&#x540C;&#x7684;&#x6838;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4EA7;&#x751F;&#x5F62;&#x72B6;&#x76F8;&#x540C;&#x7684;&#x7ED3;&#x679C;&#xFF1B;&#x53CD;&#x5377;&#x79EF;&#x65F6;, &#x540C;&#x4E00;&#x4E2A;&#x8F93;&#x5165;&#x5BF9;&#x76F8;&#x540C;&#x7684;&#x6838;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4EA7;&#x751F;&#x591A; &#x4E2A;&#x5F62;&#x72B6;&#x4E0D;&#x540C;&#x7684;&#x8F93;&#x51FA;, &#x800C;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x53EA;&#x80FD;&#x6709;&#x4E00;&#x4E2A;, &#x56E0;&#x6B64;&#x5FC5;&#x987B;&#x5BF9;&#x8F93;&#x51FA;&#x5F62;&#x72B6;&#x8FDB;&#x884C;&#x7EA6;&#x675F;&#xFF09; | <code>dilation</code> &#x91C7;&#x6837;&#x95F4;&#x9694;&#x6570;&#x91CF;. &#x5927;&#x4E8E;1&#x65F6;&#x4E3A;&#x975E;&#x81F4;&#x5BC6;&#x91C7;&#x6837;. | <code>groups</code> &#x63A7;&#x5236;&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA;&#x4E4B;&#x95F4;&#x7684;&#x8FDE;&#x63A5;, group=1, &#x8F93;&#x51FA;&#x662F;&#x6240;&#x6709;&#x8F93;&#x5165;&#x7684;&#x5377;&#x79EF;&#xFF1B; group=2, &#x6B64;&#x65F6; &#x76F8;&#x5F53;&#x4E8E;&#x6709;&#x5E76;&#x6392;&#x7684;&#x4E24;&#x4E2A;&#x5377;&#x57FA;&#x5C42;, &#x6BCF;&#x4E2A;&#x5377;&#x79EF;&#x5C42;&#x53EA;&#x5728;&#x5BF9;&#x5E94;&#x7684;&#x8F93;&#x5165;&#x901A;&#x9053;&#x548C;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x4E4B;&#x95F4;&#x8BA1;&#x7B97;, &#x5E76;&#x4E14;&#x8F93;&#x51FA;&#x65F6;&#x4F1A;&#x5C06;&#x6240;&#x6709; &#x8F93;&#x51FA;&#x901A;&#x9053;&#x7B80;&#x5355;&#x7684;&#x9996;&#x5C3E;&#x76F8;&#x63A5;&#x4F5C;&#x4E3A;&#x7ED3;&#x679C;&#x8F93;&#x51FA;.</p>
<blockquote>
<p><code>in_channels</code> &#x548C; <code>out_channels</code>&#x90FD;&#x5E94;&#x5F53;&#x53EF;&#x4EE5;&#x88AB; groups &#x6574;&#x9664;.</p>
</blockquote>
<p><code>kernel_size</code>, <code>stride</code>, <code>padding</code>, <code>output_padding</code> &#x53EF;&#x4EE5;&#x4E3A;:</p>
<blockquote>
<ul>
<li>&#x5355;&#x4E2A; <code>int</code> &#x503C; &#x2013; &#x6DF1;&#x548C;&#x5BBD;&#x548C;&#x9AD8;&#x5747;&#x88AB;&#x8BBE;&#x5B9A;&#x4E3A;&#x6B64;&#x503C;.</li>
<li>&#x7531;&#x4E09;&#x4E2A; <code>int</code> &#x7EC4;&#x6210;&#x7684; <code>tuple</code> &#x2013; &#x7B2C;&#x4E00;&#x4E2A; <code>int</code> &#x4E3A;&#x6DF1;&#x5EA6;, &#x7B2C;&#x4E8C;&#x4E2A; <code>int</code> &#x4E3A;&#x9AD8;&#x5EA6;,&#x7B2C;&#x4E09;&#x4E2A; <code>int</code> &#x4E3A;&#x5BBD;&#x5EA6;.</li>
</ul>
</blockquote>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x6570;&#x636E;&#x7684;&#x6700;&#x540E;&#x4E00;&#x5217;&#x53EF;&#x80FD;&#x4F1A;&#x56E0;&#x4E3A; kernal &#x5927;&#x5C0F;&#x8BBE;&#x5B9A;&#x4E0D;&#x5F53;&#x800C;&#x88AB;&#x4E22;&#x5F03;&#xFF08;&#x5927;&#x90E8;&#x5206;&#x53D1;&#x751F;&#x5728; kernal &#x5927;&#x5C0F;&#x4E0D;&#x80FD;&#x88AB;&#x8F93;&#x5165; &#x6574;&#x9664;&#x7684;&#x65F6;&#x5019;, &#x9002;&#x5F53;&#x7684; padding &#x53EF;&#x4EE5;&#x907F;&#x514D;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF09;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>in_channels (-)</code> &#x2013; &#x8F93;&#x5165;&#x4FE1;&#x53F7;&#x7684;&#x901A;&#x9053;&#x6570;.</li>
<li><code>out_channels (-)</code> &#x2013; &#x5377;&#x79EF;&#x540E;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x7684;&#x901A;&#x9053;&#x6570;.</li>
<li><code>kernel_size (-)</code> &#x2013; &#x5377;&#x79EF;&#x6838;&#x7684;&#x5F62;&#x72B6;.</li>
<li><code>stride (-)</code> &#x2013; &#x5377;&#x79EF;&#x6BCF;&#x6B21;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x4E3A;1.</li>
<li><code>padding (-)</code> &#x2013; &#x5904;&#x7406;&#x8FB9;&#x754C;&#x65F6;&#x586B;&#x5145;0&#x7684;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;0(&#x4E0D;&#x586B;&#x5145;).</li>
<li><code>output_padding (-)</code> &#x2013; &#x8F93;&#x51FA;&#x65F6;&#x5019;&#x5728;&#x9996;&#x5C3E;&#x8865;&#x503C;&#x7684;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;0. &#xFF08;&#x5377;&#x79EF;&#x65F6;, &#x5F62;&#x72B6;&#x4E0D;&#x540C;&#x7684;&#x8F93;&#x5165;&#x6570;&#x636E;</li>
<li><code>&#x540C;&#x4E00;&#x4E2A;&#x8F93;&#x5165;&#x5BF9;&#x76F8;&#x540C;&#x7684;&#x6838;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4EA7;&#x751F;&#x591A; (_&#x5BF9;&#x76F8;&#x540C;&#x7684;&#x6838;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4EA7;&#x751F;&#x5F62;&#x72B6;&#x76F8;&#x540C;&#x7684;&#x7ED3;&#x679C;&#xFF1B;&#x53CD;&#x5377;&#x79EF;&#x65F6;_,)</code> &#x2013;</li>
<li>&#x800C;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x53EA;&#x80FD;&#x6709;&#x4E00;&#x4E2A;, &#x56E0;&#x6B64;&#x5FC5;&#x987B;&#x5BF9;&#x8F93;&#x51FA;&#x5F62;&#x72B6;&#x8FDB;&#x884C;&#x7EA6;&#x675F;&#xFF09; (<em>&#x4E2A;&#x5F62;&#x72B6;&#x4E0D;&#x540C;&#x7684;&#x8F93;&#x51FA;</em>,) &#x2013;</li>
<li><code>groups (-)</code> &#x2013; &#x8F93;&#x5165;&#x4E0E;&#x8F93;&#x51FA;&#x901A;&#x9053;&#x7684;&#x5206;&#x7EC4;&#x6570;&#x91CF;. &#x5F53;&#x4E0D;&#x4E3A;1&#x65F6;, &#x9ED8;&#x8BA4;&#x4E3A;1(&#x5168;&#x8FDE;&#x63A5;).</li>
<li><code>bias (-)</code> &#x2013; &#x4E3A; <code>True</code> &#x65F6;, &#x6DFB;&#x52A0;&#x504F;&#x7F6E;.</li>
<li><code>dilation (-)</code> &#x2013; &#x91C7;&#x6837;&#x95F4;&#x9694;&#x6570;&#x91CF;, &#x9ED8;&#x8BA4;&#x4E3A;1, &#x65E0;&#x95F4;&#x9694;&#x91C7;&#x6837;.</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165; Input: <img src="img/tex-3284da09db0303b6608e4bc197b59361.gif" alt="(N, C_{in}, D_{in}, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA; Output: <img src="img/tex-5b2f3f7fabcd6ee5b9f89543b54d71e2.gif" alt="(N, C_{out}, D_{out}, H_{out}, W_{out})"> &#x5176;&#x4E2D; <img src="img/tex-02979cc7d8145e84e5beef17eed9af98.gif" alt="D_{out} = (D_{in} - 1) * stride[0] - 2 * padding[0] + kernel\_size[0] + output\_padding[0]"> <img src="img/tex-fd675a2fc6af8db9a43fc6aee6bba673.gif" alt="H_{out} = (H_{in} - 1) * stride[1] - 2 * padding[1] + kernel\_size[1] + output\_padding[1]"> <img src="img/tex-ed1eac6d6bea1843a9838431c595dcb5.gif" alt="W_{out} = (W_{in} - 1) * stride[2] - 2 * padding[2] + kernel\_size[2] + output\_padding[2]"></li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li>&#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A;weight (<em>&#x5377;&#x79EF;&#x7F51;&#x7EDC;&#x5C42;&#x95F4;&#x8FDE;&#x63A5;&#x7684;&#x6743;&#x91CD;</em>,) &#x2013; &#x5377;&#x79EF;&#x7F51;&#x7EDC;&#x5C42;&#x95F4;&#x8FDE;&#x63A5;&#x7684;&#x6743;&#x91CD;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A; (in_channels, out_channels, kernel_size[0], kernel_size[1], kernel_size[2])</li>
<li><code>bias (Tensor)</code> &#x2013; &#x504F;&#x7F6E;, &#x662F;&#x6A21;&#x578B;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x53D8;&#x91CF;, &#x5F62;&#x72B6;&#x4E3A; (out_channels)</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With square kernels and equal stride</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ConvTranspose3d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># non-square kernels and unequal stride and with padding</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Conv3d(<span class="hljs-number">16</span>, <span class="hljs-number">33</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">2</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>, <span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">10</span>, <span class="hljs-number">50</span>, <span class="hljs-number">100</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h2 id="pooling-layers-&#x6C60;&#x5316;&#x5C42;">Pooling Layers (&#x6C60;&#x5316;&#x5C42;)</h2>
<h3 id="maxpool1d">MaxPool1d</h3>
<pre><code class="lang-py">class torch.nn.MaxPool1d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E00;&#x7EF4;&#x7684;&#x6700;&#x5927;&#x6C60;&#x5316; <code>max pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x6700;&#x7B80;&#x5355;&#x7684;&#x4F8B;&#x5B50;, &#x5982;&#x679C;&#x8F93;&#x5165;&#x5927;&#x5C0F;&#x4E3A; <img src="img/tex-543737499dba0095d9151b4fd440b509.gif" alt="(N, C, L)">, &#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x4E3A; <img src="img/tex-5b25a4bc4c225a5e291c54a4166929b8.gif" alt="(N, C, L_{out})">, &#x8BE5;&#x5C42;&#x8F93;&#x51FA;&#x503C;&#x53EF;&#x4EE5;&#x7528;&#x4E0B;&#x5F0F;&#x7CBE;&#x786E;&#x8BA1;&#x7B97;:</p>
<p><img src="img/tex-033027842cb7efcbf0cb915d541c69c5.gif" alt="\begin{array}{ll} out(N_i, C_j, k) = \max_{m=0}^{kernel\_size-1} input(N_i, C_j, stride * k + m) \end{array}"></p>
<p>&#x5982;&#x679C; <code>padding</code> &#x4E0D;&#x662F;0,&#x90A3;&#x4E48;&#x5728;&#x8F93;&#x5165;&#x6570;&#x636E;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x4E0A;&#x4F1A;&#x9690;&#x5F0F;&#x586B;&#x8865;&#x5BF9;&#x5E94; <code>padding</code> &#x6570;&#x91CF;&#x7684;0&#x503C;&#x70B9;<code>dilation</code> &#x7528;&#x4E8E;&#x63A7;&#x5236;&#x5185;&#x6838;&#x70B9;&#x4E4B;&#x95F4;&#x7684;&#x95F4;&#x9694;, <a href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md" target="_blank">link</a> &#x5F88;&#x597D;&#x5730;&#x53EF;&#x89C6;&#x5316;&#x5C55;&#x793A;&#x4E86; <code>dilation</code> &#x7684;&#x529F;&#x80FD;</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>kernel_size</code> &#x2013; &#x6700;&#x5927;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7684;&#x7A97;&#x53E3;&#x5927;&#x5C0F;</li>
<li><code>stride</code> &#x2013; &#x6700;&#x5927;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7A97;&#x53E3;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x503C;&#x662F; <code>kernel_size</code></li>
<li><code>padding</code> &#x2013; &#x8F93;&#x5165;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x9690;&#x5F0F;&#x8865;0&#x7684;&#x6570;&#x91CF;</li>
<li><code>dilation</code> &#x2013; &#x7528;&#x4E8E;&#x63A7;&#x5236;&#x7A97;&#x53E3;&#x4E2D;&#x5143;&#x7D20;&#x7684;&#x6B65;&#x957F;&#x7684;&#x53C2;&#x6570;</li>
<li><code>return_indices</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>, &#x5728;&#x8FD4;&#x56DE; max pooling &#x7ED3;&#x679C;&#x7684;&#x540C;&#x65F6;&#x8FD4;&#x56DE;&#x6700;&#x5927;&#x503C;&#x7684;&#x7D22;&#x5F15;. &#x8FD9;&#x5728;&#x4E4B;&#x540E;&#x7684; Unpooling &#x65F6;&#x5F88;&#x6709;&#x7528;</li>
<li><code>ceil_mode</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>, &#x5728;&#x8BA1;&#x7B97;&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x65F6;,&#x5C06;&#x91C7;&#x7528;&#x5411;&#x4E0A;&#x53D6;&#x6574;&#x6765;&#x4EE3;&#x66FF;&#x9ED8;&#x8BA4;&#x7684;&#x5411;&#x4E0B;&#x53D6;&#x6574;&#x7684;&#x65B9;&#x5F0F;</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-6c8971de65a57273c075bc491fa6ba0a.gif" alt="(N, C, L_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-5b25a4bc4c225a5e291c54a4166929b8.gif" alt="(N, C, L_{out})"> &#x9075;&#x4ECE;&#x5982;&#x4E0B;&#x5173;&#x7CFB; <img src="img/tex-1ef60f8e6f123a4369ccdc2117bd3f0d.gif" alt="L_{out} = floor((L_{in} + 2 * padding - dilation * (kernel\_size - 1) - 1) / stride + 1)"></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool of size=3, stride=2</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.MaxPool1d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">50</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="maxpool2d">MaxPool2d</h3>
<pre><code class="lang-py">class torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E8C;&#x7EF4;&#x7684;&#x6700;&#x5927;&#x6C60;&#x5316; <code>max pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x6700;&#x7B80;&#x5355;&#x7684;&#x4F8B;&#x5B50;, &#x5982;&#x679C;&#x8F93;&#x5165;&#x5927;&#x5C0F;&#x4E3A; <img src="img/tex-38d00342060234da90e0c2c5493892cb.gif" alt="(N, C, H, W)">, &#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x4E3A; <img src="img/tex-403ffd9231342159e36ba660b2bf3ff3.gif" alt="(N, C, H_{out}, W_{out})">, &#x6C60;&#x5316;&#x7A97;&#x53E3;&#x5927;&#x5C0F; <code>kernel_size</code> &#x4E3A; <img src="img/tex-11acc7e0901ba5158f843445d5bbdc92.gif" alt="(kH, kW)"> &#x8BE5;&#x5C42;&#x8F93;&#x51FA;&#x503C;&#x53EF;&#x4EE5;&#x7528;&#x4E0B;&#x5F0F;&#x7CBE;&#x786E;&#x8BA1;&#x7B97;:</p>
<p><img src="img/tex-573dc90f741480b5e40bf216db293982.gif" alt="\begin{array}{ll} out(N_i, C_j, h, w) = \max_{m=0}^{kH-1} \max_{n=0}^{kW-1} input(N_i, C_j, stride[0] * h + m, stride[1] * w + n) \end{array}"></p>
<p>&#x5982;&#x679C; <code>padding</code> &#x4E0D;&#x662F;0, &#x90A3;&#x4E48;&#x5728;&#x8F93;&#x5165;&#x6570;&#x636E;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x4E0A;&#x4F1A;&#x9690;&#x5F0F;&#x586B;&#x8865;&#x5BF9;&#x5E94; <code>padding</code> &#x6570;&#x91CF;&#x7684;0&#x503C;&#x70B9;<code>dilation</code> &#x7528;&#x4E8E;&#x63A7;&#x5236;&#x5185;&#x6838;&#x70B9;&#x4E4B;&#x95F4;&#x7684;&#x95F4;&#x9694;, <a href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md" target="_blank">link</a> &#x5F88;&#x597D;&#x5730;&#x53EF;&#x89C6;&#x5316;&#x5C55;&#x793A;&#x4E86; <code>dilation</code> &#x7684;&#x529F;&#x80FD;</p>
<p>&#x53C2;&#x6570; <code>kernel_size</code>, <code>stride</code>, <code>padding</code>, <code>dilation</code> &#x53EF;&#x4EE5;&#x662F;&#x4EE5;&#x4E0B;&#x4EFB;&#x610F;&#x4E00;&#x79CD;&#x6570;&#x636E;&#x7C7B;&#x578B;:</p>
<blockquote>
<ul>
<li>&#x5355;&#x4E2A; <code>int</code> &#x7C7B;&#x578B;&#x6570;&#x636E; &#x2013; &#x6B64;&#x65F6;&#x5728; height &#x548C; width &#x7EF4;&#x5EA6;&#x4E0A;&#x5C06;&#x4F7F;&#x7528;&#x76F8;&#x540C;&#x7684;&#x503C;</li>
<li>&#x5305;&#x542B;&#x4E24;&#x4E2A; int &#x7C7B;&#x578B;&#x6570;&#x636E;&#x7684; <code>tuple</code> &#x5143;&#x7EC4; &#x2013; &#x6B64;&#x65F6;&#x7B2C;&#x4E00;&#x4E2A; <code>int</code> &#x6570;&#x636E;&#x8868;&#x793A; height &#x7EF4;&#x5EA6;&#x4E0A;&#x7684;&#x6570;&#x503C;, &#x7B2C;&#x4E8C;&#x4E2A; <code>int</code> &#x6570;&#x636E;&#x8868;&#x793A; width &#x7EF4;&#x5EA6;&#x4E0A;&#x7684;&#x6570;&#x503C;</li>
</ul>
</blockquote>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>kernel_size</code> &#x2013; &#x6700;&#x5927;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7684;&#x7A97;&#x53E3;&#x5927;&#x5C0F;</li>
<li><code>stride</code> &#x2013; &#x6700;&#x5927;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7A97;&#x53E3;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x503C;&#x662F; <code>kernel_size</code></li>
<li><code>padding</code> &#x2013; &#x8F93;&#x5165;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x9690;&#x5F0F;&#x8865;0&#x7684;&#x6570;&#x91CF;</li>
<li><code>dilation</code> &#x2013; &#x7528;&#x4E8E;&#x63A7;&#x5236;&#x7A97;&#x53E3;&#x4E2D;&#x5143;&#x7D20;&#x7684;&#x6B65;&#x957F;&#x7684;&#x53C2;&#x6570;</li>
<li><code>return_indices</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>, &#x5728;&#x8FD4;&#x56DE; max pooling &#x7ED3;&#x679C;&#x7684;&#x540C;&#x65F6;&#x8FD4;&#x56DE;&#x6700;&#x5927;&#x503C;&#x7684;&#x7D22;&#x5F15; &#x8FD9;&#x5728;&#x4E4B;&#x540E;&#x7684; Unpooling &#x65F6;&#x5F88;&#x6709;&#x7528;</li>
<li><code>ceil_mode</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>, &#x5728;&#x8BA1;&#x7B97;&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x65F6;,&#x5C06;&#x91C7;&#x7528;&#x5411;&#x4E0A;&#x53D6;&#x6574;&#x6765;&#x4EE3;&#x66FF;&#x9ED8;&#x8BA4;&#x7684;&#x5411;&#x4E0B;&#x53D6;&#x6574;&#x7684;&#x65B9;&#x5F0F;</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-d5acb55d3d2dd49b5b0d71ab7cf3b2d1.gif" alt="(N, C, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-403ffd9231342159e36ba660b2bf3ff3.gif" alt="(N, C, H_{out}, W_{out})"> &#x9075;&#x4ECE;&#x5982;&#x4E0B;&#x5173;&#x7CFB; <img src="img/tex-79b3618ba1cd1e8e6e665aae1b4fc446.gif" alt="H_{out} = floor((H_{in} + 2 * padding[0] - dilation[0] * (kernel\_size[0] - 1) - 1) / stride[0] + 1)"> <img src="img/tex-e9f44b9b5fc42bdb5991cfcd52e2dced.gif" alt="W_{out} = floor((W_{in} + 2 * padding[1] - dilation[1] * (kernel\_size[1] - 1) - 1) / stride[1] + 1)"></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool of square window of size=3, stride=2</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.MaxPool2d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool of non-square window</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.MaxPool2d((<span class="hljs-number">3</span>, <span class="hljs-number">2</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">50</span>, <span class="hljs-number">32</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="maxpool3d">MaxPool3d</h3>
<pre><code class="lang-py">class torch.nn.MaxPool3d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E09;&#x7EF4;&#x7684;&#x6700;&#x5927;&#x6C60;&#x5316; <code>max pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x6700;&#x7B80;&#x5355;&#x7684;&#x4F8B;&#x5B50;, &#x5982;&#x679C;&#x8F93;&#x5165;&#x5927;&#x5C0F;&#x4E3A; <img src="img/tex-6d9465a2eb2377437689121f4915b6b4.gif" alt="(N, C, D, H, W)">,&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x4E3A; <img src="img/tex-d14df6868b2b3f7ee945a69616a0b867.gif" alt="(N, C, D_{out}, H_{out}, W_{out})"> &#x6C60;&#x5316;&#x7A97;&#x53E3;&#x5927;&#x5C0F; <code>kernel_size</code> &#x4E3A; <img src="img/tex-b53b272ea52997eb2ccf903b6d58b4bc.gif" alt="(kD, kH, kW)"> &#x8BE5;&#x5C42;&#x8F93;&#x51FA;&#x503C;&#x53EF;&#x4EE5;&#x7528;&#x4E0B;&#x5F0F;&#x7CBE;&#x786E;&#x8BA1;&#x7B97;:</p>
<p><img src="img/tex-42f8d78c4f022c0857c8561088078429.gif" alt="\begin{array}{ll} out(N_i, C_j, d, h, w) = \max_{k=0}^{kD-1} \max_{m=0}^{kH-1} \max_{n=0}^{kW-1} input(N_i, C_j, stride[0] * k + d, stride[1] * h + m, stride[2] * w + n) \end{array}"></p>
<p>&#x5982;&#x679C; <code>padding</code> &#x4E0D;&#x662F;0, &#x90A3;&#x4E48;&#x5728;&#x8F93;&#x5165;&#x6570;&#x636E;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x4E0A;&#x4F1A;&#x9690;&#x5F0F;&#x586B;&#x8865;&#x5BF9;&#x5E94; <code>padding</code> &#x6570;&#x91CF;&#x7684;0&#x503C;&#x70B9;<code>dilation</code> &#x7528;&#x4E8E;&#x63A7;&#x5236;&#x5185;&#x6838;&#x70B9;&#x4E4B;&#x95F4;&#x7684;&#x95F4;&#x9694;, <a href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md" target="_blank">link</a> &#x5F88;&#x597D;&#x5730;&#x53EF;&#x89C6;&#x5316;&#x5C55;&#x793A;&#x4E86; <code>dilation</code> &#x7684;&#x529F;&#x80FD;</p>
<p>&#x53C2;&#x6570; <code>kernel_size</code>, <code>stride</code>, <code>padding</code>, <code>dilation</code> &#x53EF;&#x4EE5;&#x662F;&#x4EE5;&#x4E0B;&#x4EFB;&#x610F;&#x4E00;&#x79CD;&#x6570;&#x636E;&#x7C7B;&#x578B;:</p>
<blockquote>
<ul>
<li>&#x5355;&#x4E2A; <code>int</code> &#x7C7B;&#x578B;&#x6570;&#x636E; &#x2013; &#x6B64;&#x65F6;&#x5728; depth, height &#x548C; width &#x7EF4;&#x5EA6;&#x4E0A;&#x5C06;&#x4F7F;&#x7528;&#x76F8;&#x540C;&#x7684;&#x503C;</li>
<li>&#x5305;&#x542B;&#x4E09;&#x4E2A; int &#x7C7B;&#x578B;&#x6570;&#x636E;&#x7684; <code>tuple</code> &#x5143;&#x7EC4; &#x2013; &#x6B64;&#x65F6;&#x7B2C;&#x4E00;&#x4E2A; <code>int</code> &#x6570;&#x636E;&#x8868;&#x793A; depth &#x7EF4;&#x5EA6;&#x4E0A;&#x7684;&#x6570;&#x503C;, &#x7B2C;&#x4E8C;&#x4E2A; <code>int</code> &#x6570;&#x636E;&#x8868;&#x793A; height &#x7EF4;&#x5EA6;&#x4E0A;&#x7684;&#x6570;&#x503C;,&#x7B2C;&#x4E09;&#x4E2A; <code>int</code> &#x6570;&#x636E;&#x8868;&#x793A; width &#x7EF4;&#x5EA6;&#x4E0A;&#x7684;&#x6570;&#x503C;</li>
</ul>
</blockquote>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>kernel_size</code> &#x2013; &#x6700;&#x5927;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7684;&#x7A97;&#x53E3;&#x5927;&#x5C0F;</li>
<li><code>stride</code> &#x2013; &#x6700;&#x5927;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7A97;&#x53E3;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x503C;&#x662F; <code>kernel_size</code></li>
<li><code>padding</code> &#x2013; &#x8F93;&#x5165;&#x6240;&#x6709;&#x4E09;&#x6761;&#x8FB9;&#x4E0A;&#x9690;&#x5F0F;&#x8865;0&#x7684;&#x6570;&#x91CF;</li>
<li><code>dilation</code> &#x2013; &#x7528;&#x4E8E;&#x63A7;&#x5236;&#x7A97;&#x53E3;&#x4E2D;&#x5143;&#x7D20;&#x7684;&#x6B65;&#x957F;&#x7684;&#x53C2;&#x6570;</li>
<li><code>return_indices</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>, &#x5728;&#x8FD4;&#x56DE; max pooling &#x7ED3;&#x679C;&#x7684;&#x540C;&#x65F6;&#x8FD4;&#x56DE;&#x6700;&#x5927;&#x503C;&#x7684;&#x7D22;&#x5F15; &#x8FD9;&#x5728;&#x4E4B;&#x540E;&#x7684; Unpooling &#x65F6;&#x5F88;&#x6709;&#x7528;</li>
<li><code>ceil_mode</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>, &#x5728;&#x8BA1;&#x7B97;&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x65F6;,&#x5C06;&#x91C7;&#x7528;&#x5411;&#x4E0A;&#x53D6;&#x6574;&#x6765;&#x4EE3;&#x66FF;&#x9ED8;&#x8BA4;&#x7684;&#x5411;&#x4E0B;&#x53D6;&#x6574;&#x7684;&#x65B9;&#x5F0F;</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-ce19deda602cf16ded15c0fb9cd5d280.gif" alt="(N, C, D_{in}, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-d14df6868b2b3f7ee945a69616a0b867.gif" alt="(N, C, D_{out}, H_{out}, W_{out})"> &#x9075;&#x4ECE;&#x5982;&#x4E0B;&#x5173;&#x7CFB; <img src="img/tex-ba168d43ee6e937903b387d0afce9a40.gif" alt="D_{out} = floor((D_{in} + 2 * padding[0] - dilation[0] * (kernel\_size[0] - 1) - 1) / stride[0] + 1)"> <img src="img/tex-89213fb2d0850f4cc41af72bae650bd0.gif" alt="H_{out} = floor((H_{in} + 2 * padding[1] - dilation[1] * (kernel\_size[1] - 1) - 1) / stride[1] + 1)"> <img src="img/tex-397d0048589e3a1a6644d6613e7d4722.gif" alt="W_{out} = floor((W_{in} + 2 * padding[2] - dilation[2] * (kernel\_size[2] - 1) - 1) / stride[2] + 1)"></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool of square window of size=3, stride=2</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.MaxPool3d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool of non-square window</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.MaxPool3d((<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">50</span>,<span class="hljs-number">44</span>, <span class="hljs-number">31</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="maxunpool1d">MaxUnpool1d</h3>
<pre><code class="lang-py">class torch.nn.MaxUnpool1d(kernel_size, stride=None, padding=0)
</code></pre>
<p><code>MaxPool1d</code> &#x7684;&#x9006;&#x8FC7;&#x7A0B;</p>
<p>&#x8981;&#x6CE8;&#x610F;&#x7684;&#x662F; <code>MaxPool1d</code> &#x5E76;&#x4E0D;&#x662F;&#x5B8C;&#x5168;&#x53EF;&#x9006;&#x7684;, &#x56E0;&#x4E3A;&#x5728;max pooling&#x8FC7;&#x7A0B;&#x4E2D;&#x975E;&#x6700;&#x5927;&#x503C;&#x5DF2;&#x7ECF;&#x4E22;&#x5931;</p>
<p><code>MaxUnpool1d</code> &#x4EE5; <code>MaxPool1d</code> &#x7684;&#x8F93;&#x51FA;, &#x5305;&#x542B;&#x6700;&#x5927;&#x503C;&#x7684;&#x7D22;&#x5F15;&#x4F5C;&#x4E3A;&#x8F93;&#x5165; &#x8BA1;&#x7B97;max poooling&#x7684;&#x90E8;&#x5206;&#x9006;&#x8FC7;&#x7A0B;(&#x5BF9;&#x4E8E;&#x90A3;&#x4E9B;&#x6700;&#x5927;&#x503C;&#x533A;&#x57DF;), &#x5BF9;&#x4E8E;&#x90A3;&#x4E9B;&#x975E;&#x6700;&#x5927;&#x503C;&#x533A;&#x57DF;&#x5C06;&#x8BBE;&#x7F6E;&#x4E3A;0&#x503C;</p>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p><cite>MaxPool1d</cite> &#x53EF;&#x4EE5;&#x5C06;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x5927;&#x5C0F;&#x6620;&#x5C04;&#x5230;&#x76F8;&#x540C;&#x7684;&#x8F93;&#x51FA;&#x5927;&#x5C0F;, &#x56E0;&#x6B64;&#x53CD;&#x6F14;&#x8FC7;&#x7A0B;&#x53EF;&#x80FD;&#x4F1A;&#x6A21;&#x68F1;&#x4E24;&#x53EF; &#x4E3A;&#x9002;&#x5E94;&#x8FD9;&#x4E00;&#x70B9;, &#x5728;&#x8C03;&#x7528;forward&#x51FD;&#x6570;&#x65F6;&#x53EF;&#x4EE5;&#x5C06;&#x9700;&#x8981;&#x7684;&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x4F5C;&#x4E3A;&#x989D;&#x5916;&#x7684;&#x53C2;&#x6570; <cite>output_size</cite> &#x4F20;&#x5165;.</p>
<p>&#xFFFD; &#x5177;&#x4F53;&#x7528;&#x6CD5;,&#x8BF7;&#x53C2;&#x9605;&#x4E0B;&#x9762;&#x7684;&#x8F93;&#x5165;&#x548C;&#x793A;&#x4F8B;</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>kernel_size (int &#x6216; tuple)</code> &#x2013; &#x6700;&#x5927;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7684;&#x7A97;&#x53E3;&#x5927;&#x5C0F;</li>
<li><code>stride (int &#x6216; tuple)</code> &#x2013; &#x6700;&#x5927;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7A97;&#x53E3;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x503C;&#x662F; <code>kernel_size</code></li>
<li><code>padding (int &#x6216; tuple)</code> &#x2013; &#x8F93;&#x5165;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x586B;&#x5145;0&#x503C;&#x7684;&#x4E2A;&#x6570;</li>
</ul>
<p>Inputs:</p>
<ul>
<li><code>input</code>: &#x9700;&#x8981;&#x8F6C;&#x5316;&#x7684;&#x8F93;&#x5165;&#x7684; Tensor</li>
<li><code>indices</code>: <code>MaxPool1d</code> &#x63D0;&#x4F9B;&#x7684;&#x6700;&#x5927;&#x503C;&#x7D22;&#x5F15;</li>
<li><code>output_size</code> (&#x53EF;&#x9009;) : <code>torch.Size</code> &#x7C7B;&#x578B;&#x7684;&#x6570;&#x636E;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x7684;&#x5927;&#x5C0F;</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-99d3564b110d4919681501387a6ddf09.gif" alt="(N, C, H_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-ec05c6d8987b027dc39dd18a863a9e03.gif" alt="(N, C, H_{out})"> &#x9075;&#x4ECE;&#x5982;&#x4E0B;&#x5173;&#x7CFB; <img src="img/tex-3e4cc86575ff480ad4c4141a89f2b470.gif" alt="H_{out} = (H_{in} - 1) * stride[0] - 2 * padding[0] + kernel\_size[0]"> &#x6216;&#x8005;&#x5728;&#x8C03;&#x7528;&#x65F6;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x5927;&#x5C0F; <code>output_size</code></li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>pool = nn.MaxPool1d(<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, return_indices=<span class="hljs-keyword">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>unpool = nn.MaxUnpool1d(<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = Variable(torch.Tensor([[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>]]]))
<span class="hljs-meta">&gt;&gt;&gt; </span>output, indices = pool(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>unpool(output, indices)
Variable containing:
(<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">0</span>   <span class="hljs-number">2</span>   <span class="hljs-number">0</span>   <span class="hljs-number">4</span>   <span class="hljs-number">0</span>   <span class="hljs-number">6</span>   <span class="hljs-number">0</span>   <span class="hljs-number">8</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x8]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Example showcasing the use of output_size</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>input = Variable(torch.Tensor([[[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>]]]))
<span class="hljs-meta">&gt;&gt;&gt; </span>output, indices = pool(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>unpool(output, indices, output_size=input.size())
Variable containing:
(<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">0</span>   <span class="hljs-number">2</span>   <span class="hljs-number">0</span>   <span class="hljs-number">4</span>   <span class="hljs-number">0</span>   <span class="hljs-number">6</span>   <span class="hljs-number">0</span>   <span class="hljs-number">8</span>   <span class="hljs-number">0</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x9]

<span class="hljs-meta">&gt;&gt;&gt; </span>unpool(output, indices)
Variable containing:
(<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">0</span>   <span class="hljs-number">2</span>   <span class="hljs-number">0</span>   <span class="hljs-number">4</span>   <span class="hljs-number">0</span>   <span class="hljs-number">6</span>   <span class="hljs-number">0</span>   <span class="hljs-number">8</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x8]
</code></pre>
<h3 id="maxunpool2d">MaxUnpool2d</h3>
<pre><code class="lang-py">class torch.nn.MaxUnpool2d(kernel_size, stride=None, padding=0)
</code></pre>
<p><code>MaxPool2d</code> &#x7684;&#x9006;&#x8FC7;&#x7A0B;</p>
<p>&#x8981;&#x6CE8;&#x610F;&#x7684;&#x662F; <code>MaxPool2d</code> &#x5E76;&#x4E0D;&#x662F;&#x5B8C;&#x5168;&#x53EF;&#x9006;&#x7684;, &#x56E0;&#x4E3A;&#x5728;max pooling&#x8FC7;&#x7A0B;&#x4E2D;&#x975E;&#x6700;&#x5927;&#x503C;&#x5DF2;&#x7ECF;&#x4E22;&#x5931;</p>
<p><code>MaxUnpool2d</code> &#x4EE5; <code>MaxPool2d</code> &#x7684;&#x8F93;&#x51FA;, &#x5305;&#x542B;&#x6700;&#x5927;&#x503C;&#x7684;&#x7D22;&#x5F15;&#x4F5C;&#x4E3A;&#x8F93;&#x5165; &#x8BA1;&#x7B97;max poooling&#x7684;&#x90E8;&#x5206;&#x9006;&#x8FC7;&#x7A0B;(&#x5BF9;&#x4E8E;&#x90A3;&#x4E9B;&#x6700;&#x5927;&#x503C;&#x533A;&#x57DF;), &#x5BF9;&#x4E8E;&#x90A3;&#x4E9B;&#x975E;&#x6700;&#x5927;&#x503C;&#x533A;&#x57DF;&#x5C06;&#x8BBE;&#x7F6E;&#x4E3A;0&#x503C;</p>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p><cite>MaxPool2d</cite> &#x53EF;&#x4EE5;&#x5C06;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x5927;&#x5C0F;&#x6620;&#x5C04;&#x5230;&#x76F8;&#x540C;&#x7684;&#x8F93;&#x51FA;&#x5927;&#x5C0F;, &#x56E0;&#x6B64;&#x53CD;&#x6F14;&#x8FC7;&#x7A0B;&#x53EF;&#x80FD;&#x4F1A;&#x6A21;&#x68F1;&#x4E24;&#x53EF;. &#x4E3A;&#x9002;&#x5E94;&#x8FD9;&#x4E00;&#x70B9;, &#x5728;&#x8C03;&#x7528;forward&#x51FD;&#x6570;&#x65F6;&#x53EF;&#x4EE5;&#x5C06;&#x9700;&#x8981;&#x7684;&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x4F5C;&#x4E3A;&#x989D;&#x5916;&#x7684;&#x53C2;&#x6570; <cite>output_size</cite> &#x4F20;&#x5165;.</p>
<p>&#xFFFD; &#x5177;&#x4F53;&#x7528;&#x6CD5;,&#x8BF7;&#x53C2;&#x9605;&#x4E0B;&#x9762;&#x7684;&#x8F93;&#x5165;&#x548C;&#x793A;&#x4F8B;</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>kernel_size (int &#x6216; tuple)</code> &#x2013; &#x6700;&#x5927;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7684;&#x7A97;&#x53E3;&#x5927;&#x5C0F;</li>
<li><code>stride (int &#x6216; tuple)</code> &#x2013; &#x6700;&#x5927;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7A97;&#x53E3;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x503C;&#x662F; <code>kernel_size</code></li>
<li><code>padding (int &#x6216; tuple)</code> &#x2013; &#x8F93;&#x5165;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x586B;&#x5145;0&#x503C;&#x7684;&#x4E2A;&#x6570;</li>
</ul>
<p>Inputs:</p>
<ul>
<li><code>input</code>: &#x9700;&#x8981;&#x8F6C;&#x5316;&#x7684;&#x8F93;&#x5165;&#x7684; Tensor</li>
<li><code>indices</code>: <code>MaxPool2d</code> &#x63D0;&#x4F9B;&#x7684;&#x6700;&#x5927;&#x503C;&#x7D22;&#x5F15;</li>
<li><code>output_size</code> (&#x53EF;&#x9009;) : <code>torch.Size</code> &#x7C7B;&#x578B;&#x7684;&#x6570;&#x636E;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x7684;&#x5927;&#x5C0F;</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-d5acb55d3d2dd49b5b0d71ab7cf3b2d1.gif" alt="(N, C, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-403ffd9231342159e36ba660b2bf3ff3.gif" alt="(N, C, H_{out}, W_{out})"> &#x9075;&#x4ECE;&#x5982;&#x4E0B;&#x5173;&#x7CFB; <img src="img/tex-bc6952442952352a9c45fd1615b9c8ab.gif" alt="H_{out} = (H_{in} - 1) * stride[0] -2 * padding[0] + kernel\_size[0]"> <img src="img/tex-271dbbdd3ca44e09a3a07b7353048057.gif" alt="W_{out} = (W_{in} - 1) * stride[1] -2 * padding[1] + kernel\_size[1]"> &#x6216;&#x8005;&#x5728;&#x8C03;&#x7528;&#x65F6;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x5927;&#x5C0F; <code>output_size</code></li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>pool = nn.MaxPool2d(<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, return_indices=<span class="hljs-keyword">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>unpool = nn.MaxUnpool2d(<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = Variable(torch.Tensor([[[[ <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>],
<span class="hljs-meta">... </span>                                 [ <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>,  <span class="hljs-number">7</span>,  <span class="hljs-number">8</span>],
<span class="hljs-meta">... </span>                                 [ <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>],
<span class="hljs-meta">... </span>                                 [<span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>, <span class="hljs-number">16</span>]]]]))
<span class="hljs-meta">&gt;&gt;&gt; </span>output, indices = pool(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>unpool(output, indices)
Variable containing:
(<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>
 <span class="hljs-number">0</span>   <span class="hljs-number">6</span>   <span class="hljs-number">0</span>   <span class="hljs-number">8</span>
 <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>
 <span class="hljs-number">0</span>  <span class="hljs-number">14</span>   <span class="hljs-number">0</span>  <span class="hljs-number">16</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x4x4]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># specify a different output size than input size</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>unpool(output, indices, output_size=torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>]))
Variable containing:
(<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>
 <span class="hljs-number">6</span>   <span class="hljs-number">0</span>   <span class="hljs-number">8</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>
 <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>  <span class="hljs-number">14</span>   <span class="hljs-number">0</span>
 <span class="hljs-number">16</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>
 <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x5x5]
</code></pre>
<h3 id="maxunpool3d">MaxUnpool3d</h3>
<pre><code class="lang-py">class torch.nn.MaxUnpool3d(kernel_size, stride=None, padding=0)
</code></pre>
<p><code>MaxPool3d</code> &#x7684;&#x9006;&#x8FC7;&#x7A0B;</p>
<p>&#x8981;&#x6CE8;&#x610F;&#x7684;&#x662F; <code>MaxPool3d</code> &#x5E76;&#x4E0D;&#x662F;&#x5B8C;&#x5168;&#x53EF;&#x9006;&#x7684;, &#x56E0;&#x4E3A;&#x5728;max pooling&#x8FC7;&#x7A0B;&#x4E2D;&#x975E;&#x6700;&#x5927;&#x503C;&#x5DF2;&#x7ECF;&#x4E22;&#x5931; <code>MaxUnpool3d</code> &#x4EE5; <code>MaxPool3d</code> &#x7684;&#x8F93;&#x51FA;, &#x5305;&#x542B;&#x6700;&#x5927;&#x503C;&#x7684;&#x7D22;&#x5F15;&#x4F5C;&#x4E3A;&#x8F93;&#x5165; &#x8BA1;&#x7B97;max poooling&#x7684;&#x90E8;&#x5206;&#x9006;&#x8FC7;&#x7A0B;(&#x5BF9;&#x4E8E;&#x90A3;&#x4E9B;&#x6700;&#x5927;&#x503C;&#x533A;&#x57DF;), &#x5BF9;&#x4E8E;&#x90A3;&#x4E9B;&#x975E;&#x6700;&#x5927;&#x503C;&#x533A;&#x57DF;&#x5C06;&#x8BBE;&#x7F6E;&#x4E3A;0&#x503C;</p>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p><cite>MaxPool3d</cite> &#x53EF;&#x4EE5;&#x5C06;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x5927;&#x5C0F;&#x6620;&#x5C04;&#x5230;&#x76F8;&#x540C;&#x7684;&#x8F93;&#x51FA;&#x5927;&#x5C0F;, &#x56E0;&#x6B64;&#x53CD;&#x6F14;&#x8FC7;&#x7A0B;&#x53EF;&#x80FD;&#x4F1A;&#x6A21;&#x68F1;&#x4E24;&#x53EF;. &#x4E3A;&#x9002;&#x5E94;&#x8FD9;&#x4E00;&#x70B9;, &#x5728;&#x8C03;&#x7528;forward&#x51FD;&#x6570;&#x65F6;&#x53EF;&#x4EE5;&#x5C06;&#x9700;&#x8981;&#x7684;&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x4F5C;&#x4E3A;&#x989D;&#x5916;&#x7684;&#x53C2;&#x6570; <cite>output_size</cite> &#x4F20;&#x5165;.</p>
<p>&#xFFFD; &#x5177;&#x4F53;&#x7528;&#x6CD5;,&#x8BF7;&#x53C2;&#x9605;&#x4E0B;&#x9762;&#x7684;&#x8F93;&#x5165;&#x548C;&#x793A;&#x4F8B;</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>kernel_size (int &#x6216; tuple)</code> &#x2013; &#x6700;&#x5927;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7684;&#x7A97;&#x53E3;&#x5927;&#x5C0F;</li>
<li><code>stride (int &#x6216; tuple)</code> &#x2013; &#x6700;&#x5927;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7A97;&#x53E3;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x503C;&#x662F; <code>kernel_size</code></li>
<li><code>padding (int &#x6216; tuple)</code> &#x2013; &#x8F93;&#x5165;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x586B;&#x5145;0&#x503C;&#x7684;&#x4E2A;&#x6570;</li>
</ul>
<p>Inputs:</p>
<ul>
<li><code>input</code>: &#x9700;&#x8981;&#x8F6C;&#x5316;&#x7684;&#x8F93;&#x5165;&#x7684; Tensor</li>
<li><code>indices</code>: <code>MaxPool3d</code> &#x63D0;&#x4F9B;&#x7684;&#x6700;&#x5927;&#x503C;&#x7D22;&#x5F15;</li>
<li><code>output_size</code> (&#x53EF;&#x9009;) : <code>torch.Size</code> &#x7C7B;&#x578B;&#x7684;&#x6570;&#x636E;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x7684;&#x5927;&#x5C0F;</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-ce19deda602cf16ded15c0fb9cd5d280.gif" alt="(N, C, D_{in}, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-d14df6868b2b3f7ee945a69616a0b867.gif" alt="(N, C, D_{out}, H_{out}, W_{out})"> &#x9075;&#x4ECE;&#x5982;&#x4E0B;&#x5173;&#x7CFB; <img src="img/tex-570c38500306b160a0747f548ed0f215.gif" alt="D_{out} = (D_{in} - 1) * stride[0] - 2 * padding[0] + kernel\_size[0]"> <img src="img/tex-f359d5e863d259e3983a5b5c33f30f38.gif" alt="H_{out} = (H_{in} - 1) * stride[1] - 2 * padding[1] + kernel\_size[1]"> <img src="img/tex-0aaee5bf5ff41e2d03d399eead71c93e.gif" alt="W_{out} = (W_{in} - 1) * stride[2] - 2 * padding[2] + kernel\_size[2]"> &#x6216;&#x8005;&#x5728;&#x8C03;&#x7528;&#x65F6;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x5927;&#x5C0F; <code>output_size</code></li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool of square window of size=3, stride=2</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pool = nn.MaxPool3d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, return_indices=<span class="hljs-keyword">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>unpool = nn.MaxUnpool3d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>output, indices = pool(Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">51</span>, <span class="hljs-number">33</span>, <span class="hljs-number">15</span>)))
<span class="hljs-meta">&gt;&gt;&gt; </span>unpooled_output = unpool(output, indices)
<span class="hljs-meta">&gt;&gt;&gt; </span>unpooled_output.size()
torch.Size([<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">51</span>, <span class="hljs-number">33</span>, <span class="hljs-number">15</span>])
</code></pre>
<h3 id="avgpool1d">AvgPool1d</h3>
<pre><code class="lang-py">class torch.nn.AvgPool1d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E00;&#x7EF4;&#x7684;&#x5E73;&#x5747;&#x6C60;&#x5316; <code>average pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x6700;&#x7B80;&#x5355;&#x7684;&#x4F8B;&#x5B50;, &#x5982;&#x679C;&#x8F93;&#x5165;&#x5927;&#x5C0F;&#x4E3A; <img src="img/tex-543737499dba0095d9151b4fd440b509.gif" alt="(N, C, L)">, &#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x4E3A; <img src="img/tex-5b25a4bc4c225a5e291c54a4166929b8.gif" alt="(N, C, L_{out})">, &#x6C60;&#x5316;&#x7A97;&#x53E3;&#x5927;&#x5C0F; <code>kernel_size</code> &#x4E3A; <img src="img/tex-8ce4b16b22b58894aa86c421e8759df3.gif" alt="k"> &#x8BE5;&#x5C42;&#x8F93;&#x51FA;&#x503C;&#x53EF;&#x4EE5;&#x7528;&#x4E0B;&#x5F0F;&#x7CBE;&#x786E;&#x8BA1;&#x7B97;:</p>
<p><img src="img/tex-5fb224489269649392e58309a75afb8b.gif" alt="\begin{array}{ll} out(N_i, C_j, l) = 1 / k * \sum_{m=0}^{k} input(N_i, C_j, stride * l + m) \end{array}"></p>
<p>&#x5982;&#x679C; <code>padding</code> &#x4E0D;&#x662F;0, &#x90A3;&#x4E48;&#x5728;&#x8F93;&#x5165;&#x6570;&#x636E;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x4E0A;&#x4F1A;&#x9690;&#x5F0F;&#x586B;&#x8865;&#x5BF9;&#x5E94; <code>padding</code> &#x6570;&#x91CF;&#x7684;0&#x503C;&#x70B9;</p>
<p>&#x53C2;&#x6570; <code>kernel_size</code>, <code>stride</code>, <code>padding</code> &#x53EF;&#x4EE5;&#x4E3A;&#x5355;&#x4E2A; <code>int</code> &#x7C7B;&#x578B;&#x7684;&#x6570;&#x636E; &#x6216;&#x8005;&#x662F;&#x4E00;&#x4E2A;&#x5355;&#x5143;&#x7D20;&#x7684;tuple&#x5143;&#x7EC4;</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>kernel_size</code> &#x2013; &#x5E73;&#x5747;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x53D6;&#x5E73;&#x5747;&#x503C;&#x7684;&#x7A97;&#x53E3;&#x7684;&#x5927;&#x5C0F;</li>
<li><code>stride</code> &#x2013; &#x5E73;&#x5747;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7A97;&#x53E3;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x503C;&#x662F; <code>kernel_size</code></li>
<li><code>padding</code> &#x2013; &#x8F93;&#x5165;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x9690;&#x5F0F;&#x8865;0&#x7684;&#x6570;&#x91CF;</li>
<li><code>ceil_mode</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>, &#x5728;&#x8BA1;&#x7B97;&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x65F6;,&#x5C06;&#x91C7;&#x7528;&#x5411;&#x4E0A;&#x53D6;&#x6574;&#x6765;&#x4EE3;&#x66FF;&#x9ED8;&#x8BA4;&#x7684;&#x5411;&#x4E0B;&#x53D6;&#x6574;&#x7684;&#x65B9;&#x5F0F;</li>
<li><code>count_include_pad</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>, &#x5728;&#x8BA1;&#x7B97;&#x5E73;&#x5747;&#x6C60;&#x5316;&#x7684;&#x503C;&#x65F6;,&#x5C06;&#x8003;&#x8651; <code>padding</code> &#x586B;&#x5145;&#x7684;0</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-6c8971de65a57273c075bc491fa6ba0a.gif" alt="(N, C, L_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-5b25a4bc4c225a5e291c54a4166929b8.gif" alt="(N, C, L_{out})"> &#x9075;&#x4ECE;&#x5982;&#x4E0B;&#x5173;&#x7CFB; <img src="img/tex-ff3e003837e50249919e7bf1fa948e5c.gif" alt="L_{out} = floor((L_{in} + 2 * padding - kernel\_size) / stride + 1)"></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool with window of size=3, stride=2</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AvgPool1d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>m(Variable(torch.Tensor([[[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]]])))
Variable containing:
(<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">2</span>  <span class="hljs-number">4</span>  <span class="hljs-number">6</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x3]
</code></pre>
<h3 id="avgpool2d">AvgPool2d</h3>
<pre><code class="lang-py">class torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E8C;&#x7EF4;&#x7684;&#x5E73;&#x5747;&#x6C60;&#x5316; <code>average pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x6700;&#x7B80;&#x5355;&#x7684;&#x4F8B;&#x5B50;,&#x5982;&#x679C;&#x8F93;&#x5165;&#x5927;&#x5C0F;&#x4E3A; <img src="img/tex-38d00342060234da90e0c2c5493892cb.gif" alt="(N, C, H, W)">,&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x4E3A; <img src="img/tex-403ffd9231342159e36ba660b2bf3ff3.gif" alt="(N, C, H_{out}, W_{out})">, &#x6C60;&#x5316;&#x7A97;&#x53E3;&#x5927;&#x5C0F; <code>kernel_size</code> &#x4E3A; <img src="img/tex-11acc7e0901ba5158f843445d5bbdc92.gif" alt="(kH, kW)"> &#x8BE5;&#x5C42;&#x8F93;&#x51FA;&#x503C;&#x53EF;&#x4EE5;&#x7528;&#x4E0B;&#x5F0F;&#x7CBE;&#x786E;&#x8BA1;&#x7B97;:</p>
<p><img src="img/tex-83e390b13d2c73927b15f35344142d36.gif" alt="\begin{array}{ll} out(N_i, C_j, h, w) = 1 / (kH * kW) * \sum_{m=0}^{kH-1} \sum_{n=0}^{kW-1} input(N_i, C_j, stride[0] * h + m, stride[1] * w + n) \end{array}"></p>
<p>&#x5982;&#x679C; <code>padding</code> &#x4E0D;&#x662F;0, &#x90A3;&#x4E48;&#x5728;&#x8F93;&#x5165;&#x6570;&#x636E;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x4E0A;&#x4F1A;&#x9690;&#x5F0F;&#x586B;&#x8865;&#x5BF9;&#x5E94; <code>padding</code> &#x6570;&#x91CF;&#x7684;0&#x503C;&#x70B9;</p>
<p>&#x53C2;&#x6570; <code>kernel_size</code>, <code>stride</code>, <code>padding</code> &#x53EF;&#x4EE5;&#x662F;&#x4EE5;&#x4E0B;&#x4EFB;&#x610F;&#x4E00;&#x79CD;&#x6570;&#x636E;&#x7C7B;&#x578B;:</p>
<blockquote>
<ul>
<li>&#x5355;&#x4E2A; <code>int</code> &#x7C7B;&#x578B;&#x6570;&#x636E; &#x2013; &#x6B64;&#x65F6;&#x5728; height &#x548C; width &#x7EF4;&#x5EA6;&#x4E0A;&#x5C06;&#x4F7F;&#x7528;&#x76F8;&#x540C;&#x7684;&#x503C;</li>
<li>&#x5305;&#x542B;&#x4E24;&#x4E2A; int &#x7C7B;&#x578B;&#x6570;&#x636E;&#x7684; <code>tuple</code> &#x5143;&#x7EC4; &#x2013; &#x6B64;&#x65F6;&#x7B2C;&#x4E00;&#x4E2A; <code>int</code> &#x6570;&#x636E;&#x8868;&#x793A; height &#x7EF4;&#x5EA6;&#x4E0A;&#x7684;&#x6570;&#x503C;, &#x7B2C;&#x4E8C;&#x4E2A; <code>int</code> &#x6570;&#x636E;&#x8868;&#x793A; width &#x7EF4;&#x5EA6;&#x4E0A;&#x7684;&#x6570;&#x503C;</li>
</ul>
</blockquote>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>kernel_size</code> &#x2013; &#x5E73;&#x5747;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x53D6;&#x5E73;&#x5747;&#x503C;&#x7684;&#x7A97;&#x53E3;&#x7684;&#x5927;&#x5C0F;</li>
<li><code>stride</code> &#x2013; &#x5E73;&#x5747;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7A97;&#x53E3;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x503C;&#x662F; <code>kernel_size</code></li>
<li><code>padding</code> &#x2013; &#x8F93;&#x5165;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x9690;&#x5F0F;&#x8865;0&#x7684;&#x6570;&#x91CF;</li>
<li><code>ceil_mode</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>, &#x5728;&#x8BA1;&#x7B97;&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x65F6;,&#x5C06;&#x91C7;&#x7528;&#x5411;&#x4E0A;&#x53D6;&#x6574;&#x6765;&#x4EE3;&#x66FF;&#x9ED8;&#x8BA4;&#x7684;&#x5411;&#x4E0B;&#x53D6;&#x6574;&#x7684;&#x65B9;&#x5F0F;</li>
<li><code>count_include_pad</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>, &#x5728;&#x8BA1;&#x7B97;&#x5E73;&#x5747;&#x6C60;&#x5316;&#x7684;&#x503C;&#x65F6;,&#x5C06;&#x8003;&#x8651; <code>padding</code> &#x586B;&#x5145;&#x7684;0</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-d5acb55d3d2dd49b5b0d71ab7cf3b2d1.gif" alt="(N, C, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-403ffd9231342159e36ba660b2bf3ff3.gif" alt="(N, C, H_{out}, W_{out})"> &#x9075;&#x4ECE;&#x5982;&#x4E0B;&#x5173;&#x7CFB; <img src="img/tex-741bce32e0f25e0789dd133c8f7efabd.gif" alt="H_{out} = floor((H_{in} + 2 * padding[0] - kernel\_size[0]) / stride[0] + 1)"> <img src="img/tex-e529efd000cb956703fed84faea15127.gif" alt="W_{out} = floor((W_{in} + 2 * padding[1] - kernel\_size[1]) / stride[1] + 1)"></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool of square window of size=3, stride=2</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AvgPool2d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool of non-square window</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AvgPool2d((<span class="hljs-number">3</span>, <span class="hljs-number">2</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">50</span>, <span class="hljs-number">32</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="avgpool3d">AvgPool3d</h3>
<pre><code class="lang-py">class torch.nn.AvgPool3d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E09;&#x7EF4;&#x7684;&#x5E73;&#x5747;&#x6C60;&#x5316; <code>average pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x6700;&#x7B80;&#x5355;&#x7684;&#x4F8B;&#x5B50;, &#x5982;&#x679C;&#x8F93;&#x5165;&#x5927;&#x5C0F;&#x4E3A; <img src="img/tex-6d9465a2eb2377437689121f4915b6b4.gif" alt="(N, C, D, H, W)">,&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x4E3A; <img src="img/tex-d14df6868b2b3f7ee945a69616a0b867.gif" alt="(N, C, D_{out}, H_{out}, W_{out})"> &#x6C60;&#x5316;&#x7A97;&#x53E3;&#x5927;&#x5C0F; <code>kernel_size</code> &#x4E3A; <img src="img/tex-b53b272ea52997eb2ccf903b6d58b4bc.gif" alt="(kD, kH, kW)"> &#x8BE5;&#x5C42;&#x8F93;&#x51FA;&#x503C;&#x53EF;&#x4EE5;&#x7528;&#x4E0B;&#x5F0F;&#x7CBE;&#x786E;&#x8BA1;&#x7B97;:</p>
<p><img src="img/tex-fbe2c38eff7c51172e8dab64682e8248.gif" alt="\begin{array}{ll} out(N_i, C_j, d, h, w) = 1 / (kD * kH * kW) * \sum_{k=0}^{kD-1} \sum_{m=0}^{kH-1} \sum_{n=0}^{kW-1} input(N_i, C_j, stride[0] * d + k, stride[1] * h + m, stride[2] * w + n) \end{array}"></p>
<p>&#x5982;&#x679C; <code>padding</code> &#x4E0D;&#x662F;0, &#x90A3;&#x4E48;&#x5728;&#x8F93;&#x5165;&#x6570;&#x636E;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x4E0A;&#x4F1A;&#x9690;&#x5F0F;&#x586B;&#x8865;&#x5BF9;&#x5E94; <code>padding</code> &#x6570;&#x91CF;&#x7684;0&#x503C;&#x70B9;</p>
<p>&#x53C2;&#x6570; <code>kernel_size</code>, <code>stride</code> &#x53EF;&#x4EE5;&#x662F;&#x4EE5;&#x4E0B;&#x4EFB;&#x610F;&#x4E00;&#x79CD;&#x6570;&#x636E;&#x7C7B;&#x578B;:</p>
<blockquote>
<ul>
<li>&#x5355;&#x4E2A; <code>int</code> &#x7C7B;&#x578B;&#x6570;&#x636E; &#x2013; &#x6B64;&#x65F6;&#x5728; depth, height &#x548C; width &#x7EF4;&#x5EA6;&#x4E0A;&#x5C06;&#x4F7F;&#x7528;&#x76F8;&#x540C;&#x7684;&#x503C;</li>
<li>&#x5305;&#x542B;&#x4E09;&#x4E2A; int &#x7C7B;&#x578B;&#x6570;&#x636E;&#x7684; <code>tuple</code> &#x5143;&#x7EC4; &#x2013; &#x6B64;&#x65F6;&#x7B2C;&#x4E00;&#x4E2A; <code>int</code> &#x6570;&#x636E;&#x8868;&#x793A; depth &#x7EF4;&#x5EA6;&#x4E0A;&#x7684;&#x6570;&#x503C;, &#x7B2C;&#x4E8C;&#x4E2A; <code>int</code> &#x6570;&#x636E;&#x8868;&#x793A; height &#x7EF4;&#x5EA6;&#x4E0A;&#x7684;&#x6570;&#x503C;,&#x7B2C;&#x4E09;&#x4E2A; <code>int</code> &#x6570;&#x636E;&#x8868;&#x793A; width &#x7EF4;&#x5EA6;&#x4E0A;&#x7684;&#x6570;&#x503C;</li>
</ul>
</blockquote>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>kernel_size</code> &#x2013; &#x5E73;&#x5747;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x53D6;&#x5E73;&#x5747;&#x503C;&#x7684;&#x7A97;&#x53E3;&#x7684;&#x5927;&#x5C0F;</li>
<li><code>stride</code> &#x2013; &#x5E73;&#x5747;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7A97;&#x53E3;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x503C;&#x662F; <code>kernel_size</code></li>
<li><code>padding</code> &#x2013; &#x8F93;&#x5165;&#x7684;&#x6BCF;&#x6761;&#x8FB9;&#x9690;&#x5F0F;&#x8865;0&#x7684;&#x6570;&#x91CF;</li>
<li><code>ceil_mode</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>, &#x5728;&#x8BA1;&#x7B97;&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x65F6;,&#x5C06;&#x91C7;&#x7528;&#x5411;&#x4E0A;&#x53D6;&#x6574;&#x6765;&#x4EE3;&#x66FF;&#x9ED8;&#x8BA4;&#x7684;&#x5411;&#x4E0B;&#x53D6;&#x6574;&#x7684;&#x65B9;&#x5F0F;</li>
<li><code>count_include_pad</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>, &#x5728;&#x8BA1;&#x7B97;&#x5E73;&#x5747;&#x6C60;&#x5316;&#x7684;&#x503C;&#x65F6;,&#x5C06;&#x8003;&#x8651; <code>padding</code> &#x586B;&#x5145;&#x7684;0</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-ce19deda602cf16ded15c0fb9cd5d280.gif" alt="(N, C, D_{in}, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-d14df6868b2b3f7ee945a69616a0b867.gif" alt="(N, C, D_{out}, H_{out}, W_{out})"> &#x9075;&#x4ECE;&#x5982;&#x4E0B;&#x5173;&#x7CFB; <img src="img/tex-8b48af0f996fb14285ac4c971f261f39.gif" alt="D_{out} = floor((D_{in} + 2 * padding[0] - kernel\_size[0]) / stride[0] + 1)"> <img src="img/tex-442ab69f414e2fff99841eec0edaa03e.gif" alt="H_{out} = floor((H_{in} + 2 * padding[1] - kernel\_size[1]) / stride[1] + 1)"> <img src="img/tex-d5ddd94486a3777d830d45cb65de8dc5.gif" alt="W_{out} = floor((W_{in} + 2 * padding[2] - kernel\_size[2]) / stride[2] + 1)"></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool of square window of size=3, stride=2</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AvgPool3d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool of non-square window</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AvgPool3d((<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">50</span>,<span class="hljs-number">44</span>, <span class="hljs-number">31</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="fractionalmaxpool2d">FractionalMaxPool2d</h3>
<pre><code class="lang-py">class torch.nn.FractionalMaxPool2d(kernel_size, output_size=None, output_ratio=None, return_indices=False, _random_samples=None)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E8C;&#x7EF4;&#x7684;&#x5206;&#x6570;&#x6700;&#x5927;&#x6C60;&#x5316; <code>fractional max pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x5206;&#x6570;&#x6700;&#x5927;&#x6C60;&#x5316; <code>Fractiona MaxPooling</code> &#x7684;&#x5177;&#x4F53;&#x7EC6;&#x8282;&#x63CF;&#x8FF0;,&#x8BE6;&#x89C1;Ben Graham&#x8BBA;&#x6587; <a href="http://arxiv.org/abs/1412.6071" target="_blank">Fractional MaxPooling</a></p>
<p>&#x7531;&#x76EE;&#x6807;&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x786E;&#x5B9A;&#x968F;&#x673A;&#x6B65;&#x957F;,&#x5728; kH x kW &#x533A;&#x57DF;&#x5185;&#x8FDB;&#x884C;&#x6700;&#x5927;&#x6C60;&#x5316;&#x7684;&#x64CD;&#x4F5C; &#x8F93;&#x51FA;&#x7279;&#x5F81;&#x7684;&#x6570;&#x91CF;&#x4E0E;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7684;&#x6570;&#x91CF;&#x76F8;&#x540C;</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>kernel_size</code> &#x2013; &#x6700;&#x5927;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7A97;&#x53E3;&#x7684;&#x5927;&#x5C0F;. &#x53EF;&#x4EE5;&#x662F;&#x5355;&#x4E2A;&#x6570;&#x5B57; k (&#x7B49;&#x4EF7;&#x4E8E; k x k &#x7684;&#x6B63;&#x65B9;&#x5F62;&#x7A97;&#x53E3;) &#x6216;&#x8005;&#x662F; &#x4E00;&#x4E2A;&#x5143;&#x7EC4; tuple (kh x kw)</li>
<li><code>output_size</code> &#x2013; oH x oW &#x5F62;&#x5F0F;&#x7684;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5C3A;&#x5BF8;. &#x53EF;&#x4EE5;&#x7528; &#x4E00;&#x4E2A; tuple &#x5143;&#x7EC4; (oH, oW) &#x8868;&#x793A; oH x oW &#x7684;&#x8F93;&#x51FA;&#x5C3A;&#x5BF8;, &#x6216;&#x8005;&#x662F;&#x5355;&#x4E2A;&#x7684;&#x6570;&#x5B57; oH &#x8868;&#x793A; oH x oH &#x7684;&#x8F93;&#x51FA;&#x5C3A;&#x5BF8;</li>
<li><code>output_ratio</code> &#x2013; &#x5982;&#x679C;&#x60F3;&#x7528;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x7684;&#x767E;&#x5206;&#x6BD4;&#x6765;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5927;&#x5C0F;,&#x53EF;&#x9009;&#x7528;&#x8BE5;&#x9009;&#x9879;. &#x4F7F;&#x7528;&#x8303;&#x56F4;&#x5728; (0,1) &#x4E4B;&#x95F4;&#x7684;&#x4E00;&#x4E2A;&#x503C;&#x6765;&#x6307;&#x5B9A;.</li>
<li><code>return_indices</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>,&#x5728;&#x8FD4;&#x56DE;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x7684;&#x540C;&#x65F6;&#x8FD4;&#x56DE;&#x6700;&#x5927;&#x503C;&#x7684;&#x7D22;&#x5F15;,&#x8BE5;&#x7D22;&#x5F15;&#x5BF9; nn.MaxUnpool2d &#x6709;&#x7528;. &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;&#x8BE5;&#x503C;&#x7B49;&#x4E8E; <code>False</code></li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool of square window of size=3, and target output size 13x12</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.FractionalMaxPool2d(<span class="hljs-number">3</span>, output_size=(<span class="hljs-number">13</span>, <span class="hljs-number">12</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool of square window and target output size being half of input image size</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.FractionalMaxPool2d(<span class="hljs-number">3</span>, output_ratio=(<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">50</span>, <span class="hljs-number">32</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="lppool2d">LPPool2d</h3>
<pre><code class="lang-py">class torch.nn.LPPool2d(norm_type, kernel_size, stride=None, ceil_mode=False)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E8C;&#x7EF4;&#x7684;&#x5E42;&#x5E73;&#x5747;&#x6C60;&#x5316; <code>power-average pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x5728;&#x6BCF;&#x4E2A;&#x7A97;&#x53E3;&#x5185;, &#x8F93;&#x51FA;&#x7684;&#x8BA1;&#x7B97;&#x65B9;&#x5F0F;: <img src="img/tex-c9c65ffb1f46231549f42a241f22e52d.gif" alt="f(X) = pow(sum(pow(X, p)), 1/p)"></p>
<blockquote>
<ul>
<li>&#x5F53; p &#x65E0;&#x7A77;&#x5927;&#x65F6;,&#x7B49;&#x4EF7;&#x4E8E;&#x6700;&#x5927;&#x6C60;&#x5316; <code>Max Pooling</code> &#x64CD;&#x4F5C;</li>
<li>&#x5F53; <code>p=1</code> &#x65F6;, &#x7B49;&#x4EF7;&#x4E8E;&#x5E73;&#x5747;&#x6C60;&#x5316; <code>Average Pooling</code> &#x64CD;&#x4F5C;</li>
</ul>
</blockquote>
<p>&#x53C2;&#x6570; <code>kernel_size</code>, <code>stride</code> &#x53EF;&#x4EE5;&#x662F;&#x4EE5;&#x4E0B;&#x4EFB;&#x610F;&#x4E00;&#x79CD;&#x6570;&#x636E;&#x7C7B;&#x578B;:</p>
<blockquote>
<ul>
<li>&#x5355;&#x4E2A; <code>int</code> &#x7C7B;&#x578B;&#x6570;&#x636E; &#x2013; &#x6B64;&#x65F6;&#x5728;height&#x548C;width&#x7EF4;&#x5EA6;&#x4E0A;&#x5C06;&#x4F7F;&#x7528;&#x76F8;&#x540C;&#x7684;&#x503C;</li>
<li>&#x5305;&#x542B;&#x4E24;&#x4E2A; int &#x7C7B;&#x578B;&#x6570;&#x636E;&#x7684; <code>tuple</code> &#x5143;&#x7EC4; &#x2013; &#x6B64;&#x65F6;&#x7B2C;&#x4E00;&#x4E2A; <code>int</code> &#x6570;&#x636E;&#x8868;&#x793A; height &#x7EF4;&#x5EA6;&#x4E0A;&#x7684;&#x6570;&#x503C;, &#x7B2C;&#x4E8C;&#x4E2A; <code>int</code> &#x6570;&#x636E;&#x8868;&#x793A; width &#x7EF4;&#x5EA6;&#x4E0A;&#x7684;&#x6570;&#x503C;</li>
</ul>
</blockquote>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>kernel_size</code> &#x2013; &#x5E42;&#x5E73;&#x5747;&#x6C60;&#x5316;&#x65F6;&#x7A97;&#x53E3;&#x7684;&#x5927;&#x5C0F;</li>
<li><code>stride</code> &#x2013; &#x5E42;&#x5E73;&#x5747;&#x6C60;&#x5316;&#x64CD;&#x4F5C;&#x65F6;&#x7A97;&#x53E3;&#x79FB;&#x52A8;&#x7684;&#x6B65;&#x957F;, &#x9ED8;&#x8BA4;&#x503C;&#x662F; <code>kernel_size</code></li>
<li><code>ceil_mode</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>, &#x5728;&#x8BA1;&#x7B97;&#x8F93;&#x51FA;&#x5927;&#x5C0F;&#x65F6;,&#x5C06;&#x91C7;&#x7528;&#x5411;&#x4E0A;&#x53D6;&#x6574;&#x6765;&#x4EE3;&#x66FF;&#x9ED8;&#x8BA4;&#x7684;&#x5411;&#x4E0B;&#x53D6;&#x6574;&#x7684;&#x65B9;&#x5F0F;</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-d5acb55d3d2dd49b5b0d71ab7cf3b2d1.gif" alt="(N, C, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-403ffd9231342159e36ba660b2bf3ff3.gif" alt="(N, C, H_{out}, W_{out})"> &#x9075;&#x4ECE;&#x5982;&#x4E0B;&#x5173;&#x7CFB; <img src="img/tex-79b3618ba1cd1e8e6e665aae1b4fc446.gif" alt="H_{out} = floor((H_{in} + 2 * padding[0] - dilation[0] * (kernel\_size[0] - 1) - 1) / stride[0] + 1)"> <img src="img/tex-e9f44b9b5fc42bdb5991cfcd52e2dced.gif" alt="W_{out} = floor((W_{in} + 2 * padding[1] - dilation[1] * (kernel\_size[1] - 1) - 1) / stride[1] + 1)"></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># power-2 pool of square window of size=3, stride=2</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.LPPool2d(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># pool of non-square window of power 1.2</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.LPPool2d(<span class="hljs-number">1.2</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">2</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">50</span>, <span class="hljs-number">32</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="adaptivemaxpool1d">AdaptiveMaxPool1d</h3>
<pre><code class="lang-py">class torch.nn.AdaptiveMaxPool1d(output_size, return_indices=False)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E00;&#x7EF4;&#x7684;&#x81EA;&#x9002;&#x5E94;&#x6700;&#x5927;&#x6C60;&#x5316; <code>adaptive max pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x5BF9;&#x4E8E;&#x4EFB;&#x610F;&#x5927;&#x5C0F;&#x7684;&#x8F93;&#x5165;,&#x53EF;&#x4EE5;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x7684;&#x5C3A;&#x5BF8;&#x4E3A; H &#x8F93;&#x51FA;&#x7279;&#x5F81;&#x7684;&#x6570;&#x91CF;&#x4E0E;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7684;&#x6570;&#x91CF;&#x76F8;&#x540C;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>output_size</code> &#x2013; &#x76EE;&#x6807;&#x8F93;&#x51FA;&#x7684;&#x5C3A;&#x5BF8; H</li>
<li><code>return_indices</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>,&#x5728;&#x8FD4;&#x56DE;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x7684;&#x540C;&#x65F6;&#x8FD4;&#x56DE;&#x6700;&#x5927;&#x503C;&#x7684;&#x7D22;&#x5F15;,&#x8BE5;&#x7D22;&#x5F15;&#x5BF9; nn.MaxUnpool1d &#x6709;&#x7528;. &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;&#x8BE5;&#x503C;&#x7B49;&#x4E8E; <code>False</code></li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># target output size of 5</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AdaptiveMaxPool1d(<span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">8</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="adaptivemaxpool2d">AdaptiveMaxPool2d</h3>
<pre><code class="lang-py">class torch.nn.AdaptiveMaxPool2d(output_size, return_indices=False)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E8C;&#x7EF4;&#x7684;&#x81EA;&#x9002;&#x5E94;&#x6700;&#x5927;&#x6C60;&#x5316; <code>adaptive max pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x5BF9;&#x4E8E;&#x4EFB;&#x610F;&#x5927;&#x5C0F;&#x7684;&#x8F93;&#x5165;,&#x53EF;&#x4EE5;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x7684;&#x5C3A;&#x5BF8;&#x4E3A; H x W &#x8F93;&#x51FA;&#x7279;&#x5F81;&#x7684;&#x6570;&#x91CF;&#x4E0E;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7684;&#x6570;&#x91CF;&#x76F8;&#x540C;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>output_size</code> &#x2013; H x W &#x5F62;&#x5F0F;&#x7684;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5C3A;&#x5BF8;. &#x53EF;&#x4EE5;&#x7528; &#x4E00;&#x4E2A; tuple &#x5143;&#x7EC4; (H, W) &#x8868;&#x793A; H x W &#x7684;&#x8F93;&#x51FA;&#x5C3A;&#x5BF8;, &#x6216;&#x8005;&#x662F;&#x5355;&#x4E2A;&#x7684;&#x6570;&#x5B57; H &#x8868;&#x793A; H x H &#x7684;&#x8F93;&#x51FA;&#x5C3A;&#x5BF8;</li>
<li><code>return_indices</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>,&#x5728;&#x8FD4;&#x56DE;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x7684;&#x540C;&#x65F6;&#x8FD4;&#x56DE;&#x6700;&#x5927;&#x503C;&#x7684;&#x7D22;&#x5F15;,&#x8BE5;&#x7D22;&#x5F15;&#x5BF9; nn.MaxUnpool2d &#x6709;&#x7528;. &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;&#x8BE5;&#x503C;&#x7B49;&#x4E8E; <code>False</code></li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># target output size of 5x7</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AdaptiveMaxPool2d((<span class="hljs-number">5</span>,<span class="hljs-number">7</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># target output size of 7x7 (square)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AdaptiveMaxPool2d(<span class="hljs-number">7</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">10</span>, <span class="hljs-number">9</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="adaptivemaxpool3d">AdaptiveMaxPool3d</h3>
<pre><code class="lang-py">class torch.nn.AdaptiveMaxPool3d(output_size, return_indices=False)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E09;&#x7EF4;&#x7684;&#x81EA;&#x9002;&#x5E94;&#x6700;&#x5927;&#x6C60;&#x5316; <code>adaptive max pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x5BF9;&#x4E8E;&#x4EFB;&#x610F;&#x5927;&#x5C0F;&#x7684;&#x8F93;&#x5165;,&#x53EF;&#x4EE5;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x7684;&#x5C3A;&#x5BF8;&#x4E3A; D x H x W &#x8F93;&#x51FA;&#x7279;&#x5F81;&#x7684;&#x6570;&#x91CF;&#x4E0E;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7684;&#x6570;&#x91CF;&#x76F8;&#x540C;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>output_size</code> &#x2013; D x H x W &#x5F62;&#x5F0F;&#x7684;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5C3A;&#x5BF8;. &#x53EF;&#x4EE5;&#x7528; &#x4E00;&#x4E2A; tuple &#x5143;&#x7EC4; (D, H, W) &#x8868;&#x793A; D x H x W &#x7684;&#x8F93;&#x51FA;&#x5C3A;&#x5BF8;, &#x6216;&#x8005;&#x662F;&#x5355;&#x4E2A;&#x7684;&#x6570;&#x5B57; D &#x8868;&#x793A; D x D x D &#x7684;&#x8F93;&#x51FA;&#x5C3A;&#x5BF8;</li>
<li><code>return_indices</code> &#x2013; &#x5982;&#x679C;&#x7B49;&#x4E8E; <code>True</code>,&#x5728;&#x8FD4;&#x56DE;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x7684;&#x540C;&#x65F6;&#x8FD4;&#x56DE;&#x6700;&#x5927;&#x503C;&#x7684;&#x7D22;&#x5F15;,&#x8BE5;&#x7D22;&#x5F15;&#x5BF9; nn.MaxUnpool3d &#x6709;&#x7528;. &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;&#x8BE5;&#x503C;&#x7B49;&#x4E8E; <code>False</code></li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># target output size of 5x7x9</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AdaptiveMaxPool3d((<span class="hljs-number">5</span>,<span class="hljs-number">7</span>,<span class="hljs-number">9</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># target output size of 7x7x7 (cube)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AdaptiveMaxPool3d(<span class="hljs-number">7</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">10</span>, <span class="hljs-number">9</span>, <span class="hljs-number">8</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="adaptiveavgpool1d">AdaptiveAvgPool1d</h3>
<pre><code class="lang-py">class torch.nn.AdaptiveAvgPool1d(output_size)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E00;&#x7EF4;&#x7684;&#x81EA;&#x9002;&#x5E94;&#x5E73;&#x5747;&#x6C60;&#x5316; <code>adaptive average pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x5BF9;&#x4E8E;&#x4EFB;&#x610F;&#x5927;&#x5C0F;&#x7684;&#x8F93;&#x5165;,&#x53EF;&#x4EE5;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x7684;&#x5C3A;&#x5BF8;&#x4E3A; H &#x8F93;&#x51FA;&#x7279;&#x5F81;&#x7684;&#x6570;&#x91CF;&#x4E0E;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7684;&#x6570;&#x91CF;&#x76F8;&#x540C;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;output_size &#x2013; &#x76EE;&#x6807;&#x8F93;&#x51FA;&#x7684;&#x5C3A;&#x5BF8; H</p>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># target output size of 5</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AdaptiveAvgPool1d(<span class="hljs-number">5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">8</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="adaptiveavgpool2d">AdaptiveAvgPool2d</h3>
<pre><code class="lang-py">class torch.nn.AdaptiveAvgPool2d(output_size)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E8C;&#x7EF4;&#x7684;&#x81EA;&#x9002;&#x5E94;&#x5E73;&#x5747;&#x6C60;&#x5316; <code>adaptive average pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x5BF9;&#x4E8E;&#x4EFB;&#x610F;&#x5927;&#x5C0F;&#x7684;&#x8F93;&#x5165;,&#x53EF;&#x4EE5;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x7684;&#x5C3A;&#x5BF8;&#x4E3A; H x W &#x8F93;&#x51FA;&#x7279;&#x5F81;&#x7684;&#x6570;&#x91CF;&#x4E0E;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7684;&#x6570;&#x91CF;&#x76F8;&#x540C;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;output_size &#x2013; H x W &#x5F62;&#x5F0F;&#x7684;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5C3A;&#x5BF8;. &#x53EF;&#x4EE5;&#x7528; &#x4E00;&#x4E2A; tuple &#x5143;&#x7EC4; (H, W) &#x8868;&#x793A; H x W &#x7684;&#x8F93;&#x51FA;&#x5C3A;&#x5BF8;, &#x6216;&#x8005;&#x662F;&#x5355;&#x4E2A;&#x7684;&#x6570;&#x5B57; H &#x8868;&#x793A; H x H &#x7684;&#x8F93;&#x51FA;&#x5C3A;&#x5BF8;</p>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># target output size of 5x7</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AdaptiveAvgPool2d((<span class="hljs-number">5</span>,<span class="hljs-number">7</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># target output size of 7x7 (square)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AdaptiveAvgPool2d(<span class="hljs-number">7</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">10</span>, <span class="hljs-number">9</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="adaptiveavgpool3d">AdaptiveAvgPool3d</h3>
<pre><code class="lang-py">class torch.nn.AdaptiveAvgPool3d(output_size)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;,&#x5E94;&#x7528;&#x4E09;&#x7EF4;&#x7684;&#x81EA;&#x9002;&#x5E94;&#x5E73;&#x5747;&#x6C60;&#x5316; <code>adaptive average pooling</code> &#x64CD;&#x4F5C;</p>
<p>&#x5BF9;&#x4E8E;&#x4EFB;&#x610F;&#x5927;&#x5C0F;&#x7684;&#x8F93;&#x5165;,&#x53EF;&#x4EE5;&#x6307;&#x5B9A;&#x8F93;&#x51FA;&#x7684;&#x5C3A;&#x5BF8;&#x4E3A; D x H x W &#x8F93;&#x51FA;&#x7279;&#x5F81;&#x7684;&#x6570;&#x91CF;&#x4E0E;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7684;&#x6570;&#x91CF;&#x76F8;&#x540C;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;output_size &#x2013; D x H x W &#x5F62;&#x5F0F;&#x7684;&#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5C3A;&#x5BF8;. &#x53EF;&#x4EE5;&#x7528; &#x4E00;&#x4E2A; tuple &#x5143;&#x7EC4; (D, H, W) &#x8868;&#x793A; D x H x W &#x7684;&#x8F93;&#x51FA;&#x5C3A;&#x5BF8;, &#x6216;&#x8005;&#x662F;&#x5355;&#x4E2A;&#x7684;&#x6570;&#x5B57; D &#x8868;&#x793A; D x D x D &#x7684;&#x8F93;&#x51FA;&#x5C3A;&#x5BF8;</p>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># target output size of 5x7x9</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AdaptiveAvgPool3d((<span class="hljs-number">5</span>,<span class="hljs-number">7</span>,<span class="hljs-number">9</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># target output size of 7x7x7 (cube)</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.AdaptiveAvgPool3d(<span class="hljs-number">7</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">10</span>, <span class="hljs-number">9</span>, <span class="hljs-number">8</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h2 id="padding-layers-&#x586B;&#x5145;&#x5C42;">Padding Layers (&#x586B;&#x5145;&#x5C42;)</h2>
<h3 id="reflectionpad2d">ReflectionPad2d</h3>
<pre><code class="lang-py">class torch.nn.ReflectionPad2d(padding)
</code></pre>
<p>&#x4F7F;&#x7528;&#x8F93;&#x5165;&#x8FB9;&#x754C;&#x7684;&#x53CD;&#x5C04;&#x586B;&#x5145;&#x8F93;&#x5165;&#x5F20;&#x91CF;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>padding (int, tuple)</code> &#x2013; &#x586B;&#x5145;&#x7684;&#x5927;&#x5C0F;. &#x5982;&#x679C;&#x662F;int, &#x5219;&#x5728;&#x6240;&#x6709;&#x8FB9;&#x754C;&#x586B;&#x5145;&#x4F7F;&#x7528;&#x76F8;&#x540C;&#x7684;.</li>
<li><code>&#x5219;&#x4F7F;&#x7528; (_&#x5982;&#x679C;&#x662F;4&#x4E2A;&#x5143;&#x7EC4;_,)</code> &#x2013;</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-d5acb55d3d2dd49b5b0d71ab7cf3b2d1.gif" alt="(N, C, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-403ffd9231342159e36ba660b2bf3ff3.gif" alt="(N, C, H_{out}, W_{out})"> where <img src="img/tex-aadeb8a243fd73b11a90d3e81647b9ce.gif" alt="H_{out} = H_{in} + paddingTop + paddingBottom"> <img src="img/tex-b59826cca9d58f84da90f697b0482901.gif" alt="W_{out} = W_{in} + paddingLeft + paddingRight"></li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ReflectionPad2d(<span class="hljs-number">3</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">16</span>, <span class="hljs-number">3</span>, <span class="hljs-number">320</span>, <span class="hljs-number">480</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># &#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x7684;&#x586B;&#x5145;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ReflectionPad2d((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">6</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="replicationpad2d">ReplicationPad2d</h3>
<pre><code class="lang-py">class torch.nn.ReplicationPad2d(padding)
</code></pre>
<p>&#x4F7F;&#x7528;&#x8F93;&#x5165;&#x8FB9;&#x754C;&#x7684;&#x590D;&#x5236;&#x586B;&#x5145;&#x8F93;&#x5165;&#x5F20;&#x91CF;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;<code>padding (int, tuple)</code> &#x2013; &#x586B;&#x5145;&#x7684;&#x5927;&#x5C0F;. &#x5982;&#x679C;&#x662F;int, &#x5219;&#x5728;&#x6240;&#x6709;&#x8FB9;&#x754C;&#x4F7F;&#x7528;&#x76F8;&#x540C;&#x7684;&#x586B;&#x5145;. &#x5982;&#x679C;&#x662F;4&#x4E2A;&#x5143;&#x7EC4;, &#x5219;&#x4F7F;&#x7528;(paddingLeft, paddingRight, paddingTop, paddingBottom)</p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-d5acb55d3d2dd49b5b0d71ab7cf3b2d1.gif" alt="(N, C, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-403ffd9231342159e36ba660b2bf3ff3.gif" alt="(N, C, H_{out}, W_{out})"> where <img src="img/tex-aadeb8a243fd73b11a90d3e81647b9ce.gif" alt="H_{out} = H_{in} + paddingTop + paddingBottom"> <img src="img/tex-b59826cca9d58f84da90f697b0482901.gif" alt="W_{out} = W_{in} + paddingLeft + paddingRight"></li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ReplicationPad2d(<span class="hljs-number">3</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">16</span>, <span class="hljs-number">3</span>, <span class="hljs-number">320</span>, <span class="hljs-number">480</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># &#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x7684;&#x586B;&#x5145;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ReplicationPad2d((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">6</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="replicationpad3d">ReplicationPad3d</h3>
<pre><code class="lang-py">class torch.nn.ReplicationPad3d(padding)
</code></pre>
<p>&#x4F7F;&#x7528;&#x8F93;&#x5165;&#x8FB9;&#x754C;&#x7684;&#x590D;&#x5236;&#x586B;&#x5145;&#x8F93;&#x5165;&#x5F20;&#x91CF;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>padding (int, tuple)</code> &#x2013; &#x586B;&#x5145;&#x7684;&#x5927;&#x5C0F;. &#x5982;&#x679C;&#x662F;int, &#x5219;&#x5728;&#x6240;&#x6709;&#x8FB9;&#x754C;&#x4F7F;&#x7528;&#x76F8;&#x540C;&#x7684;&#x586B;&#x5145;.</li>
<li><code>&#x5219;&#x4F7F;&#x7528; (paddingLeft, paddingRight, (_&#x5982;&#x679C;&#x662F;&#x56DB;&#x4E2A;&#x5143;&#x7EC4;_,)</code> &#x2013;</li>
<li>paddingBottom, paddingFront, paddingBack) (<em>paddingTop</em>,) &#x2013;</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-ce19deda602cf16ded15c0fb9cd5d280.gif" alt="(N, C, D_{in}, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-d14df6868b2b3f7ee945a69616a0b867.gif" alt="(N, C, D_{out}, H_{out}, W_{out})"> where <img src="img/tex-1c73dcb800c79e8783388e4bd8318e9b.gif" alt="D_{out} = D_{in} + paddingFront + paddingBack"> <img src="img/tex-aadeb8a243fd73b11a90d3e81647b9ce.gif" alt="H_{out} = H_{in} + paddingTop + paddingBottom"> <img src="img/tex-b59826cca9d58f84da90f697b0482901.gif" alt="W_{out} = W_{in} + paddingLeft + paddingRight"></li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ReplicationPad3d(<span class="hljs-number">3</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">16</span>, <span class="hljs-number">3</span>, <span class="hljs-number">8</span>, <span class="hljs-number">320</span>, <span class="hljs-number">480</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># &#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x7684;&#x586B;&#x5145;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ReplicationPad3d((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">6</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="zeropad2d">ZeroPad2d</h3>
<pre><code class="lang-py">class torch.nn.ZeroPad2d(padding)
</code></pre>
<p>&#x7528;&#x96F6;&#x586B;&#x5145;&#x8F93;&#x5165;&#x5F20;&#x91CF;&#x8FB9;&#x754C;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>padding (int, tuple)</code> &#x2013; &#x586B;&#x5145;&#x7684;&#x5927;&#x5C0F;. &#x5982;&#x679C;&#x662F;int, &#x5219;&#x5728;&#x6240;&#x6709;&#x8FB9;&#x754C;&#x4F7F;&#x7528;&#x76F8;&#x540C;&#x7684;&#x586B;&#x5145;.</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-d5acb55d3d2dd49b5b0d71ab7cf3b2d1.gif" alt="(N, C, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-403ffd9231342159e36ba660b2bf3ff3.gif" alt="(N, C, H_{out}, W_{out})"> where <img src="img/tex-aadeb8a243fd73b11a90d3e81647b9ce.gif" alt="H_{out} = H_{in} + paddingTop + paddingBottom"> <img src="img/tex-b59826cca9d58f84da90f697b0482901.gif" alt="W_{out} = W_{in} + paddingLeft + paddingRight"></li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ZeroPad2d(<span class="hljs-number">3</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">16</span>, <span class="hljs-number">3</span>, <span class="hljs-number">320</span>, <span class="hljs-number">480</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># &#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x7684;&#x586B;&#x5145;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ZeroPad2d((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">6</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="constantpad2d">ConstantPad2d</h3>
<pre><code class="lang-py">class torch.nn.ConstantPad2d(padding, value)
</code></pre>
<p>&#x7528;&#x4E00;&#x4E2A;&#x5E38;&#x6570;&#x503C;&#x586B;&#x5145;&#x8F93;&#x5165;&#x5F20;&#x91CF;&#x8FB9;&#x754C;.</p>
<p>&#x5BF9;&#x4E8E; Nd-padding, &#x4F7F;&#x7528; nn.functional.pad().</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>padding (int, tuple)</code> &#x2013; &#x586B;&#x5145;&#x7684;&#x5927;&#x5C0F;. &#x5982;&#x679C;&#x662F;int, &#x5219;&#x5728;&#x6240;&#x6709;&#x8FB9;&#x754C;&#x4F7F;&#x7528;&#x76F8;&#x540C;&#x7684;&#x586B;&#x5145;.</li>
<li><code>value</code> &#x2013;</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-d5acb55d3d2dd49b5b0d71ab7cf3b2d1.gif" alt="(N, C, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-403ffd9231342159e36ba660b2bf3ff3.gif" alt="(N, C, H_{out}, W_{out})"> where <img src="img/tex-aadeb8a243fd73b11a90d3e81647b9ce.gif" alt="H_{out} = H_{in} + paddingTop + paddingBottom"> <img src="img/tex-b59826cca9d58f84da90f697b0482901.gif" alt="W_{out} = W_{in} + paddingLeft + paddingRight"></li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ConstantPad2d(<span class="hljs-number">3</span>, <span class="hljs-number">3.5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">16</span>, <span class="hljs-number">3</span>, <span class="hljs-number">320</span>, <span class="hljs-number">480</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># &#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x7684;&#x586B;&#x5145;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ConstantPad2d((<span class="hljs-number">3</span>, <span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">6</span>), <span class="hljs-number">3.5</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h2 id="non-linear-activations-&#x975E;&#x7EBF;&#x6027;&#x5C42;">Non-linear Activations (&#x975E;&#x7EBF;&#x6027;&#x5C42;)</h2>
<h3 id="relu">ReLU</h3>
<pre><code class="lang-py">class torch.nn.ReLU(inplace=False)
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x8FD0;&#x7528;&#x4FEE;&#x6B63;&#x7EBF;&#x6027;&#x5355;&#x5143;&#x51FD;&#x6570; <img src="img/tex-98df823380c3c79a6f2651016f4e2d04.gif" alt="{ReLU}(x)= max(0, x)"></p>
<p>&#x53C2;&#x6570;&#xFF1A;inplace &#x2013; &#x9009;&#x62E9;&#x662F;&#x5426;&#x8FDB;&#x884C;&#x8986;&#x76D6;&#x8FD0;&#x7B97; Default: <code>False</code></p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> <code>*</code> &#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x6570;&#x76EE;&#x9644;&#x52A0;&#x7EF4;&#x5EA6;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x4E0E;&#x8F93;&#x5165;&#x62E5;&#x6709;&#x540C;&#x6837;&#x7684; shape &#x5C5E;&#x6027;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ReLU()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="relu6">ReLU6</h3>
<pre><code class="lang-py">class torch.nn.ReLU6(inplace=False)
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#x8FD0;&#x7528;&#x51FD;&#x6570; <img src="img/tex-5c301d6fee27c04949bb9a71a985c404.gif" alt="{ReLU6}(x) = min(max(0,x), 6)"></p>
<p>&#x53C2;&#x6570;&#xFF1A;inplace &#x2013; &#x9009;&#x62E9;&#x662F;&#x5426;&#x8FDB;&#x884C;&#x8986;&#x76D6;&#x8FD0;&#x7B97; &#x9ED8;&#x8BA4;&#x503C;: <code>False</code></p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, <code>*</code> &#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x6570;&#x76EE;&#x9644;&#x52A0;&#x7EF4;&#x5EA6;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x4E0E;&#x8F93;&#x5165;&#x62E5;&#x6709;&#x540C;&#x6837;&#x7684; shape &#x5C5E;&#x6027;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ReLU6()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="elu">ELU</h3>
<pre><code class="lang-py">class torch.nn.ELU(alpha=1.0, inplace=False)
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#x8FD0;&#x7528;&#x51FD;&#x6570;, <img src="img/tex-41cc8dcdf01c5ef5ba2584557d879fa6.gif" alt="f(x) = max(0,x) + min(0, alpha * (exp(x) - 1))"></p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>alpha</code> &#x2013; ELU &#x5B9A;&#x4E49;&#x516C;&#x5F0F;&#x4E2D;&#x7684; alpha &#x503C;. &#x9ED8;&#x8BA4;&#x503C;: 1.0</li>
<li><code>inplace</code> &#x2013; &#x9009;&#x62E9;&#x662F;&#x5426;&#x8FDB;&#x884C;&#x8986;&#x76D6;&#x8FD0;&#x7B97; &#x9ED8;&#x8BA4;&#x503C;: <code>False</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> <code>*</code> &#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x6570;&#x76EE;&#x9644;&#x52A0;&#x7EF4;&#x5EA6;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x4E0E;&#x8F93;&#x5165;&#x62E5;&#x6709;&#x540C;&#x6837;&#x7684; shape &#x5C5E;&#x6027;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.ELU()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="selu">SELU</h3>
<pre><code class="lang-py">class torch.nn.SELU(inplace=False)
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#x8FD0;&#x7528;&#x51FD;&#x6570;, <img src="img/tex-5b47266764559d96f29472d6fa7549cf.gif" alt="f(x) = scale * (\max(0,x) + \min(0, alpha * (\exp(x) - 1)))">, <code>alpha=1.6732632423543772848170429916717</code>, <code>scale=1.0507009873554804934193349852946</code>.</p>
<p>&#x66F4;&#x591A;&#x5730;&#x7EC6;&#x8282;&#x53EF;&#x4EE5;&#x53C2;&#x9605;&#x8BBA;&#x6587; <a href="https://arxiv.org/abs/1706.02515" target="_blank">Self-Normalizing Neural Networks</a> .</p>
<p>&#x53C2;&#x6570;&#xFF1A;<code>inplace (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9009;&#x62E9;&#x662F;&#x5426;&#x8FDB;&#x884C;&#x8986;&#x76D6;&#x8FD0;&#x7B97;. &#x9ED8;&#x8BA4;&#x503C;: <code>False</code></p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> where <code>*</code> means, any number of additional dimensions</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, same shape as the input</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.SELU()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="prelu">PReLU</h3>
<pre><code class="lang-py">class torch.nn.PReLU(num_parameters=1, init=0.25)
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#x8FD0;&#x7528;&#x51FD;&#x6570; <img src="img/tex-1fdf83b42b80c315119cb53c14c86985.gif" alt="PReLU(x) = max(0,x) + a * min(0,x)"> &#x8FD9;&#x91CC;&#x7684; &#x201C;a&#x201D; &#x662F;&#x81EA;&#x5B66;&#x4E60;&#x7684;&#x53C2;&#x6570;. &#x5F53;&#x4E0D;&#x5E26;&#x53C2;&#x6570;&#x5730;&#x8C03;&#x7528;&#x65F6;, nn.PReLU() &#x5728;&#x6240;&#x6709;&#x8F93;&#x5165;&#x901A;&#x9053;&#x4E2D;&#x4F7F;&#x7528;&#x5355;&#x4E2A;&#x53C2;&#x6570; &#x201C;a&#x201D; . &#x800C;&#x5982;&#x679C;&#x7528; nn.PReLU(nChannels) &#x8C03;&#x7528;, &#x201C;a&#x201D; &#x5C06;&#x5E94;&#x7528;&#x5230;&#x6BCF;&#x4E2A;&#x8F93;&#x5165;.</p>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x5F53;&#x4E3A;&#x4E86;&#x8868;&#x73B0;&#x66F4;&#x4F73;&#x7684;&#x6A21;&#x578B;&#x800C;&#x5B66;&#x4E60;&#x53C2;&#x6570; &#x201C;a&#x201D; &#x65F6;&#x4E0D;&#x8981;&#x4F7F;&#x7528;&#x6743;&#x91CD;&#x8870;&#x51CF; (weight decay)</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>num_parameters</code> &#x2013; &#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684; &#x201C;a&#x201D; &#x7684;&#x4E2A;&#x6570;. &#x9ED8;&#x8BA4;&#x7B49;&#x4E8E;1</li>
<li><code>init</code> &#x2013; &#x201C;a&#x201D; &#x7684;&#x521D;&#x59CB;&#x503C;. &#x9ED8;&#x8BA4;&#x7B49;&#x4E8E;0.25</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> &#x5176;&#x4E2D; <code>*</code> &#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x6570;&#x76EE;&#x7684;&#x9644;&#x52A0;&#x7EF4;&#x5EA6;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x548C;&#x8F93;&#x5165;&#x7684;&#x683C;&#x5F0F; shape &#x4E00;&#x81F4;</li>
</ul>
<p>&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.PReLU()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="leakyrelu">LeakyReLU</h3>
<pre><code class="lang-py">class torch.nn.LeakyReLU(negative_slope=0.01, inplace=False)
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#x8FD0;&#x7528;, <img src="img/tex-82e596913d879999b551a54f1e7b1d62.gif" alt="f(x) = max(0, x) + {negative\_slope} * min(0, x)"></p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>negative_slope</code> &#x2013; &#x63A7;&#x5236;&#x8D1F;&#x659C;&#x7387;&#x7684;&#x89D2;&#x5EA6;, &#x9ED8;&#x8BA4;&#x503C;: 1e-2</li>
<li><code>inplace</code> &#x2013; &#x9009;&#x62E9;&#x662F;&#x5426;&#x8FDB;&#x884C;&#x8986;&#x76D6;&#x8FD0;&#x7B97; &#x9ED8;&#x8BA4;&#x503C;: <code>False</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> &#x5176;&#x4E2D; <code>*</code> &#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x6570;&#x76EE;&#x7684;&#x9644;&#x52A0;&#x7EF4;&#x5EA6;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x548C;&#x8F93;&#x5165;&#x7684;&#x683C;&#x5F0F;shape&#x4E00;&#x81F4;</li>
</ul>
<p>&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.LeakyReLU(<span class="hljs-number">0.1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="threshold">Threshold</h3>
<pre><code class="lang-py">class torch.nn.Threshold(threshold, value, inplace=False)
</code></pre>
<p>&#x57FA;&#x4E8E; Tensor &#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x521B;&#x9020;&#x9608;&#x503C;&#x51FD;&#x6570;</p>
<p>Threshold &#x88AB;&#x5B9A;&#x4E49;&#x4E3A;</p>
<pre><code class="lang-py">y =  x        <span class="hljs-keyword">if</span> x &gt;  threshold
     value    <span class="hljs-keyword">if</span> x &lt;= threshold
</code></pre>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>threshold</code> &#x2013; &#x9608;&#x503C;</li>
<li><code>value</code> &#x2013; &#x8F93;&#x5165;&#x503C;&#x5C0F;&#x4E8E;&#x9608;&#x503C;&#x5219;&#x4F1A;&#x88AB; value &#x4EE3;&#x66FF;</li>
<li><code>inplace</code> &#x2013; &#x9009;&#x62E9;&#x662F;&#x5426;&#x8FDB;&#x884C;&#x8986;&#x76D6;&#x8FD0;&#x7B97;. &#x9ED8;&#x8BA4;&#x503C;: <code>False</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> &#x5176;&#x4E2D; <code>*</code> &#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x6570;&#x76EE;&#x7684;&#x9644;&#x52A0;&#x7EF4;&#x5EA6;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x548C;&#x8F93;&#x5165;&#x7684;&#x683C;&#x5F0F; shape &#x4E00;&#x81F4;</li>
</ul>
<p>&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Threshold(<span class="hljs-number">0.1</span>, <span class="hljs-number">20</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="hardtanh">Hardtanh</h3>
<pre><code class="lang-py">class torch.nn.Hardtanh(min_val=-1, max_val=1, inplace=False, min_value=None, max_value=None)
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#x8FD0;&#x7528; HardTanh</p>
<p>HardTanh &#x88AB;&#x5B9A;&#x4E49;&#x4E3A;:</p>
<pre><code class="lang-py">f(x) = +<span class="hljs-number">1</span>, <span class="hljs-keyword">if</span> x  &gt;  <span class="hljs-number">1</span>
f(x) = <span class="hljs-number">-1</span>, <span class="hljs-keyword">if</span> x  &lt; <span class="hljs-number">-1</span>
f(x) =  x,  otherwise
</code></pre>
<p>&#x7EBF;&#x6027;&#x533A;&#x57DF;&#x7684;&#x8303;&#x56F4; <img src="img/tex-7dec1d46e68831c4eca28b020fcb1604.gif" alt="[-1, 1]"> &#x53EF;&#x4EE5;&#x88AB;&#x8C03;&#x6574;</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>min_val</code> &#x2013; &#x7EBF;&#x6027;&#x533A;&#x57DF;&#x8303;&#x56F4;&#x6700;&#x5C0F;&#x503C;. &#x9ED8;&#x8BA4;&#x503C;: -1</li>
<li><code>max_val</code> &#x2013; &#x7EBF;&#x6027;&#x533A;&#x57DF;&#x8303;&#x56F4;&#x6700;&#x5927;&#x503C;. &#x9ED8;&#x8BA4;&#x503C;: 1</li>
<li><code>inplace</code> &#x2013; &#x9009;&#x62E9;&#x662F;&#x5426;&#x8FDB;&#x884C;&#x8986;&#x76D6;&#x8FD0;&#x7B97;. &#x9ED8;&#x8BA4;&#x503C;: <code>False</code></li>
</ul>
<p>&#x5173;&#x952E;&#x5B57;&#x53C2;&#x6570; <code>min_value</code> &#x4EE5;&#x53CA; <code>max_value</code> &#x5DF2;&#x88AB;&#x5F03;&#x7528;. &#x66F4;&#x6539;&#x4E3A; <code>min_val</code> &#x548C; <code>max_val</code></p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> &#x5176;&#x4E2D; <code>*</code> &#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x7EF4;&#x5EA6;&#x7EC4;&#x5408;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x4E0E;&#x8F93;&#x5165;&#x6709;&#x76F8;&#x540C;&#x7684; shape &#x5C5E;&#x6027;</li>
</ul>
<p>&#x4F8B;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Hardtanh(<span class="hljs-number">-2</span>, <span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="sigmoid">Sigmoid</h3>
<pre><code class="lang-py">class torch.nn.Sigmoid
</code></pre>
<p>&#x5BF9;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x8FD0;&#x7528; Sigmoid &#x51FD;&#x6570;. Sigmoid &#x5B9A;&#x4E49;&#x5982;&#x4E0B; <img src="img/tex-8d2c9846ab7f8067f6c3890e303e2a58.gif" alt="f(x) = 1 / ( 1 + exp(-x))"></p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> <code>*</code> &#x8868;&#x793A;&#x4EFB;&#x610F;&#x7EF4;&#x5EA6;&#x7EC4;&#x5408;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x4E0E;&#x8F93;&#x5165;&#x6709;&#x76F8;&#x540C;&#x7684; shape &#x5C5E;&#x6027;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Sigmoid()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="tanh">Tanh</h3>
<pre><code class="lang-py">class torch.nn.Tanh
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x7684;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;, <img src="img/tex-2e45b4a6182e5220661502b8945d0023.gif" alt="f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))"></p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> <code>*</code> &#x8868;&#x793A;&#x4EFB;&#x610F;&#x7EF4;&#x5EA6;&#x7EC4;&#x5408;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x4E0E;&#x8F93;&#x5165;&#x6709;&#x76F8;&#x540C;&#x7684; shape &#x5C5E;&#x6027;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Tanh()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="logsigmoid">LogSigmoid</h3>
<pre><code class="lang-py">class torch.nn.LogSigmoid
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#x8FD0;&#x7528;&#x51FD;&#x6570; <img src="img/tex-d50941aafbaeba290ac473d7bad1177a.gif" alt="LogSigmoid(x) = log( 1 / (1 + exp(-x_i)))"></p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> &#x5176;&#x4E2D; <code>*</code> &#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x6570;&#x76EE;&#x7684;&#x9644;&#x52A0;&#x7EF4;&#x5EA6;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x548C;&#x8F93;&#x5165;&#x7684;&#x683C;&#x5F0F;shape&#x4E00;&#x81F4;</li>
</ul>
<p>&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.LogSigmoid()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="softplus">Softplus</h3>
<pre><code class="lang-py">class torch.nn.Softplus(beta=1, threshold=20)
</code></pre>
<p>&#x5BF9;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x8FD0;&#x7528;Softplus&#x51FD;&#x6570;, Softplus &#x5B9A;&#x4E49;&#x5982;&#x4E0B; :: <img src="img/tex-6fe0507610989a3ed06095e1c518ba44.gif" alt="f(x) = 1/beta * log(1 + exp(beta * x_i))"></p>
<p>Softplus &#x51FD;&#x6570;&#x662F;ReLU&#x51FD;&#x6570;&#x7684;&#x5E73;&#x6ED1;&#x903C;&#x8FD1;. Softplus &#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4F7F;&#x5F97;&#x8F93;&#x51FA;&#x503C;&#x9650;&#x5B9A;&#x4E3A;&#x6B63;&#x6570;.</p>
<p>&#x4E3A;&#x4E86;&#x4FDD;&#x8BC1;&#x6570;&#x503C;&#x7A33;&#x5B9A;&#x6027;. &#x7EBF;&#x6027;&#x51FD;&#x6570;&#x7684;&#x8F6C;&#x6362;&#x53EF;&#x4EE5;&#x4F7F;&#x8F93;&#x51FA;&#x5927;&#x4E8E;&#x67D0;&#x4E2A;&#x503C;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>beta</code> &#x2013; Softplus &#x516C;&#x5F0F;&#x4E2D;&#x7684; beta &#x503C;. &#x9ED8;&#x8BA4;&#x503C;: 1</li>
<li><code>threshold</code> &#x2013; &#x9608;&#x503C;. &#x5F53;&#x8F93;&#x5165;&#x5230;&#x8BE5;&#x503C;&#x4EE5;&#x4E0A;&#x65F6;&#x6211;&#x4EEC;&#x7684;SoftPlus&#x5B9E;&#x73B0;&#x5C06;&#x8FD8;&#x539F;&#x4E3A;&#x7EBF;&#x6027;&#x51FD;&#x6570;. &#x9ED8;&#x8BA4;&#x503C;: 20</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> &#x5176;&#x4E2D; <code>*</code> &#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x6570;&#x76EE;&#x7684;&#x9644;&#x52A0;&#x7EF4;&#x5EA6; dimensions</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x548C;&#x8F93;&#x5165;&#x7684;&#x683C;&#x5F0F;shape&#x4E00;&#x81F4;</li>
</ul>
<p>&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Softplus()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="softshrink">Softshrink</h3>
<pre><code class="lang-py">class torch.nn.Softshrink(lambd=0.5)
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#x8FD0;&#x7528; soft shrinkage &#x51FD;&#x6570;</p>
<p>SoftShrinkage &#x8FD0;&#x7B97;&#x7B26;&#x5B9A;&#x4E49;&#x4E3A;:</p>
<pre><code class="lang-py">f(x) = x-<span class="hljs-keyword">lambda</span>, <span class="hljs-keyword">if</span> x &gt; <span class="hljs-keyword">lambda</span> &gt;  f(x) = x+<span class="hljs-keyword">lambda</span>, <span class="hljs-keyword">if</span> x &lt; -<span class="hljs-keyword">lambda</span>
f(x) = <span class="hljs-number">0</span>, otherwise
</code></pre>
<p>&#x53C2;&#x6570;&#xFF1A;lambd &#x2013; Softshrink &#x516C;&#x5F0F;&#x4E2D;&#x7684; lambda &#x503C;. &#x9ED8;&#x8BA4;&#x503C;: 0.5</p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> &#x5176;&#x4E2D; <code>*</code> &#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x6570;&#x76EE;&#x7684;&#x9644;&#x52A0;&#x7EF4;&#x5EA6;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x548C;&#x8F93;&#x5165;&#x7684;&#x683C;&#x5F0F; shape &#x4E00;&#x81F4;</li>
</ul>
<p>&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Softshrink()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="softsign">Softsign</h3>
<pre><code class="lang-py">class torch.nn.Softsign
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#x8FD0;&#x7528;&#x51FD;&#x6570; <img src="img/tex-7a038009b4e21f541255cead92ff31e1.gif" alt="f(x) = x / (1 + |x|)"></p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> &#x5176;&#x4E2D; <code>*</code> &#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x6570;&#x76EE;&#x7684;&#x9644;&#x52A0;&#x7EF4;&#x5EA6;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x548C;&#x8F93;&#x5165;&#x7684;&#x683C;&#x5F0F; shape &#x4E00;&#x81F4;</li>
</ul>
<p>&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Softsign()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="tanhshrink">Tanhshrink</h3>
<pre><code class="lang-py">class torch.nn.Tanhshrink
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#x8FD0;&#x7528;&#x51FD;&#x6570;, <img src="img/tex-44c80efbc996ac6e387947091850f54b.gif" alt="Tanhshrink(x) = x - Tanh(x)"></p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> &#x5176;&#x4E2D; <code>*</code> &#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x6570;&#x76EE;&#x7684;&#x9644;&#x52A0;&#x7EF4;&#x5EA6;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x548C;&#x8F93;&#x5165;&#x7684;&#x683C;&#x5F0F;shape&#x4E00;&#x81F4;</li>
</ul>
<p>&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Tanhshrink()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="softmin">Softmin</h3>
<pre><code class="lang-py">class torch.nn.Softmin(dim=None)
</code></pre>
<p>&#x5BF9;n&#x7EF4;&#x8F93;&#x5165;&#x5F20;&#x91CF;&#x8FD0;&#x7528; Softmin &#x51FD;&#x6570;, &#x5C06;&#x5F20;&#x91CF;&#x7684;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7F29;&#x653E;&#x5230; (0,1) &#x533A;&#x95F4;&#x4E14;&#x548C;&#x4E3A; 1.</p>
<p><img src="img/tex-4607c4c06b3ced41a4dfab06b8ac970a.gif" alt="f(x) = \frac{\exp(-x_i)}{\sum_j \exp(-x_j)}"></p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;&#x4EFB;&#x610F;shape</li>
<li>&#x8F93;&#x51FA;&#xFF1A;&#x548C;&#x8F93;&#x5165;&#x76F8;&#x540C;</li>
</ul>
<p>&#x53C2;&#x6570;&#xFF1A;<code>dim (int)</code> &#x2013; &#x8FD9;&#x662F;&#x5C06;&#x8BA1;&#x7B97; Softmax &#x7684;&#x7EF4;&#x5EA6; (&#x6240;&#x4EE5;&#x6BCF;&#x4E2A;&#x6CBF;&#x7740; dim &#x7684;&#x5207;&#x7247;&#x548C;&#x4E3A; 1).</p>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;&#x8FD4;&#x56DE;&#x7ED3;&#x679C;&#x662F;&#x4E00;&#x4E2A;&#x4E0E;&#x8F93;&#x5165;&#x7EF4;&#x5EA6;&#x76F8;&#x540C;&#x7684;&#x5F20;&#x91CF;, &#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x53D6;&#x503C;&#x8303;&#x56F4;&#x5728; [0, 1] &#x533A;&#x95F4;.</p>
<p>&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Softmin()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="softmax">Softmax</h3>
<pre><code class="lang-py">class torch.nn.Softmax(dim=None)
</code></pre>
<p>&#x5BF9;n&#x7EF4;&#x8F93;&#x5165;&#x5F20;&#x91CF;&#x8FD0;&#x7528; Softmax &#x51FD;&#x6570;, &#x5C06;&#x5F20;&#x91CF;&#x7684;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7F29;&#x653E;&#x5230; (0,1) &#x533A;&#x95F4;&#x4E14;&#x548C;&#x4E3A; 1. Softmax &#x51FD;&#x6570;&#x5B9A;&#x4E49;&#x5982;&#x4E0B; <img src="img/tex-b1981394d33a113054724aea38de02f4.gif" alt="f_i(x) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}"></p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;&#x4EFB;&#x610F;shape</li>
<li>&#x8F93;&#x51FA;&#xFF1A;&#x548C;&#x8F93;&#x5165;&#x76F8;&#x540C;</li>
</ul>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;&#x8FD4;&#x56DE;&#x7ED3;&#x679C;&#x662F;&#x4E00;&#x4E2A;&#x4E0E;&#x8F93;&#x5165;&#x7EF4;&#x5EA6;&#x76F8;&#x540C;&#x7684;&#x5F20;&#x91CF;, &#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x53D6;&#x503C;&#x8303;&#x56F4;&#x5728; [0, 1] &#x533A;&#x95F4;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;<code>dim (int)</code> &#x2013; &#x8FD9;&#x662F;&#x5C06;&#x8BA1;&#x7B97; Softmax &#x7684;&#x90A3;&#x4E2A;&#x7EF4;&#x5EA6; (&#x6240;&#x4EE5;&#x6BCF;&#x4E2A;&#x6CBF;&#x7740; dim &#x7684;&#x5207;&#x7247;&#x548C;&#x4E3A; 1).</p>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x5982;&#x679C;&#x4F60;&#x60F3;&#x5BF9;&#x539F;&#x59CB; Softmax &#x6570;&#x636E;&#x8BA1;&#x7B97; Log &#x8FDB;&#x884C;&#x6536;&#x7F29;, &#x5E76;&#x4E0D;&#x80FD;&#x4F7F;&#x8BE5;&#x6A21;&#x5757;&#x76F4;&#x63A5;&#x4F7F;&#x7528; NLLLoss &#x8D1F;&#x5BF9;&#x6570;&#x4F3C;&#x7136;&#x635F;&#x5931;&#x51FD;&#x6570;. &#x53D6;&#x800C;&#x4EE3;&#x4E4B;, &#x5E94;&#x8BE5;&#x4F7F;&#x7528; Logsoftmax (&#x5B83;&#x6709;&#x66F4;&#x5FEB;&#x7684;&#x8FD0;&#x7B97;&#x901F;&#x5EA6;&#x548C;&#x66F4;&#x597D;&#x7684;&#x6570;&#x503C;&#x6027;&#x8D28;).</p>
<p>&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Softmax()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="softmax2d">Softmax2d</h3>
<pre><code class="lang-py">class torch.nn.Softmax2d
</code></pre>
<p>&#x628A; SoftMax &#x5E94;&#x7528;&#x4E8E;&#x6BCF;&#x4E2A;&#x7A7A;&#x95F4;&#x4F4D;&#x7F6E;&#x7684;&#x7279;&#x5F81;.</p>
<p>&#x7ED9;&#x5B9A;&#x56FE;&#x7247;&#x7684; &#x901A;&#x9053;&#x6570; Channels x &#x9AD8; Height x &#x5BBD; Width, &#x5B83;&#x5C06;&#x5BF9;&#x56FE;&#x7247;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x4F4D;&#x7F6E; &#x4F7F;&#x7528; Softmax <img src="img/tex-a198a66fa501df7564f9b1e3564f34ca.gif" alt="(Channels, h_i, w_j)"></p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-38d00342060234da90e0c2c5493892cb.gif" alt="(N, C, H, W)"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-38d00342060234da90e0c2c5493892cb.gif" alt="(N, C, H, W)"> (&#x683C;&#x5F0F; shape &#x4E0E;&#x8F93;&#x5165;&#x76F8;&#x540C;)</li>
</ul>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;&#x4E00;&#x4E2A;&#x7EF4;&#x5EA6;&#x53CA;&#x683C;&#x5F0F; shape &#x90FD;&#x548C;&#x8F93;&#x5165;&#x76F8;&#x540C;&#x7684; Tensor, &#x53D6;&#x503C;&#x8303;&#x56F4;&#x5728;[0, 1]</p>
<p>&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Softmax2d()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># you softmax over the 2nd dimension</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">12</span>, <span class="hljs-number">13</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h3 id="logsoftmax">LogSoftmax</h3>
<pre><code class="lang-py">class torch.nn.LogSoftmax(dim=None)
</code></pre>
<p>&#x5BF9;&#x6BCF;&#x4E2A;&#x8F93;&#x5165;&#x7684; n &#x7EF4; Tensor &#x4F7F;&#x7528; Log(Softmax(x)). LogSoftmax &#x516C;&#x5F0F;&#x53EF;&#x7B80;&#x5316;&#x4E3A;</p>
<p><img src="img/tex-e74abbc6578adf65f8ae7c421cafc170.gif" alt="f_i(x) = log(exp(x_i) / sum_j exp(x_j) )"></p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;&#x4EFB;&#x610F;&#x683C;&#x5F0F; shape</li>
<li>&#x8F93;&#x51FA;&#xFF1A;&#x548C;&#x8F93;&#x5165;&#x7684;&#x683C;&#x5F0F; shape &#x4E00;&#x81F4;</li>
</ul>
<p>&#x53C2;&#x6570;&#xFF1A;<code>dim (int)</code> &#x2013; &#x8FD9;&#x662F;&#x5C06;&#x8BA1;&#x7B97; Softmax &#x7684;&#x90A3;&#x4E2A;&#x7EF4;&#x5EA6; (&#x6240;&#x4EE5;&#x6BCF;&#x4E2A;&#x6CBF;&#x7740; dim &#x7684;&#x5207;&#x7247;&#x548C;&#x4E3A;1).</p>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;&#x4E00;&#x4E2A;&#x7EF4;&#x5EA6;&#x53CA;&#x683C;&#x5F0F; shape &#x90FD;&#x548C;&#x8F93;&#x5165;&#x76F8;&#x540C;&#x7684; Tensor, &#x53D6;&#x503C;&#x8303;&#x56F4;&#x5728; [-inf, 0)</p>
<p>&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.LogSoftmax()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>print(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(m(input))
</code></pre>
<h2 id="normalization-layers-&#x5F52;&#x4E00;&#x5316;&#x5C42;">Normalization layers (&#x5F52;&#x4E00;&#x5316;&#x5C42;)</h2>
<h3 id="batchnorm1d">BatchNorm1d</h3>
<pre><code class="lang-py">class torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True)
</code></pre>
<p>&#x5BF9; 2d &#x6216;&#x8005; 3d &#x7684;&#x5C0F;&#x6279;&#x91CF; (mini-batch) &#x6570;&#x636E;&#x8FDB;&#x884C;&#x6279;&#x6807;&#x51C6;&#x5316; (Batch Normalization) &#x64CD;&#x4F5C;.</p>
<p><img src="img/tex-7845c007673a63d2279ae8173ba805f4.gif" alt="y = \frac{x - mean[x]}{ \sqrt{Var[x] + \epsilon}} * gamma + beta"></p>
<p>&#x6BCF;&#x4E2A;&#x5C0F;&#x6279;&#x91CF;&#x6570;&#x636E;&#x4E2D;,&#x8BA1;&#x7B97;&#x5404;&#x4E2A;&#x7EF4;&#x5EA6;&#x7684;&#x5747;&#x503C;&#x548C;&#x6807;&#x51C6;&#x5DEE;,&#x5E76;&#x4E14; gamma &#x548C; beta &#x662F;&#x5927;&#x5C0F;&#x4E3A; C &#x7684;&#x53EF;&#x5B66;&#x4E60;, &#x53EF;&#x6539;&#x53D8;&#x7684;&#x4EFF;&#x5C04;&#x53C2;&#x6570;&#x5411;&#x91CF;( C &#x4E3A;&#x8F93;&#x5165;&#x5927;&#x5C0F;).</p>
<p>&#x5728;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x4E2D;,&#x8BE5;&#x5C42;&#x8BA1;&#x7B97;&#x5747;&#x503C;&#x548C;&#x65B9;&#x5DEE;,&#x5E76;&#x8FDB;&#x884C;&#x5E73;&#x5747;&#x79FB;&#x52A8;,&#x9ED8;&#x8BA4;&#x7684;&#x5E73;&#x5747;&#x79FB;&#x52A8;&#x52A8;&#x91CF;&#x503C;&#x4E3A; 0.1.</p>
<p>&#x5728;&#x9A8C;&#x8BC1;&#x65F6;,&#x8BAD;&#x7EC3;&#x5F97;&#x5230;&#x7684;&#x5747;&#x503C;/&#x65B9;&#x5DEE;,&#x7528;&#x4E8E;&#x6807;&#x51C6;&#x5316;&#x9A8C;&#x8BC1;&#x6570;&#x636E;.</p>
<p>BatchNorm &#x5728; &#x2018;C&#x2019; &#x7EF4;&#x4E0A;&#x5904;&#x7406;,&#x5373; &#x2018;(N,L)&#x2019; &#x90E8;&#x5206;&#x8FD0;&#x884C;,&#x88AB;&#x79F0;&#x4F5C; &#x2018;Temporal BatchNorm&#x2019;</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>num_features</code> &#x2013; &#x9884;&#x671F;&#x8F93;&#x5165;&#x7684;&#x7279;&#x5F81;&#x6570;,&#x5927;&#x5C0F;&#x4E3A; &#x2018;batch_size x num_features [x width]&#x2019;</li>
<li><code>eps</code> &#x2013; &#x7ED9;&#x5206;&#x6BCD;&#x52A0;&#x4E0A;&#x7684;&#x503C;,&#x4FDD;&#x8BC1;&#x6570;&#x503C;&#x7A33;&#x5B9A;(&#x5206;&#x6BCD;&#x4E0D;&#x80FD;&#x8D8B;&#x8FD1;0&#x6216;&#x53D6;0),&#x9ED8;&#x8BA4;&#x4E3A; 1e-5</li>
<li><code>momentum</code> &#x2013; &#x52A8;&#x6001;&#x5747;&#x503C;&#x548C;&#x52A8;&#x6001;&#x65B9;&#x5DEE;&#x4F7F;&#x7528;&#x7684;&#x79FB;&#x52A8;&#x52A8;&#x91CF;&#x503C;,&#x9ED8;&#x8BA4;&#x4E3A; 0.1</li>
<li><code>affine</code> &#x2013; &#x5E03;&#x5C14;&#x503C;,&#x8BBE;&#x4E3A; True &#x65F6;,&#x8868;&#x793A;&#x8BE5;&#x5C42;&#x6DFB;&#x52A0;&#x53EF;&#x5B66;&#x4E60;,&#x53EF;&#x6539;&#x53D8;&#x7684;&#x4EFF;&#x5C04;&#x53C2;&#x6570;,&#x5373; gamma &#x548C; beta,&#x9ED8;&#x8BA4;&#x4E3A; True</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-0adbd266d78d43d0298b110b7b60ef70.gif" alt="(N, C)"> or <img src="img/tex-543737499dba0095d9151b4fd440b509.gif" alt="(N, C, L)"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-0adbd266d78d43d0298b110b7b60ef70.gif" alt="(N, C)"> or <img src="img/tex-543737499dba0095d9151b4fd440b509.gif" alt="(N, C, L)"> (same shape as input)</li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With Learnable Parameters</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.BatchNorm1d(<span class="hljs-number">100</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Without Learnable Parameters</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.BatchNorm1d(<span class="hljs-number">100</span>, affine=<span class="hljs-keyword">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">100</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="batchnorm2d">BatchNorm2d</h3>
<pre><code class="lang-py">class torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True)
</code></pre>
<p>&#x5BF9;&#x5C0F;&#x6279;&#x91CF; (mini-batch) 3d &#x6570;&#x636E;&#x7EC4;&#x6210;&#x7684; 4d &#x8F93;&#x5165;&#x8FDB;&#x884C;&#x6807;&#x51C6;&#x5316; (Batch Normalization) &#x64CD;&#x4F5C;.</p>
<p><img src="img/tex-7845c007673a63d2279ae8173ba805f4.gif" alt="y = \frac{x - mean[x]}{ \sqrt{Var[x] + \epsilon}} * gamma + beta"></p>
<p>&#x6BCF;&#x4E2A;&#x5C0F;&#x6279;&#x91CF;&#x6570;&#x636E;&#x4E2D;,&#x8BA1;&#x7B97;&#x5404;&#x4E2A;&#x7EF4;&#x5EA6;&#x7684;&#x5747;&#x503C;&#x548C;&#x6807;&#x51C6;&#x5DEE;, &#x5E76;&#x4E14; gamma &#x548C; beta &#x662F;&#x5927;&#x5C0F;&#x4E3A; C &#x7684;&#x53EF;&#x5B66;&#x4E60;,&#x53EF;&#x6539;&#x53D8;&#x7684;&#x4EFF;&#x5C04;&#x53C2;&#x6570;&#x5411;&#x91CF; (C &#x4E3A;&#x8F93;&#x5165;&#x5927;&#x5C0F;).</p>
<p>&#x5728;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x4E2D;,&#x8BE5;&#x5C42;&#x8BA1;&#x7B97;&#x5747;&#x503C;&#x548C;&#x65B9;&#x5DEE;,&#x5E76;&#x8FDB;&#x884C;&#x5E73;&#x5747;&#x79FB;&#x52A8;.&#x9ED8;&#x8BA4;&#x7684;&#x5E73;&#x5747;&#x79FB;&#x52A8;&#x52A8;&#x91CF;&#x503C;&#x4E3A; 0.1.</p>
<p>&#x5728;&#x9A8C;&#x8BC1;&#x65F6;,&#x8BAD;&#x7EC3;&#x5F97;&#x5230;&#x7684;&#x5747;&#x503C;/&#x65B9;&#x5DEE;,&#x7528;&#x4E8E;&#x6807;&#x51C6;&#x5316;&#x9A8C;&#x8BC1;&#x6570;&#x636E;.</p>
<p>BatchNorm &#x5728; &#x2018;C&#x2019; &#x7EF4;&#x4E0A;&#x5904;&#x7406;,&#x5373; &#x2018;(N, H, W)&#x2019; &#x90E8;&#x5206;&#x8FD0;&#x884C;,&#x88AB;&#x79F0;&#x4F5C; &#x2018;Spatial BatchNorm&#x2019;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>num_features</code> &#x2013; &#x9884;&#x671F;&#x8F93;&#x5165;&#x7684;&#x7279;&#x5F81;&#x6570;,&#x5927;&#x5C0F;&#x4E3A; &#x2018;batch_size x num_features x height x width&#x2019;</li>
<li><code>eps</code> &#x2013; &#x7ED9;&#x5206;&#x6BCD;&#x52A0;&#x4E0A;&#x7684;&#x503C;,&#x4FDD;&#x8BC1;&#x6570;&#x503C;&#x7A33;&#x5B9A;(&#x5206;&#x6BCD;&#x4E0D;&#x80FD;&#x8D8B;&#x8FD1;0&#x6216;&#x53D6;0),&#x9ED8;&#x8BA4;&#x4E3A; 1e-5</li>
<li><code>momentum</code> &#x2013; &#x52A8;&#x6001;&#x5747;&#x503C;&#x548C;&#x52A8;&#x6001;&#x65B9;&#x5DEE;&#x4F7F;&#x7528;&#x7684;&#x79FB;&#x52A8;&#x52A8;&#x91CF;&#x503C;,&#x9ED8;&#x8BA4;&#x4E3A; 0.1</li>
<li><code>affine</code> &#x2013; &#x5E03;&#x5C14;&#x503C;,&#x8BBE;&#x4E3A; True &#x65F6;,&#x8868;&#x793A;&#x8BE5;&#x5C42;&#x6DFB;&#x52A0;&#x53EF;&#x5B66;&#x4E60;,&#x53EF;&#x6539;&#x53D8;&#x7684;&#x4EFF;&#x5C04;&#x53C2;&#x6570;,&#x5373; gamma &#x548C; beta,&#x9ED8;&#x8BA4;&#x4E3A; True</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-38d00342060234da90e0c2c5493892cb.gif" alt="(N, C, H, W)"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-38d00342060234da90e0c2c5493892cb.gif" alt="(N, C, H, W)"> (same shape as input)</li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With Learnable Parameters</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.BatchNorm2d(<span class="hljs-number">100</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Without Learnable Parameters</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.BatchNorm2d(<span class="hljs-number">100</span>, affine=<span class="hljs-keyword">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">100</span>, <span class="hljs-number">35</span>, <span class="hljs-number">45</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="batchnorm3d">BatchNorm3d</h3>
<pre><code class="lang-py">class torch.nn.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, affine=True)
</code></pre>
<p>&#x5BF9;&#x5C0F;&#x6279;&#x91CF; (mini-batch) 4d &#x6570;&#x636E;&#x7EC4;&#x6210;&#x7684; 5d &#x8F93;&#x5165;&#x8FDB;&#x884C;&#x6807;&#x51C6;&#x5316; (Batch Normalization) &#x64CD;&#x4F5C;.</p>
<p><img src="img/tex-7845c007673a63d2279ae8173ba805f4.gif" alt="y = \frac{x - mean[x]}{ \sqrt{Var[x] + \epsilon}} * gamma + beta"></p>
<p>&#x6BCF;&#x4E2A;&#x5C0F;&#x6279;&#x91CF;&#x6570;&#x636E;&#x4E2D;,&#x8BA1;&#x7B97;&#x5404;&#x4E2A;&#x7EF4;&#x5EA6;&#x7684;&#x5747;&#x503C;&#x548C;&#x6807;&#x51C6;&#x5DEE;, &#x5E76;&#x4E14; gamma &#x548C; beta &#x662F;&#x5927;&#x5C0F;&#x4E3A; C &#x7684;&#x53EF;&#x5B66;&#x4E60;,&#x53EF;&#x6539;&#x53D8;&#x7684;&#x4EFF;&#x5C04;&#x53C2;&#x6570;&#x5411;&#x91CF; (C &#x4E3A;&#x8F93;&#x5165;&#x5927;&#x5C0F;).</p>
<p>&#x5728;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x4E2D;,&#x8BE5;&#x5C42;&#x8BA1;&#x7B97;&#x5747;&#x503C;&#x548C;&#x65B9;&#x5DEE;,&#x5E76;&#x8FDB;&#x884C;&#x5E73;&#x5747;&#x79FB;&#x52A8;.&#x9ED8;&#x8BA4;&#x7684;&#x5E73;&#x5747;&#x79FB;&#x52A8;&#x52A8;&#x91CF;&#x503C;&#x4E3A; 0.1.</p>
<p>&#x5728;&#x9A8C;&#x8BC1;&#x65F6;,&#x8BAD;&#x7EC3;&#x5F97;&#x5230;&#x7684;&#x5747;&#x503C;/&#x65B9;&#x5DEE;,&#x7528;&#x4E8E;&#x6807;&#x51C6;&#x5316;&#x9A8C;&#x8BC1;&#x6570;&#x636E;.</p>
<p>BatchNorm &#x5728; &#x2018;C&#x2019; &#x7EF4;&#x4E0A;&#x5904;&#x7406;,&#x5373; &#x2018;(N, D, H, W)&#x2019; &#x90E8;&#x5206;&#x8FD0;&#x884C;,&#x88AB;&#x79F0;&#x4F5C; &#x2018;Volumetric BatchNorm&#x2019; &#x6216;&#x8005; &#x2018;Spatio-temporal BatchNorm&#x2019;</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>num_features</code> &#x2013; &#x9884;&#x671F;&#x8F93;&#x5165;&#x7684;&#x7279;&#x5F81;&#x6570;,&#x5927;&#x5C0F;&#x4E3A; &#x2018;batch_size x num_features x depth x height x width&#x2019;</li>
<li><code>eps</code> &#x2013; &#x7ED9;&#x5206;&#x6BCD;&#x52A0;&#x4E0A;&#x7684;&#x503C;,&#x4FDD;&#x8BC1;&#x6570;&#x503C;&#x7A33;&#x5B9A;(&#x5206;&#x6BCD;&#x4E0D;&#x80FD;&#x8D8B;&#x8FD1;0&#x6216;&#x53D6;0),&#x9ED8;&#x8BA4;&#x4E3A; 1e-5</li>
<li><code>momentum</code> &#x2013; &#x52A8;&#x6001;&#x5747;&#x503C;&#x548C;&#x52A8;&#x6001;&#x65B9;&#x5DEE;&#x4F7F;&#x7528;&#x7684;&#x79FB;&#x52A8;&#x52A8;&#x91CF;&#x503C;,&#x9ED8;&#x8BA4;&#x4E3A; 0.1</li>
<li><code>affine</code> &#x2013; &#x5E03;&#x5C14;&#x503C;,&#x8BBE;&#x4E3A; True &#x65F6;,&#x8868;&#x793A;&#x8BE5;&#x5C42;&#x6DFB;&#x52A0;&#x53EF;&#x5B66;&#x4E60;,&#x53EF;&#x6539;&#x53D8;&#x7684;&#x4EFF;&#x5C04;&#x53C2;&#x6570;,&#x5373; gamma &#x548C; beta,&#x9ED8;&#x8BA4;&#x4E3A; True</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-6d9465a2eb2377437689121f4915b6b4.gif" alt="(N, C, D, H, W)"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-6d9465a2eb2377437689121f4915b6b4.gif" alt="(N, C, D, H, W)"> (same shape as input)</li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With Learnable Parameters</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.BatchNorm3d(<span class="hljs-number">100</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Without Learnable Parameters</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.BatchNorm3d(<span class="hljs-number">100</span>, affine=<span class="hljs-keyword">False</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">100</span>, <span class="hljs-number">35</span>, <span class="hljs-number">45</span>, <span class="hljs-number">10</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="instancenorm1d">InstanceNorm1d</h3>
<pre><code class="lang-py">class torch.nn.InstanceNorm1d(num_features, eps=1e-05, momentum=0.1, affine=False)
</code></pre>
<p>&#x5BF9; 2d &#x6216;&#x8005; 3d &#x7684;&#x5C0F;&#x6279;&#x91CF; (mini-batch) &#x6570;&#x636E;&#x8FDB;&#x884C;&#x5B9E;&#x4F8B;&#x6807;&#x51C6;&#x5316; (Instance Normalization) &#x64CD;&#x4F5C;. .. math:</p>
<pre><code class="lang-py">y = \frac{x - mean[x]}{ \sqrt{Var[x]} + \epsilon} * gamma + beta
</code></pre>
<p>&#x5BF9;&#x5C0F;&#x6279;&#x91CF;&#x6570;&#x636E;&#x4E2D;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x5BF9;&#x8C61;,&#x8BA1;&#x7B97;&#x5176;&#x5404;&#x4E2A;&#x7EF4;&#x5EA6;&#x7684;&#x5747;&#x503C;&#x548C;&#x6807;&#x51C6;&#x5DEE;,&#x5E76;&#x4E14; gamma &#x548C; beta &#x662F;&#x5927;&#x5C0F;&#x4E3A; C &#x7684;&#x53EF;&#x5B66;&#x4E60;, &#x53EF;&#x6539;&#x53D8;&#x7684;&#x4EFF;&#x5C04;&#x53C2;&#x6570;&#x5411;&#x91CF;( C &#x4E3A;&#x8F93;&#x5165;&#x5927;&#x5C0F;).</p>
<p>&#x5728;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x4E2D;,&#x8BE5;&#x5C42;&#x8BA1;&#x7B97;&#x5747;&#x503C;&#x548C;&#x65B9;&#x5DEE;,&#x5E76;&#x8FDB;&#x884C;&#x5E73;&#x5747;&#x79FB;&#x52A8;,&#x9ED8;&#x8BA4;&#x7684;&#x5E73;&#x5747;&#x79FB;&#x52A8;&#x52A8;&#x91CF;&#x503C;&#x4E3A; 0.1.</p>
<p>&#x5728;&#x9A8C;&#x8BC1;&#x65F6; (<code>.eval()</code>),InstanceNorm &#x6A21;&#x578B;&#x9ED8;&#x8BA4;&#x4FDD;&#x6301;&#x4E0D;&#x53D8;,&#x5373;&#x6C42;&#x5F97;&#x7684;&#x5747;&#x503C;/&#x65B9;&#x5DEE;&#x4E0D;&#x7528;&#x4E8E;&#x6807;&#x51C6;&#x5316;&#x9A8C;&#x8BC1;&#x6570;&#x636E;, &#x4F46;&#x53EF;&#x4EE5;&#x7528; <code>.train(False)</code> &#x65B9;&#x6CD5;&#x5F3A;&#x5236;&#x4F7F;&#x7528;&#x5B58;&#x50A8;&#x7684;&#x5747;&#x503C;&#x548C;&#x65B9;&#x5DEE;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>num_features</code> &#x2013; &#x9884;&#x671F;&#x8F93;&#x5165;&#x7684;&#x7279;&#x5F81;&#x6570;,&#x5927;&#x5C0F;&#x4E3A; &#x2018;batch_size x num_features x width&#x2019;</li>
<li><code>eps</code> &#x2013; &#x7ED9;&#x5206;&#x6BCD;&#x52A0;&#x4E0A;&#x7684;&#x503C;,&#x4FDD;&#x8BC1;&#x6570;&#x503C;&#x7A33;&#x5B9A;(&#x5206;&#x6BCD;&#x4E0D;&#x80FD;&#x8D8B;&#x8FD1;0&#x6216;&#x53D6;0),&#x9ED8;&#x8BA4;&#x4E3A; 1e-5</li>
<li><code>momentum</code> &#x2013; &#x52A8;&#x6001;&#x5747;&#x503C;&#x548C;&#x52A8;&#x6001;&#x65B9;&#x5DEE;&#x4F7F;&#x7528;&#x7684;&#x79FB;&#x52A8;&#x52A8;&#x91CF;&#x503C;,&#x9ED8;&#x8BA4;&#x4E3A; 0.1</li>
<li><code>affine</code> &#x2013; &#x5E03;&#x5C14;&#x503C;,&#x8BBE;&#x4E3A; <code>True</code> &#x65F6;,&#x8868;&#x793A;&#x8BE5;&#x5C42;&#x6DFB;&#x52A0;&#x53EF;&#x5B66;&#x4E60;,&#x53EF;&#x6539;&#x53D8;&#x7684;&#x4EFF;&#x5C04;&#x53C2;&#x6570;,&#x5373; gamma &#x548C; beta,&#x9ED8;&#x8BA4;&#x4E3A; <code>False</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-543737499dba0095d9151b4fd440b509.gif" alt="(N, C, L)"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-543737499dba0095d9151b4fd440b509.gif" alt="(N, C, L)"> (same shape as input)</li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Without Learnable Parameters</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.InstanceNorm1d(<span class="hljs-number">100</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With Learnable Parameters</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.InstanceNorm1d(<span class="hljs-number">100</span>, affine=<span class="hljs-keyword">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">100</span>, <span class="hljs-number">40</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="instancenorm2d">InstanceNorm2d</h3>
<pre><code class="lang-py">class torch.nn.InstanceNorm2d(num_features, eps=1e-05, momentum=0.1, affine=False)
</code></pre>
<p>&#x5BF9;&#x5C0F;&#x6279;&#x91CF; (mini-batch) 3d &#x6570;&#x636E;&#x7EC4;&#x6210;&#x7684; 4d &#x8F93;&#x5165;&#x8FDB;&#x884C;&#x5B9E;&#x4F8B;&#x6807;&#x51C6;&#x5316; (Batch Normalization) &#x64CD;&#x4F5C;. .. math:</p>
<pre><code class="lang-py">y = \frac{x - mean[x]}{ \sqrt{Var[x]} + \epsilon} * gamma + beta
</code></pre>
<p>&#x5BF9;&#x5C0F;&#x6279;&#x91CF;&#x6570;&#x636E;&#x4E2D;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x5BF9;&#x8C61;,&#x8BA1;&#x7B97;&#x5176;&#x5404;&#x4E2A;&#x7EF4;&#x5EA6;&#x7684;&#x5747;&#x503C;&#x548C;&#x6807;&#x51C6;&#x5DEE;,&#x5E76;&#x4E14; gamma &#x548C; beta &#x662F;&#x5927;&#x5C0F;&#x4E3A; C &#x7684;&#x53EF;&#x5B66;&#x4E60;, &#x53EF;&#x6539;&#x53D8;&#x7684;&#x4EFF;&#x5C04;&#x53C2;&#x6570;&#x5411;&#x91CF;( C &#x4E3A;&#x8F93;&#x5165;&#x5927;&#x5C0F;).</p>
<p>&#x5728;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x4E2D;,&#x8BE5;&#x5C42;&#x8BA1;&#x7B97;&#x5747;&#x503C;&#x548C;&#x65B9;&#x5DEE;,&#x5E76;&#x8FDB;&#x884C;&#x5E73;&#x5747;&#x79FB;&#x52A8;,&#x9ED8;&#x8BA4;&#x7684;&#x5E73;&#x5747;&#x79FB;&#x52A8;&#x52A8;&#x91CF;&#x503C;&#x4E3A; 0.1.</p>
<p>&#x5728;&#x9A8C;&#x8BC1;&#x65F6; (<code>.eval()</code>),InstanceNorm &#x6A21;&#x578B;&#x9ED8;&#x8BA4;&#x4FDD;&#x6301;&#x4E0D;&#x53D8;,&#x5373;&#x6C42;&#x5F97;&#x7684;&#x5747;&#x503C;/&#x65B9;&#x5DEE;&#x4E0D;&#x7528;&#x4E8E;&#x6807;&#x51C6;&#x5316;&#x9A8C;&#x8BC1;&#x6570;&#x636E;, &#x4F46;&#x53EF;&#x4EE5;&#x7528; <code>.train(False)</code> &#x65B9;&#x6CD5;&#x5F3A;&#x5236;&#x4F7F;&#x7528;&#x5B58;&#x50A8;&#x7684;&#x5747;&#x503C;&#x548C;&#x65B9;&#x5DEE;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>num_features</code> &#x2013; &#x9884;&#x671F;&#x8F93;&#x5165;&#x7684;&#x7279;&#x5F81;&#x6570;,&#x5927;&#x5C0F;&#x4E3A; &#x2018;batch_size x num_features x height x width&#x2019;</li>
<li><code>eps</code> &#x2013; &#x7ED9;&#x5206;&#x6BCD;&#x52A0;&#x4E0A;&#x7684;&#x503C;,&#x4FDD;&#x8BC1;&#x6570;&#x503C;&#x7A33;&#x5B9A;(&#x5206;&#x6BCD;&#x4E0D;&#x80FD;&#x8D8B;&#x8FD1;0&#x6216;&#x53D6;0),&#x9ED8;&#x8BA4;&#x4E3A; 1e-5</li>
<li><code>momentum</code> &#x2013; &#x52A8;&#x6001;&#x5747;&#x503C;&#x548C;&#x52A8;&#x6001;&#x65B9;&#x5DEE;&#x4F7F;&#x7528;&#x7684;&#x79FB;&#x52A8;&#x52A8;&#x91CF;&#x503C;,&#x9ED8;&#x8BA4;&#x4E3A; 0.1</li>
<li><code>affine</code> &#x2013; &#x5E03;&#x5C14;&#x503C;,&#x8BBE;&#x4E3A; <code>True</code> &#x65F6;,&#x8868;&#x793A;&#x8BE5;&#x5C42;&#x6DFB;&#x52A0;&#x53EF;&#x5B66;&#x4E60;,&#x53EF;&#x6539;&#x53D8;&#x7684;&#x4EFF;&#x5C04;&#x53C2;&#x6570;,&#x5373; gamma &#x548C; beta,&#x9ED8;&#x8BA4;&#x4E3A; <code>False</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-38d00342060234da90e0c2c5493892cb.gif" alt="(N, C, H, W)"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-38d00342060234da90e0c2c5493892cb.gif" alt="(N, C, H, W)"> (same shape as input)</li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Without Learnable Parameters</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.InstanceNorm2d(<span class="hljs-number">100</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With Learnable Parameters</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.InstanceNorm2d(<span class="hljs-number">100</span>, affine=<span class="hljs-keyword">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">100</span>, <span class="hljs-number">35</span>, <span class="hljs-number">45</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="instancenorm3d">InstanceNorm3d</h3>
<pre><code class="lang-py">class torch.nn.InstanceNorm3d(num_features, eps=1e-05, momentum=0.1, affine=False)
</code></pre>
<p>&#x5BF9;&#x5C0F;&#x6279;&#x91CF; (mini-batch) 4d &#x6570;&#x636E;&#x7EC4;&#x6210;&#x7684; 5d &#x8F93;&#x5165;&#x8FDB;&#x884C;&#x5B9E;&#x4F8B;&#x6807;&#x51C6;&#x5316; (Batch Normalization) &#x64CD;&#x4F5C;. .. math:</p>
<pre><code class="lang-py">y = \frac{x - mean[x]}{ \sqrt{Var[x]} + \epsilon} * gamma + beta
</code></pre>
<p>&#x5BF9;&#x5C0F;&#x6279;&#x91CF;&#x6570;&#x636E;&#x4E2D;&#x7684;&#x6BCF;&#x4E00;&#x4E2A;&#x5BF9;&#x8C61;,&#x8BA1;&#x7B97;&#x5176;&#x5404;&#x4E2A;&#x7EF4;&#x5EA6;&#x7684;&#x5747;&#x503C;&#x548C;&#x6807;&#x51C6;&#x5DEE;,&#x5E76;&#x4E14; gamma &#x548C; beta &#x662F;&#x5927;&#x5C0F;&#x4E3A; C &#x7684;&#x53EF;&#x5B66;&#x4E60;, &#x53EF;&#x6539;&#x53D8;&#x7684;&#x4EFF;&#x5C04;&#x53C2;&#x6570;&#x5411;&#x91CF;( C &#x4E3A;&#x8F93;&#x5165;&#x5927;&#x5C0F;).</p>
<p>&#x5728;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x4E2D;,&#x8BE5;&#x5C42;&#x8BA1;&#x7B97;&#x5747;&#x503C;&#x548C;&#x65B9;&#x5DEE;,&#x5E76;&#x8FDB;&#x884C;&#x5E73;&#x5747;&#x79FB;&#x52A8;,&#x9ED8;&#x8BA4;&#x7684;&#x5E73;&#x5747;&#x79FB;&#x52A8;&#x52A8;&#x91CF;&#x503C;&#x4E3A; 0.1.</p>
<p>&#x5728;&#x9A8C;&#x8BC1;&#x65F6; (<code>.eval()</code>),InstanceNorm &#x6A21;&#x578B;&#x9ED8;&#x8BA4;&#x4FDD;&#x6301;&#x4E0D;&#x53D8;,&#x5373;&#x6C42;&#x5F97;&#x7684;&#x5747;&#x503C;/&#x65B9;&#x5DEE;&#x4E0D;&#x7528;&#x4E8E;&#x6807;&#x51C6;&#x5316;&#x9A8C;&#x8BC1;&#x6570;&#x636E;, &#x4F46;&#x53EF;&#x4EE5;&#x7528; <code>.train(False)</code> &#x65B9;&#x6CD5;&#x5F3A;&#x5236;&#x4F7F;&#x7528;&#x5B58;&#x50A8;&#x7684;&#x5747;&#x503C;&#x548C;&#x65B9;&#x5DEE;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>num_features</code> &#x2013; &#x9884;&#x671F;&#x8F93;&#x5165;&#x7684;&#x7279;&#x5F81;&#x6570;,&#x5927;&#x5C0F;&#x4E3A; &#x2018;batch_size x num_features x depth x height x width&#x2019;</li>
<li><code>eps</code> &#x2013; &#x7ED9;&#x5206;&#x6BCD;&#x52A0;&#x4E0A;&#x7684;&#x503C;,&#x4FDD;&#x8BC1;&#x6570;&#x503C;&#x7A33;&#x5B9A;(&#x5206;&#x6BCD;&#x4E0D;&#x80FD;&#x8D8B;&#x8FD1;0&#x6216;&#x53D6;0),&#x9ED8;&#x8BA4;&#x4E3A; 1e-5</li>
<li><code>momentum</code> &#x2013; &#x52A8;&#x6001;&#x5747;&#x503C;&#x548C;&#x52A8;&#x6001;&#x65B9;&#x5DEE;&#x4F7F;&#x7528;&#x7684;&#x79FB;&#x52A8;&#x52A8;&#x91CF;&#x503C;,&#x9ED8;&#x8BA4;&#x4E3A; 0.1</li>
<li><code>affine</code> &#x2013; &#x5E03;&#x5C14;&#x503C;,&#x8BBE;&#x4E3A; <code>True</code> &#x65F6;,&#x8868;&#x793A;&#x8BE5;&#x5C42;&#x6DFB;&#x52A0;&#x53EF;&#x5B66;&#x4E60;,&#x53EF;&#x6539;&#x53D8;&#x7684;&#x4EFF;&#x5C04;&#x53C2;&#x6570;,&#x5373; gamma &#x548C; beta,&#x9ED8;&#x8BA4;&#x4E3A; <code>False</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-6d9465a2eb2377437689121f4915b6b4.gif" alt="(N, C, D, H, W)"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-6d9465a2eb2377437689121f4915b6b4.gif" alt="(N, C, D, H, W)"> (same shape as input)</li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Without Learnable Parameters</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.InstanceNorm3d(<span class="hljs-number">100</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With Learnable Parameters</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.InstanceNorm3d(<span class="hljs-number">100</span>, affine=<span class="hljs-keyword">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">100</span>, <span class="hljs-number">35</span>, <span class="hljs-number">45</span>, <span class="hljs-number">10</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h2 id="recurrent-layers-&#x5FAA;&#x73AF;&#x5C42;">Recurrent layers (&#x5FAA;&#x73AF;&#x5C42;)</h2>
<h3 id="rnn">RNN</h3>
<pre><code class="lang-py">class torch.nn.RNN(*args, **kwargs)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#x4F7F;&#x7528;&#x4E00;&#x4E2A;&#x591A;&#x5C42;&#x7684; <code>Elman RNN</code>, &#x5B83;&#x7684;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x4E3A; <code>tanh</code> &#x6216;&#x8005; <code>ReLU</code> .</p>
<p>&#x5BF9;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;, &#x6BCF;&#x5C42;&#x8BA1;&#x7B97;&#x516C;&#x5F0F;&#x4E3A;:</p>
<p><img src="img/tex-f8ac3a86ecb6d9bb814d9e166cdd6edb.gif" alt="h_t = \tanh(w_{ih} * x_t + b_{ih} + w_{hh} * h_{(t-1)} + b_{hh})"></p>
<p>&#x8FD9;&#x91CC; <img src="img/tex-6c4ff69dbcc329835a33b80fe3a145c7.gif" alt="h_t"> &#x662F;&#x5F53;&#x524D;&#x5728;&#x65F6;&#x523B; <code>t</code> &#x7684;&#x9690;&#x72B6;&#x6001;, &#x5E76;&#x4E14; <img src="img/tex-cf7ee950cf61a6003c0ec4af7971d8a8.gif" alt="x_t"> &#x662F;&#x4E4B;&#x524D;&#x4E00;&#x5C42;&#x5728; <code>t</code> &#x65F6;&#x523B;&#x7684;&#x9690;&#x72B6;&#x6001;, &#x6216;&#x8005;&#x662F;&#x7B2C;&#x4E00;&#x5C42;&#x7684;&#x8F93;&#x5165;. &#x5982;&#x679C; <code>nonlinearity=&apos;relu&apos;</code> ,&#x90A3;&#x4E48;&#x5C06;&#x4F7F;&#x7528; relu &#x4EE3;&#x66FF; tanh &#x4F5C;&#x4E3A;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>input_size</code> &#x2013; &#x8F93;&#x5165; x &#x7684;&#x7279;&#x5F81;&#x6570;&#x91CF;</li>
<li><code>hidden_size</code> &#x2013; &#x9690;&#x72B6;&#x6001; <code>h</code> &#x4E2D;&#x7684;&#x7279;&#x5F81;&#x6570;&#x91CF;</li>
<li><code>num_layers</code> &#x2013; RNN &#x7684;&#x5C42;&#x6570;</li>
<li><code>nonlinearity</code> &#x2013; &#x6307;&#x5B9A;&#x975E;&#x7EBF;&#x6027;&#x51FD;&#x6570;&#x4F7F;&#x7528; [&#x2018;tanh&#x2019;|&#x2019;relu&#x2019;]. &#x9ED8;&#x8BA4;: &#x2018;tanh&#x2019;</li>
<li><code>bias</code> &#x2013; &#x5982;&#x679C;&#x662F; <code>False</code> , &#x90A3;&#x4E48; RNN &#x5C42;&#x5C31;&#x4E0D;&#x4F1A;&#x4F7F;&#x7528;&#x504F;&#x7F6E;&#x6743;&#x91CD; b_ih &#x548C; b_hh, &#x9ED8;&#x8BA4;: <code>True</code></li>
<li><code>batch_first</code> &#x2013; &#x5982;&#x679C; <code>True</code>, &#x90A3;&#x4E48;&#x8F93;&#x5165; <code>Tensor</code> &#x7684; shape &#x5E94;&#x8BE5;&#x662F; (batch, seq, feature),&#x5E76;&#x4E14;&#x8F93;&#x51FA;&#x4E5F;&#x662F;&#x4E00;&#x6837;</li>
<li><code>dropout</code> &#x2013; &#x5982;&#x679C;&#x503C;&#x975E;&#x96F6;, &#x90A3;&#x4E48;&#x9664;&#x4E86;&#x6700;&#x540E;&#x4E00;&#x5C42;&#x5916;, &#x5176;&#x5B83;&#x5C42;&#x7684;&#x8F93;&#x51FA;&#x90FD;&#x4F1A;&#x5957;&#x4E0A;&#x4E00;&#x4E2A; <code>dropout</code> &#x5C42;</li>
<li><code>bidirectional</code> &#x2013; &#x5982;&#x679C; <code>True</code> , &#x5C06;&#x4F1A;&#x53D8;&#x6210;&#x4E00;&#x4E2A;&#x53CC;&#x5411; RNN, &#x9ED8;&#x8BA4;&#x4E3A; <code>False</code></li>
</ul>
<p>Inputs: input, h_0</p>
<ul>
<li><code>input (seq_len, batch, input_size)</code>: &#x5305;&#x542B;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#x7279;&#x5F81;&#x7684; <code>tensor</code> , <code>input</code> &#x53EF;&#x4EE5;&#x662F;&#x88AB;&#x586B;&#x5145;&#x7684;&#x53D8;&#x957F;&#x5E8F;&#x5217;.&#x7EC6;&#x8282;&#x8BF7;&#x770B; <code>torch.nn.utils.rnn.pack_padded_sequence()</code> .</li>
<li><code>h_0 (num_layers * num_directions, batch, hidden_size)</code>: &#x5305;&#x542B; <code>batch</code> &#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x4FDD;&#x5B58;&#x7740;&#x521D;&#x59CB;&#x9690;&#x72B6;&#x6001;&#x7684; <code>tensor</code></li>
</ul>
<p>Outputs: output, h_n</p>
<ul>
<li><code>output (seq_len, batch, hidden_size * num_directions)</code>: &#x5305;&#x542B; RNN &#x6700;&#x540E;&#x4E00;&#x5C42;&#x8F93;&#x51FA;&#x7279;&#x5F81; (h_k) &#x7684; <code>tensor</code> &#x5BF9;&#x4E8E;&#x6BCF;&#x4E2A; k ,&#x5982;&#x679C;&#x8F93;&#x5165;&#x662F;&#x4E00;&#x4E2A; <code>torch.nn.utils.rnn.PackedSequence</code> , &#x90A3;&#x4E48;&#x8F93;&#x51FA;&#x4E5F;&#x662F;&#x4E00;&#x4E2A;&#x53EF;&#x4EE5;&#x662F;&#x88AB;&#x586B;&#x5145;&#x7684;&#x53D8;&#x957F;&#x5E8F;&#x5217;.</li>
<li><code>h_n (num_layers * num_directions, batch, hidden_size)</code>: &#x5305;&#x542B; k= seq_len &#x9690;&#x72B6;&#x6001;&#x7684; <code>tensor</code>.</li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li>weight_ih_l[k] &#x2013; &#x7B2C; k &#x5C42;&#x7684; input-hidden &#x6743;&#x91CD;,&#x53EF;&#x5B66;&#x4E60;, shape &#x662F; <code>(input_size x hidden_size)</code></li>
<li>weight_hh_l[k] &#x2013; &#x7B2C; k &#x5C42;&#x7684; hidden-hidden &#x6743;&#x91CD;, &#x53EF;&#x5B66;&#x4E60;, shape &#x662F; <code>(hidden_size x hidden_size)</code></li>
<li>bias_ih_l[k] &#x2013; &#x7B2C; k &#x5C42;&#x7684; input-hidden &#x504F;&#x7F6E;, &#x53EF;&#x5B66;&#x4E60;, shape &#x662F; <code>(hidden_size)</code></li>
<li>bias_hh_l[k] &#x2013; &#x7B2C; k &#x5C42;&#x7684; hidden-hidden &#x504F;&#x7F6E;, &#x53EF;&#x5B66;&#x4E60;, shape &#x662F; <code>(hidden_size)</code></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>rnn = nn.RNN(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = Variable(torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>, <span class="hljs-number">10</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>h0 = Variable(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">20</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output, hn = rnn(input, h0)
</code></pre>
<h3 id="lstm">LSTM</h3>
<pre><code class="lang-py">class torch.nn.LSTM(*args, **kwargs)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#x4F7F;&#x7528;&#x4E00;&#x4E2A;&#x591A;&#x5C42;&#x7684; <code>LSTM</code> ( long short-term memory ).</p>
<p>&#x5BF9;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#x7684;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;, <code>LSTM</code> &#x7684;&#x6BCF;&#x5C42;&#x90FD;&#x4F1A;&#x6267;&#x884C;&#x4EE5;&#x4E0B;&#x8BA1;&#x7B97;:</p>
<p><img src="img/tex-8d71c956f0fdd364faeb8fb4011edafe.gif" alt="\begin{split}\begin{array}{ll} i_t = \mathrm{sigmoid}(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\ f_t = \mathrm{sigmoid}(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\ g_t = \tanh(W_{ig} x_t + b_{ig} + W_{hc} h_{(t-1)} + b_{hg}) \\ o_t = \mathrm{sigmoid}(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\ c_t = f_t * c_{(t-1)} + i_t * g_t \\ h_t = o_t * \tanh(c_t) \end{array}\end{split}"></p>
<p>&#x8FD9;&#x91CC; <img src="img/tex-6c4ff69dbcc329835a33b80fe3a145c7.gif" alt="h_t"> &#x662F;&#x5728;&#x65F6;&#x523B; <code>t</code> &#x7684;&#x9690;&#x72B6;&#x6001;, <img src="img/tex-da6834ea306c993ae190d8ac693a25f0.gif" alt="c_t"> &#x662F;&#x5728;&#x65F6;&#x523B; <code>t</code> &#x7684;&#x7EC6;&#x80DE;&#x72B6;&#x6001; (cell state), <img src="img/tex-cf7ee950cf61a6003c0ec4af7971d8a8.gif" alt="x_t"> &#x662F;&#x4E0A;&#x4E00;&#x5C42;&#x7684;&#x5728;&#x65F6;&#x523B; <code>t</code> &#x7684;&#x9690;&#x72B6;&#x6001;&#x6216;&#x8005;&#x662F;&#x7B2C;&#x4E00;&#x5C42;&#x7684; <img src="img/tex-bbcb26ab6bab8f51269870e0abcec697.gif" alt="input_t"> , &#x800C; <img src="img/tex-56e99db17308c13a71cfc5da5a3165df.gif" alt="i_t">, <img src="img/tex-bae155438877126b42cbddee193c048a.gif" alt="f_t">, <img src="img/tex-f752008a78c8519e9f8f178faf0b87ed.gif" alt="g_t">, <img src="img/tex-2b2a0a4b3fbc78a61cec549a40912932.gif" alt="o_t"> &#x5206;&#x522B;&#x4EE3;&#x8868; &#x8F93;&#x5165;&#x95E8;,&#x9057;&#x5FD8;&#x95E8;,&#x7EC6;&#x80DE;&#x548C;&#x8F93;&#x51FA;&#x95E8;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>input_size</code> &#x2013; &#x8F93;&#x5165;&#x7684;&#x7279;&#x5F81;&#x7EF4;&#x5EA6;</li>
<li><code>hidden_size</code> &#x2013; &#x9690;&#x72B6;&#x6001;&#x7684;&#x7279;&#x5F81;&#x7EF4;&#x5EA6;</li>
<li><code>num_layers</code> &#x2013; &#x5C42;&#x6570;(&#x548C;&#x65F6;&#x5E8F;&#x5C55;&#x5F00;&#x8981;&#x533A;&#x5206;&#x5F00;)</li>
<li><code>bias</code> &#x2013; &#x5982;&#x679C;&#x4E3A; <code>False</code> ,&#x90A3;&#x4E48; LSTM &#x5C06;&#x4E0D;&#x4F1A;&#x4F7F;&#x7528; b_ih &#x548C; b_hh ,&#x9ED8;&#x8BA4;: <code>True</code></li>
<li><code>batch_first</code> &#x2013; &#x5982;&#x679C;&#x4E3A; <code>True</code> , &#x90A3;&#x4E48;&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA; Tensor &#x7684;&#x5F62;&#x72B6;&#x4E3A; (batch, seq, feature)</li>
<li><code>dropout</code> &#x2013; &#x5982;&#x679C;&#x975E;&#x96F6;&#x7684;&#x8BDD;, &#x5C06;&#x4F1A;&#x5728; RNN &#x7684;&#x8F93;&#x51FA;&#x4E0A;&#x52A0;&#x4E2A; dropout , &#x6700;&#x540E;&#x4E00;&#x5C42;&#x9664;&#x5916;</li>
<li><code>bidirectional</code> &#x2013; &#x5982;&#x679C;&#x4E3A; <code>True</code>,&#x5C06;&#x4F1A;&#x53D8;&#x6210;&#x4E00;&#x4E2A;&#x53CC;&#x5411; RNN ,&#x9ED8;&#x8BA4;&#x4E3A; <code>False</code></li>
</ul>
<p>Inputs: input, (h_0, c_0)</p>
<ul>
<li><code>input (seq_len, batch, input_size)</code>: &#x5305;&#x542B;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#x7279;&#x5F81;&#x7684; <code>tensor</code> . &#x4E5F;&#x53EF;&#x4EE5;&#x662F; <code>packed variable length sequence</code>, &#x8BE6;&#x89C1; <code>torch.nn.utils.rnn.pack_padded_sequence()</code> .</li>
<li><code>h_0 (num_layers * num_directions, batch, hidden_size)</code>: &#x5305;&#x542B; batch &#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x521D;&#x59CB;&#x5316;&#x9690;&#x72B6;&#x6001;&#x7684; <code>tensor</code> .</li>
<li><code>c_0 (num_layers * num_directions, batch, hidden_size)</code>: &#x5305;&#x542B; batch &#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x521D;&#x59CB;&#x5316;&#x7EC6;&#x80DE;&#x72B6;&#x6001;&#x7684; <code>tensor</code> .</li>
</ul>
<p>Outputs: output, (h_n, c_n)</p>
<ul>
<li><code>output (seq_len, batch, hidden_size * num_directions)</code>: &#x5305;&#x542B; RNN &#x6700;&#x540E;&#x4E00;&#x5C42;&#x7684;&#x8F93;&#x51FA;&#x7279;&#x5F81; <code>(h_t)</code> &#x7684; <code>tensor</code> , &#x5BF9;&#x4E8E;&#x6BCF;&#x4E2A; t . &#x5982;&#x679C;&#x8F93;&#x5165;&#x662F; <code>torch.nn.utils.rnn.PackedSequence</code> &#x90A3;&#x4E48;&#x8F93;&#x51FA;&#x4E5F;&#x662F;&#x4E00;&#x4E2A;&#x53EF;&#x4EE5;&#x662F;&#x88AB;&#x586B;&#x5145;&#x7684;&#x53D8;&#x957F;&#x5E8F;&#x5217;.</li>
<li><code>h_n (num_layers * num_directions, batch, hidden_size)</code>: &#x5305;&#x542B; t=seq_len &#x9690;&#x72B6;&#x6001;&#x7684; <code>tensor</code>.</li>
<li><code>c_n (num_layers * num_directions, batch, hidden_size)</code>: &#x5305;&#x542B; t=seq_len &#x7EC6;&#x80DE;&#x72B6;&#x6001;&#x7684; <code>tensor</code>.</li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li>weight_ih_l[k] &#x2013; &#x7B2C; k &#x5C42;&#x53EF;&#x5B66;&#x4E60;&#x7684; input-hidden &#x6743;&#x91CD; <code>(W_ii&amp;#124;W_if&amp;#124;W_ig&amp;#124;W_io)</code>, shape &#x662F; <code>(4*hidden_size x input_size)</code></li>
<li>weight_hh_l[k] &#x2013; &#x7B2C; k &#x5C42;&#x53EF;&#x5B66;&#x4E60;&#x7684; hidden-hidden &#x6743;&#x91CD; <code>(W_hi&amp;#124;W_hf&amp;#124;W_hg&amp;#124;W_ho)</code>, shape &#x662F; <code>(4*hidden_size x hidden_size)</code></li>
<li>bias_ih_l[k] &#x2013; &#x7B2C; k &#x5C42;&#x53EF;&#x5B66;&#x4E60;&#x7684; input-hidden &#x504F;&#x7F6E; <code>(b_ii&amp;#124;b_if&amp;#124;b_ig&amp;#124;b_io)</code>, shape &#x662F; <code>(4*hidden_size)</code></li>
<li>bias_hh_l[k] &#x2013; &#x7B2C; k &#x5C42;&#x53EF;&#x5B66;&#x4E60;&#x7684; hidden-hidden &#x504F;&#x7F6E; <code>(b_hi&amp;#124;b_hf&amp;#124;b_hg&amp;#124;b_ho)</code>, shape &#x662F; <code>(4*hidden_size)</code></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>rnn = nn.LSTM(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = Variable(torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>, <span class="hljs-number">10</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>h0 = Variable(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">20</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>c0 = Variable(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">20</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output, hn = rnn(input, (h0, c0))
</code></pre>
<h3 id="gru">GRU</h3>
<pre><code class="lang-py">class torch.nn.GRU(*args, **kwargs)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#x4F7F;&#x7528;&#x4E00;&#x4E2A;&#x591A;&#x5C42;&#x7684; <code>GRU</code> (gated recurrent unit).</p>
<p>&#x5BF9;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#x7684;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;, &#x6BCF;&#x5C42;&#x90FD;&#x4F1A;&#x6267;&#x884C;&#x4EE5;&#x4E0B;&#x8BA1;&#x7B97;:</p>
<p><img src="img/tex-acd0dd125732ec681cab120f096f4a00.gif" alt="\begin{split}\begin{array}{ll} r_t = \mathrm{sigmoid}(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\ z_t = \mathrm{sigmoid}(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\ n_t = \tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\ h_t = (1 - z_t) * n_t + z_t * h_{(t-1)} \\ \end{array}\end{split}"></p>
<p>&#x8FD9;&#x91CC; <img src="img/tex-6c4ff69dbcc329835a33b80fe3a145c7.gif" alt="h_t"> &#x662F;&#x5728;&#x65F6;&#x523B; <code>t</code> &#x7684;&#x9690;&#x72B6;&#x6001;, <img src="img/tex-cf7ee950cf61a6003c0ec4af7971d8a8.gif" alt="x_t"> &#x662F;&#x524D;&#x4E00;&#x5C42;&#x5728;&#x65F6;&#x523B; <code>t</code> &#x7684;&#x9690;&#x72B6;&#x6001;&#x6216;&#x8005;&#x662F;&#x7B2C;&#x4E00;&#x5C42;&#x7684; <img src="img/tex-bbcb26ab6bab8f51269870e0abcec697.gif" alt="input_t"> , &#x800C; <img src="img/tex-3d1dfe70cdc0d574aa6cf3e228a57166.gif" alt="r_t">, <img src="img/tex-0bcd91fb6432f991d5b4cbb079e562c7.gif" alt="z_t">, <img src="img/tex-871b354d265716a852eea9970e53ff5e.gif" alt="n_t"> &#x5206;&#x522B;&#x662F;&#x91CD;&#x7F6E;&#x95E8;,&#x8F93;&#x5165;&#x95E8;&#x548C;&#x65B0;&#x95E8;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>input_size</code> &#x2013; &#x8F93;&#x5165;&#x7684;&#x7279;&#x5F81;&#x7EF4;&#x5EA6;</li>
<li><code>hidden_size</code> &#x2013; &#x9690;&#x72B6;&#x6001;&#x7684;&#x7279;&#x5F81;&#x7EF4;&#x5EA6;</li>
<li><code>num_layers</code> &#x2013; RNN &#x7684;&#x5C42;&#x6570;</li>
<li><code>bias</code> &#x2013; &#x5982;&#x679C;&#x4E3A; <code>False</code>, &#x90A3;&#x4E48; RNN &#x5C42;&#x5C06;&#x4E0D;&#x4F1A;&#x4F7F;&#x7528;&#x504F;&#x7F6E;&#x6743;&#x91CD; b_ih &#x548C; b_hh &#x9ED8;&#x8BA4;: <code>True</code></li>
<li><code>batch_first</code> &#x2013; &#x5982;&#x679C;&#x4E3A; <code>True</code>, &#x90A3;&#x4E48;&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA;&#x7684; <code>tensor</code> &#x7684;&#x5F62;&#x72B6;&#x662F; (batch, seq, feature)</li>
<li><code>dropout</code> &#x2013; &#x5982;&#x679C;&#x975E;&#x96F6;&#x7684;&#x8BDD;,&#x5C06;&#x4F1A;&#x5728; RNN &#x7684;&#x8F93;&#x51FA;&#x4E0A;&#x52A0;&#x4E2A; dropout ,&#x6700;&#x540E;&#x4E00;&#x5C42;&#x9664;&#x5916;</li>
<li><code>bidirectional</code> &#x2013; &#x5982;&#x679C;&#x4E3A; <code>True</code>, &#x5C06;&#x4F1A;&#x53D8;&#x6210;&#x4E00;&#x4E2A;&#x53CC;&#x5411; RNN . &#x9ED8;&#x8BA4;: <code>False</code></li>
</ul>
<p>Inputs: input, h_0</p>
<ul>
<li><code>input (seq_len, batch, input_size)</code>: &#x5305;&#x542B;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#x7279;&#x5F81;&#x7684; <code>tensor</code> . &#x4E5F;&#x53EF;&#x4EE5;&#x662F; <code>packed variable length sequence</code>, &#x8BE6;&#x89C1; <code>torch.nn.utils.rnn.pack_padded_sequence()</code> .</li>
<li><code>h_0 (num_layers * num_directions, batch, hidden_size)</code>: &#x5305;&#x542B; batch &#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x521D;&#x59CB;&#x5316;&#x9690;&#x72B6;&#x6001;&#x7684; <code>tensor</code></li>
</ul>
<p>Outputs: output, h_n</p>
<ul>
<li><code>output (seq_len, batch, hidden_size * num_directions)</code>: &#x5305;&#x542B; RNN &#x6700;&#x540E;&#x4E00;&#x5C42;&#x7684;&#x8F93;&#x51FA;&#x7279;&#x5F81; <code>(h_t)</code> &#x7684; <code>tensor</code> , &#x5BF9;&#x4E8E;&#x6BCF;&#x4E2A; t . &#x5982;&#x679C;&#x8F93;&#x5165;&#x662F; <code>torch.nn.utils.rnn.PackedSequence</code> &#x90A3;&#x4E48;&#x8F93;&#x51FA;&#x4E5F;&#x662F;&#x4E00;&#x4E2A;&#x53EF;&#x4EE5;&#x662F;&#x88AB;&#x586B;&#x5145;&#x7684;&#x53D8;&#x957F;&#x5E8F;&#x5217;.</li>
<li><code>h_n (num_layers * num_directions, batch, hidden_size)</code>: &#x5305;&#x542B; t=seq_len &#x9690;&#x72B6;&#x6001;&#x7684; <code>tensor</code>.</li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li>weight_ih_l[k] &#x2013; &#x7B2C; k &#x5C42;&#x53EF;&#x5B66;&#x4E60;&#x7684; input-hidden &#x6743;&#x91CD; (W_ir|W_iz|W_in), shape &#x4E3A; <code>(3*hidden_size x input_size)</code></li>
<li>weight_hh_l[k] &#x2013; &#x7B2C; k &#x5C42;&#x53EF;&#x5B66;&#x4E60;&#x7684; hidden-hidden &#x6743;&#x91CD; (W_hr|W_hz|W_hn), shape &#x4E3A; <code>(3*hidden_size x hidden_size)</code></li>
<li>bias_ih_l[k] &#x2013; &#x7B2C; k &#x5C42;&#x53EF;&#x5B66;&#x4E60;&#x7684; input-hidden &#x504F;&#x7F6E; (b_ir|b_iz|b_in), shape &#x4E3A; <code>(3*hidden_size)</code></li>
<li>bias_hh_l[k] &#x2013; &#x7B2C; k &#x5C42;&#x53EF;&#x5B66;&#x4E60;&#x7684; hidden-hidden &#x504F;&#x7F6E; (b_hr|b_hz|b_hn), shape &#x4E3A; <code>(3*hidden_size)</code></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>rnn = nn.GRU(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = Variable(torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">3</span>, <span class="hljs-number">10</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>h0 = Variable(torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">20</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output, hn = rnn(input, h0)
</code></pre>
<h3 id="rnncell">RNNCell</h3>
<pre><code class="lang-py">class torch.nn.RNNCell(input_size, hidden_size, bias=True, nonlinearity=&apos;tanh&apos;)
</code></pre>
<p>&#x4E00;&#x4E2A; <code>Elan RNN cell</code> , &#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x662F; tanh &#x6216; ReLU , &#x7528;&#x4E8E;&#x8F93;&#x5165;&#x5E8F;&#x5217;.</p>
<p><img src="img/tex-209461341961969b0f0807545f76affd.gif" alt="h&apos; = \tanh(w_{ih} * x + b_{ih} + w_{hh} * h + b_{hh})"></p>
<p>&#x5982;&#x679C; nonlinearity=&#x2019;relu&#x2019;, &#x90A3;&#x4E48;&#x5C06;&#x4F1A;&#x4F7F;&#x7528; ReLU &#x6765;&#x4EE3;&#x66FF; tanh .</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>input_size</code> &#x2013; &#x8F93;&#x5165;&#x7684;&#x7279;&#x5F81;&#x7EF4;&#x5EA6;</li>
<li><code>hidden_size</code> &#x2013; &#x9690;&#x72B6;&#x6001;&#x7684;&#x7279;&#x5F81;&#x7EF4;&#x5EA6;</li>
<li><code>bias</code> &#x2013; &#x5982;&#x679C;&#x4E3A; <code>False</code>, &#x90A3;&#x4E48;RNN&#x5C42;&#x5C06;&#x4E0D;&#x4F1A;&#x4F7F;&#x7528;&#x504F;&#x7F6E;&#x6743;&#x91CD; b_ih &#x548C; b_hh. &#x9ED8;&#x8BA4;: <code>True</code></li>
<li><code>nonlinearity</code> &#x2013; &#x7528;&#x4E8E;&#x9009;&#x62E9;&#x975E;&#x7EBF;&#x6027;&#x6FC0;&#x6D3B;&#x51FD;&#x6570; [&#x2018;tanh&#x2019;|&#x2019;relu&#x2019;]. &#x9ED8;&#x8BA4;: &#x2018;tanh&#x2019;</li>
</ul>
<p>Inputs: input, hidden</p>
<ul>
<li><code>input (batch, input_size)</code>: &#x5305;&#x542B;&#x8F93;&#x5165;&#x7279;&#x5F81;&#x7684; <code>tensor</code> .</li>
<li><code>hidden (batch, hidden_size)</code>: &#x5305;&#x542B; batch &#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x521D;&#x59CB;&#x5316;&#x9690;&#x72B6;&#x6001;&#x7684; <code>tensor</code>.</li>
</ul>
<p>Outputs: h&#x2019;</p>
<ul>
<li>h&#x2019; (batch, hidden_size): &#x4FDD;&#x5B58;&#x7740; batch &#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x4E0B;&#x4E00;&#x5C42;&#x9690;&#x72B6;&#x6001;&#x7684; <code>tensor</code> .</li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li><code>weight_ih</code> &#x2013; <code>input-hidden</code> &#x6743;&#x91CD;, &#x53EF;&#x5B66;&#x4E60;, shape &#x4E3A; <code>(input_size x hidden_size)</code></li>
<li><code>weight_hh</code> &#x2013; <code>hidden-hidden</code> &#x6743;&#x91CD;, &#x53EF;&#x5B66;&#x4E60;, shape &#x4E3A; <code>(hidden_size x hidden_size)</code></li>
<li><code>bias_ih</code> &#x2013; <code>input-hidden</code> &#x504F;&#x7F6E;,&#x53EF;&#x5B66;&#x4E60;, shape &#x4E3A; <code>(hidden_size)</code></li>
<li><code>bias_hh</code> &#x2013; <code>hidden-hidden</code> &#x504F;&#x7F6E;,&#x53EF;&#x5B66;&#x4E60;, shape &#x4E3A; <code>(hidden_size)</code></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>rnn = nn.RNNCell(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = Variable(torch.randn(<span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">10</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>hx = Variable(torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">20</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = []
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">6</span>):
<span class="hljs-meta">... </span>    hx = rnn(input[i], hx)
<span class="hljs-meta">... </span>    output.append(hx)
</code></pre>
<h3 id="lstmcell">LSTMCell</h3>
<pre><code class="lang-py">class torch.nn.LSTMCell(input_size, hidden_size, bias=True)
</code></pre>
<p>LSTM &#x7EC6;&#x80DE;.</p>
<p><img src="img/tex-00f313e58f35fa58da4f06223a36c475.gif" alt="\begin{split}\begin{array}{ll} i = \mathrm{sigmoid}(W_{ii} x + b_{ii} + W_{hi} h + b_{hi}) \\ f = \mathrm{sigmoid}(W_{if} x + b_{if} + W_{hf} h + b_{hf}) \\ g = \tanh(W_{ig} x + b_{ig} + W_{hc} h + b_{hg}) \\ o = \mathrm{sigmoid}(W_{io} x + b_{io} + W_{ho} h + b_{ho}) \\ c&apos; = f * c + i * g \\ h&apos; = o * \tanh(c&apos;) \\ \end{array}\end{split}"></p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>input_size</code> &#x2013; &#x8F93;&#x5165;&#x7684;&#x7279;&#x5F81;&#x7EF4;&#x5EA6;</li>
<li><code>hidden_size</code> &#x2013; &#x9690;&#x72B6;&#x6001;&#x7684;&#x7EF4;&#x5EA6;</li>
<li><code>bias</code> &#x2013; &#x5982;&#x679C;&#x4E3A; <code>False</code>, &#x90A3;&#x4E48;RNN&#x5C42;&#x5C06;&#x4E0D;&#x4F1A;&#x4F7F;&#x7528;&#x504F;&#x7F6E;&#x6743;&#x91CD; b_ih &#x548C; b_hh &#x9ED8;&#x8BA4;: <code>True</code></li>
</ul>
<p>Inputs: input, (h_0, c_0)</p>
<ul>
<li><code>input (batch, input_size)</code>: &#x5305;&#x542B;&#x8F93;&#x5165;&#x7279;&#x5F81;&#x7684; <code>tensor</code> .</li>
<li><code>h_0 (batch, hidden_size)</code>: &#x5305;&#x542B; batch &#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x521D;&#x59CB;&#x5316;&#x9690;&#x72B6;&#x6001;&#x7684; <code>tensor</code>.</li>
<li><code>c_0 (batch. hidden_size)</code>: &#x5305;&#x542B; batch &#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x521D;&#x59CB;&#x5316;&#x7EC6;&#x80DE;&#x72B6;&#x6001;&#x7684; <code>tensor</code></li>
</ul>
<p>Outputs: h_1, c_1</p>
<ul>
<li><code>h_1 (batch, hidden_size)</code>: &#x4FDD;&#x5B58;&#x7740; batch &#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x4E0B;&#x4E00;&#x5C42;&#x9690;&#x72B6;&#x6001;&#x7684; <code>tensor</code></li>
<li><code>c_1 (batch, hidden_size)</code>: &#x4FDD;&#x5B58;&#x7740; batch &#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x4E0B;&#x4E00;&#x7EC6;&#x80DE;&#x72B6;&#x6001;&#x7684; <code>tensor</code></li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li><code>weight_ih</code> &#x2013; <code>input-hidden</code> &#x6743;&#x91CD;, &#x53EF;&#x5B66;&#x4E60;, &#x5F62;&#x72B6;&#x4E3A; <code>(4*hidden_size x input_size)</code></li>
<li><code>weight_hh</code> &#x2013; <code>hidden-hidden</code> &#x6743;&#x91CD;, &#x53EF;&#x5B66;&#x4E60;, &#x5F62;&#x72B6;&#x4E3A; <code>(4*hidden_size x hidden_size)</code></li>
<li><code>bias_ih</code> &#x2013; <code>input-hidden</code> &#x504F;&#x7F6E;, &#x53EF;&#x5B66;&#x4E60;, &#x5F62;&#x72B6;&#x4E3A; <code>(4*hidden_size)</code></li>
<li><code>bias_hh</code> &#x2013; <code>hidden-hidden</code> &#x504F;&#x7F6E;, &#x53EF;&#x5B66;&#x4E60;, &#x5F62;&#x72B6;&#x4E3A; <code>(4*hidden_size)</code></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>rnn = nn.LSTMCell(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = Variable(torch.randn(<span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">10</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>hx = Variable(torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">20</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>cx = Variable(torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">20</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = []
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">6</span>):
<span class="hljs-meta">... </span>    hx, cx = rnn(input[i], (hx, cx))
<span class="hljs-meta">... </span>    output.append(hx)
</code></pre>
<h3 id="grucell">GRUCell</h3>
<pre><code class="lang-py">class torch.nn.GRUCell(input_size, hidden_size, bias=True)
</code></pre>
<p>GRU &#x7EC6;&#x80DE;</p>
<p><img src="img/tex-16404bdd55736af51799dd91ad2bcbf4.gif" alt="\begin{split}\begin{array}{ll} r = \mathrm{sigmoid}(W_{ir} x + b_{ir} + W_{hr} h + b_{hr}) \\ z = \mathrm{sigmoid}(W_{iz} x + b_{iz} + W_{hz} h + b_{hz}) \\ n = \tanh(W_{in} x + b_{in} + r * (W_{hn} h + b_{hn})) \\ h&apos; = (1 - z) * n + z * h \end{array}\end{split}"></p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>input_size</code> &#x2013; &#x8F93;&#x5165;&#x7684;&#x7279;&#x5F81;&#x7EF4;&#x5EA6;</li>
<li><code>hidden_size</code> &#x2013; &#x9690;&#x72B6;&#x6001;&#x7684;&#x7EF4;&#x5EA6;</li>
<li><code>bias</code> &#x2013; &#x5982;&#x679C;&#x4E3A; <code>False</code>, &#x90A3;&#x4E48;RNN&#x5C42;&#x5C06;&#x4E0D;&#x4F1A;&#x4F7F;&#x7528;&#x504F;&#x7F6E;&#x6743;&#x91CD; b_ih &#x548C; b_hh &#x9ED8;&#x8BA4;: <code>True</code></li>
</ul>
<p>Inputs: input, hidden</p>
<ul>
<li><code>input (batch, input_size)</code>: &#x5305;&#x542B;&#x8F93;&#x5165;&#x7279;&#x5F81;&#x7684; <code>tensor</code> .</li>
<li><code>hidden (batch, hidden_size)</code>: &#x5305;&#x542B; batch &#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x521D;&#x59CB;&#x5316;&#x9690;&#x72B6;&#x6001;&#x7684; <code>tensor</code>.</li>
</ul>
<p>Outputs: h&#x2019;</p>
<ul>
<li>h&#x2019;: (batch, hidden_size): &#x4FDD;&#x5B58;&#x7740; batch &#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x4E0B;&#x4E00;&#x5C42;&#x9690;&#x72B6;&#x6001;&#x7684; <code>tensor</code></li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li><code>weight_ih</code> &#x2013; <code>input-hidden</code> &#x6743;&#x91CD;, &#x53EF;&#x5B66;&#x4E60;, shape &#x4E3A;, <code>(3*hidden_size x input_size)</code></li>
<li><code>weight_hh</code> &#x2013; <code>hidden-hidden</code> &#x6743;&#x91CD;, &#x53EF;&#x5B66;&#x4E60;, shape &#x4E3A; <code>(3*hidden_size x hidden_size)</code></li>
<li><code>bias_ih</code> &#x2013; <code>input-hidden</code> &#x504F;&#x7F6E;, &#x53EF;&#x5B66;&#x4E60;, shape &#x4E3A; <code>(3*hidden_size)</code></li>
<li><code>bias_hh</code> &#x2013; <code>hidden-hidden</code> &#x504F;&#x7F6E;, &#x53EF;&#x5B66;&#x4E60;, shape &#x4E3A; <code>(3*hidden_size)</code></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>rnn = nn.GRUCell(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = Variable(torch.randn(<span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">10</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>hx = Variable(torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">20</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = []
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">6</span>):
<span class="hljs-meta">... </span>    hx = rnn(input[i], hx)
<span class="hljs-meta">... </span>    output.append(hx)
</code></pre>
<h2 id="linear-layers-&#x7EBF;&#x6027;&#x5C42;">Linear layers (&#x7EBF;&#x6027;&#x5C42;)</h2>
<h3 id="linear">Linear</h3>
<pre><code class="lang-py">class torch.nn.Linear(in_features, out_features, bias=True)
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x7EBF;&#x6027;&#x53D8;&#x6362;: <img src="img/tex-7b9f11d97a4a0531566a8b3ceb4b3cd2.gif" alt="y = Ax + b"></p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>in_features</code> &#x2013; &#x6BCF;&#x4E2A;&#x8F93;&#x5165;&#x6837;&#x672C;&#x7684;&#x5927;&#x5C0F;</li>
<li><code>out_features</code> &#x2013; &#x6BCF;&#x4E2A;&#x8F93;&#x51FA;&#x6837;&#x672C;&#x7684;&#x5927;&#x5C0F;</li>
<li><code>bias</code> &#x2013; &#x82E5;&#x8BBE;&#x7F6E;&#x4E3A; False, &#x8FD9;&#x5C42;&#x4E0D;&#x4F1A;&#x5B66;&#x4E60;&#x504F;&#x7F6E;. &#x9ED8;&#x8BA4;&#x503C;: True</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-473bd210940b2d1080beaaa69de08f28.gif" alt="(N, *, in\_features)"> &#x8FD9;&#x91CC; <code>*</code> &#x610F;&#x5473;&#x7740;&#x53EF;&#x4EE5;&#x6DFB;&#x52A0;&#x4EFB;&#x610F;&#x6570;&#x91CF;&#x7684;&#x5176;&#x4ED6;&#x7EF4;&#x5EA6;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-5726e9a80713e6a886ae6140fcdba481.gif" alt="(N, *, out\_features)"> &#x9664;&#x4E86;&#x6700;&#x540E;&#x4E00;&#x4E2A;&#x7EF4;&#x5EA6;&#x5916;, &#x5176;&#x4F59;&#x7684;&#x90FD;&#x4E0E;&#x8F93;&#x5165;&#x76F8;&#x540C;</li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li><code>weight</code> &#x2013; &#x5F62;&#x72B6;&#x4E3A; (out_features x in_features) &#x7684;&#x6A21;&#x5757;&#x4E2D;&#x53EF;&#x5B66;&#x4E60;&#x7684;&#x6743;&#x503C;</li>
<li><code>bias</code> &#x2013; &#x5F62;&#x72B6;&#x4E3A; (out_features) &#x7684;&#x6A21;&#x5757;&#x4E2D;&#x53EF;&#x5B66;&#x4E60;&#x7684;&#x504F;&#x7F6E;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Linear(<span class="hljs-number">20</span>, <span class="hljs-number">30</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">128</span>, <span class="hljs-number">20</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(output.size())
</code></pre>
<h3 id="bilinear">Bilinear</h3>
<pre><code class="lang-py">class torch.nn.Bilinear(in1_features, in2_features, out_features, bias=True)
</code></pre>
<p>&#x5BF9;&#x8F93;&#x5165;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x53CC;&#x7EBF;&#x6027;&#x53D8;&#x6362;: <img src="img/tex-aaf171cac82685c3c340333937649cd0.gif" alt="y = x_1 * A * x_2 + b"></p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>in1_features</code> &#x2013; &#x8F93;&#x5165;&#x4E00;&#x7684;&#x6BCF;&#x4E2A;&#x8F93;&#x5165;&#x6837;&#x672C;&#x7684;&#x5927;&#x5C0F;</li>
<li><code>in2_features</code> &#x2013; &#x8F93;&#x5165;&#x4E8C;&#x7684;&#x6BCF;&#x4E2A;&#x8F93;&#x5165;&#x6837;&#x672C;&#x7684;&#x5927;&#x5C0F;</li>
<li><code>out_features</code> &#x2013; &#x6BCF;&#x4E2A;&#x8F93;&#x51FA;&#x6837;&#x672C;&#x7684;&#x5927;&#x5C0F;</li>
<li><code>bias</code> &#x2013; &#x82E5;&#x8BBE;&#x7F6E;&#x4E3A;False, &#x8FD9;&#x5C42;&#x4E0D;&#x4F1A;&#x5B66;&#x4E60;&#x504F;&#x7F6E;. &#x9ED8;&#x8BA4;&#x503C;: True</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-cd06e008711b0ac8b3a44cfab48eb593.gif" alt="(N, in1\_features)">, <img src="img/tex-91654b72e709cc4b218047fb1f65ece3.gif" alt="(N, in2\_features)"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-899e6c8f98b5fd7650a52ead62f6c414.gif" alt="(N, out\_features)"></li>
</ul>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li><code>weight</code> &#x2013; &#x5F62;&#x72B6;&#x4E3A; (out_features x in1_features x in2_features) &#x7684;&#x6A21;&#x5757;&#x4E2D;&#x53EF;&#x5B66;&#x4E60;&#x7684;&#x6743;&#x503C;</li>
<li><code>bias</code> &#x2013; &#x5F62;&#x72B6;&#x4E3A; (out_features) &#x7684;&#x6A21;&#x5757;&#x4E2D;&#x53EF;&#x5B66;&#x4E60;&#x7684;&#x504F;&#x7F6E;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Bilinear(<span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">40</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input1 = autograd.Variable(torch.randn(<span class="hljs-number">128</span>, <span class="hljs-number">20</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input2 = autograd.Variable(torch.randn(<span class="hljs-number">128</span>, <span class="hljs-number">30</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input1, input2)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(output.size())
</code></pre>
<h2 id="dropout-layers">Dropout layers</h2>
<h3 id="dropout">Dropout</h3>
<pre><code class="lang-py">class torch.nn.Dropout(p=0.5, inplace=False)
</code></pre>
<p>Dropout &#x5728;&#x8BAD;&#x7EC3;&#x671F;&#x95F4;, &#x6309;&#x7167;&#x4F2F;&#x52AA;&#x5229;&#x6982;&#x7387;&#x5206;&#x5E03;, &#x4EE5;&#x6982;&#x7387; p &#x968F;&#x673A;&#x5730;&#x5C06;&#x8F93;&#x5165;&#x5F20;&#x91CF;&#x4E2D;&#x7684;&#x90E8;&#x5206;&#x5143;&#x7D20;</p>
<p>&#x7F6E;&#x4E3A; 0, &#x5728;&#x6BCF;&#x6B21;&#x8C03;&#x7528;&#x65F6;, &#x88AB;&#x7F6E;&#x4E3A; 0 &#x7684;&#x5143;&#x7D20;&#x662F;&#x968F;&#x673A;&#x7684;.</p>
<p>Dropout &#x5DF2;&#x88AB;&#x8BC1;&#x660E;&#x662F;&#x6B63;&#x5219;&#x5316;&#x7684;&#x4E00;&#x4E2A;&#x884C;&#x4E4B;&#x6709;&#x6548;&#x7684;&#x6280;&#x672F;, &#x5E76;&#x4E14;&#x5728;&#x9632;&#x6B62;&#x795E;&#x7ECF;&#x5143;&#x4E4B;&#x95F4;&#x4E92;&#x9002;&#x5E94;&#x95EE;&#x9898;&#x4E0A; &#x4E5F;&#x5353;&#x6709;&#x6210;&#x6548;.&#xFF08;&#x795E;&#x7ECF;&#x5143;&#x4E92;&#x9002;&#x5E94;&#x95EE;&#x9898;&#x8BE6;&#x89C1;&#x8BBA;&#x6587; <a href="https://arxiv.org/abs/1207.0580" target="_blank">Improving neural networks by preventing co-adaptation of feature detectors</a> &#xFF09;</p>
<p>&#x5E76;&#x4E14;, Dropout &#x7684;&#x8F93;&#x51FA;&#x5747;&#x4E0E; <em>1/(1-p)</em> &#x7684;&#x6BD4;&#x4F8B;&#x7CFB;&#x6570;&#x8FDB;&#x884C;&#x4E86;&#x76F8;&#x4E58;, &#x4FDD;&#x8BC1;&#x4E86;&#x6C42;&#x503C;&#x65F6;&#x51FD;&#x6570;&#x662F;&#x5F52;&#x4E00;&#x5316;&#x7684;.</p>
<p>Args: p: &#x5143;&#x7D20;&#x88AB;&#x7F6E;&#x4E3A;0&#x7684;&#x6982;&#x7387;, &#x9ED8;&#x8BA4;&#x503C;: 0.5 inplace: &#x5982;&#x679C;&#x4E3A; True, &#x7F6E;0&#x64CD;&#x4F5C;&#x5C06;&#x76F4;&#x63A5;&#x53D1;&#x751F;&#x5728;&#x4F20;&#x5165;&#x7684;&#x5143;&#x7D20;&#x4E0A;.&#x9ED8;&#x8BA4;&#x503C;: false Shape:</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;any.&#x8F93;&#x5165;&#x6570;&#x636E;&#x53EF;&#x4EE5;&#x662F;&#x4EFB;&#x4F55;&#x5927;&#x5C0F;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;Same.&#x8F93;&#x51FA;&#x6570;&#x636E;&#x5927;&#x5C0F;&#x4E0E;&#x8F93;&#x5165;&#x76F8;&#x540C;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Dropout(p=<span class="hljs-number">0.2</span>)
</code></pre>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = m(input)
</code></pre>
<h3 id="dropout2d">Dropout2d</h3>
<pre><code class="lang-py">class torch.nn.Dropout2d(p=0.5, inplace=False)
</code></pre>
<p>Dropout2d &#x5C06;&#x8F93;&#x5165;&#x5F20;&#x91CF;&#x7684;&#x6240;&#x6709;&#x901A;&#x9053;&#x968F;&#x673A;&#x5730;&#x7F6E;&#x4E3A; 0.&#x88AB;&#x7F6E;&#x4E3A; 0 &#x7684;&#x901A;&#x9053;&#x5728;&#x6BCF;&#x6B21;&#x8C03;&#x7528;&#x65F6;&#x662F;&#x968F;&#x673A;&#x7684;.</p>
<blockquote>
<p>&#x901A;&#x5E38;&#x8F93;&#x5165;&#x6570;&#x636E;&#x6765;&#x81EA; Conv2d &#x6A21;&#x5757;.</p>
<p>&#x5728;&#x8BBA;&#x6587; <a href="http://arxiv.org/abs/1411.4280" target="_blank">Efficient Object Localization Using Convolutional Networks</a> &#x4E2D;&#x6709;&#x5982;&#x4E0B; &#x63CF;&#x8FF0;: &#x5982;&#x679C;&#x7279;&#x5F81;&#x6620;&#x5C04;&#x4E2D;&#x7684;&#x90BB;&#x63A5;&#x50CF;&#x7D20;&#x662F;&#x5F3A;&#x76F8;&#x5173;&#x7684;&#xFF08;&#x5728;&#x65E9;&#x671F;&#x7684;&#x5377;&#x79EF;&#x5C42;&#x4E2D;&#x5F88;&#x5E38;&#x89C1;&#xFF09;, &#x90A3;&#x4E48;&#x72EC;&#x7ACB;&#x540C;&#x5206;&#x5E03; &#x7684; dropout &#x5C06;&#x4E0D;&#x4F1A;&#x6B63;&#x5219;&#x5316;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;, &#x76F8;&#x53CD;&#x5176;&#x4F1A;&#x5BFC;&#x81F4;&#x6709;&#x6548;&#x7684;&#x5B66;&#x4E60;&#x7387;&#x7684;&#x4E0B;&#x964D;.</p>
<p>&#x5728;&#x8FD9;&#x6837;&#x7684;&#x60C5;&#x51B5;&#x4E0B;, &#x5E94;&#x8BE5;&#x4F7F;&#x7528;&#x51FD;&#x6570;&#x51FD;&#x6570; nn.Dropout2d , &#x5B83;&#x80FD;&#x591F;&#x63D0;&#x5347;&#x7279;&#x5F81;&#x6620;&#x5C04;&#x4E4B;&#x95F4;&#x7684;&#x72EC;&#x7ACB;&#x6027;.</p>
<p>Args: p (float,optional): &#x5143;&#x7D20;&#x88AB;&#x7F6E;0&#x7684;&#x6982;&#x7387; inplace&#xFF08;bool, &#x53EF;&#x9009;&#xFF09;: &#x5982;&#x679C;&#x88AB;&#x8BBE;&#x4E3A;&#x2019;True&#x2019;, &#x7F6E;0&#x64CD;&#x4F5C;&#x5C06;&#x76F4;&#x63A5;&#x4F5C;&#x7528;&#x5728;&#x8F93;&#x5165;&#x5143;&#x7D20;&#x4E0A; Shape:</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;math:(N, C, H, W)</li>
<li>&#x8F93;&#x51FA;&#xFF1A;math:(N, C, H, W) &#xFF08;&#x4E0E;&#x8F93;&#x5165;&#x76F8;&#x540C;&#xFF09;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py">&amp;gt;&amp;gt;&amp;gt; m = nn.Dropout2d(p=<span class="hljs-number">0.2</span>)
</code></pre>
<pre><code class="lang-py">&amp;gt;&amp;gt;&amp;gt; input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>))
&amp;gt;&amp;gt;&amp;gt; output = m(input)
</code></pre>
</blockquote>
<h3 id="dropout3d">Dropout3d</h3>
<pre><code class="lang-py">class torch.nn.Dropout3d(p=0.5, inplace=False)
</code></pre>
<p>Dropout3d &#x5C06;&#x8F93;&#x5165;&#x5F20;&#x91CF;&#x7684;&#x6240;&#x6709;&#x901A;&#x9053;&#x968F;&#x673A;&#x5730;&#x7F6E;&#x4E3A; 0.&#x88AB;&#x7F6E;&#x4E3A; 0 &#x7684;&#x901A;&#x9053;&#x5728;&#x6BCF;&#x6B21;&#x8C03;&#x7528;&#x65F6;&#x662F;&#x968F;&#x673A;&#x7684;.</p>
<blockquote>
<p>&#x901A;&#x5E38;&#x8F93;&#x5165;&#x6570;&#x636E;&#x6765;&#x81EA; Conv3d &#x6A21;&#x5757;.</p>
<p>&#x5728;&#x8BBA;&#x6587; <a href="http://arxiv.org/abs/1411.4280" target="_blank">Efficient Object Localization Using Convolutional Networks</a> &#x4E2D;&#x6709;&#x5982;&#x4E0B; &#x63CF;&#x8FF0;: &#x5982;&#x679C;&#x7279;&#x5F81;&#x6620;&#x5C04;&#x4E2D;&#x7684;&#x90BB;&#x63A5;&#x50CF;&#x7D20;&#x662F;&#x5F3A;&#x76F8;&#x5173;&#x7684;&#xFF08;&#x5728;&#x65E9;&#x671F;&#x7684;&#x5377;&#x79EF;&#x5C42;&#x4E2D;&#x5F88;&#x5E38;&#x89C1;&#xFF09;, &#x90A3;&#x4E48;&#x72EC;&#x7ACB;&#x540C;&#x5206;&#x5E03; &#x7684; dropout &#x5C06;&#x4E0D;&#x4F1A;&#x6B63;&#x5219;&#x5316;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;, &#x76F8;&#x53CD;&#x5176;&#x4F1A;&#x5BFC;&#x81F4;&#x6709;&#x6548;&#x7684;&#x5B66;&#x4E60;&#x7387;&#x7684;&#x4E0B;&#x964D;.</p>
<p>&#x5728;&#x8FD9;&#x6837;&#x7684;&#x60C5;&#x51B5;&#x4E0B;, &#x5E94;&#x8BE5;&#x4F7F;&#x7528;&#x51FD;&#x6570;&#x51FD;&#x6570; nn.Dropout3d , &#x5B83;&#x80FD;&#x591F;&#x4FC3;&#x8FDB;&#x7279;&#x5F81;&#x6620;&#x5C04;&#x4E4B;&#x95F4;&#x7684;&#x72EC;&#x7ACB;&#x6027;.</p>
<p>Args: p (float,optional): &#x5143;&#x7D20;&#x88AB;&#x7F6E;0&#x7684;&#x6982;&#x7387; inplace&#xFF08;bool, &#x53EF;&#x9009;&#xFF09;: &#x5982;&#x679C;&#x88AB;&#x8BBE;&#x4E3A; True , &#x7F6E;0&#x64CD;&#x4F5C;&#x5C06;&#x76F4;&#x63A5;&#x4F5C;&#x7528;&#x5728;&#x8F93;&#x5165;&#x5143;&#x7D20;&#x4E0A; Shape:</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;math:(N, C, H, W)</li>
<li>&#x8F93;&#x51FA;&#xFF1A;math:(N, C, H, W) &#xFF08;&#x4E0E;&#x8F93;&#x5165;&#x76F8;&#x540C;&#xFF09;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py">&amp;gt;&amp;gt;&amp;gt; m = nn.Dropout3d(p=<span class="hljs-number">0.2</span>)
</code></pre>
<pre><code class="lang-py">&amp;gt;&amp;gt;&amp;gt; input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>, <span class="hljs-number">4</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>))
&amp;gt;&amp;gt;&amp;gt; output = m(input)
</code></pre>
</blockquote>
<h3 id="alphadropout">AlphaDropout</h3>
<pre><code class="lang-py">class torch.nn.AlphaDropout(p=0.5)
</code></pre>
<p>&#x5728;&#x8F93;&#x5165;&#x4E0A;&#x5E94;&#x7528; Alpha Dropout.</p>
<blockquote>
<p>Alpha Dropout &#x662F;&#x4E00;&#x79CD;&#x7EF4;&#x6301;&#x81EA;&#x6B63;&#x4EA4;&#x6027;&#x8D28;&#x7684; Dropout . &#x5BF9;&#x4E8E;&#x4E00;&#x4E2A;&#x5747;&#x503C;&#x4E3A; 0 &#x548C;&#x6807;&#x51C6;&#x5DEE;&#x4E3A; 1 &#x7684;&#x8F93;&#x5165; &#x6765;&#x8BF4;, Alpha Dropout &#x80FD;&#x4FDD;&#x6301;&#x539F;&#x59CB;&#x6570;&#x636E;&#x7684;&#x5747;&#x503C;&#x548C;&#x6807;&#x51C6;&#x5DEE;.Alpha Dropout &#x548C; SELU &#x6FC0;&#x6D3B;&#x51FD;&#x6570; &#x643A;&#x624B;&#x540C;&#x884C;, &#x540E;&#x8005;&#x4E5F;&#x4FDD;&#x8BC1;&#x4E86;&#x8F93;&#x51FA;&#x62E5;&#x6709;&#x4E0E;&#x8F93;&#x5165;&#x76F8;&#x540C;&#x7684;&#x5747;&#x503C;&#x548C;&#x6807;&#x51C6;&#x5DEE;.</p>
<p>Alpha Dropout &#x5728;&#x8BAD;&#x7EC3;&#x671F;&#x95F4;, &#x6309;&#x7167;&#x4F2F;&#x52AA;&#x5229;&#x6982;&#x7387;&#x5206;&#x5E03;, &#x4EE5;&#x6982;&#x7387; p &#x968F;&#x673A;&#x5730;&#x5C06;&#x8F93;&#x5165;&#x5F20;&#x91CF;&#x4E2D;&#x7684;&#x90E8;&#x5206;&#x5143;&#x7D20; &#x7F6E;&#x8FDB;&#x884C;&#x63A9;&#x76D6;, &#x5728;&#x6BCF;&#x6B21;&#x8C03;&#x7528;&#x4E2D;, &#x88AB;&#x63A9;&#x76D6;&#x7684;&#x5143;&#x7D20;&#x662F;&#x968F;&#x673A;&#x7684;, &#x5E76;&#x4E14;&#x5BF9;&#x8F93;&#x51FA;&#x4F1A;&#x8FDB;&#x884C;&#x7F29;&#x653E;&#x3001;&#x53D8;&#x6362;&#x7B49;&#x64CD;&#x4F5C; &#x4EE5;&#x4FDD;&#x6301;&#x5747;&#x503C;&#x4E3A; 0&#x3001;&#x6807;&#x51C6;&#x5DEE;&#x4E3A; 1.</p>
<p>&#x5728;&#x6C42;&#x503C;&#x671F;&#x95F4;, &#x6A21;&#x5757;&#x7B80;&#x5355;&#x7684;&#x8BA1;&#x7B97;&#x4E00;&#x4E2A;&#x5F52;&#x4E00;&#x5316;&#x7684;&#x51FD;&#x6570;.</p>
<p>&#x66F4;&#x591A;&#x4FE1;&#x606F;&#x8BF7;&#x53C2;&#x8003;&#x8BBA;&#x6587;: Self-Normalizing Neural Networks</p>
<p>Args: p&#xFF08;float&#xFF09;: &#x5143;&#x7D20;&#x88AB;&#x63A9;&#x76D6;&#x7684;&#x6982;&#x7387;, &#x9ED8;&#x8BA4;&#x503C;: 0.5 Shape:</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;any.&#x8F93;&#x5165;&#x6570;&#x636E;&#x53EF;&#x4EE5;&#x662F;&#x4EFB;&#x4F55;&#x5927;&#x5C0F;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;Same.&#x8F93;&#x51FA;&#x6570;&#x636E;&#x5927;&#x5C0F;&#x4E0E;&#x8F93;&#x5165;&#x76F8;&#x540C;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py">&amp;gt;&amp;gt;&amp;gt; m = nn.AlphaDropout(p=<span class="hljs-number">0.2</span>)
</code></pre>
<pre><code class="lang-py">&amp;gt;&amp;gt;&amp;gt; input = autograd.Variable(torch.randn(<span class="hljs-number">20</span>, <span class="hljs-number">16</span>))
&amp;gt;&amp;gt;&amp;gt; output = m(input)
</code></pre>
</blockquote>
<h2 id="sparse-layers-&#x7A00;&#x758F;&#x5C42;">Sparse layers (&#x7A00;&#x758F;&#x5C42;)</h2>
<h3 id="embedding">Embedding</h3>
<pre><code class="lang-py">class torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, sparse=False)
</code></pre>
<p>&#x4E00;&#x4E2A;&#x7B80;&#x5355;&#x7684;&#x67E5;&#x627E;&#x8868;, &#x5B58;&#x50A8;&#x4E86;&#x56FA;&#x5B9A;&#x5B57;&#x5178;&#x548C;&#x5927;&#x5C0F;&#x7684; embedding.</p>
<p>&#x8FD9;&#x4E2A;&#x6A21;&#x5757;&#x7ECF;&#x5E38;&#x7528;&#x6765;&#x5B58;&#x50A8; word embeddings, &#x5E76;&#x901A;&#x8FC7;&#x7D22;&#x5F15;&#x6765;&#x68C0;&#x7D22;, &#x6A21;&#x5757;&#x7684;&#x8F93;&#x5165;&#x662F;&#x7D22;&#x5F15;&#x6784;&#x6210;&#x7684;&#x5217;&#x8868;, &#x8F93;&#x51FA;&#x662F;&#x5BF9;&#x5E94;&#x7684; word embeddings.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>num_embeddings (int)</code> &#x2013; embeddings &#x5B57;&#x5178;&#x7684;&#x5927;&#x5C0F;</li>
<li><code>embedding_dim (int)</code> &#x2013; &#x6BCF;&#x4E2A; embedding &#x5411;&#x91CF;&#x7684;&#x5927;&#x5C0F;</li>
<li><code>padding_idx (int, &#x53EF;&#x9009;)</code> &#x2013; &#x5982;&#x679C;&#x7ED9;&#x51FA;, &#x5728;&#x7D22;&#x5F15;&#x5904;, &#x8F93;&#x51FA;&#x8865;&#x96F6;</li>
<li><code>max_norm (float, &#x53EF;&#x9009;)</code> &#x2013; &#x5982;&#x679C;&#x7ED9;&#x51FA;, &#x91CD;&#x65B0;&#x5F52;&#x4E00;&#x5316; embeddings, &#x4F7F;&#x5176;&#x8303;&#x6570;&#x5C0F;&#x4E8E;&#x8BE5;&#x503C;</li>
<li><code>norm_type (float, &#x53EF;&#x9009;)</code> &#x2013; &#x4E3A; max_norm &#x9009;&#x9879;&#x8BA1;&#x7B97; p &#x8303;&#x6570;&#x65F6; P</li>
<li><code>scale_grad_by_freq (boolean, &#x53EF;&#x9009;)</code> &#x2013; &#x5982;&#x679C;&#x7ED9;&#x51FA;, &#x4F1A;&#x6839;&#x636E; words &#x5728; mini-batch &#x4E2D;&#x7684;&#x9891;&#x7387;&#x7F29;&#x653E;&#x68AF;&#x5EA6;</li>
<li><code>sparse (boolean, &#x53EF;&#x9009;)</code> &#x2013; &#x5982;&#x679C;&#x4E3A; <code>True</code>, &#x5173;&#x4E8E;&#x6743;&#x91CD;&#x77E9;&#x9635;&#x7684;&#x68AF;&#x5EA6;&#x662F;&#x4E00;&#x4E2A;&#x7A00;&#x758F;&#x5F20;&#x91CF;, &#x8BE6;&#x60C5;&#x8BF7;&#x53C2;&#x8003;&#x7A00;&#x758F;&#x68AF;&#x5EA6;</li>
</ul>
<table>
<thead>
<tr>
<th>Variables:</th>
<th><strong>weight</strong> (Tensor) &#x2013; shape &#x4E3A; (num_embeddings, embedding_dim) &#x7684;&#x6A21;&#x5757;&#x7684;&#x53EF;&#x5B66;&#x4E60;&#x6743;&#x91CD;</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;LongTensor <code>(N, W)</code>, N = mini-batch, W = &#x6BCF;&#x4E2A; mini-batch &#x4E2D;&#x7528;&#x6765;&#x63D0;&#x53D6;&#x7684;&#x7D22;&#x5F15;&#x6570;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<code>(N, W, embedding_dim)</code></li>
</ul>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x8BF7;&#x6CE8;&#x610F;, &#x53EA;&#x652F;&#x6301;&#x6709;&#x9650;&#x6570;&#x91CF;&#x7684;&#x4F18;&#x5316;&#x5668;. &#x7A00;&#x758F;&#x68AF;&#x5EA6;: &#x5F53;&#x524D;&#x662F; (<code>cuda</code> &#x548C; <code>cpu</code>) &#x7248;&#x672C;&#x7684; <code>optim.SGD</code>, &#x548C; (<code>cpu</code>) &#x7248;&#x672C;&#x7684; <code>optim.Adagrad</code>.</p>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># an Embedding module containing 10 tensors of size 3</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>embedding = nn.Embedding(<span class="hljs-number">10</span>, <span class="hljs-number">3</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># a batch of 2 samples of 4 indices each</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>input = Variable(torch.LongTensor([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">9</span>]]))
<span class="hljs-meta">&gt;&gt;&gt; </span>embedding(input)

Variable containing:
(<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">-1.0822</span>  <span class="hljs-number">1.2522</span>  <span class="hljs-number">0.2434</span>
 <span class="hljs-number">0.8393</span> <span class="hljs-number">-0.6062</span> <span class="hljs-number">-0.3348</span>
 <span class="hljs-number">0.6597</span>  <span class="hljs-number">0.0350</span>  <span class="hljs-number">0.0837</span>
 <span class="hljs-number">0.5521</span>  <span class="hljs-number">0.9447</span>  <span class="hljs-number">0.0498</span>

(<span class="hljs-number">1</span> ,.,.) =
 <span class="hljs-number">0.6597</span>  <span class="hljs-number">0.0350</span>  <span class="hljs-number">0.0837</span>
 <span class="hljs-number">-0.1527</span>  <span class="hljs-number">0.0877</span>  <span class="hljs-number">0.4260</span>
 <span class="hljs-number">0.8393</span> <span class="hljs-number">-0.6062</span> <span class="hljs-number">-0.3348</span>
 <span class="hljs-number">-0.8738</span> <span class="hljs-number">-0.9054</span>  <span class="hljs-number">0.4281</span>
[torch.FloatTensor of size <span class="hljs-number">2</span>x4x3]

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># example with padding_idx</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>embedding = nn.Embedding(<span class="hljs-number">10</span>, <span class="hljs-number">3</span>, padding_idx=<span class="hljs-number">0</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = Variable(torch.LongTensor([[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">5</span>]]))
<span class="hljs-meta">&gt;&gt;&gt; </span>embedding(input)

Variable containing:
(<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">0.0000</span>  <span class="hljs-number">0.0000</span>  <span class="hljs-number">0.0000</span>
 <span class="hljs-number">0.3452</span>  <span class="hljs-number">0.4937</span> <span class="hljs-number">-0.9361</span>
 <span class="hljs-number">0.0000</span>  <span class="hljs-number">0.0000</span>  <span class="hljs-number">0.0000</span>
 <span class="hljs-number">0.0706</span> <span class="hljs-number">-2.1962</span> <span class="hljs-number">-0.6276</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x4x3]
</code></pre>
<h3 id="embeddingbag">EmbeddingBag</h3>
<pre><code class="lang-py">class torch.nn.EmbeddingBag(num_embeddings, embedding_dim, max_norm=None, norm_type=2, scale_grad_by_freq=False, mode=&apos;mean&apos;)
</code></pre>
<p>&#x8BA1;&#x7B97;&#x4E00; &#x4E2A;&#x2019;bags&#x2019; &#x91CC;&#x7684; embedding s&#x7684;&#x5747;&#x503C;&#x6216;&#x548C;, &#x4E0D;&#x7528;&#x5B9E;&#x4F8B;&#x5316;&#x4E2D;&#x95F4;&#x7684; embeddings</p>
<p>&#x5BF9;&#x4E8E;&#x56FA;&#x5B9A;&#x957F;&#x5EA6;&#x7684; bags</p>
<ul>
<li>nn.EmbeddingBag &#x548C; <code>mode=sum</code> &#x76F8;&#x5F53;&#x4E8E; nn.Embedding &#x4E0E;&#x4E4B;&#x540E;&#x7684; <code>torch.sum(dim=1)</code></li>
<li>&#x5176;&#x4E0E; <code>mode=mean</code> &#x76F8;&#x5F53;&#x4E8E; nn.Embedding &#x4E0E;&#x4E4B;&#x540E;&#x7684; <code>torch.mean(dim=1)</code></li>
</ul>
<p>&#x7136;&#x800C;, &#x6BD4;&#x8D77;&#x4E00;&#x8FDE;&#x4E32;&#x8FD9;&#x6837;&#x7684;&#x64CD;&#x4F5C;, nn.EmbeddingBag &#x5728;&#x65F6;&#x95F4;&#x548C;&#x5185;&#x5B58;&#x4E0A;&#x66F4;&#x52A0;&#x9AD8;&#x6548;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>num_embeddings (int)</code> &#x2013; embeddings &#x5B57;&#x5178;&#x7684;&#x5927;&#x5C0F;</li>
<li><code>embedding_dim (int)</code> &#x2013; &#x6BCF;&#x4E2A; embedding &#x5411;&#x91CF;&#x7684;&#x5927;&#x5C0F;</li>
<li><code>max_norm (float, &#x53EF;&#x9009;)</code> &#x2013; &#x5982;&#x679C;&#x7ED9;&#x51FA;, &#x91CD;&#x65B0;&#x5F52;&#x4E00;&#x5316; embeddings, &#x4F7F;&#x5176;&#x8303;&#x6570;&#x5C0F;&#x4E8E;&#x8BE5;&#x503C;</li>
<li><code>norm_type (float, &#x53EF;&#x9009;)</code> &#x2013; &#x4E3A; max_norm &#x9009;&#x9879;&#x8BA1;&#x7B97; p &#x8303;&#x6570;&#x65F6;&#x7684; P</li>
<li><code>scale_grad_by_freq (boolean, &#x53EF;&#x9009;)</code> &#x2013; &#x5982;&#x679C;&#x7ED9;&#x51FA;, &#x4F1A;&#x6839;&#x636E; words &#x5728; mini-batch &#x4E2D;&#x7684;&#x9891;&#x7387;&#x7F29;&#x653E;&#x68AF;&#x5EA6;</li>
<li><code>mode (string, &#x53EF;&#x9009;)</code> &#x2013; &#x2018;sum&#x2019; | &#x2018;mean&#x2019;. &#x6307;&#x5B9A;&#x51CF;&#x5C11; bag &#x7684;&#x65B9;&#x5F0F;. &#x9ED8;&#x8BA4;: &#x2018;mean&#x2019;</li>
</ul>
<table>
<thead>
<tr>
<th>Variables:</th>
<th><strong>weight</strong> (Tensor) &#x2013; shape &#x4E3A; (num_embeddings, embedding_dim) &#x7684;&#x6A21;&#x5757;&#x7684;&#x53EF;&#x5B66;&#x4E60;&#x6743;&#x91CD;</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<p>Inputs: input, offsets</p>
<ul>
<li><code>input (N or BxN)</code>: LongTensor, &#x5305;&#x62EC;&#x8981;&#x63D0;&#x53D6;&#x7684; embeddings &#x7684;&#x7D22;&#x5F15;, &#x5F53; <code>input</code> &#x662F;&#x5F62;&#x72B6;&#x4E3A; <code>N</code> &#x7684; 1D &#x5F20;&#x91CF;&#x65F6;, &#x4E00;&#x4E2A;&#x7ED9;&#x51FA;&#x7684; <code>offsets</code> &#x5F20;&#x91CF;&#x4E2D;&#x5305;&#x62EC;: mini-batch &#x4E2D;&#x6BCF;&#x4E2A;&#x65B0;&#x5E8F;&#x5217;&#x7684;&#x8D77;&#x59CB;&#x4F4D;&#x7F6E;</li>
<li><code>offsets (B or None)</code>: LongTensor, &#x5305;&#x62EC;&#x4E00;&#x4E2A; mini-batch &#x7684;&#x53EF;&#x53D8;&#x957F;&#x5EA6;&#x5E8F;&#x5217;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x65B0;&#x6837;&#x672C;&#x7684;&#x8D77;&#x59CB;&#x4F4D;&#x7F6E; &#x5982;&#x679C; <code>input</code> &#x662F; 2D (BxN) &#x7684;, offset &#x5C31;&#x4E0D;&#x7528;&#x518D;&#x7ED9;&#x51FA;; &#x5982;&#x679C; <code>input</code> &#x662F;&#x4E00;&#x4E2A; mini-batch &#x7684;&#x56FA;&#x5B9A;&#x957F;&#x5EA6;&#x7684;&#x5E8F;&#x5217;, &#x6BCF;&#x4E2A;&#x5E8F;&#x5217;&#x7684;&#x957F;&#x5EA6;&#x4E3A; <code>N</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;LongTensor <code>N</code>, N = &#x8981;&#x63D0;&#x53D6;&#x7684; embeddings &#x7684;&#x6570;&#x91CF;,</li>
</ul>
<blockquote>
<p>&#x6216;&#x8005;&#x662F; LongTensor <code>BxN</code>, B = mini-batch &#x4E2D;&#x5E8F;&#x5217;&#x7684;&#x6570;&#x91CF;, N = &#x6BCF;&#x4E2A;&#x5E8F;&#x5217;&#x4E2D; embeddings &#x7684;&#x6570;&#x91CF;</p>
</blockquote>
<ul>
<li>Offsets: LongTensor <code>B</code>, B = bags &#x7684;&#x6570;&#x91CF;, &#x503C;&#x4E3A;&#x6BCF;&#x4E2A; bag &#x4E2D; <code>input</code> &#x7684; offset, i.e. &#x662F;&#x957F;&#x5EA6;&#x7684;&#x7D2F;&#x52A0;. Offsets &#x4E0D;&#x4F1A;&#x7ED9;&#x51FA;, &#x5982;&#x679C; Input&#x662F; 2D &#x7684;<code>BxN</code> &#x5F20;&#x91CF;, &#x8F93;&#x5165;&#x88AB;&#x8BA4;&#x4E3A;&#x662F;&#x56FA;&#x5B9A;&#x957F;&#x5EA6;&#x7684;&#x5E8F;&#x5217;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<code>(B, embedding_dim)</code></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># an Embedding module containing 10 tensors of size 3</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>embedding_sum = nn.EmbeddingBag(<span class="hljs-number">10</span>, <span class="hljs-number">3</span>, mode=<span class="hljs-string">&apos;sum&apos;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># a batch of 2 samples of 4 indices each</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>input = Variable(torch.LongTensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">4</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">9</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>offsets = Variable(torch.LongTensor([<span class="hljs-number">0</span>,<span class="hljs-number">4</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>embedding_sum(input, offsets)

Variable containing:
<span class="hljs-number">-0.7296</span> <span class="hljs-number">-4.6926</span>  <span class="hljs-number">0.3295</span>
<span class="hljs-number">-0.5186</span> <span class="hljs-number">-0.5631</span> <span class="hljs-number">-0.2792</span>
[torch.FloatTensor of size <span class="hljs-number">2</span>x3]
</code></pre>
<h2 id="distance-functions-&#x8DDD;&#x79BB;&#x51FD;&#x6570;">Distance functions (&#x8DDD;&#x79BB;&#x51FD;&#x6570;)</h2>
<h3 id="cosinesimilarity">CosineSimilarity</h3>
<pre><code class="lang-py">class torch.nn.CosineSimilarity(dim=1, eps=1e-08)
</code></pre>
<p>&#x8FD4;&#x56DE;&#x6CBF;&#x7740; dim &#x65B9;&#x5411;&#x8BA1;&#x7B97;&#x7684; x1 &#x4E0E; x2 &#x4E4B;&#x95F4;&#x7684;&#x4F59;&#x5F26;&#x76F8;&#x4F3C;&#x5EA6;.</p>
<p><img src="img/tex-ff1174b83879355a400c05f671e9b5f0.gif" alt="\text{similarity} = \dfrac{x_1 \cdot x_2}{\max(\Vert x_1 \Vert _2 \cdot \Vert x_2 \Vert _2, \epsilon)}"></p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>dim (int, &#x53EF;&#x9009;)</code> &#x2013; &#x8BA1;&#x7B97;&#x4F59;&#x5F26;&#x76F8;&#x4F3C;&#x5EA6;&#x7684;&#x7EF4;&#x5EA6;. Default: 1</li>
<li><code>eps (float, &#x53EF;&#x9009;)</code> &#x2013; &#x5C0F;&#x7684;&#x503C;&#x4EE5;&#x907F;&#x514D;&#x88AB;&#x96F6;&#x9664;. Default: 1e-8</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>Input1: <img src="img/tex-76ea2d76e7fbeacf40dc68145779869f.gif" alt="(\ast_1, D, \ast_2)">, &#x5176;&#x4E2D;&#x7684; D &#x8868;&#x793A; <code>dim</code> &#x7684;&#x4F4D;&#x7F6E;</li>
<li>Input2: <img src="img/tex-76ea2d76e7fbeacf40dc68145779869f.gif" alt="(\ast_1, D, \ast_2)">, &#x4E0E; Input1 &#x4E00;&#x6837;&#x7684; shape</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-17b66a91a0da1de30c6ed32b4a64db01.gif" alt="(\ast_1, \ast_2)"></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>input1 = autograd.Variable(torch.randn(<span class="hljs-number">100</span>, <span class="hljs-number">128</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input2 = autograd.Variable(torch.randn(<span class="hljs-number">100</span>, <span class="hljs-number">128</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>cos = nn.CosineSimilarity(dim=<span class="hljs-number">1</span>, eps=<span class="hljs-number">1e-6</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>output = cos(input1, input2)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(output)
</code></pre>
<h3 id="pairwisedistance">PairwiseDistance</h3>
<pre><code class="lang-py">class torch.nn.PairwiseDistance(p=2, eps=1e-06)
</code></pre>
<p>&#x8BA1;&#x7B97;&#x5411;&#x91CF; v1, v2 &#x4E4B;&#x95F4;&#x7684; batchwise pairwise distance(&#x5206;&#x6279;&#x6210;&#x5BF9;&#x8DDD;&#x79BB;):</p>
<p><img src="img/tex-917e152b0e5035ea50d39db268bf9fca.gif" alt="\Vert x \Vert _p := \left( \sum_{i=1}^n \vert x_i \vert ^ p \right) ^ {1/p}"></p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>p (_real_)</code> &#x2013; norm degree(&#x89C4;&#x8303;&#x7A0B;&#x5EA6;). Default: 2</li>
<li><code>eps (float, &#x53EF;&#x9009;)</code> &#x2013; &#x5C0F;&#x7684;&#x503C;&#x4EE5;&#x907F;&#x514D;&#x88AB;&#x96F6;&#x9664;. Default: 1e-6</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>Input1: <img src="img/tex-df68502f8935f32bcaef520a28eb3e21.gif" alt="(N, D)">, &#x5176;&#x4E2D;&#x7684; <code>D = vector dimension(&#x5411;&#x91CF;&#x7EF4;&#x5EA6;)</code></li>
<li>Input2: <img src="img/tex-df68502f8935f32bcaef520a28eb3e21.gif" alt="(N, D)">, &#x4E0E; Input1 &#x7684; shape &#x4E00;&#x6837;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-eb4023c8eeb604a58f58c44e29f7924a.gif" alt="(N, 1)"></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>pdist = nn.PairwiseDistance(p=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input1 = autograd.Variable(torch.randn(<span class="hljs-number">100</span>, <span class="hljs-number">128</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input2 = autograd.Variable(torch.randn(<span class="hljs-number">100</span>, <span class="hljs-number">128</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = pdist(input1, input2)
</code></pre>
<h2 id="loss-functions-&#x635F;&#x5931;&#x51FD;&#x6570;">Loss functions (&#x635F;&#x5931;&#x51FD;&#x6570;)</h2>
<h3 id="l1loss">L1Loss</h3>
<pre><code class="lang-py">class torch.nn.L1Loss(size_average=True, reduce=True)
</code></pre>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x8861;&#x91CF;&#x8F93;&#x5165; <code>x</code> &#x4E0E;&#x76EE;&#x6807; <code>y</code> &#x4E4B;&#x95F4;&#x5DEE;&#x7684;&#x7EDD;&#x5BF9;&#x503C;&#x7684;&#x5E73;&#x5747;&#x503C;&#x7684;&#x6807;&#x51C6;, &#x8BE5; &#x51FD;&#x6570;&#x4F1A;&#x9010;&#x5143;&#x7D20;&#x5730;&#x6C42;&#x51FA; <code>x</code> &#x548C; <code>y</code> &#x4E4B;&#x95F4;&#x5DEE;&#x7684;&#x7EDD;&#x5BF9;&#x503C;, &#x6700;&#x540E;&#x8FD4;&#x56DE;&#x7EDD;&#x5BF9;&#x503C;&#x7684;&#x5E73;&#x5747;&#x503C;.</p>
<p><img src="img/tex-811b7ac372ab6fb167b5d3302c959dd3.gif" alt="{loss}(x, y) = 1/n \sum |x_i - y_i|"></p>
<p><code>x</code> &#x548C; <code>y</code> &#x53EF;&#x4EE5;&#x662F;&#x4EFB;&#x610F;&#x7EF4;&#x5EA6;&#x7684;&#x6570;&#x7EC4;, &#x4F46;&#x9700;&#x8981;&#x6709;&#x76F8;&#x540C;&#x6570;&#x91CF;&#x7684;n&#x4E2A;&#x5143;&#x7D20;.</p>
<p>&#x6C42;&#x548C;&#x64CD;&#x4F5C;&#x4F1A;&#x5BF9;n&#x4E2A;&#x5143;&#x7D20;&#x6C42;&#x548C;, &#x6700;&#x540E;&#x9664;&#x4EE5; <code>n</code> .</p>
<p>&#x5728;&#x6784;&#x9020;&#x51FD;&#x6570;&#x7684;&#x53C2;&#x6570;&#x4E2D;&#x4F20;&#x5165; <code>size_average=False</code>, &#x6700;&#x540E;&#x6C42;&#x51FA;&#x6765;&#x7684;&#x7EDD;&#x5BF9;&#x503C;&#x5C06;&#x4E0D;&#x4F1A;&#x9664;&#x4EE5; <code>n</code>.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>size_average (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09; &#x4E0A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5982;&#x679C;&#x5B57;&#x6BB5; size_average &#x88AB;&#x8BBE;&#x7F6E;&#x4E3A; <code>False</code>, loss &#x5C06;&#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09; &#x4E0A;&#x7D2F;&#x52A0;, &#x800C;&#x4E0D;&#x4F1A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5F53; reduce &#x7684;&#x503C;&#x4E3A; <code>False</code> &#x65F6;&#x8BE5;&#x5B57;&#x6BB5;&#x4F1A;&#x88AB;&#x5FFD;&#x7565;. &#x9ED8;&#x8BA4;&#x503C;: <code>True</code></li>
<li><code>reduce (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x4E0A;&#x6C42;&#x5E73;&#x5747;&#x503C;&#x6216;&#x8005; &#x6C42;&#x548C;. &#x5F53; reduce &#x662F; <code>False</code> &#x65F6;, &#x635F;&#x5931;&#x51FD;&#x6570;&#x4F1A;&#x5BF9;&#x6BCF;&#x4E2A; batch &#x5143;&#x7D20;&#x90FD;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A; loss &#x5E76;&#x5FFD; &#x7565; size_average &#x5B57;&#x6BB5;. &#x9ED8;&#x8BA4;&#x503C;: <code>True</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;: <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, <code>*</code> &#x8868;&#x793A;&#x4EFB;&#x610F;&#x6570;&#x91CF;&#x7684;&#x989D;&#x5916;&#x7EF4;&#x5EA6;</li>
<li>&#x76EE;&#x6807;: <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x548C;&#x8F93;&#x5165;&#x7684;shape&#x76F8;&#x540C;</li>
<li>&#x8F93;&#x51FA;: &#x6807;&#x91CF;. &#x5982;&#x679C; reduce &#x662F; <code>False</code> , &#x5219;&#x8F93;&#x51FA;&#x4E3A; <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, shape&#x4E0E;&#x8F93;&#x51FA;&#x76F8;&#x540C;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>loss = nn.L1Loss()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>), requires_grad=<span class="hljs-keyword">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>target = autograd.Variable(torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = loss(input, target)
<span class="hljs-meta">&gt;&gt;&gt; </span>output.backward()
</code></pre>
<h3 id="mseloss">MSELoss</h3>
<pre><code class="lang-py">class torch.nn.MSELoss(size_average=True, reduce=True)
</code></pre>
<p>&#x8F93;&#x5165; <code>x</code> &#x548C; &#x76EE;&#x6807; <code>y</code> &#x4E4B;&#x95F4;&#x7684;&#x5747;&#x65B9;&#x5DEE;</p>
<p><img src="img/tex-b6d841cf2185a4776e1b61740870a9bf.gif" alt="{loss}(x, y) = 1/n \sum |x_i - y_i|^2"></p>
<p><code>x</code> &#x548C; <code>y</code> &#x53EF;&#x4EE5;&#x662F;&#x4EFB;&#x610F;&#x7EF4;&#x5EA6;&#x7684;&#x6570;&#x7EC4;, &#x4F46;&#x9700;&#x8981;&#x6709;&#x76F8;&#x540C;&#x6570;&#x91CF;&#x7684;n&#x4E2A;&#x5143;&#x7D20;.</p>
<p>&#x6C42;&#x548C;&#x64CD;&#x4F5C;&#x4F1A;&#x5BF9;n&#x4E2A;&#x5143;&#x7D20;&#x6C42;&#x548C;, &#x6700;&#x540E;&#x9664;&#x4EE5; <code>n</code>.</p>
<p>&#x5728;&#x6784;&#x9020;&#x51FD;&#x6570;&#x7684;&#x53C2;&#x6570;&#x4E2D;&#x4F20;&#x5165; <code>size_average=False</code> , &#x6700;&#x540E;&#x6C42;&#x51FA;&#x6765;&#x7684;&#x7EDD;&#x5BF9;&#x503C;&#x5C06;&#x4E0D;&#x4F1A;&#x9664;&#x4EE5; <code>n</code>.</p>
<p>&#x8981;&#x5F97;&#x5230;&#x6BCF;&#x4E2A; batch &#x4E2D;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x7684; loss, &#x8BBE;&#x7F6E; <code>reduce</code> &#x4E3A; <code>False</code>. &#x8FD4;&#x56DE;&#x7684; loss &#x5C06;&#x4E0D;&#x4F1A; &#x53D6;&#x5E73;&#x5747;&#x503C;, &#x4E5F;&#x4E0D;&#x4F1A;&#x88AB; <code>size_average</code> &#x5F71;&#x54CD;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>size_average (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09; &#x4E0A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5982;&#x679C;&#x5B57;&#x6BB5; size_average &#x88AB;&#x8BBE;&#x7F6E;&#x4E3A; <code>False</code> , loss &#x4F1A;&#x5728;&#x6BCF; &#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x4E0A;&#x6C42;&#x548C;. &#x53EA;&#x6709;&#x5F53; reduce &#x7684;&#x503C;&#x4E3A; <code>True</code> &#x624D;&#x4F1A;&#x751F;&#x6548;. &#x9ED8;&#x8BA4;&#x503C;: <code>True</code></li>
<li><code>reduce (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x6839;&#x636E; size_average &#x7684;&#x503C;&#x5728;&#x6BCF; &#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x4E0A;&#x6C42;&#x5E73;&#x5747;&#x503C;&#x6216;&#x8005;&#x6C42;&#x548C;. &#x5F53; reduce &#x662F; <code>False</code> &#x65F6;, &#x635F;&#x5931;&#x51FD;&#x6570;&#x4F1A;&#x5BF9;&#x6BCF; &#x4E2A; batch &#x5143;&#x7D20;&#x90FD;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A; loss &#x5E76;&#x5FFD;&#x7565; size_average&#x5B57;&#x6BB5;. &#x9ED8;&#x8BA4;&#x503C;: <code>True</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;: <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x5176;&#x4E2D; <code>*</code> &#x8868;&#x793A;&#x4EFB;&#x610F;&#x6570;&#x91CF;&#x7684;&#x989D;&#x5916;&#x7EF4;&#x5EA6;.</li>
<li>&#x76EE;&#x6807;: <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, shape &#x8DDF;&#x8F93;&#x5165;&#x76F8;&#x540C;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>loss = nn.MSELoss()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>), requires_grad=<span class="hljs-keyword">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>target = autograd.Variable(torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = loss(input, target)
<span class="hljs-meta">&gt;&gt;&gt; </span>output.backward()
</code></pre>
<h3 id="crossentropyloss">CrossEntropyLoss</h3>
<pre><code class="lang-py">class torch.nn.CrossEntropyLoss(weight=None, size_average=True, ignore_index=-100, reduce=True)
</code></pre>
<p>&#x8BE5;&#x7C7B;&#x628A; <code>LogSoftMax</code> &#x548C; <code>NLLLoss</code> &#x7ED3;&#x5408;&#x5230;&#x4E86;&#x4E00;&#x4E2A;&#x7C7B;&#x4E2D;</p>
<p>&#x5F53;&#x8BAD;&#x7EC3;&#x6709; <code>C</code> &#x4E2A;&#x7C7B;&#x522B;&#x7684;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x65F6;&#x5F88;&#x6709;&#x6548;. &#x53EF;&#x9009;&#x53C2;&#x6570; <code>weight</code> &#x5FC5;&#x987B;&#x662F;&#x4E00;&#x4E2A;1&#x7EF4; Tensor, &#x6743;&#x91CD;&#x5C06;&#x88AB;&#x5206;&#x914D;&#x7ED9;&#x5404;&#x4E2A;&#x7C7B;&#x522B;. &#x5BF9;&#x4E8E;&#x4E0D;&#x5E73;&#x8861;&#x7684;&#x8BAD;&#x7EC3;&#x96C6;&#x975E;&#x5E38;&#x6709;&#x6548;.</p>
<p><code>input</code> &#x542B;&#x6709;&#x6BCF;&#x4E2A;&#x7C7B;&#x522B;&#x7684;&#x5206;&#x6570;</p>
<p><code>input</code> &#x5FC5;&#x987B;&#x662F;&#x4E00;&#x4E2A;2&#x7EF4;&#x7684;&#x5F62;&#x5982; <code>(minibatch, C)</code> &#x7684; <code>Tensor</code>.</p>
<p><code>target</code> &#x662F;&#x4E00;&#x4E2A;&#x7C7B;&#x522B;&#x7D22;&#x5F15; (0 to C-1), &#x5BF9;&#x5E94;&#x4E8E; <code>minibatch</code> &#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;</p>
<p>loss &#x53EF;&#x4EE5;&#x63CF;&#x8FF0;&#x4E3A;:</p>
<pre><code class="lang-py">loss(x, class) = -log(exp(x[class]) / (\sum_j exp(x[j])))
               = -x[class] + log(\sum_j exp(x[j]))
</code></pre>
<p>&#x5F53; <code>weight</code> &#x53C2;&#x6570;&#x5B58;&#x5728;&#x65F6;:</p>
<pre><code class="lang-py">loss(x, class) = weight[class] * (-x[class] + log(\sum_j exp(x[j])))
</code></pre>
<p>loss &#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x4E0A;&#x53D6;&#x5E73;&#x5747;&#x503C;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>weight (Tensor, &#x53EF;&#x9009;)</code> &#x2013; &#x81EA;&#x5B9A;&#x4E49;&#x7684;&#x6BCF;&#x4E2A;&#x7C7B;&#x522B;&#x7684;&#x6743;&#x91CD;. &#x5FC5;&#x987B;&#x662F;&#x4E00;&#x4E2A;&#x957F;&#x5EA6;&#x4E3A; <code>C</code> &#x7684; Tensor</li>
<li><code>size_average (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09; &#x4E0A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5982;&#x679C;&#x5B57;&#x6BB5; size_average &#x88AB;&#x8BBE;&#x7F6E;&#x4E3A; <code>False</code>, loss &#x5C06;&#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09; &#x4E0A;&#x7D2F;&#x52A0;, &#x800C;&#x4E0D;&#x4F1A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5F53; reduce &#x7684;&#x503C;&#x4E3A; <code>False</code> &#x65F6;&#x8BE5;&#x5B57;&#x6BB5;&#x4F1A;&#x88AB;&#x5FFD;&#x7565;.</li>
<li><code>ignore_index (int, &#x53EF;&#x9009;)</code> &#x2013; &#x8BBE;&#x7F6E;&#x4E00;&#x4E2A;&#x76EE;&#x6807;&#x503C;, &#x8BE5;&#x76EE;&#x6807;&#x503C;&#x4F1A;&#x88AB;&#x5FFD;&#x7565;, &#x4ECE;&#x800C;&#x4E0D;&#x4F1A;&#x5F71;&#x54CD;&#x5230; &#x8F93;&#x5165;&#x7684;&#x68AF;&#x5EA6;. &#x5F53; size_average &#x5B57;&#x6BB5;&#x4E3A; <code>True</code> &#x65F6;, loss &#x5C06;&#x4F1A;&#x5728;&#x6CA1;&#x6709;&#x88AB;&#x5FFD;&#x7565;&#x7684;&#x5143;&#x7D20;&#x4E0A; &#x53D6;&#x5E73;&#x5747;.</li>
<li><code>reduce (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x6839;&#x636E; size_average &#x7684;&#x503C;&#x5728;&#x6BCF; &#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x4E0A;&#x6C42;&#x5E73;&#x5747;&#x503C;&#x6216;&#x8005;&#x6C42;&#x548C;. &#x5F53; reduce &#x662F; <code>False</code> &#x65F6;, &#x635F;&#x5931;&#x51FD;&#x6570;&#x4F1A;&#x5BF9; &#x6BCF;&#x4E2A; batch &#x5143;&#x7D20;&#x90FD;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A; loss &#x5E76;&#x5FFD;&#x7565; size_average &#x5B57;&#x6BB5;. &#x9ED8;&#x8BA4;&#x503C;: <code>True</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;: <img src="img/tex-0adbd266d78d43d0298b110b7b60ef70.gif" alt="(N, C)">, &#x5176;&#x4E2D; <code>C</code> &#x662F;&#x7C7B;&#x522B;&#x7684;&#x6570;&#x91CF;</li>
<li>&#x76EE;&#x6807;: <img src="img/tex-6e622d72b90c249c3e04aebf0eb12ca4.gif" alt="(N)">, &#x5176;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x90FD;&#x6EE1;&#x8DB3; <code>0 &amp;lt;= targets[i] &amp;lt;= C-1</code></li>
<li>&#x8F93;&#x51FA;: &#x6807;&#x91CF;. &#x5982;&#x679C; reduce &#x662F; <code>False</code>, &#x5219;&#x8F93;&#x51FA;&#x4E3A; <img src="img/tex-6e622d72b90c249c3e04aebf0eb12ca4.gif" alt="(N)">.</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>loss = nn.CrossEntropyLoss()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>), requires_grad=<span class="hljs-keyword">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>target = autograd.Variable(torch.LongTensor(<span class="hljs-number">3</span>).random_(<span class="hljs-number">5</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = loss(input, target)
<span class="hljs-meta">&gt;&gt;&gt; </span>output.backward()
</code></pre>
<h3 id="nllloss">NLLLoss</h3>
<pre><code class="lang-py">class torch.nn.NLLLoss(weight=None, size_average=True, ignore_index=-100, reduce=True)
</code></pre>
<p>&#x8D1F;&#x5BF9;&#x6570;&#x4F3C;&#x7136;&#x635F;&#x5931;. &#x7528;&#x4E8E;&#x8BAD;&#x7EC3; <code>C</code> &#x4E2A;&#x7C7B;&#x522B;&#x7684;&#x5206;&#x7C7B;&#x95EE;&#x9898;. &#x53EF;&#x9009;&#x53C2;&#x6570; <code>weight</code> &#x662F; &#x4E00;&#x4E2A;1&#x7EF4;&#x7684; Tensor, &#x7528;&#x6765;&#x8BBE;&#x7F6E;&#x6BCF;&#x4E2A;&#x7C7B;&#x522B;&#x7684;&#x6743;&#x91CD;. &#x5F53;&#x8BAD;&#x7EC3;&#x96C6;&#x4E0D;&#x5E73;&#x8861;&#x65F6;&#x8BE5;&#x53C2;&#x6570;&#x5341;&#x5206;&#x6709;&#x7528;.</p>
<p>&#x7531;&#x524D;&#x5411;&#x4F20;&#x64AD;&#x5F97;&#x5230;&#x7684;&#x8F93;&#x5165;&#x5E94;&#x8BE5;&#x542B;&#x6709;&#x6BCF;&#x4E2A;&#x7C7B;&#x522B;&#x7684;&#x5BF9;&#x6570;&#x6982;&#x7387;: &#x8F93;&#x5165;&#x5FC5;&#x987B;&#x662F;&#x5F62;&#x5982; <code>(minibatch, C)</code> &#x7684; 2&#x7EF4; Tensor.</p>
<p>&#x5728;&#x4E00;&#x4E2A;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x6700;&#x540E;&#x4E00;&#x5C42;&#x6DFB;&#x52A0; <code>LogSoftmax</code> &#x5C42;&#x53EF;&#x4EE5;&#x5F97;&#x5230;&#x5BF9;&#x6570;&#x6982;&#x7387;. &#x5982;&#x679C;&#x4F60;&#x4E0D;&#x5E0C;&#x671B;&#x5728;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x4E2D; &#x52A0;&#x5165;&#x989D;&#x5916;&#x7684;&#x4E00;&#x5C42;, &#x4E5F;&#x53EF;&#x4EE5;&#x4F7F;&#x7528; <code>CrossEntropyLoss</code> &#x51FD;&#x6570;.</p>
<p>&#x8BE5;&#x635F;&#x5931;&#x51FD;&#x6570;&#x9700;&#x8981;&#x7684;&#x76EE;&#x6807;&#x503C;&#x662F;&#x4E00;&#x4E2A;&#x7C7B;&#x522B;&#x7D22;&#x5F15; <code>(0 &#x5230; C-1, &#x5176;&#x4E2D; C &#x662F;&#x7C7B;&#x522B;&#x6570;&#x91CF;)</code></p>
<p>&#x8BE5; loss &#x53EF;&#x4EE5;&#x63CF;&#x8FF0;&#x4E3A;:</p>
<pre><code class="lang-py">loss(x, class) = -x[class]
</code></pre>
<p>&#x6216;&#x8005;&#x5F53; weight &#x53C2;&#x6570;&#x5B58;&#x5728;&#x65F6;&#x53EF;&#x4EE5;&#x63CF;&#x8FF0;&#x4E3A;:</p>
<pre><code class="lang-py">loss(x, class) = -weight[class] * x[class]
</code></pre>
<p>&#x53C8;&#x6216;&#x8005;&#x5F53; ignore_index &#x53C2;&#x6570;&#x5B58;&#x5728;&#x65F6;&#x53EF;&#x4EE5;&#x63CF;&#x8FF0;&#x4E3A;:</p>
<pre><code class="lang-py">loss(x, class) = class != ignoreIndex ? -weight[class] * x[class] : 0
</code></pre>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>weight (Tensor, &#x53EF;&#x9009;)</code> &#x2013; &#x81EA;&#x5B9A;&#x4E49;&#x7684;&#x6BCF;&#x4E2A;&#x7C7B;&#x522B;&#x7684;&#x6743;&#x91CD;. &#x5FC5;&#x987B;&#x662F;&#x4E00;&#x4E2A;&#x957F;&#x5EA6;&#x4E3A; <code>C</code> &#x7684; Tensor</li>
<li><code>size_average (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09; &#x4E0A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5982;&#x679C;&#x5B57;&#x6BB5; size_average &#x88AB;&#x8BBE;&#x7F6E;&#x4E3A; <code>False</code>, loss &#x5C06;&#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09; &#x4E0A;&#x7D2F;&#x52A0;, &#x800C;&#x4E0D;&#x4F1A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5F53; reduce &#x7684;&#x503C;&#x4E3A; <code>False</code> &#x65F6;&#x8BE5;&#x5B57;&#x6BB5;&#x4F1A;&#x88AB;&#x5FFD;&#x7565;. &#x9ED8;&#x8BA4;&#x503C;: <code>True</code></li>
<li><code>ignore_index (int, &#x53EF;&#x9009;)</code> &#x2013; &#x8BBE;&#x7F6E;&#x4E00;&#x4E2A;&#x76EE;&#x6807;&#x503C;, &#x8BE5;&#x76EE;&#x6807;&#x503C;&#x4F1A;&#x88AB;&#x5FFD;&#x7565;, &#x4ECE;&#x800C;&#x4E0D;&#x4F1A;&#x5F71;&#x54CD;&#x5230; &#x8F93;&#x5165;&#x7684;&#x68AF;&#x5EA6;. &#x5F53; size_average &#x4E3A; <code>True</code> &#x65F6;, loss &#x5C06;&#x4F1A;&#x5728;&#x6CA1;&#x6709;&#x88AB;&#x5FFD;&#x7565;&#x7684;&#x5143;&#x7D20;&#x4E0A; &#x53D6;&#x5E73;&#x5747;&#x503C;.</li>
<li><code>reduce (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x4E0A;&#x6C42;&#x5E73;&#x5747;&#x503C;&#x6216;&#x8005; &#x6C42;&#x548C;. &#x5F53; reduce &#x662F; <code>False</code> &#x65F6;, &#x635F;&#x5931;&#x51FD;&#x6570;&#x4F1A;&#x5BF9;&#x6BCF;&#x4E2A; batch &#x5143;&#x7D20;&#x90FD;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A; loss &#x5E76;&#x5FFD; &#x7565; size_average &#x5B57;&#x6BB5;. &#x9ED8;&#x8BA4;&#x503C;: <code>True</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;: <img src="img/tex-0adbd266d78d43d0298b110b7b60ef70.gif" alt="(N, C)">, &#x5176;&#x4E2D; <code>C</code> &#x662F;&#x7C7B;&#x522B;&#x7684;&#x6570;&#x91CF;</li>
<li>&#x76EE;&#x6807;: <img src="img/tex-6e622d72b90c249c3e04aebf0eb12ca4.gif" alt="(N)">, &#x5176;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x90FD;&#x6EE1;&#x8DB3; <code>0 &amp;lt;= targets[i] &amp;lt;= C-1</code></li>
<li>&#x8F93;&#x51FA;: &#x6807;&#x91CF;. &#x5982;&#x679C; reduce &#x662F; <code>False</code>, &#x5219;&#x8F93;&#x51FA;&#x4E3A; <img src="img/tex-6e622d72b90c249c3e04aebf0eb12ca4.gif" alt="(N)">.</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.LogSoftmax()
<span class="hljs-meta">&gt;&gt;&gt; </span>loss = nn.NLLLoss()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># input is of size N x C = 3 x 5</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>), requires_grad=<span class="hljs-keyword">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># each element in target has to have 0 &lt;= value &lt; C</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>target = autograd.Variable(torch.LongTensor([<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">4</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = loss(m(input), target)
<span class="hljs-meta">&gt;&gt;&gt; </span>output.backward()
</code></pre>
<h3 id="poissonnllloss">PoissonNLLLoss</h3>
<pre><code class="lang-py">class torch.nn.PoissonNLLLoss(log_input=True, full=False, size_average=True, eps=1e-08)
</code></pre>
<p>&#x76EE;&#x6807;&#x503C;&#x4E3A;&#x6CCA;&#x677E;&#x5206;&#x5E03;&#x7684;&#x8D1F;&#x5BF9;&#x6570;&#x4F3C;&#x7136;&#x635F;&#x5931;.</p>
<p>&#x8BE5;&#x635F;&#x5931;&#x53EF;&#x4EE5;&#x63CF;&#x8FF0;&#x4E3A;:</p>
<blockquote>
<p>target ~ Pois(input) loss(input, target) = input - target * log(input) + log(target!)</p>
</blockquote>
<p>&#x6700;&#x540E;&#x4E00;&#x9879;&#x53EF;&#x4EE5;&#x88AB;&#x7701;&#x7565;&#x6216;&#x8005;&#x7528; Stirling &#x516C;&#x5F0F;&#x6765;&#x8FD1;&#x4F3C;. &#x8BE5;&#x8FD1;&#x4F3C;&#x7528;&#x4E8E;&#x5927;&#x4E8E;1&#x7684;&#x76EE;&#x6807;&#x503C;. &#x5F53;&#x76EE;&#x6807;&#x503C; &#x5C0F;&#x4E8E;&#x6216;&#x7B49;&#x4E8E;1&#x65F6;, &#x5219;&#x5C06;0&#x52A0;&#x5230; loss &#x4E2D;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>log_input (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x5982;&#x679C;&#x8BBE;&#x7F6E;&#x4E3A; <code>True</code> , loss &#x5C06;&#x4F1A;&#x6309;&#x7167;&#x516C; &#x5F0F; <code>exp(input) - target * input</code> &#x6765;&#x8BA1;&#x7B97;, &#x5982;&#x679C;&#x8BBE;&#x7F6E;&#x4E3A; <code>False</code> , loss &#x5C06;&#x4F1A;&#x6309;&#x7167; <code>input - target * log(input+eps)</code> &#x8BA1;&#x7B97;.</li>
<li><code>full (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x662F;&#x5426;&#x8BA1;&#x7B97;&#x5168;&#x90E8;&#x7684; loss, i. e. &#x52A0;&#x4E0A; Stirling &#x8FD1;&#x4F3C;&#x9879; <code>target * log(target) - target + 0.5 * log(2 * pi * target)</code>.</li>
<li><code>size_average (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09; &#x4E0A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5982;&#x679C;&#x5B57;&#x6BB5; size_average &#x88AB;&#x8BBE;&#x7F6E;&#x4E3A; <code>False</code>, loss &#x5C06;&#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09; &#x4E0A;&#x7D2F;&#x52A0;, &#x800C;&#x4E0D;&#x4F1A;&#x53D6;&#x5E73;&#x5747;&#x503C;.</li>
<li><code>eps (float, &#x53EF;&#x9009;)</code> &#x2013; &#x5F53; log_input==<code>False</code> &#x65F6;, &#x53D6;&#x4E00;&#x4E2A;&#x5F88;&#x5C0F;&#x7684;&#x503C;&#x7528;&#x6765;&#x907F;&#x514D;&#x8BA1;&#x7B97; log(0). &#x9ED8;&#x8BA4;&#x503C;: 1e-8</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>loss = nn.PoissonNLLLoss()
<span class="hljs-meta">&gt;&gt;&gt; </span>log_input = autograd.Variable(torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">2</span>), requires_grad=<span class="hljs-keyword">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>target = autograd.Variable(torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = loss(log_input, target)
<span class="hljs-meta">&gt;&gt;&gt; </span>output.backward()
</code></pre>
<h3 id="nllloss2d">NLLLoss2d</h3>
<pre><code class="lang-py">class torch.nn.NLLLoss2d(weight=None, size_average=True, ignore_index=-100, reduce=True)
</code></pre>
<p>&#x5BF9;&#x4E8E;&#x56FE;&#x7247;&#x8F93;&#x5165;&#x7684;&#x8D1F;&#x5BF9;&#x6570;&#x4F3C;&#x7136;&#x635F;&#x5931;. &#x5B83;&#x8BA1;&#x7B97;&#x6BCF;&#x4E2A;&#x50CF;&#x7D20;&#x7684;&#x8D1F;&#x5BF9;&#x6570;&#x4F3C;&#x7136;&#x635F;&#x5931;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>weight (Tensor, &#x53EF;&#x9009;)</code> &#x2013; &#x81EA;&#x5B9A;&#x4E49;&#x7684;&#x6BCF;&#x4E2A;&#x7C7B;&#x522B;&#x7684;&#x6743;&#x91CD;. &#x5FC5;&#x987B;&#x662F;&#x4E00;&#x4E2A;&#x957F;&#x5EA6;&#x4E3A; <code>C</code> &#x7684; Tensor</li>
<li><code>size_average</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09; &#x4E0A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5982;&#x679C;&#x5B57;&#x6BB5; size_average &#x88AB;&#x8BBE;&#x7F6E;&#x4E3A; <code>False</code>, loss &#x5C06;&#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09; &#x4E0A;&#x7D2F;&#x52A0;, &#x800C;&#x4E0D;&#x4F1A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5F53; reduce &#x7684;&#x503C;&#x4E3A; <code>False</code> &#x65F6;&#x8BE5;&#x5B57;&#x6BB5;&#x4F1A;&#x88AB;&#x5FFD;&#x7565;. &#x9ED8;&#x8BA4;&#x503C;: <code>True</code></li>
<li><code>reduce (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x4E0A;&#x6C42;&#x5E73;&#x5747;&#x503C;&#x6216;&#x8005; &#x6C42;&#x548C;. &#x5F53; reduce &#x662F; <code>False</code> &#x65F6;, &#x635F;&#x5931;&#x51FD;&#x6570;&#x4F1A;&#x5BF9;&#x6BCF;&#x4E2A; batch &#x5143;&#x7D20;&#x90FD;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A; loss &#x5E76;&#x5FFD; &#x7565; size_average &#x5B57;&#x6BB5;. &#x9ED8;&#x8BA4;&#x503C;: <code>True</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-38d00342060234da90e0c2c5493892cb.gif" alt="(N, C, H, W)"> where <code>C = number of classes</code></li>
<li>Target: <img src="img/tex-54826f002c63d212644cea7b448d5816.gif" alt="(N, H, W)"> where each value is <code>0 &amp;lt;= targets[i] &amp;lt;= C-1</code></li>
<li>&#x8F93;&#x51FA;&#xFF1A;scalar. If reduce is <code>False</code>, then <img src="img/tex-54826f002c63d212644cea7b448d5816.gif" alt="(N, H, W)"> instead.</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">32</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>)).float()
<span class="hljs-meta">&gt;&gt;&gt; </span>loss = nn.NLLLoss2d()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># input is of size N x C x height x width</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">3</span>, <span class="hljs-number">16</span>, <span class="hljs-number">10</span>, <span class="hljs-number">10</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># each element in target has to have 0 &lt;= value &lt; C</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>target = autograd.Variable(torch.LongTensor(<span class="hljs-number">3</span>, <span class="hljs-number">8</span>, <span class="hljs-number">8</span>).random_(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = loss(m(input), target)
<span class="hljs-meta">&gt;&gt;&gt; </span>output.backward()
</code></pre>
<h3 id="kldivloss">KLDivLoss</h3>
<pre><code class="lang-py">class torch.nn.KLDivLoss(size_average=True, reduce=True)
</code></pre>
<p><a href="https://en.wikipedia.org/wiki/Kullback-Leibler_divergence" target="_blank">Kullback-Leibler divergence</a> &#x635F;&#x5931;</p>
<p>KL &#x6563;&#x5EA6;&#x53EF;&#x7528;&#x4E8E;&#x8861;&#x91CF;&#x4E0D;&#x540C;&#x7684;&#x8FDE;&#x7EED;&#x5206;&#x5E03;&#x4E4B;&#x95F4;&#x7684;&#x8DDD;&#x79BB;, &#x5728;&#x8FDE;&#x7EED;&#x7684;&#x8F93;&#x51FA;&#x5206;&#x5E03;&#x7684;&#x7A7A;&#x95F4;&#x4E0A;(&#x79BB;&#x6563;&#x91C7;&#x6837;)&#x4E0A;&#x8FDB;&#x884C;&#x76F4;&#x63A5;&#x56DE;&#x5F52;&#x65F6; &#x5F88;&#x6709;&#x6548;.</p>
<p>&#x8DDF; <code>NLLLoss</code> &#x4E00;&#x6837;, <code>input</code> &#x9700;&#x8981;&#x542B;&#x6709; <em>&#x5BF9;&#x6570;&#x6982;&#x7387;</em> , &#x4E0D;&#x540C;&#x4E8E; <code>ClassNLLLoss</code>, <code>input</code> &#x53EF; &#x4EE5;&#x4E0D;&#x662F;2&#x7EF4;&#x7684; Tensor, &#x56E0;&#x4E3A;&#x8BE5;&#x51FD;&#x6570;&#x4F1A;&#x9010;&#x5143;&#x7D20;&#x5730;&#x6C42;&#x503C;.</p>
<p>&#x8BE5;&#x65B9;&#x6CD5;&#x9700;&#x8981;&#x4E00;&#x4E2A;shape&#x8DDF; <code>input</code> <code>Tensor</code> &#x4E00;&#x6837;&#x7684; <code>target</code> <code>Tensor</code>.</p>
<p>&#x635F;&#x5931;&#x53EF;&#x4EE5;&#x63CF;&#x8FF0;&#x4E3A;:</p>
<p><img src="img/tex-9263028fed946a64b024a39508fa4339.gif" alt="loss(x, target) = 1/n \sum(target_i * (log(target_i) - x_i))"></p>
<p>&#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x4E0A;&#x548C; <strong>&#x7EF4;&#x5EA6;</strong> &#x4E0A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5982;&#x679C;&#x5B57;&#x6BB5; <code>size_average</code> &#x8BBE;&#x7F6E;&#x4E3A; <code>False</code>, &#x5219; loss &#x4E0D;&#x4F1A;&#x53D6;&#x5E73;&#x5747;&#x503C;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>size_average (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x4E0A; &#x548C; <strong>&#x7EF4;&#x5EA6;</strong> &#x4E0A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5982;&#x679C;&#x8BBE;&#x7F6E;&#x4E3A; <code>False</code>, &#x5219; loss &#x4F1A;&#x7D2F;&#x52A0;, &#x800C;&#x4E0D;&#x662F;&#x53D6;&#x5E73;&#x5747;&#x503C;.</li>
<li><code>reduce (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x6839;&#x636E; size_average &#x5728;&#x6BCF; &#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x4E0A;&#x6C42;&#x5E73;&#x5747;&#x503C;&#x6216;&#x8005;&#x6C42;&#x548C;. &#x5F53; reduce &#x662F; <code>False</code> &#x65F6;, &#x635F;&#x5931;&#x51FD;&#x6570;&#x4F1A;&#x5BF9;&#x6BCF; &#x4E2A; batch &#x5143;&#x7D20;&#x90FD;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A; loss &#x5E76;&#x5FFD;&#x7565; size_average &#x5B57;&#x6BB5;. &#x9ED8;&#x8BA4;&#x503C;: <code>True</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;: <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x5176;&#x4E2D; <code>*</code> &#x8868;&#x793A;&#x4EFB;&#x610F;&#x6570;&#x91CF;&#x7684;&#x989D;&#x5916;&#x7EF4;&#x5EA6;.</li>
<li>&#x76EE;&#x6807;: <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, shape &#x8DDF;&#x8F93;&#x5165;&#x76F8;&#x540C;</li>
<li>&#x8F93;&#x51FA;: &#x6807;&#x91CF;. &#x5982;&#x679C; <code>reduce</code> &#x662F; <code>True</code>, &#x5219;&#x8F93;&#x51FA;&#x4E3A; <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, shape &#x8DDF;&#x8F93;&#x5165;&#x76F8;&#x540C;.</li>
</ul>
<h3 id="bceloss">BCELoss</h3>
<pre><code class="lang-py">class torch.nn.BCELoss(weight=None, size_average=True)
</code></pre>
<p>&#x8BA1;&#x7B97;&#x76EE;&#x6807;&#x548C;&#x8F93;&#x51FA;&#x4E4B;&#x95F4;&#x7684;&#x4E8C;&#x8FDB;&#x5236;&#x4EA4;&#x53C9;&#x71B5;:</p>
<p><img src="img/tex-c665b18ba021122b899fb17d4f215496.gif" alt="loss(o, t) = - 1/n \sum_i (t[i] * log(o[i]) + (1 - t[i]) * log(1 - o[i]))"></p>
<p>&#x5F53;&#x5B9A;&#x4E49;&#x4E86; weight &#x53C2;&#x6570;&#x65F6;:</p>
<p><img src="img/tex-a75feea82623649f822315604b9dff5a.gif" alt="loss(o, t) = - 1/n \sum_i weight[i] * (t[i] * log(o[i]) + (1 - t[i]) * log(1 - o[i]))"></p>
<p>&#x8FD9;&#x53EF;&#x7528;&#x4E8E;&#x6D4B;&#x91CF;&#x91CD;&#x6784;&#x7684;&#x8BEF;&#x5DEE;, &#x4F8B;&#x5982;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;. &#x6CE8;&#x610F;&#x76EE;&#x6807;&#x7684;&#x503C; <code>t[i]</code> &#x7684;&#x8303;&#x56F4;&#x4E3A;0&#x5230;1&#x4E4B;&#x95F4;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>weight (Tensor, &#x53EF;&#x9009;)</code> &#x2013; &#x81EA;&#x5B9A;&#x4E49;&#x7684;&#x6BCF;&#x4E2A; batch &#x5143;&#x7D20;&#x7684; loss &#x7684;&#x6743;&#x91CD;. &#x5FC5;&#x987B;&#x662F;&#x4E00;&#x4E2A;&#x957F;&#x5EA6;&#x4E3A; &#x201C;nbatch&#x201D; &#x7684; &#x7684; Tensor</li>
<li><code>size_average (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09; &#x4E0A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5982;&#x679C;&#x5B57;&#x6BB5; size_average &#x88AB;&#x8BBE;&#x7F6E;&#x4E3A; <code>False</code> , loss &#x4F1A;&#x5728;&#x6BCF; &#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x4E0A;&#x7D2F;&#x52A0;, &#x800C;&#x4E0D;&#x662F;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x9ED8;&#x8BA4;&#x503C;: <code>True</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;: <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x5176;&#x4E2D; <code>*</code> &#x8868;&#x793A;&#x4EFB;&#x610F;&#x6570;&#x91CF;&#x7684;&#x989D;&#x5916;&#x7EF4;&#x5EA6;.</li>
<li>&#x76EE;&#x6807;: <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, shape &#x8DDF;&#x8F93;&#x5165;&#x76F8;&#x540C;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Sigmoid()
<span class="hljs-meta">&gt;&gt;&gt; </span>loss = nn.BCELoss()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">3</span>), requires_grad=<span class="hljs-keyword">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>target = autograd.Variable(torch.FloatTensor(<span class="hljs-number">3</span>).random_(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = loss(m(input), target)
<span class="hljs-meta">&gt;&gt;&gt; </span>output.backward()
</code></pre>
<h3 id="bcewithlogitsloss">BCEWithLogitsLoss</h3>
<pre><code class="lang-py">class torch.nn.BCEWithLogitsLoss(weight=None, size_average=True)
</code></pre>
<p>&#x8BE5;&#x635F;&#x5931;&#x51FD;&#x6570;&#x628A; <code>Sigmoid</code> &#x5C42;&#x96C6;&#x6210;&#x5230;&#x4E86; <code>BCELoss</code> &#x7C7B;&#x4E2D;. &#x8BE5;&#x7248;&#x6BD4;&#x7528;&#x4E00;&#x4E2A;&#x7B80;&#x5355;&#x7684; <code>Sigmoid</code> &#x5C42;&#x548C; <code>BCELoss</code> &#x5728;&#x6570;&#x503C;&#x4E0A;&#x66F4;&#x7A33;&#x5B9A;, &#x56E0;&#x4E3A;&#x628A;&#x8FD9;&#x4E24;&#x4E2A;&#x64CD;&#x4F5C;&#x5408;&#x5E76;&#x4E3A;&#x4E00;&#x4E2A;&#x5C42;&#x4E4B;&#x540E;, &#x53EF;&#x4EE5;&#x5229;&#x7528; log-sum-exp &#x7684; &#x6280;&#x5DE7;&#x6765;&#x5B9E;&#x73B0;&#x6570;&#x503C;&#x7A33;&#x5B9A;.</p>
<p>&#x76EE;&#x6807;&#x548C;&#x8F93;&#x51FA;&#x4E4B;&#x95F4;&#x7684;&#x4E8C;&#x503C;&#x4EA4;&#x53C9;&#x71B5;(&#x4E0D;&#x542B;sigmoid&#x51FD;&#x6570;)&#x662F;:</p>
<p><img src="img/tex-f7f1487d3258a1beca2e4eb99261fbad.gif" alt="loss(o, t) = - 1/n \sum_i (t[i] * log(sigmoid(o[i])) + (1 - t[i]) * log(1 - sigmoid(o[i])))"></p>
<p>&#x5F53;&#x5B9A;&#x4E49;&#x4E86; weight &#x53C2;&#x6570;&#x4E4B;&#x540E;&#x53EF;&#x63CF;&#x8FF0;&#x4E3A;:</p>
<p><img src="img/tex-131660545fb84e407d9855bc8e08e7c1.gif" alt="loss(o, t) = - 1/n \sum_i weight[i] * (t[i] * log(sigmoid(o[i])) + (1 - t[i]) * log(1 - sigmoid(o[i])))"></p>
<p>&#x8FD9;&#x53EF;&#x7528;&#x4E8E;&#x6D4B;&#x91CF;&#x91CD;&#x6784;&#x7684;&#x8BEF;&#x5DEE;, &#x4F8B;&#x5982;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x673A;. &#x6CE8;&#x610F;&#x76EE;&#x6807;&#x7684;&#x503C; <code>t[i]</code> &#x7684;&#x8303;&#x56F4;&#x4E3A;0&#x5230;1&#x4E4B;&#x95F4;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>weight (Tensor, &#x53EF;&#x9009;)</code> &#x2013; &#x81EA;&#x5B9A;&#x4E49;&#x7684;&#x6BCF;&#x4E2A; batch &#x5143;&#x7D20;&#x7684; loss &#x7684;&#x6743;&#x91CD;. &#x5FC5;&#x987B;&#x662F;&#x4E00;&#x4E2A;&#x957F;&#x5EA6; &#x4E3A; &#x201C;nbatch&#x201D; &#x7684; Tensor</li>
<li><code>size_average (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, loss &#x4F1A;&#x5728;&#x6BCF;&#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09; &#x4E0A;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x5982;&#x679C;&#x5B57;&#x6BB5; size_average &#x88AB;&#x8BBE;&#x7F6E;&#x4E3A; <code>False</code> , loss &#x4F1A;&#x5728;&#x6BCF; &#x4E2A; mini-batch&#xFF08;&#x5C0F;&#x6279;&#x91CF;&#xFF09;&#x4E0A;&#x7D2F;&#x52A0;, &#x800C;&#x4E0D;&#x662F;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x9ED8;&#x8BA4;&#x503C;: <code>True</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;: <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x5176;&#x4E2D; <code>*</code> &#x8868;&#x793A;&#x4EFB;&#x610F;&#x6570;&#x91CF;&#x7684;&#x989D;&#x5916;&#x7EF4;&#x5EA6;.</li>
<li>&#x76EE;&#x6807;: <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, shape &#x8DDF;&#x8F93;&#x5165;&#x76F8;&#x540C;</li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>loss = nn.BCEWithLogitsLoss()
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.randn(<span class="hljs-number">3</span>), requires_grad=<span class="hljs-keyword">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>target = autograd.Variable(torch.FloatTensor(<span class="hljs-number">3</span>).random_(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = loss(input, target)
<span class="hljs-meta">&gt;&gt;&gt; </span>output.backward()
</code></pre>
<h3 id="marginrankingloss">MarginRankingLoss</h3>
<pre><code class="lang-py">class torch.nn.MarginRankingLoss(margin=0, size_average=True)
</code></pre>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x8861;&#x91CF; mini-batch(&#x5C0F;&#x6279;&#x91CF;) &#x4E2D;&#x7684;2&#x4E2A;1&#x7EF4; <code>Tensor</code> &#x7684;&#x8F93;&#x5165; <code>x1</code> &#x548C; <code>x2</code>, &#x548C;1&#x4E2A;1&#x7EF4; <code>Tensor</code> &#x7684;&#x76EE;&#x6807; <code>y</code>(<code>y</code> &#x7684;&#x53D6;&#x503C;&#x662F; <code>1</code> &#x6216;&#x8005; <code>-1</code>) &#x4E4B;&#x95F4;&#x635F;&#x5931;&#x7684;&#x6807;&#x51C6;.</p>
<p>&#x5982;&#x679C; <code>y == 1</code> &#x5219;&#x8BA4;&#x4E3A;&#x7B2C;&#x4E00;&#x4E2A;&#x8F93;&#x5165;&#x503C;&#x5E94;&#x8BE5;&#x6392;&#x5217;&#x5728;&#x7B2C;&#x4E8C;&#x4E2A;&#x8F93;&#x5165;&#x503C;&#x4E4B;&#x4E0A;(&#x5373;&#x503C;&#x66F4;&#x5927;), <code>y == -1</code> &#x65F6;&#x5219;&#x76F8;&#x53CD;.</p>
<p>&#x5BF9;&#x4E8E; mini-batch(&#x5C0F;&#x6279;&#x91CF;) &#x4E2D;&#x6BCF;&#x4E2A;&#x5B9E;&#x4F8B;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#x5982;&#x4E0B;:</p>
<pre><code class="lang-py">loss(x, y) = max(<span class="hljs-number">0</span>, -y * (x1 - x2) + margin)
</code></pre>
<p>&#x5982;&#x679C;&#x5185;&#x90E8;&#x53D8;&#x91CF; <code>size_average = True</code>, &#x5219;&#x635F;&#x5931;&#x51FD;&#x6570;&#x8BA1;&#x7B97;&#x6279;&#x6B21;&#x4E2D;&#x6240;&#x6709;&#x5B9E;&#x4F8B;&#x7684;&#x635F;&#x5931;&#x503C;&#x7684;&#x5E73;&#x5747;&#x503C;; &#x5982;&#x679C; <code>size_average = False</code>, &#x5219;&#x635F;&#x5931;&#x51FD;&#x6570;&#x8BA1;&#x7B97;&#x6279;&#x6B21;&#x4E2D;&#x6240;&#x6709;&#x5B9E;&#x4F8B;&#x7684;&#x635F;&#x5931;&#x81F3;&#x7684;&#x5408;&#x8BA1;. <code>size_average</code> &#x9ED8;&#x8BA4;&#x503C;&#x4E3A; <code>True</code>.</p>
<h3 id="hingeembeddingloss">HingeEmbeddingLoss</h3>
<pre><code class="lang-py">class torch.nn.HingeEmbeddingLoss(margin=1.0, size_average=True)
</code></pre>
<p>&#x8861;&#x91CF;&#x8F93;&#x5165; Tensor(&#x5F20;&#x91CF;) <code>x</code> &#x548C; &#x76EE;&#x6807; Tensor(&#x5F20;&#x91CF;) <code>y</code> (&#x53D6;&#x503C;&#x4E3A; <code>1</code> &#x548C; <code>-1</code>) &#x4E4B;&#x95F4;&#x7684;&#x635F;&#x5931;&#x503C;. &#x6B64;&#x65B9;&#x6CD5;&#x901A;&#x5E38;&#x7528;&#x6765;&#x8861;&#x91CF;&#x4E24;&#x4E2A;&#x8F93;&#x5165;&#x503C;&#x662F;&#x5426;&#x76F8;&#x4F3C;, &#x4F8B;&#x5982;&#x4F7F;&#x7528;L1&#x6210;&#x5BF9;&#x8DDD;&#x79BB;&#x4F5C;&#x4E3A; <code>x</code>, &#x5E76;&#x4E14;&#x901A;&#x5E38;&#x7528;&#x6765;&#x8FDB;&#x884C;&#x975E;&#x7EBF;&#x6027;&#x5D4C;&#x5165;&#x5B66;&#x4E60;&#x6216;&#x8005; &#x534A;&#x76D1;&#x7763;&#x5B66;&#x4E60;:</p>
<pre><code class="lang-py">                 { x_i,                  <span class="hljs-keyword">if</span> y_i ==  <span class="hljs-number">1</span>
loss(x, y) = <span class="hljs-number">1</span>/n {
                 { max(<span class="hljs-number">0</span>, margin - x_i), <span class="hljs-keyword">if</span> y_i == <span class="hljs-number">-1</span>
</code></pre>
<p><code>x</code> &#x548C; <code>y</code> &#x5206;&#x522B;&#x53EF;&#x4EE5;&#x662F;&#x5177;&#x6709; <code>n</code> &#x4E2A;&#x5143;&#x7D20;&#x7684;&#x4EFB;&#x610F;&#x5F62;&#x72B6;. &#x5408;&#x8BA1;&#x64CD;&#x4F5C;&#x5BF9;&#x6240;&#x6709;&#x5143;&#x7D20;&#x8FDB;&#x884C;&#x8BA1;&#x7B97;.</p>
<p>&#x5982;&#x679C; <code>size_average=False</code>, &#x5219;&#x8BA1;&#x7B97;&#x65F6;&#x4E0D;&#x4F1A;&#x9664;&#x4EE5; <code>n</code> &#x53D6;&#x5E73;&#x5747;&#x503C;.</p>
<p><code>margin</code> &#x7684;&#x9ED8;&#x8BA4;&#x503C;&#x662F; <code>1</code>, &#x6216;&#x8005;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x6784;&#x9020;&#x51FD;&#x6570;&#x6765;&#x8BBE;&#x7F6E;.</p>
<h3 id="multilabelmarginloss">MultiLabelMarginLoss</h3>
<pre><code class="lang-py">class torch.nn.MultiLabelMarginLoss(size_average=True)
</code></pre>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x6807;&#x51C6;, &#x7528;&#x4EE5;&#x4F18;&#x5316;&#x591A;&#x5143;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x7684;&#x5408;&#x9875;&#x635F;&#x5931;&#x51FD;&#x6570; (&#x57FA;&#x4E8E;&#x7A7A;&#x767D;&#x7684;&#x635F;&#x5931;), &#x8BA1;&#x7B97;&#x635F;&#x5931;&#x503C;&#x65F6; &#x9700;&#x8981;2&#x4E2A;&#x53C2;&#x6570;&#x5206;&#x522B;&#x4E3A;&#x8F93;&#x5165;, <code>x</code> (&#x4E00;&#x4E2A;2&#x7EF4;&#x5C0F;&#x6279;&#x91CF; <code>Tensor</code>) &#x548C;&#x8F93;&#x51FA; <code>y</code> (&#x4E00;&#x4E2A;2&#x7EF4; <code>Tensor</code>, &#x5176;&#x503C;&#x4E3A; <code>x</code> &#x7684;&#x7D22;&#x5F15;&#x503C;). &#x5BF9;&#x4E8E;mini-batch(&#x5C0F;&#x6279;&#x91CF;) &#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x6837;&#x672C;&#x6309;&#x5982;&#x4E0B;&#x516C;&#x5F0F;&#x8BA1;&#x7B97;&#x635F;&#x5931;:</p>
<pre><code class="lang-py">loss(x, y) = sum_ij(max(<span class="hljs-number">0</span>, <span class="hljs-number">1</span> - (x[y[j]] - x[i]))) / x.size(<span class="hljs-number">0</span>)
</code></pre>
<p>&#x5176;&#x4E2D; <code>i</code> &#x7684;&#x53D6;&#x503C;&#x8303;&#x56F4;&#x662F; <code>0</code> &#x5230; <code>x.size(0)</code>, <code>j</code> &#x7684;&#x53D6;&#x503C;&#x8303;&#x56F4;&#x662F; <code>0</code> &#x5230; <code>y.size(0)</code>, <code>y[j] &amp;gt;= 0</code>, &#x5E76;&#x4E14;&#x5BF9;&#x4E8E;&#x6240;&#x6709; <code>i</code> &#x548C; <code>j</code> &#x6709; <code>i != y[j]</code>.</p>
<p><code>y</code> &#x548C; <code>x</code> &#x5FC5;&#x987B;&#x6709;&#x76F8;&#x540C;&#x7684;&#x5143;&#x7D20;&#x6570;&#x91CF;.</p>
<p>&#x6B64;&#x6807;&#x51C6;&#x4EC5;&#x8003;&#x8651; <code>y[j]</code> &#x4E2D;&#x6700;&#x5148;&#x51FA;&#x73B0;&#x7684;&#x975E;&#x96F6;&#x503C;.</p>
<p>&#x5982;&#x6B64;&#x53EF;&#x4EE5;&#x5141;&#x8BB8;&#x6BCF;&#x4E2A;&#x6837;&#x672C;&#x53EF;&#x4EE5;&#x6709;&#x6570;&#x91CF;&#x4E0D;&#x540C;&#x7684;&#x76EE;&#x6807;&#x7C7B;&#x522B;.</p>
<h3 id="smoothl1loss">SmoothL1Loss</h3>
<pre><code class="lang-py">class torch.nn.SmoothL1Loss(size_average=True, reduce=True)
</code></pre>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x6807;&#x51C6;, &#x5F53;&#x67D0;&#x4E2A;&#x5143;&#x7D20;&#x7684;&#x9519;&#x8BEF;&#x503C;&#x7684;&#x7EDD;&#x5BF9;&#x503C;&#x5C0F;&#x4E8E;1&#x65F6;&#x4F7F;&#x7528;&#x5E73;&#x65B9;&#x9879;&#x8BA1;&#x7B97;, &#x5176;&#x4ED6;&#x60C5;&#x51B5;&#x5219;&#x4F7F;&#x7528;L1&#x8303;&#x5F0F;&#x8BA1;&#x7B97;. &#x6B64;&#x65B9;&#x6CD5;&#x521B;&#x5EFA;&#x7684;&#x6807;&#x51C6;&#x5BF9;&#x4E8E;&#x5F02;&#x5E38;&#x503C;&#x4E0D;&#x5982; <code>MSELoss</code>&#x654F;&#x611F;, &#x4F46;&#x662F;&#x540C;&#x65F6;&#x5728;&#x67D0;&#x4E9B;&#x60C5;&#x51B5;&#x4E0B;&#x53EF;&#x4EE5;&#x9632;&#x6B62;&#x68AF;&#x5EA6;&#x7206;&#x70B8; (&#x6BD4;&#x5982; &#x53C2;&#x89C1;&#x8BBA;&#x6587; &#x201C;Fast R-CNN&#x201D; &#x4F5C;&#x8005; Ross Girshick). &#x4E5F;&#x88AB;&#x79F0;&#x4E3A; Huber &#x635F;&#x5931;&#x51FD;&#x6570;:</p>
<pre><code class="lang-py">                      { <span class="hljs-number">0.5</span> * (x_i - y_i)^<span class="hljs-number">2</span>, <span class="hljs-keyword">if</span> |x_i - y_i| &lt; <span class="hljs-number">1</span>
loss(x, y) = <span class="hljs-number">1</span>/n \sum {
                      { |x_i - y_i| - <span class="hljs-number">0.5</span>,   otherwise
</code></pre>
<p><code>x</code> &#x548C; <code>y</code> &#x53EF;&#x4EE5;&#x662F;&#x4EFB;&#x610F;&#x5F62;&#x72B6;&#x53EA;&#x8981;&#x90FD;&#x5177;&#x5907;&#x603B;&#x8BA1; <code>n</code> &#x4E2A;&#x5143;&#x7D20; &#x5408;&#x8BA1;&#x4ECD;&#x7136;&#x9488;&#x5BF9;&#x6240;&#x6709;&#x5143;&#x7D20;&#x8FDB;&#x884C;&#x8BA1;&#x7B97;, &#x5E76;&#x4E14;&#x6700;&#x540E;&#x9664;&#x4EE5; <code>n</code>.</p>
<p>&#x5982;&#x679C;&#x628A;&#x5185;&#x90E8;&#x53D8;&#x91CF; <code>size_average</code> &#x8BBE;&#x7F6E;&#x4E3A; <code>False</code>, &#x5219;&#x4E0D;&#x4F1A;&#x88AB;&#x9664;&#x4EE5; <code>n</code>.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>size_average (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x635F;&#x5931;&#x503C;&#x9ED8;&#x8BA4;&#x4F1A;&#x6309;&#x7167;&#x6240;&#x6709;&#x5143;&#x7D20;&#x53D6;&#x5E73;&#x5747;&#x503C;. &#x4F46;&#x662F;, &#x5982;&#x679C; size_average &#x88AB; &#x8BBE;&#x7F6E;&#x4E3A; <code>False</code>, &#x5219;&#x635F;&#x5931;&#x503C;&#x4E3A;&#x6240;&#x6709;&#x5143;&#x7D20;&#x7684;&#x5408;&#x8BA1;. &#x5982;&#x679C; reduce &#x53C2;&#x6570;&#x8BBE;&#x4E3A; <code>False</code>, &#x5219;&#x5FFD;&#x7565;&#x6B64;&#x53C2;&#x6570;&#x7684;&#x503C;. &#x9ED8;&#x8BA4;: <code>True</code></li>
<li><code>reduce (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x635F;&#x5931;&#x503C;&#x9ED8;&#x8BA4;&#x4F1A;&#x6309;&#x7167;&#x6240;&#x6709;&#x5143;&#x7D20;&#x53D6;&#x5E73;&#x5747;&#x503C;&#x6216;&#x8005;&#x53D6;&#x5408;&#x8BA1;&#x503C;. &#x5F53; reduce &#x8BBE;&#x7F6E;&#x4E3A; <code>False</code> &#x65F6;, &#x635F;&#x5931;&#x51FD;&#x6570;&#x5BF9;&#x4E8E;&#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x90FD;&#x8FD4;&#x56DE;&#x635F;&#x5931;&#x503C;&#x5E76;&#x4E14;&#x5FFD;&#x7565; size_average &#x53C2;&#x6570;. &#x9ED8;&#x8BA4;: <code>True</code></li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;: <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)"> <code>*</code> &#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x4E2A;&#x5176;&#x4ED6;&#x7EF4;&#x5EA6;</li>
<li>&#x76EE;&#x6807;: <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x540C;&#x8F93;&#x5165;</li>
<li>&#x8F93;&#x51FA;: &#x6807;&#x91CF;. &#x5982;&#x679C; reduce &#x8BBE;&#x4E3A; <code>False</code> &#x5219;&#x4E3A; <img src="img/tex-b0400390724111bb8254d8d21c6a9f0d.gif" alt="(N, *)">, &#x540C;&#x8F93;&#x5165;</li>
</ul>
<h3 id="softmarginloss">SoftMarginLoss</h3>
<pre><code class="lang-py">class torch.nn.SoftMarginLoss(size_average=True)
</code></pre>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x6807;&#x51C6;, &#x7528;&#x4EE5;&#x4F18;&#x5316;&#x4E24;&#x5206;&#x7C7B;&#x7684; logistic loss. &#x8F93;&#x5165;&#x4E3A; <code>x</code> (&#x4E00;&#x4E2A;2&#x7EF4; mini-batch Tensor)&#x548C; &#x76EE;&#x6807; <code>y</code> (&#x4E00;&#x4E2A;&#x5305;&#x542B; <code>1</code> &#x6216;&#x8005; <code>-1</code> &#x7684; Tensor).</p>
<pre><code class="lang-py">loss(x, y) = sum_i (log(<span class="hljs-number">1</span> + exp(-y[i]*x[i]))) / x.nelement()
</code></pre>
<p>&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x8BBE;&#x7F6E; <code>self.size_average</code> &#x4E3A; <code>False</code> &#x6765;&#x7981;&#x7528;&#x6309;&#x7167;&#x5143;&#x7D20;&#x6570;&#x91CF;&#x53D6;&#x5E73;&#x5747;&#x7684;&#x6B63;&#x5219;&#x5316;&#x64CD;&#x4F5C;.</p>
<h3 id="multilabelsoftmarginloss">MultiLabelSoftMarginLoss</h3>
<pre><code class="lang-py">class torch.nn.MultiLabelSoftMarginLoss(weight=None, size_average=True)
</code></pre>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x6807;&#x51C6;, &#x57FA;&#x4E8E;&#x8F93;&#x5165; <code>x</code> &#x548C;&#x76EE;&#x6807; <code>y</code>&#x7684; max-entropy(&#x6700;&#x5927;&#x71B5;), &#x4F18;&#x5316;&#x591A;&#x6807;&#x7B7E; one-versus-all &#x635F;&#x5931;. &#x8F93;&#x5165; <code>x</code> &#x4E3A;&#x4E00;&#x4E2A;2&#x7EF4; mini-batch <code>Tensor</code>, &#x76EE;&#x6807; <code>y</code> &#x4E3A;2&#x8FDB;&#x5236;2&#x7EF4; <code>Tensor</code>. &#x5BF9;&#x6BCF;&#x4E2A; mini-batch &#x4E2D;&#x7684;&#x6837;&#x672C;, &#x5BF9;&#x5E94;&#x7684; loss &#x4E3A;:</p>
<pre><code class="lang-py">loss(x, y) = - sum_i (y[i] * log( <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + exp(-x[i])) )
                  + ( (<span class="hljs-number">1</span>-y[i]) * log(exp(-x[i]) / (<span class="hljs-number">1</span> + exp(-x[i])) ) )
</code></pre>
<p>&#x5176;&#x4E2D; <code>i == 0</code> &#x81F3; <code>x.nElement()-1</code>, <code>y[i] in {0,1}</code>. <code>y</code> &#x548C; <code>x</code> &#x5FC5;&#x987B;&#x5177;&#x6709;&#x76F8;&#x540C;&#x7684;&#x7EF4;&#x5EA6;.</p>
<h3 id="cosineembeddingloss">CosineEmbeddingLoss</h3>
<pre><code class="lang-py">class torch.nn.CosineEmbeddingLoss(margin=0, size_average=True)
</code></pre>
<p>&#x65B0;&#x5EFA;&#x4E00;&#x4E2A;&#x6807;&#x51C6;, &#x7528;&#x4EE5;&#x8861;&#x91CF;&#x8F93;&#x5165; <code>Tensor</code> x1, x2 &#x548C;&#x53D6;&#x503C;&#x4E3A; 1 &#x6216;&#x8005; -1 &#x7684;&#x6807;&#x7B7E; <code>Tensor</code> <code>y</code>&#x4E4B;&#x95F4;&#x7684; &#x635F;&#x5931;&#x503C;. &#x6B64;&#x6807;&#x51C6;&#x7528; cosine &#x8DDD;&#x79BB;&#x6765;&#x8861;&#x91CF;2&#x4E2A;&#x8F93;&#x5165;&#x53C2;&#x6570;&#x4E4B;&#x95F4;&#x662F;&#x5426;&#x76F8;&#x4F3C;, &#x5E76;&#x4E14;&#x4E00;&#x822C;&#x7528;&#x6765;&#x5B66;&#x4E60;&#x975E;&#x7EBF;&#x6027; embedding &#x6216;&#x8005;&#x534A;&#x76D1;&#x7763; &#x5B66;&#x4E60;.</p>
<p><code>margin</code> &#x5E94;&#x8BE5;&#x53D6; <code>-1</code> &#x5230; <code>1</code> &#x4E4B;&#x95F4;&#x7684;&#x503C;, &#x5EFA;&#x8BAE;&#x53D6;&#x503C;&#x8303;&#x56F4;&#x662F; <code>0</code> &#x5230; <code>0.5</code>. &#x5982;&#x679C;&#x6CA1;&#x6709;&#x8BBE;&#x7F6E; <code>margin</code> &#x53C2;&#x6570;, &#x5219;&#x9ED8;&#x8BA4;&#x503C;&#x53D6; <code>0</code>.</p>
<p>&#x6BCF;&#x4E2A;&#x6837;&#x672C;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#x5982;&#x4E0B;:</p>
<pre><code class="lang-py">             { <span class="hljs-number">1</span> - cos(x1, x2),              <span class="hljs-keyword">if</span> y ==  <span class="hljs-number">1</span>
loss(x, y) = {
             { max(<span class="hljs-number">0</span>, cos(x1, x2) - margin), <span class="hljs-keyword">if</span> y == <span class="hljs-number">-1</span>
</code></pre>
<p>&#x5982;&#x679C;&#x5185;&#x90E8;&#x53D8;&#x91CF; <code>size_average</code> &#x8BBE;&#x7F6E;&#x4E3A; <code>True</code>, &#x5219;&#x635F;&#x5931;&#x51FD;&#x6570;&#x4EE5; batch &#x4E2D;&#x6240;&#x6709;&#x7684;&#x6837;&#x672C;&#x6570;&#x53D6;&#x5E73;&#x5747;&#x503C;; &#x5982;&#x679C; <code>size_average</code> &#x8BBE;&#x7F6E;&#x4E3A; <code>False</code>, &#x5219;&#x635F;&#x5931;&#x51FD;&#x6570;&#x5BF9; batch &#x4E2D;&#x6240;&#x6709;&#x7684;&#x6837;&#x672C;&#x6C42;&#x548C;. &#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, <code>size_average = True</code>.</p>
<h3 id="multimarginloss">MultiMarginLoss</h3>
<pre><code class="lang-py">class torch.nn.MultiMarginLoss(p=1, margin=1, weight=None, size_average=True)
</code></pre>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x6807;&#x51C6;, &#x7528;&#x4EE5;&#x4F18;&#x5316;&#x591A;&#x5143;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x7684;&#x5408;&#x9875;&#x635F;&#x5931;&#x51FD;&#x6570; (&#x57FA;&#x4E8E;&#x7A7A;&#x767D;&#x7684;&#x635F;&#x5931;), &#x8BA1;&#x7B97;&#x635F;&#x5931;&#x503C;&#x65F6; &#x9700;&#x8981;2&#x4E2A;&#x53C2;&#x6570;&#x5206;&#x522B;&#x4E3A;&#x8F93;&#x5165;, <code>x</code> (&#x4E00;&#x4E2A;2&#x7EF4;&#x5C0F;&#x6279;&#x91CF; <code>Tensor</code>) &#x548C;&#x8F93;&#x51FA; <code>y</code> (&#x4E00;&#x4E2A;1&#x7EF4; <code>Tensor</code>, &#x5176;&#x503C;&#x4E3A; <code>x</code> &#x7684;&#x7D22;&#x5F15;&#x503C;, <code>0</code> &lt;= <code>y</code> &lt;= <code>x.size(1)</code>):</p>
<p>&#x5BF9;&#x4E8E;&#x6BCF;&#x4E2A; mini-batch(&#x5C0F;&#x6279;&#x91CF;) &#x6837;&#x672C;:</p>
<pre><code class="lang-py">loss(x, y) = sum_i(max(<span class="hljs-number">0</span>, (margin - x[y] + x[i]))^p) / x.size(<span class="hljs-number">0</span>)
</code></pre>
<p>&#x5176;&#x4E2D; <code>i == 0</code> &#x81F3; <code>x.size(0)</code> &#x5E76;&#x4E14; <code>i != y</code>.</p>
<p>&#x53EF;&#x9009;&#x62E9;&#x7684;, &#x5982;&#x679C;&#x60A8;&#x4E0D;&#x60F3;&#x6240;&#x6709;&#x7684;&#x7C7B;&#x62E5;&#x6709;&#x540C;&#x6837;&#x7684;&#x6743;&#x91CD;&#x7684;&#x8BDD;, &#x60A8;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x5728;&#x6784;&#x9020;&#x51FD;&#x6570;&#x4E2D;&#x4F20;&#x5165; <code>weight</code> &#x53C2;&#x6570;&#x6765; &#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;, <code>weight</code> &#x662F;&#x4E00;&#x4E2A;1&#x7EF4; Tensor.</p>
<p>&#x4F20;&#x5165; <code>weight</code> &#x540E;, &#x635F;&#x5931;&#x51FD;&#x6570;&#x53D8;&#x4E3A;:</p>
<blockquote>
<p>loss(x, y) = sum_i(max(0, w[y] * (margin - x[y] - x[i]))^p) / x.size(0)</p>
</blockquote>
<p>&#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, &#x6C42;&#x51FA;&#x7684;&#x635F;&#x5931;&#x503C;&#x4F1A;&#x5BF9;&#x6BCF;&#x4E2A; minibatch &#x6837;&#x672C;&#x7684;&#x7ED3;&#x679C;&#x53D6;&#x5E73;&#x5747;. &#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x8BBE;&#x7F6E; <code>size_average</code> &#x4E3A; <code>False</code> &#x6765;&#x7528;&#x5408;&#x8BA1;&#x64CD;&#x4F5C;&#x53D6;&#x4EE3;&#x53D6;&#x5E73;&#x5747;&#x64CD;&#x4F5C;.</p>
<h3 id="tripletmarginloss">TripletMarginLoss</h3>
<pre><code class="lang-py">class torch.nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-06, swap=False)
</code></pre>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x6807;&#x51C6;, &#x7528;&#x4EE5;&#x8861;&#x91CF;&#x4E09;&#x5143;&#x7EC4;&#x5408;&#x7684;&#x635F;&#x5931;&#x503C;, &#x8BA1;&#x7B97;&#x635F;&#x5931;&#x503C;&#x65F6;&#x9700;&#x8981;3&#x4E2A;&#x8F93;&#x5165;&#x5F20;&#x91CF; <code>x1</code>, <code>x2</code>, <code>x3</code> &#x548C; &#x4E00;&#x4E2A;&#x5927;&#x4E8E;&#x96F6;&#x7684; <code>margin</code> &#x503C;. &#x6B64;&#x6807;&#x51C6;&#x53EF;&#x4EE5;&#x7528;&#x6765;&#x8861;&#x91CF;&#x8F93;&#x5165;&#x6837;&#x672C;&#x95F4;&#x7684;&#x76F8;&#x5BF9;&#x76F8;&#x4F3C;&#x6027;. &#x4E00;&#x4E2A;&#x4E09;&#x5143;&#x8F93;&#x5165;&#x7EC4;&#x5408;&#x7531; <code>a</code>, <code>p</code> &#x548C; <code>n</code>: anchor, positive &#x6837;&#x672C; &#x548C; negative &#x6837;&#x672C;&#x7EC4;&#x6210;. &#x6240;&#x6709;&#x8F93;&#x5165;&#x53D8;&#x91CF;&#x7684;&#x5F62;&#x5F0F;&#x5FC5;&#x987B;&#x4E3A; <img src="img/tex-df68502f8935f32bcaef520a28eb3e21.gif" alt="(N, D)">.</p>
<p>&#x8DDD;&#x79BB;&#x4EA4;&#x6362;&#x7684;&#x8BE6;&#x7EC6;&#x8BF4;&#x660E;&#x8BF7;&#x53C2;&#x8003;&#x8BBA;&#x6587; <a href="http://www.iis.ee.ic.ac.uk/%7Evbalnt/shallow_descr/TFeat_paper.pdf" target="_blank">Learning shallow convolutional feature descriptors with triplet losses</a> by V. Balntas, E. Riba et al.</p>
<p><img src="img/tex-cf988cda62d3487317968d4fce873e69.gif" alt="L(a, p, n) = \frac{1}{N} \left( \sum_{i=1}^N \max \{d(a_i, p_i) - d(a_i, n_i) + {\rm margin}, 0\} \right)"></p>
<p>&#x5176;&#x4E2D; <img src="img/tex-58c638474fe46f788c74d4a7a62c5e1f.gif" alt="d(x_i, y_i) = \left\lVert {\bf x}_i - {\bf y}_i \right\rVert_p">.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>anchor</code> &#x2013; anchor &#x8F93;&#x5165; tensor</li>
<li><code>positive</code> &#x2013; positive &#x8F93;&#x5165; tensor</li>
<li><code>negative</code> &#x2013; negative &#x8F93;&#x5165; tensor</li>
<li><code>p</code> &#x2013; &#x6B63;&#x5219;&#x5316;&#x7387;. Default: 2</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-df68502f8935f32bcaef520a28eb3e21.gif" alt="(N, D)"> &#x5176;&#x4E2D; <code>D = vector dimension</code></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-eb4023c8eeb604a58f58c44e29f7924a.gif" alt="(N, 1)"></li>
</ul>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>triplet_loss = nn.TripletMarginLoss(margin=<span class="hljs-number">1.0</span>, p=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input1 = autograd.Variable(torch.randn(<span class="hljs-number">100</span>, <span class="hljs-number">128</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input2 = autograd.Variable(torch.randn(<span class="hljs-number">100</span>, <span class="hljs-number">128</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>input3 = autograd.Variable(torch.randn(<span class="hljs-number">100</span>, <span class="hljs-number">128</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = triplet_loss(input1, input2, input3)
<span class="hljs-meta">&gt;&gt;&gt; </span>output.backward()
</code></pre>
<h2 id="vision-layers-&#x89C6;&#x89C9;&#x5C42;">Vision layers (&#x89C6;&#x89C9;&#x5C42;)</h2>
<h3 id="pixelshuffle">PixelShuffle</h3>
<pre><code class="lang-py">class torch.nn.PixelShuffle(upscale_factor)
</code></pre>
<p>&#x5BF9;&#x5F20;&#x91CF;&#x4E2D;&#x5F62;&#x5982; <img src="img/tex-92312e8331c8111c53ea986a22d9bfd2.gif" alt="(*, C * r^2, H, W]"> &#x7684;&#x5143;&#x7D20;, &#x91CD;&#x65B0;&#x6392;&#x5217;&#x6210; <img src="img/tex-fe414d0d481aa30dbc63aa33276b42d6.gif" alt="(C, H * r, W * r)">.</p>
<p>&#x5F53;&#x4F7F;&#x7528; stride = <img src="img/tex-305837540b14c05ec56167e74aea3132.gif" alt="1/r"> &#x7684;&#x9AD8;&#x6548;&#x5B50;&#x50CF;&#x7D20;&#x5377;&#x79EF;&#x5F88;&#x6709;&#x7528;.</p>
<p>&#x53C2;&#x8003;&#x5982;&#x4E0B;&#x8BBA;&#x6587;&#x83B7;&#x5F97;&#x66F4;&#x591A;&#x4FE1;&#x606F;: <a href="https://arxiv.org/abs/1609.05158" target="_blank">Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network</a> Shi et. al (2016) .</p>
<p>&#x53C2;&#x6570;&#xFF1A;<code>upscale_factor (int)</code> &#x2013; &#x589E;&#x52A0;&#x7A7A;&#x95F4;&#x5206;&#x8FA8;&#x7387;&#x7684;&#x56E0;&#x5B50;</p>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;: <img src="img/tex-35b4ae66acb21958d7890c5288813439.gif" alt="(N, C * {upscale\_factor}^2, H, W)"></li>
<li>&#x8F93;&#x51FA;: <img src="img/tex-506e21c8cc042a71de4738e50912853e.gif" alt="(N, C, H * {upscale\_factor}, W * {upscale\_factor})"></li>
</ul>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>ps = nn.PixelShuffle(<span class="hljs-number">3</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>input = autograd.Variable(torch.Tensor(<span class="hljs-number">1</span>, <span class="hljs-number">9</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>output = ps(input)
<span class="hljs-meta">&gt;&gt;&gt; </span>print(output.size())
torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">12</span>, <span class="hljs-number">12</span>])
</code></pre>
<h3 id="upsample">Upsample</h3>
<pre><code class="lang-py">class torch.nn.Upsample(size=None, scale_factor=None, mode=&apos;nearest&apos;)
</code></pre>
<p>&#x5BF9;&#x7ED9;&#x5B9A;&#x7684;&#x591A;&#x901A;&#x9053;&#x4E00;&#x7EF4;&#x65F6;&#x5E8F;&#x6570;&#x636E;, &#x4E8C;&#x7EF4;&#x7A7A;&#x95F4;&#x6570;&#x636E;, &#x6216;&#x4E09;&#x7EF4;&#x5BB9;&#x79EF;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x4E0A;&#x91C7;&#x6837;.</p>
<p>&#x8F93;&#x5165;&#x6570;&#x636E;&#x7684;&#x683C;&#x5F0F;&#x4E3A; <code>minibatch x channels x [depth] x [height] x width</code>. &#x56E0;&#x6B64;, &#x5BF9;&#x4E8E;2-D&#x7A7A;&#x95F4;&#x6570;&#x636E;&#x7684;&#x8F93;&#x5165;, &#x671F;&#x671B;&#x5F97;&#x5230;&#x4E00;&#x4E2A;4-D&#x5F20;&#x91CF;&#xFF1B;&#x5BF9;&#x4E8E;3-D&#x7ACB;&#x4F53;&#x6570;&#x636E;&#x8F93;&#x5165;, &#x671F;&#x671B;&#x5F97;&#x5230;&#x4E00;&#x4E2A;5-D&#x5F20;&#x91CF;.</p>
<p>&#x5BF9;3D, 4D, 5D&#x7684;&#x8F93;&#x5165;&#x5F20;&#x91CF;&#x8FDB;&#x884C;&#x6700;&#x8FD1;&#x90BB;&#x3001;&#x7EBF;&#x6027;&#x3001;&#x53CC;&#x7EBF;&#x6027;&#x548C;&#x4E09;&#x7EBF;&#x6027;&#x91C7;&#x6837;, &#x53EF;&#x7528;&#x4E8E;&#x8BE5;&#x4E0A;&#x91C7;&#x6837;&#x65B9;&#x6CD5;.</p>
<p>&#x53EF;&#x4EE5;&#x63D0;&#x4F9B; <code>scale_factor</code> &#x6216;&#x76EE;&#x6807;&#x8F93;&#x51FA;&#x7684; <code>size</code> &#x6765;&#x8BA1;&#x7B97;&#x8F93;&#x51FA;&#x7684;&#x5927;&#x5C0F;. &#xFF08;&#x4E0D;&#x80FD;&#x540C;&#x65F6;&#x90FD;&#x7ED9;, &#x56E0;&#x4E3A;&#x8FD9;&#x6837;&#x505A;&#x662F;&#x542B;&#x7CCA;&#x4E0D;&#x6E05;&#x7684;. &#xFF09;</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>size (tuple, &#x53EF;&#x9009;)</code> &#x2013; &#x6574;&#x578B;&#x6570;&#x7684;&#x5143;&#x7EC4; ([D_out], [H_out], W_out) &#x8F93;&#x51FA;&#x5927;&#x5C0F;</li>
<li><code>scale_factor (int / tuple[int...], &#x53EF;&#x9009;)</code> &#x2013; &#x56FE;&#x50CF;&#x9AD8;&#x5EA6;/&#x5BBD;&#x5EA6;/&#x6DF1;&#x5EA6;&#x7684;&#x4E58;&#x6570;</li>
<li><code>mode (string, &#x53EF;&#x9009;)</code> &#x2013; &#x4E0A;&#x91C7;&#x6837;&#x7B97;&#x6CD5;: nearest | linear | bilinear | trilinear. &#x9ED8;&#x8BA4;&#x4E3A;: nearest</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;: <img src="img/tex-ea37c9cca622977d5bfa09dc10d5289e.gif" alt="(N, C, W_{in})">, <img src="img/tex-d5acb55d3d2dd49b5b0d71ab7cf3b2d1.gif" alt="(N, C, H_{in}, W_{in})"> &#x6216; <img src="img/tex-ce19deda602cf16ded15c0fb9cd5d280.gif" alt="(N, C, D_{in}, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;: <img src="img/tex-86a0834f28ea21dbf773dcde05f5a8a9.gif" alt="(N, C, W_{out})">, <img src="img/tex-403ffd9231342159e36ba660b2bf3ff3.gif" alt="(N, C, H_{out}, W_{out})"> &#x6216; <img src="img/tex-d14df6868b2b3f7ee945a69616a0b867.gif" alt="(N, C, D_{out}, H_{out}, W_{out})"> &#x5176;&#x4E2D;: <img src="img/tex-ea21cae2b495cce278ead54dddcbd995.gif" alt="D_{out} = floor(D_{in} * scale\_factor)"> &#x6216; <code>size[-3]</code> <img src="img/tex-125c98960333dfccfe02ac897317e5c6.gif" alt="H_{out} = floor(H_{in} * scale\_factor)"> &#x6216; <code>size[-2]</code> <img src="img/tex-0debb495c4ef7738643087520b82f93c.gif" alt="W_{out} = floor(W_{in} * scale\_factor)"> &#x6216; <code>size[-1]</code></li>
</ul>
<p>&#x793A;&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>inp
Variable containing:
(<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">1</span>  <span class="hljs-number">2</span>
 <span class="hljs-number">3</span>  <span class="hljs-number">4</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x2x2]

<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Upsample(scale_factor=<span class="hljs-number">2</span>, mode=<span class="hljs-string">&apos;bilinear&apos;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>m(inp)
Variable containing:
(<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">1.0000</span>  <span class="hljs-number">1.3333</span>  <span class="hljs-number">1.6667</span>  <span class="hljs-number">2.0000</span>
 <span class="hljs-number">1.6667</span>  <span class="hljs-number">2.0000</span>  <span class="hljs-number">2.3333</span>  <span class="hljs-number">2.6667</span>
 <span class="hljs-number">2.3333</span>  <span class="hljs-number">2.6667</span>  <span class="hljs-number">3.0000</span>  <span class="hljs-number">3.3333</span>
 <span class="hljs-number">3.0000</span>  <span class="hljs-number">3.3333</span>  <span class="hljs-number">3.6667</span>  <span class="hljs-number">4.0000</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x4x4]

<span class="hljs-meta">&gt;&gt;&gt; </span>inp
Variable containing:
(<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">1</span>  <span class="hljs-number">2</span>
 <span class="hljs-number">3</span>  <span class="hljs-number">4</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x2x2]

<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Upsample(scale_factor=<span class="hljs-number">2</span>, mode=<span class="hljs-string">&apos;nearest&apos;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>m(inp)
Variable containing:
(<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">1</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">2</span>
 <span class="hljs-number">1</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">2</span>
 <span class="hljs-number">3</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span>  <span class="hljs-number">4</span>
 <span class="hljs-number">3</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span>  <span class="hljs-number">4</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x4x4]
</code></pre>
<h3 id="upsamplingnearest2d">UpsamplingNearest2d</h3>
<pre><code class="lang-py">class torch.nn.UpsamplingNearest2d(size=None, scale_factor=None)
</code></pre>
<p>&#x5BF9;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;&#x8FDB;&#x884C;2&#x7EF4;&#x6700;&#x8FD1;&#x90BB;&#x4E0A;&#x91C7;&#x6837;.</p>
<p>&#x4E3A;&#x4E86;&#x6307;&#x5B9A;&#x91C7;&#x6837;&#x8303;&#x56F4;, &#x63D0;&#x4F9B;&#x4E86; <code>size</code> &#x6216; <code>scale_factor</code> &#x4F5C;&#x4E3A;&#x6784;&#x9020;&#x53C2;&#x6570;.</p>
<p>&#x5F53;&#x7ED9;&#x5B9A; <code>size</code>, &#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5927;&#x5C0F;&#x4E3A; (h, w).</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>size (tuple, &#x53EF;&#x9009;)</code> &#x2013; &#x8F93;&#x51FA;&#x56FE;&#x7247;&#x5927;&#x5C0F;&#x7684;&#x6574;&#x578B;&#x5143;&#x7EC4;(H_out, W_out)</li>
<li><code>scale_factor (int, &#x53EF;&#x9009;)</code> &#x2013; &#x56FE;&#x50CF;&#x7684; &#x957F;&#x548C;&#x5BBD;&#x7684;&#x4E58;&#x5B50;.</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-d5acb55d3d2dd49b5b0d71ab7cf3b2d1.gif" alt="(N, C, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-403ffd9231342159e36ba660b2bf3ff3.gif" alt="(N, C, H_{out}, W_{out})"> &#x5176;&#x4E2D; <img src="img/tex-125c98960333dfccfe02ac897317e5c6.gif" alt="H_{out} = floor(H_{in} * scale\_factor)"> <img src="img/tex-0debb495c4ef7738643087520b82f93c.gif" alt="W_{out} = floor(W_{in} * scale\_factor)"></li>
</ul>
<p>&#x793A;&#x4F8B;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>inp
Variable containing:
(<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">1</span>  <span class="hljs-number">2</span>
 <span class="hljs-number">3</span>  <span class="hljs-number">4</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x2x2]

<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.UpsamplingNearest2d(scale_factor=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>m(inp)
Variable containing:
(<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">1</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">2</span>
 <span class="hljs-number">1</span>  <span class="hljs-number">1</span>  <span class="hljs-number">2</span>  <span class="hljs-number">2</span>
 <span class="hljs-number">3</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span>  <span class="hljs-number">4</span>
 <span class="hljs-number">3</span>  <span class="hljs-number">3</span>  <span class="hljs-number">4</span>  <span class="hljs-number">4</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x4x4]
</code></pre>
<h3 id="upsamplingbilinear2d">UpsamplingBilinear2d</h3>
<pre><code class="lang-py">class torch.nn.UpsamplingBilinear2d(size=None, scale_factor=None)
</code></pre>
<p>&#x5BF9;&#x591A;&#x4E2A;&#x8F93;&#x5165;&#x901A;&#x9053;&#x7EC4;&#x6210;&#x7684;&#x8F93;&#x5165;&#x4FE1;&#x53F7;&#x8FDB;&#x884C;2&#x7EF4;&#x53CC;&#x7EBF;&#x6027;&#x4E0A;&#x91C7;&#x6837;.</p>
<p>&#x4E3A;&#x4E86;&#x6307;&#x5B9A;&#x91C7;&#x6837;&#x8303;&#x56F4;, &#x63D0;&#x4F9B;&#x4E86; <code>size</code> &#x6216; <code>scale_factor</code> &#x4F5C;&#x4E3A;&#x6784;&#x9020;&#x53C2;&#x6570;.</p>
<p>&#x5F53;&#x7ED9;&#x5B9A; <code>size</code>, &#x8F93;&#x51FA;&#x56FE;&#x50CF;&#x7684;&#x5927;&#x5C0F;&#x4E3A; (h, w).</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>size (tuple, &#x53EF;&#x9009;)</code> &#x2013; &#x8F93;&#x51FA;&#x56FE;&#x7247;&#x5927;&#x5C0F;&#x7684;&#x6574;&#x578B;&#x5143;&#x7EC4;(H_out, W_out)</li>
<li><code>scale_factor (int, &#x53EF;&#x9009;)</code> &#x2013; &#x56FE;&#x50CF;&#x7684; &#x957F;&#x548C;&#x5BBD;&#x7684;&#x4E58;&#x5B50;.</li>
</ul>
<p>&#x5F62;&#x72B6;&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;<img src="img/tex-d5acb55d3d2dd49b5b0d71ab7cf3b2d1.gif" alt="(N, C, H_{in}, W_{in})"></li>
<li>&#x8F93;&#x51FA;&#xFF1A;<img src="img/tex-403ffd9231342159e36ba660b2bf3ff3.gif" alt="(N, C, H_{out}, W_{out})"> &#x5176;&#x4E2D; <img src="img/tex-125c98960333dfccfe02ac897317e5c6.gif" alt="H_{out} = floor(H_{in} * scale\_factor)"> <img src="img/tex-0debb495c4ef7738643087520b82f93c.gif" alt="W_{out} = floor(W_{in} * scale\_factor)"></li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>inp
Variable containing:
(<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">1</span>  <span class="hljs-number">2</span>
 <span class="hljs-number">3</span>  <span class="hljs-number">4</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x2x2]

<span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.UpsamplingBilinear2d(scale_factor=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>m(inp)
Variable containing:
(<span class="hljs-number">0</span> ,<span class="hljs-number">0</span> ,.,.) =
 <span class="hljs-number">1.0000</span>  <span class="hljs-number">1.3333</span>  <span class="hljs-number">1.6667</span>  <span class="hljs-number">2.0000</span>
 <span class="hljs-number">1.6667</span>  <span class="hljs-number">2.0000</span>  <span class="hljs-number">2.3333</span>  <span class="hljs-number">2.6667</span>
 <span class="hljs-number">2.3333</span>  <span class="hljs-number">2.6667</span>  <span class="hljs-number">3.0000</span>  <span class="hljs-number">3.3333</span>
 <span class="hljs-number">3.0000</span>  <span class="hljs-number">3.3333</span>  <span class="hljs-number">3.6667</span>  <span class="hljs-number">4.0000</span>
[torch.FloatTensor of size <span class="hljs-number">1</span>x1x4x4]
</code></pre>
<h2 id="dataparallel-layers-multi-gpu-distributed-&#x6570;&#x636E;&#x5E76;&#x884C;&#x5C42;-&#x591A;-gpu-&#x7684;-&#x5206;&#x5E03;&#x5F0F;&#x7684;">DataParallel layers (multi-GPU, distributed) (&#x6570;&#x636E;&#x5E76;&#x884C;&#x5C42;, &#x591A; GPU &#x7684;, &#x5206;&#x5E03;&#x5F0F;&#x7684;)</h2>
<h3 id="dataparallel">DataParallel</h3>
<pre><code class="lang-py">class torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)
</code></pre>
<p>&#x5728;&#x6A21;&#x5757;&#x7EA7;&#x522B;&#x5B9E;&#x73B0;&#x6570;&#x636E;&#x5E76;&#x884C;&#x6027;.</p>
<p>&#x6B64;&#x5BB9;&#x5668;&#x901A;&#x8FC7;&#x5728;&#x6279;&#x6B21;&#x7EF4;&#x5EA6;&#x4E2D;&#x5206;&#x5757;, &#x5C06;&#x8F93;&#x5165;&#x5206;&#x5272;&#x5230;&#x6307;&#x5B9A;&#x8BBE;&#x5907;&#x4E0A;, &#x4ECE;&#x800C;&#x5E76;&#x884C;&#x5316;&#x7ED9;&#x5B9A;&#x6A21;&#x5757;&#x7684;&#x5E94;&#x7528;&#x7A0B; &#x5E8F;.&#x5728;&#x6B63;&#x5411;&#x4F20;&#x9012;&#x4E2D;, &#x6A21;&#x5757;&#x88AB;&#x590D;&#x5236;&#x5230;&#x6BCF;&#x4E2A;&#x8BBE;&#x5907;&#x4E0A;, &#x6BCF;&#x4E2A;&#x526F;&#x672C;&#x5904;&#x7406;&#x4E00;&#x90E8;&#x5206;&#x8F93;&#x5165;.&#x5728;&#x5411;&#x540E;&#x4F20;&#x9012;&#x671F;&#x95F4;, &#x6765;&#x81EA;&#x6BCF;&#x4E2A;&#x526F;&#x672C;&#x7684;&#x68AF;&#x5EA6;&#x53D8;&#x5316;&#x88AB;&#x6C47;&#x603B;&#x5230;&#x539F;&#x59CB;&#x6A21;&#x5757;&#x4E2D;.</p>
<p>batch size &#x5E94;&#x8BE5;&#x5927;&#x4E8E; GPUs &#x7684;&#x6570;&#x91CF;.&#x540C;&#x65F6;&#x4E5F;&#x5E94;&#x8BE5;&#x662F; GPU &#x6570;&#x91CF;&#x7684;&#x6574;&#x6570;&#x500D;, &#x4EE5; &#x4FBF;&#x6BCF;&#x4E2A;&#x5757;&#x5927;&#x5C0F;&#x76F8;&#x540C;&#xFF08;&#x4EE5;&#x4FBF;&#x6BCF;&#x4E2A; GPU &#x5904;&#x7406;&#x76F8;&#x540C;&#x6570;&#x91CF;&#x7684;&#x6837;&#x672C;&#xFF09;.</p>
<p>&#x5F15;&#x7528; :<a href="notes/cuda.html#cuda-nn-dataparallel-instead">&#x4F7F;&#x7528; nn.DataParallel &#x66FF;&#x4EE3; multiprocessing</a></p>
<p>&#x5141;&#x8BB8;&#x5C06;&#x4EFB;&#x610F;&#x4F4D;&#x7F6E;&#x548C;&#x5173;&#x952E;&#x5B57;&#x8F93;&#x5165;&#x4F20;&#x5165; DataParallel EXCEPT Tensors. &#x6240;&#x6709;&#x7684;&#x53D8;&#x91CF;&#x5C06;&#x88AB;&#x5206; &#x6563;&#x5728;&#x6307;&#x5B9A;&#x7684;&#x7EF4;&#x5EA6;&#xFF08;&#x9ED8;&#x8BA4;&#x4E3A;0&#xFF09;.&#x539F;&#x59CB;&#x7C7B;&#x578B;&#x5C06;&#x88AB;&#x5E7F;&#x64AD;, &#x4F46;&#x6240;&#x6709;&#x5176;&#x4ED6;&#x7C7B;&#x578B;&#x5C06;&#x662F;&#x4E00;&#x4E2A;&#x6D45;&#x5C42;&#x526F;&#x672C;, &#x5982; &#x679C;&#x5199;&#x5165;&#x6A21;&#x578B;&#x7684;&#x6B63;&#x5411;&#x4F20;&#x9012;, &#x53EF;&#x80FD;&#x4F1A;&#x88AB;&#x635F;&#x574F;.</p>
<p>Args : module: &#x5E76;&#x884C;&#x7684;&#x6A21;&#x578B; device_ids: CUDA devices&#xFF08;CUDA &#x9A71;&#x52A8;&#xFF09; (default: all devices) output_device: &#x8F93;&#x51FA;&#x8BBE;&#x5907;&#x4F4D;&#x7F6E; (default: device_ids[0]) &#x793A;&#x4F8B; ::</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>net = torch.nn.DataParallel(model, device_ids=[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>output = net(input_var)
</code></pre>
<h3 id="distributeddataparallel">DistributedDataParallel</h3>
<pre><code class="lang-py">class torch.nn.parallel.DistributedDataParallel(module, device_ids=None, output_device=None, dim=0)
</code></pre>
<p>&#x5728;&#x6A21;&#x5757;&#x7EA7;&#x522B;&#x5B9E;&#x73B0;&#x5206;&#x5E03;&#x5F0F;&#x6570;&#x636E;&#x5E76;&#x884C;.</p>
<p>&#x6B64;&#x5BB9;&#x5668;&#x901A;&#x8FC7;&#x5728;&#x6279;&#x6B21;&#x7EF4;&#x5EA6;&#x4E2D;&#x5206;&#x5757;, &#x5C06;&#x8F93;&#x5165;&#x5206;&#x5272;&#x5230;&#x6307;&#x5B9A;&#x8BBE;&#x5907;&#x4E0A;, &#x4ECE;&#x800C;&#x5E76;&#x884C;&#x5316;&#x7ED9;&#x5B9A;&#x6A21;&#x5757;&#x7684;&#x5E94;&#x7528;&#x7A0B;&#x5E8F;. &#x8BE5;&#x6A21;&#x5757;&#x88AB;&#x590D;&#x5236;&#x5230;&#x6BCF;&#x53F0;&#x673A;&#x5668;&#x548C;&#x6BCF;&#x4E2A;&#x8BBE;&#x5907;&#x4E0A;, &#x6BCF;&#x4E2A;&#x8FD9;&#x6837;&#x7684;&#x526F;&#x672C;&#x5904;&#x7406;&#x4E00;&#x90E8;&#x5206;&#x8F93;&#x5165;.&#x5728;&#x5411;&#x540E;&#x4F20;&#x9012;&#x671F;&#x95F4;, &#x6765;&#x81EA;&#x6BCF;&#x4E2A;&#x8282;&#x70B9;&#x7684;&#x68AF;&#x5EA6;&#x88AB;&#x5E73;&#x5747;.</p>
<p>batch size &#x5E94;&#x8BE5;&#x5927;&#x4E8E; GPUs &#x7684;&#x6570;&#x91CF;.&#x540C;&#x65F6;&#x4E5F;&#x5E94;&#x8BE5;&#x662F; GPU &#x6570;&#x91CF;&#x7684;&#x6574;&#x6570;&#x500D;, &#x4EE5;&#x4FBF;&#x6BCF;&#x4E2A;&#x5757;&#x5927;&#x5C0F; &#x76F8;&#x540C;&#xFF08;&#x4EE5;&#x4FBF;&#x6BCF;&#x4E2A; GPU &#x5904;&#x7406;&#x76F8;&#x540C;&#x6570;&#x91CF;&#x7684;&#x6837;&#x672C;&#xFF09;.</p>
<p>&#x5F15;&#x7528; :Basics](distributed.html#distributed-basics) &#x548C; <a href="notes/cuda.html#cuda-nn-dataparallel-instead">&#x4F7F;&#x7528; nn.DataParallel &#x66FF;&#x4EE3; multiprocessing</a>. &#x5BF9;&#x8F93;&#x5165;&#x7684;&#x7EA6;&#x675F;&#x548C; [<code>torch.nn.DataParallel</code> &#x4E2D;&#x4E00;&#x6837;.</p>
<p>&#x521B;&#x5EFA;&#x8FD9;&#x4E2A;&#x7C7B;&#x9700;&#x8981;&#x5206;&#x5E03;&#x5F0F;&#x5305;&#x5DF2;&#x7ECF;&#x5728; process group &#x6A21;&#x5F0F;&#x4E0B;&#x88AB;&#x521D;&#x59CB;&#x5316; (&#x5F15;&#x7528; <a href="distributed.html#torch.distributed.init_process_group" title="torch.distributed.init_process_group"><code>torch.distributed.init_process_group()</code></a>).</p>
<p>&#x8B66;&#x544A;&#xFF1A;</p>
<p>&#x8FD9;&#x4E2A;&#x6A21;&#x5757;&#x53EA;&#x80FD;&#x548C;<code>gloo</code>&#x540E;&#x7AEF;&#x4E00;&#x8D77;&#x5DE5;&#x4F5C;.</p>
<p>&#x8B66;&#x544A;&#xFF1A;</p>
<p>&#x6784;&#x9020;&#x5668;, &#x8F6C;&#x53D1;&#x65B9;&#x6CD5;&#x548C;&#x8F93;&#x51FA;&#xFF08;&#x6216;&#x8005;&#x8FD9;&#x4E2A;&#x6A21;&#x5757;&#x7684;&#x8F93;&#x51FA;&#x529F;&#x80FD;&#xFF09;&#x7684;&#x533A;&#x5206;&#x662F;&#x5206;&#x5E03;&#x5F0F;&#x540C;&#x6B65;&#x70B9;.&#x8003;&#x8651;&#x5230;&#x4E0D;&#x540C;&#x7684; &#x8FDB;&#x7A0B;&#x53EF;&#x80FD;&#x4F1A;&#x6267;&#x884C;&#x4E0D;&#x540C;&#x7684;&#x4EE3;&#x7801;.</p>
<p>&#x8B66;&#x544A;&#xFF1A;</p>
<p>&#x8BE5;&#x6A21;&#x5757;&#x5047;&#x8BBE;&#x6240;&#x6709;&#x53C2;&#x6570;&#x5728;&#x521B;&#x5EFA;&#x65F6;&#x90FD;&#x5728;&#x6A21;&#x578B;&#x4E2D;&#x6CE8;&#x518C;.&#x4E4B;&#x540E;&#x4E0D;&#x5E94;&#x8BE5;&#x6DFB;&#x52A0;&#x6216;&#x5220;&#x9664;&#x53C2;&#x6570;.&#x540C;&#x6837;&#x9002;&#x7528;&#x4E8E;&#x7F13;&#x51B2;&#x533A;.</p>
<p>&#x8B66;&#x544A;&#xFF1A;</p>
<p>&#x8FD9;&#x4E2A;&#x6A21;&#x5757;&#x5047;&#x5B9A;&#x6240;&#x6709;&#x7684;&#x7F13;&#x51B2;&#x533A;&#x548C;&#x68AF;&#x5EA6;&#x90FD;&#x662F;&#x5BC6;&#x96C6;&#x7684;.</p>
<p>&#x8B66;&#x544A;&#xFF1A;</p>
<p>&#x8FD9;&#x4E2A;&#x6A21;&#x5757;&#x4E0D;&#x80FD;&#x7528;&#x4E8E; : func: <code>torch.autograd.grad</code> &#xFF08;&#x5373;&#x53EA;&#x6709;&#x5728;&#x53C2;&#x6570;&#x7684; <code>.grad</code> &#x5C5E;&#x6027;&#x4E2D; &#x7D2F;&#x79EF;&#x68AF;&#x5EA6;&#x624D;&#x80FD;&#x4F7F;&#x7528;&#xFF09;.</p>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x53C2;&#x6570;&#x6C38;&#x8FDC;&#x4E0D;&#x4F1A;&#x5728;&#x8FDB;&#x7A0B;&#x4E4B;&#x95F4;&#x5E7F;&#x64AD;.&#x6A21;&#x5757;&#x5728;&#x68AF;&#x5EA6;&#x4E0A;&#x6267;&#x884C;&#x5168;&#x90E8;&#x4F18;&#x5316;&#x6B65;&#x9AA4;, &#x5E76;&#x5047;&#x5B9A;&#x5B83;&#x4EEC;&#x5C06;&#x4EE5;&#x76F8;&#x540C;&#x7684;&#x65B9;&#x5F0F;&#x5728; &#x6240;&#x6709;&#x8FDB;&#x7A0B;&#x4E2D;&#x8FDB;&#x884C;&#x4F18;&#x5316;.&#x7F13;&#x51B2;&#x533A;&#xFF08;e.g. BatchNorm stats&#xFF09;&#x5728;&#x7B49;&#x7EA7;0&#x7684;&#x8FC7;&#x7A0B;&#x4E2D;&#x4ECE;&#x6A21;&#x5757;&#x5E7F;&#x64AD;&#x5230;&#x7CFB;&#x7EDF; &#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x8FED;&#x4EE3;&#x4E2D;&#x7684;&#x6240;&#x6709;&#x5176;&#x4ED6;&#x526F;&#x672C;.</p>
<p>Args : module: &#x9700;&#x8981;&#x5E76;&#x884C;&#x7684;&#x6A21;&#x578B; device_ids: CUDA devices (default: all devices) output_device: device location of output (default: device_ids[0]) &#x793A;&#x4F8B; ::</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>torch.distributed.init_process_group(world_size=<span class="hljs-number">4</span>, init_method=<span class="hljs-string">&apos;...&apos;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>net = torch.nn.DistributedDataParallel(model)
</code></pre>
<h2 id="utilities-&#x5DE5;&#x5177;&#x5305;">Utilities (&#x5DE5;&#x5177;&#x5305;)</h2>
<h3 id="clipgradnorm">clip_grad_norm</h3>
<pre><code class="lang-py">torch.nn.utils.clip_grad_norm(parameters, max_norm, norm_type=<span class="hljs-number">2</span>)
</code></pre>
<p>&#x63A5;&#x6536;&#x4E00;&#x4E2A;&#x5305;&#x542B; Variable &#x7684;&#x53EF;&#x8FED;&#x4EE3;&#x5BF9;&#x8C61;, &#x5BF9; Variable &#x7684;&#x68AF;&#x5EA6;&#x6309;&#x8303;&#x6570;&#x8FDB;&#x884C;&#x88C1;&#x526A;.</p>
<p>&#x8303;&#x6570;&#x662F;&#x5BF9;&#x6240;&#x6709;&#x68AF;&#x5EA6;&#x8FDB;&#x884C;&#x8BA1;&#x7B97;&#x7684;, &#x7B49;&#x4EF7;&#x4E8E;&#x628A;&#x6240;&#x6709;&#x8F93;&#x5165;&#x53D8;&#x91CF;&#x7684;&#x68AF;&#x5EA6;&#x8FDE;&#x63A5;&#x6210;&#x4E00;&#x4E2A;&#x5411;&#x91CF;, &#x7136;&#x540E;&#x5BF9;&#x8FD9;&#x4E2A;&#x5411;&#x91CF;&#x6309;&#x8303;&#x6570;&#x8FDB;&#x884C;&#x88C1;&#x526A;. &#x68AF;&#x5EA6;&#x5C06;&#x4F1A;&#x88AB;&#x539F;&#x5730;&#x4FEE;&#x6539;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>parameters (Iterable[Variable])</code> &#x2013; &#x4E00;&#x4E2A;&#x53EF;&#x8FED;&#x4EE3;&#x5BF9;&#x8C61;, &#x5176;&#x5305;&#x542B;&#x5C06;&#x8981;&#x8FDB;&#x884C;&#x68AF;&#x5EA6;&#x6B63;&#x89C4;&#x5316;&#x7684; Variable</li>
<li><code>max_norm (float &#x6216; int)</code> &#x2013; &#x68AF;&#x5EA6;&#x7684;&#x6700;&#x5927;&#x8303;&#x6570;</li>
<li><code>norm_type (float &#x6216; int)</code> &#x2013; p &#x8303;&#x6570;(&#x6307;&#x5B9A; p ). &#x7528; <code>&apos;inf&apos;</code> &#x8868;&#x793A;&#x65E0;&#x7A77;&#x8303;&#x6570;</li>
</ul>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;&#x68AF;&#x5EA6;&#x7684;&#x8303;&#x6570; (&#x89C6;&#x4E3A;&#x5355;&#x4E2A;&#x5411;&#x91CF;&#x7684;).</p>
<h3 id="weightnorm">weight_norm</h3>
<pre><code class="lang-py">torch.nn.utils.weight_norm(module, name=<span class="hljs-string">&apos;weight&apos;</span>, dim=<span class="hljs-number">0</span>)
</code></pre>
<p>&#x5C06;&#x6743;&#x91CD;&#x5F52;&#x4E00;&#x5316;&#x5E94;&#x7528;&#x4E8E;&#x7ED9;&#x5B9A;&#x6A21;&#x5757;&#x4E2D;&#x7684;&#x6307;&#x5B9A;&#x53C2;&#x6570;. .</p>
<p><img src="img/tex-5ad6c3a5cca3e461271c3498bc99a156.gif" alt="\mathbf{w} = g \dfrac{\mathbf{v}}{\|\mathbf{v}\|}"></p>
<p>&#x6743;&#x91CD;&#x5F52;&#x4E00;&#x5316;&#x662F;&#x5C06;&#x6743;&#x91CD;&#x5F20;&#x91CF;&#x7684;&#x5927;&#x5C0F;&#x548C;&#x65B9;&#x5411;&#x5206;&#x79BB;&#x7684;&#x518D;&#x53C2;&#x6570;&#x5316;. &#x8BE5;&#x51FD;&#x6570;&#x4F1A;&#x7528;&#x4E24;&#x4E2A;&#x53C2;&#x6570;&#x4EE3;&#x66FF; <code>name</code> (e.g. &#x201C;weight&#x201D;)&#x6240;&#x6307;&#x5B9A;&#x7684;&#x53C2;&#x6570;. &#x5728;&#x65B0;&#x7684;&#x53C2;&#x6570;&#x4E2D;, &#x4E00;&#x4E2A;&#x6307;&#x5B9A;&#x53C2;&#x6570;&#x7684;&#x5927;&#x5C0F; (e.g. &#x201C;weight_g&#x201D;), &#x4E00;&#x4E2A;&#x6307;&#x5B9A;&#x53C2;&#x6570;&#x7684;&#x65B9;&#x5411;. &#x6743;&#x91CD;&#x5F52;&#x4E00;&#x5316;&#x662F;&#x901A;&#x8FC7;&#x4E00;&#x4E2A;&#x94A9;&#x5B50;&#x5B9E;&#x73B0;&#x7684;, &#x8BE5;&#x94A9;&#x5B50;&#x4F1A;&#x5728; <code>~Module.forward</code> &#x7684;&#x6BCF;&#x6B21;&#x8C03;&#x7528;&#x4E4B;&#x524D;&#x6839;&#x636E;&#x5927;&#x5C0F;&#x548C;&#x65B9;&#x5411;(&#x4E24;&#x4E2A;&#x65B0;&#x53C2;&#x6570;)&#x91CD;&#x65B0;&#x8BA1;&#x7B97;&#x6743;&#x91CD;&#x5F20;&#x91CF;.</p>
<p>&#x9ED8;&#x8BA4;&#x60C5;&#x51B5;&#x4E0B;, <code>dim=0</code>, &#x8303;&#x6570;&#x4F1A;&#x5728;&#x6BCF;&#x4E00;&#x4E2A;&#x8F93;&#x51FA;&#x7684; channel/plane &#x4E0A;&#x5206;&#x522B;&#x8BA1;&#x7B97;. &#x82E5;&#x8981;&#x5BF9;&#x6574;&#x4E2A;&#x6743;&#x91CD;&#x5F20;&#x91CF;&#x8BA1;&#x7B97;&#x8303;&#x6570;, &#x4F7F;&#x7528; <code>dim=None</code>.</p>
<p>&#x53C2;&#x89C1; <a href="https://arxiv.org/abs/1602.07868" target="_blank">https://arxiv.org/abs/1602.07868</a></p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>module (nn.Module)</code> &#x2013; &#x7ED9;&#x5B9A;&#x7684; module</li>
<li><code>name (str, &#x53EF;&#x9009;)</code> &#x2013; &#x6743;&#x91CD;&#x53C2;&#x6570;&#x7684; name</li>
<li><code>dim (int, &#x53EF;&#x9009;)</code> &#x2013; &#x8FDB;&#x884C;&#x8303;&#x6570;&#x8BA1;&#x7B97;&#x7684;&#x7EF4;&#x5EA6;</li>
</ul>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;&#x6DFB;&#x52A0;&#x4E86;&#x6743;&#x91CD;&#x5F52;&#x4E00;&#x5316;&#x94A9;&#x5B50;&#x7684;&#x539F; module</p>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py">&gt;&gt;&gt; m = weight_norm(nn.Linear(20, 40), name=&apos;weight&apos;)
Linear (20 -&gt; 40)
&gt;&gt;&gt; m.weight_g.size()
torch.Size([40, 1])
&gt;&gt;&gt; m.weight_v.size()
torch.Size([40, 20])
</code></pre>
<h3 id="removeweightnorm">remove_weight_norm</h3>
<pre><code class="lang-py">torch.nn.utils.remove_weight_norm(module, name=<span class="hljs-string">&apos;weight&apos;</span>)
</code></pre>
<p>&#x4ECE;&#x6A21;&#x5757;&#x4E2D;&#x79FB;&#x9664;&#x6743;&#x91CD;&#x5F52;&#x4E00;&#x5316;/&#x518D;&#x53C2;&#x6570;&#x5316;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>module (nn.Module)</code> &#x2013; &#x7ED9;&#x5B9A;&#x7684; module</li>
<li><code>name (str, &#x53EF;&#x9009;)</code> &#x2013; &#x6743;&#x91CD;&#x53C2;&#x6570;&#x7684; name</li>
</ul>
<p>&#x793A;&#x4F8B;&#xFF1A;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = weight_norm(nn.Linear(<span class="hljs-number">20</span>, <span class="hljs-number">40</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>remove_weight_norm(m)
</code></pre>
<h3 id="packedsequence">PackedSequence</h3>
<pre><code class="lang-py">torch.nn.utils.rnn.PackedSequence(_cls, data, batch_sizes)
</code></pre>
<p>&#x4FDD;&#x5B58;&#x4E00;&#x4E2A;&#x6253;&#x5305;&#x5E8F;&#x5217;&#x7684; data &#x548C; batch_sizes.</p>
<p>&#x6240;&#x6709;&#x7684; RNN &#x6A21;&#x5757;&#x90FD;&#x63A5;&#x6536;&#x8FD9;&#x79CD;&#x88AB;&#x5305;&#x88F9;&#x540E;&#x7684;&#x5E8F;&#x5217;&#x4F5C;&#x4E3A;&#x5B83;&#x4EEC;&#x7684;&#x8F93;&#x5165;.</p>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x6C38;&#x8FDC;&#x4E0D;&#x8981;&#x624B;&#x52A8;&#x521B;&#x5EFA;&#x8FD9;&#x4E2A;&#x7C7B;&#x7684;&#x5B9E;&#x4F8B;. &#x5B83;&#x4EEC;&#x5E94;&#x5F53;&#x88AB; <code>pack_padded_sequence()</code> &#x8FD9;&#x6837;&#x7684;&#x51FD;&#x6570;&#x5B9E;&#x4F8B;&#x5316;.</p>
<p>&#x53D8;&#x91CF;&#xFF1A;</p>
<ul>
<li><code>data (Variable)</code> &#x2013; &#x5305;&#x542B;&#x6253;&#x5305;&#x540E;&#x5E8F;&#x5217;&#x7684; Variable</li>
<li><code>batch_sizes (list[int])</code> &#x2013; &#x5305;&#x542B;&#x6BCF;&#x4E2A;&#x5E8F;&#x5217;&#x6B65;&#x7684; batch size &#x7684;&#x5217;&#x8868;</li>
</ul>
<h3 id="packpaddedsequence">pack_padded_sequence</h3>
<pre><code class="lang-py">torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=<span class="hljs-keyword">False</span>)
</code></pre>
<p>&#x5C06;&#x586B;&#x5145;&#x8FC7;&#x7684;&#x53D8;&#x957F;&#x5E8F;&#x5217;&#x6253;&#x5305;(&#x538B;&#x7D27;).</p>
<p>&#x8F93;&#x5165;&#x7684;&#x5F62;&#x72B6;&#x53EF;&#x4EE5;&#x662F; <code>TxBx*</code> . <code>T</code>&#x662F;&#x6700;&#x957F;&#x5E8F;&#x5217;&#x957F;&#x5EA6;(&#x7B49;&#x4E8E; <code>lengths[0]</code>), <code>B</code>&#x662F;&#x6279;&#x91CF;&#x5927;&#x5C0F;, <code>*</code>&#x4EE3;&#x8868;&#x4EFB;&#x610F;&#x7EF4;&#x5EA6;(&#x53EF;&#x4EE5;&#x662F; 0). &#x5982;&#x679C; <code>batch_first=True</code> , &#x90A3;&#x4E48;&#x76F8;&#x5E94;&#x7684;&#x8F93;&#x5165;&#x5927;&#x5C0F;&#x5C31;&#x662F; <code>BxTx*</code> .</p>
<p>Variable &#x4E2D;&#x4FDD;&#x5B58;&#x7684;&#x5E8F;&#x5217;, &#x5E94;&#x8BE5;&#x6309;&#x5E8F;&#x5217;&#x957F;&#x5EA6;&#x7684;&#x957F;&#x77ED;&#x6392;&#x5E8F;, &#x957F;&#x7684;&#x5728;&#x524D;, &#x77ED;&#x7684;&#x5728;&#x540E;. &#x5373; input[:,0] &#x4EE3;&#x8868;&#x7684;&#x662F;&#x6700;&#x957F;&#x7684;&#x5E8F;&#x5217;, input[:, B-1] &#x4FDD;&#x5B58;&#x7684;&#x662F;&#x6700;&#x77ED;&#x7684;&#x5E8F;&#x5217;.</p>
<p>&#x6CE8;&#x89E3;&#xFF1A;</p>
<p>&#x53EA;&#x8981;&#x662F;&#x7EF4;&#x5EA6;&#x5927;&#x4E8E;&#x7B49;&#x4E8E;2&#x7684; input &#x90FD;&#x53EF;&#x4EE5;&#x4F5C;&#x4E3A;&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x7684;&#x53C2;&#x6570;. &#x4F60;&#x53EF;&#x4EE5;&#x7528;&#x5B83;&#x6765;&#x6253;&#x5305; labels, &#x7136;&#x540E;&#x7528; RNN &#x7684;&#x8F93;&#x51FA;&#x548C;&#x6253;&#x5305;&#x540E;&#x7684; labels &#x6765;&#x8BA1;&#x7B97; loss. &#x901A;&#x8FC7; <code>PackedSequence</code> &#x5BF9;&#x8C61;&#x7684; <code>.data</code> &#x5C5E;&#x6027;&#x53EF;&#x4EE5;&#x83B7;&#x53D6; Variable.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>input (Variable)</code> &#x2013; &#x53D8;&#x957F;&#x5E8F;&#x5217;&#x88AB;&#x586B;&#x5145;&#x540E;&#x7684; batch</li>
<li><code>lengths (list[int])</code> &#x2013; Variable &#x4E2D;&#x6BCF;&#x4E2A;&#x5E8F;&#x5217;&#x7684;&#x957F;&#x5EA6;.</li>
<li><code>batch_first (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x5982;&#x679C;&#x662F; <code>True</code>, input &#x7684;&#x5F62;&#x72B6;&#x5E94;&#x8BE5;&#x662F; <code>BxTx*</code>.</li>
</ul>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;&#x4E00;&#x4E2A; <code>PackedSequence</code> &#x5BF9;&#x8C61;.</p>
<h3 id="padpackedsequence">pad_packed_sequence</h3>
<pre><code class="lang-py">torch.nn.utils.rnn.pad_packed_sequence(sequence, batch_first=<span class="hljs-keyword">False</span>, padding_value=<span class="hljs-number">0.0</span>)
</code></pre>
<p>&#x586B;&#x5145;&#x6253;&#x5305;&#x8FC7;&#x7684;&#x53D8;&#x957F;&#x5E8F;&#x5217;.</p>
<p>&#x8FD9;&#x662F; <code>pack_padded_sequence()</code> &#x7684;&#x9006;&#x64CD;&#x4F5C;.</p>
<p>&#x8FD4;&#x56DE;&#x7684; Varaible &#x7684;&#x503C;&#x7684; size &#x662F; <code>TxBx*</code>, T &#x662F;&#x6700;&#x957F;&#x5E8F;&#x5217;&#x7684;&#x957F;&#x5EA6;, B &#x662F; batch_size, &#x5982;&#x679C; <code>batch_first=True</code>, &#x90A3;&#x4E48;&#x8FD4;&#x56DE;&#x503C;&#x662F; <code>BxTx*</code>.</p>
<p>Batch&#x4E2D;&#x7684;&#x5143;&#x7D20;&#x5C06;&#x4F1A;&#x4EE5;&#x5B83;&#x4EEC;&#x957F;&#x5EA6;&#x7684;&#x9006;&#x5E8F;&#x6392;&#x5217;.</p>
<p>&#x53C2;&#x6570;&#xFF1A;</p>
<ul>
<li><code>sequence (PackedSequence)</code> &#x2013; &#x5C06;&#x8981;&#x88AB;&#x586B;&#x5145;&#x7684; batch</li>
<li><code>batch_first (bool, &#x53EF;&#x9009;)</code> &#x2013; &#x5982;&#x679C;&#x4E3A; <code>True</code> , &#x8FD4;&#x56DE;&#x7684;&#x6570;&#x636E;&#x7684;&#x683C;&#x5F0F;&#x4E3A; <code>BxTx*</code>.</li>
<li><code>padding_value (float, &#x53EF;&#x9009;)</code> &#x2013; &#x7528;&#x6765;&#x586B;&#x5145;&#x5143;&#x7D20;&#x7684;&#x503C;</li>
</ul>
<p>&#x8FD4;&#x56DE;&#x503C;&#xFF1A;&#x4E00;&#x4E2A; tuple, &#x5305;&#x542B;&#x88AB;&#x586B;&#x5145;&#x540E;&#x7684;&#x5E8F;&#x5217;, &#x548C; batch &#x4E2D;&#x5E8F;&#x5217;&#x7684;&#x957F;&#x5EA6;&#x5217;&#x8868;.</p>
<p><hr></p>
<div align="center">
    <p><a href="http://www.apachecn.org" target="_blank"><font face="KaiTi" size="6" color="red">&#x6211;&#x4EEC;&#x4E00;&#x76F4;&#x5728;&#x52AA;&#x529B;</font></a></p>
    <p><a href="https://github.com/apachecn/pytorch-doc-zh/" target="_blank">apachecn/pytorch-doc-zh</a></p>
    <p><iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&amp;repo=pytorch-doc-zh&amp;type=watch&amp;count=true&amp;v=2" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
    <iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&amp;repo=pytorch-doc-zh&amp;type=star&amp;count=true" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
    <iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&amp;repo=pytorch-doc-zh&amp;type=fork&amp;count=true" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
    <a target="_blank" href="shang.qq.com/wpa/qunwpa"><img border="0" src="http://data.apachecn.org/img/logo/ApacheCN-group.png" alt="ML | ApacheCN" title="ML | ApacheCN"></a></p>
</div>
 <div style="text-align:center;margin:0 0 10.5px;">
     <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
     <ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-3565452474788507" data-ad-slot="2543897000">
     </ins>
     <script>(adsbygoogle = window.adsbygoogle || []).push({});</script>

    <script>
      var _hmt = _hmt || [];
      (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91";
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(hm, s);
      })();
    </script>

    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-102475051-10"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-102475051-10');
    </script>
</div>

<p><meta name="google-site-verification" content="pyo9N70ZWyh8JB43bIu633mhxesJ1IcwWCZlM3jUfFo"></p>
<p><iframe src="https://www.bilibili.com/read/cv2710377" style="display:none"></iframe>
<img src="http://t.cn/AiCoDHwb" hidden="hidden"></p>
<div>
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
    <script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script>
    <script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
    <div id="gitalk-container"></div>
    <script type="text/javascript">
        const gitalk = new Gitalk({
        clientID: '2e62dee5b9896e2eede6',
        clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53',
        repo: 'pytorch-doc-zh',
        owner: 'apachecn',
        admin: ['jiangzhonglian', 'wizardforcel'],
        id: md5(location.pathname),
        distractionFreeMode: false
        })
        gitalk.render('gitalk-container')
    </script>
</div>

<footer class="page-footer"><span class="copyright">Copyright &#xA9; ibooker.org.cn 2019 all right reserved&#xFF0C;&#x7531; ApacheCN &#x56E2;&#x961F;&#x63D0;&#x4F9B;&#x652F;&#x6301;</span><span class="footer-modification">&#x8BE5;&#x6587;&#x4EF6;&#x4FEE;&#x8BA2;&#x65F6;&#x95F4;&#xFF1A; 
2019-12-27 08:05:23
</span></footer>
<script>console.log("plugin-popup....");document.onclick = function(e){ e.target.tagName === "IMG" && window.open(e.target.src,e.target.src)}</script><style>img{cursor:pointer}</style>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="storage.html" class="navigation navigation-prev " aria-label="Previous page: torch.Storage">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="optim.html" class="navigation navigation-next " aria-label="Next page: torch.optim">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"torch.nn","level":"1.3.2.5","depth":3,"next":{"title":"torch.optim","level":"1.3.2.6","depth":3,"path":"optim.md","ref":"optim.md","articles":[]},"previous":{"title":"torch.Storage","level":"1.3.2.4","depth":3,"path":"storage.md","ref":"storage.md","articles":[]},"dir":"ltr"},"config":{"plugins":["github","github-buttons","-sharing","insert-logo","sharing-plus","back-to-top-button","code","copy-code-button","mathjax","pageview-count","edit-link","emphasize","alerts","auto-scroll-table","popup","hide-element","page-toc-button","tbfed-pagefooter","sitemap","advanced-emoji","expandable-chapters","splitter","search-pro"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"tbfed-pagefooter":{"copyright":"Copyright &copy ibooker.org.cn 2019","modify_label":"该文件修订时间： ","modify_format":"YYYY-MM-DD HH:mm:ss"},"emphasize":{},"github":{"url":"https://github.com/apachecn/pytorch-doc-zh"},"splitter":{},"search-pro":{},"search":{},"sharing-plus":{"qq":false,"all":["facebook","google","twitter","instapaper","linkedin","pocket","stumbleupon"],"douban":false,"facebook":true,"weibo":false,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":true,"messenger":false,"line":false,"vk":false,"pocket":true,"google":false,"viber":false,"stumbleupon":false,"qzone":false,"linkedin":false},"auto-scroll-table":{},"popup":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"code":{"copyButtons":true},"hide-element":{"elements":[".gitbook-link"]},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"sitemap":{"hostname":"http://pytorch.apachecn.org"},"page-toc-button":{"maxTocDepth":4,"minTocSize":4},"back-to-top-button":{},"pageview-count":{},"alerts":{},"github-buttons":{"buttons":[{"user":"apachecn","repo":"pytorch-doc-zh","type":"star","count":true,"size":"small"}]},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"copy-code-button":{},"advanced-emoji":{"embedEmojis":false},"sharing":{"qq":false,"all":["qq","douban","facebook","google","linkedin","twitter","weibo","whatsapp"],"douban":false,"facebook":false,"weibo":true,"whatsapp":false,"twitter":false,"line":false,"google":false,"qzone":true},"edit-link":{"label":"编辑本页","base":"https://github.com/apachecn/pytorch-doc-zh/blob/master/docs/0.3"},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"insert-logo":{"style":"background: none; max-height: 150px; min-height: 150px","url":"http://data.apachecn.org/img/logo.jpg"},"expandable-chapters":{}},"my_links":{"sidebar":{"Home":"https://www.baidu.com"}},"theme":"default","author":"ApacheCN","my_plugins":["donate","todo","-lunr","-search","expandable-chapters-small","chapter-fold","expandable-chapters","expandable-chapters-small","back-to-top-button","ga","baidu","sitemap","tbfed-pagefooter","advanced-emoji","sectionx","page-treeview","simple-page-toc","ancre-navigation","theme-apachecn@git+https://github.com/apachecn/theme-apachecn#HEAD","pagefooter-apachecn@git+https://github.com/apachecn/gitbook-plugin-pagefooter-apachecn#HEAD"],"my_pluginsConfig":{"page-treeview":{"copyright":"Copyright &#169; aleen42","minHeaderCount":"2","minHeaderDeep":"2"},"ignores":["node_modules"],"simple-page-toc":{"maxDepth":3,"skipFirstH1":true},"page-copyright":{"wisdom":"Designer, Frontend Developer & overall web enthusiast","noPowered":false,"copyright":"Copyright &#169; 你的名字","style":"normal","timeColor":"#666","utcOffset":"8","format":"YYYY-MM-dd hh:mm:ss","signature":"你的签名","copyrightColor":"#666","description":"modified at"},"donate":{"wechat":"微信收款的二维码URL","alipay":"支付宝收款的二维码URL","title":"","button":"赏","alipayText":"支付宝打赏","wechatText":"微信打赏"},"page-toc-button":{"maxTocDepth":2,"minTocSize":2},"github-buttons":{"buttons":[{"user":"apachecn","repo":"pytorch-doc-zh","type":"star","count":true,"size":"small"},{"user":"apachecn","width":"160","type":"follow","count":true,"size":"small"}]},"ga":{"token":"UA-102475051-10"},"baidu":{"token":"75439e2cbd22bdd813226000e9dcc12f"},"pagefooter-apachecn":{"copyright":"Copyright &copy ibooker.org.cn 2019","modify_label":"该文件修订时间： ","modify_format":"YYYY-MM-DD HH:mm:ss"}},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"Pytorch 中文文档","language":"zh-hans","gitbook":"*","description":"Pytorch 中文文档: 教程和文档"},"file":{"path":"nn.md","mtime":"2019-12-27T08:05:23.699Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-12-27T08:07:11.023Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-github-buttons/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-insert-logo/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing-plus/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-copy-code-button/toggle.js"></script>
        
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-pageview-count/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-edit-link/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-alerts/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-auto-scroll-table/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-hide-element/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-page-toc-button/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

