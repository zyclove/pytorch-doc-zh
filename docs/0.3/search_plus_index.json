{"./":{"url":"./","title":"PyTorch 0.3 中文文档 & 教程","keywords":"","body":"PyTorch 0.3 中文文档 & 教程 维护组织：@ApacheCN 协议：CC BY-NC-SA 4.0 欢迎任何人参与和完善：一个人可以走的很快，但是一群人却可以走的更远。 在线阅读 ApacheCN 学习资源 PyTorch 中文翻译组 | ApacheCN 713436582 在线阅读 PDF格式 EPUB格式 MOBI格式 代码仓库 目录结构 PyTorch 0.3 中文文档 & 教程 中文教程 初学者教程 PyTorch 深度学习: 60 分钟极速入门教程 PyTorch 是什么？ 自动求导: 自动微分 神经网络 训练一个分类器 可选: 数据并行 PyTorch for former Torch users Tensors Autograd (自动求导) nn package Multi-GPU examples 跟着例子学习 PyTorch Warm-up: numpy PyTorch: Tensors PyTorch: 变量和autograd PyTorch: 定义新的autograd函数 TensorFlow: 静态图 PyTorch: nn包 PyTorch: optim包 PyTorch: 定制化nn模块 PyTorch: 动态控制流程 + 权重共享 迁移学习教程 数据加载和处理教程 针对NLP的Pytorch深度学习 PyTorch介绍 PyTorch深度学习 词汇嵌入:编码词汇语义 序列模型和 LSTM 网络（长短记忆网络） 高级教程: 作出动态决策和 Bi-LSTM CRF 中级教程 用字符级RNN分类名称 基与字符级RNN（Char-RNN）的人名生成 用基于注意力机制的seq2seq神经网络进行翻译 强化学习（DQN）教程 Writing Distributed Applications with PyTorch 空间转换网络 (Spatial Transformer Networks) 教程 高级教程 用 PyTorch 做 神经转换 (Neural Transfer) 使用 numpy 和 scipy 创建扩展 使用 ONNX 将模型从 PyTorch 迁移到 Caffe2 和 Mobile 为 pytorch 自定义 C 扩展 中文文档 介绍 自动求导机制 广播语义 CUDA 语义 扩展 PyTorch 多进程的最佳实践 序列化语义 Package 参考 torch torch.Tensor torch.sparse torch.Storage torch.nn torch.optim Automatic differentiation package - torch.autograd Probability distributions - torch.distributions Multiprocessing package - torch.multiprocessing Distributed communication package - torch.distributed Legacy package - torch.legacy torch.cuda torch.utils.ffi torch.utils.data torch.utils.model_zoo torch.onnx torchvision 参考 torchvision torchvision.datasets torchvision.models torchvision.transforms torchvision.utils 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"tut.html":{"url":"tut.html","title":"中文教程","keywords":"","body":"中文教程 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"beginner_tutorials.html":{"url":"beginner_tutorials.html","title":"初学者教程","keywords":"","body":"初学者教程 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"deep_learning_60min_blitz.html":{"url":"deep_learning_60min_blitz.html","title":"PyTorch 深度学习: 60 分钟极速入门教程","keywords":"","body":"PyTorch 深度学习: 60 分钟极速入门教程 译者：@小王子 校对者：@李子文 Author: Soumith Chintala 本教程的目标: 更高层次地理解 PyTorch 的 Tensor (张量) 库以及神经网络. 学会训练一个小的神经网络用来对图像进行分类 本教程假设您对 numpy 有基本的了解 注解： 请确认您已经安装了 torch 和 torchvision 包. PyTorch 是什么？ 自动求导: 自动微分 神经网络 训练一个分类器 可选: 数据并行 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"blitz_tensor_tutorial.html":{"url":"blitz_tensor_tutorial.html","title":"PyTorch 是什么？","keywords":"","body":"PyTorch 是什么？ 译者：@小王子 校对者：@李子文 它是一个基于 Python 的科学计算包, 其主要是为了解决两类场景: NumPy 的替代品, 以使用 GPU 的强大加速功能 一个深度学习研究平台, 提供最大的灵活性和速度 新手入门 Tensors（张量） Tensors 与 NumPy 的 ndarrays 非常相似, 除此之外还可以在 GPU 上使用张量来加速计算. from __future__ import print_function import torch 构建一个 5x3 的矩阵, 未初始化的: x = torch.Tensor(5, 3) print(x) 构建一个随机初始化的矩阵: x = torch.rand(5, 3) print(x) 获得 size: print(x.size()) 注解： torch.Size 实际上是一个 tuple（元组）, 所以它支持所有 tuple（元组）的操作. 操作 针对操作有许多语法. 在下面的例子中, 我们来看看加法运算. 加法: 语法 1 y = torch.rand(5, 3) print(x + y) 加法: 语法 2 print(torch.add(x, y)) 加法: 提供一个输出 tensor 作为参数 result = torch.Tensor(5, 3) torch.add(x, y, out = result) print(result) 加法: in-place（就地操作） # adds x to y y.add_(x) print(y) 注解： 任何改变张量的操作方法都是以后缀 _ 结尾的. 例如: x.copy_(y), x.t_(), 将改变张量 x. 你可以用类似Numpy的索引来处理所有的张量！ print(x[:, 1]) 改变大小: 如果你想要去改变tensor的大小, 可以使用 torch.view: x = torch.randn(4, 4) y = x.view(16) z = x.view(-1, 8) # the size -1 is inferred from other dimensions print(x.size(), y.size(), z.size()) 稍候阅读: 100+ Tensor 操作, 包括换位, 索引, 切片, 数学运算, 线性代数, 随机数, 等等, 都在 这里 有描述. NumPy Bridge 将一个 Torch Tensor 转换为 NumPy 数组, 反之亦然. Torch Tensor 和 NumPy 数组将会共享它们的实际的内存位置, 改变一个另一个也会跟着改变. 转换一个 Torch Tensor 为 NumPy 数组 a = torch.ones(5) print(a) b = a.numpy() print(b) 查看 numpy 数组是如何改变的. a.add_(1) print(a) print(b) 转换 NumPy 数组为 Torch Tensor 看看改变 np 数组之后 Torch Tensor 是如何自动改变的 import numpy as np a = np.ones(5) b = torch.from_numpy(a) np.add(a, 1, out = a) print(a) print(b) 除了 CharTensor 之外, CPU 上的所有 Tensor 都支持与Numpy进行互相转换 CUDA Tensors 可以使用 .cuda 方法将 Tensors 在GPU上运行. # 只要在 CUDA 是可用的情况下, 我们可以运行这段代码 if torch.cuda.is_available(): x = x.cuda() y = y.cuda() x + y 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"blitz_autograd_tutorial.html":{"url":"blitz_autograd_tutorial.html","title":"自动求导: 自动微分","keywords":"","body":"自动求导: 自动微分 译者：@小王子 校对者：@李子文 PyTorch 中所有神经网络的核心是 autograd 自动求导包. 我们先来简单介绍一下, 然后我们会去训练我们的第一个神经网络. autograd 自动求导包针对张量上的所有操作都提供了自动微分操作. 这是一个逐个运行的框架, 这意味着您的反向传播是由您的代码如何运行来定义的, 每个单一的迭代都可以不一样. 让我们用一些更简单的术语与例子来了解这些套路. Variable（变量） autograd.Variable 是包的核心类. 它包装了张量, 并且支持几乎所有的操作. 一旦你完成了你的计算, 你就可以调用 .backward() 方法, 然后所有的梯度计算会自动进行. 你还可以通过 .data 属性来访问原始的张量, 而关于该 variable（变量）的梯度会被累计到 .grad 上去. Variable 还有一个针对自动求导实现来说非常重要的类 - Function. Variable 和 Function 是相互联系的, 并且它们构建了一个非循环的图, 编码了一个完整的计算历史信息. 每一个 variable（变量）都有一个 .grad_fn 属性, 它引用了一个已经创建了 Variable 的 Function （除了用户创建的 Variable 之外 - 它们的 grad_fn 为 None ）. 如果你想计算导数, 你可以在 Variable 上调用 .backward() 方法. 如果 Variable 是标量的形式（例如, 它包含一个元素数据）, 你不必指定任何参数给 backward(), 但是, 如果它有更多的元素. 你需要去指定一个 grad_output 参数, 该参数是一个匹配 shape（形状）的张量. import torch from torch.autograd import Variable 创建 variable（变量）: x = Variable(torch.ones(2, 2), requires_grad = True) print(x) variable（变量）的操作: y = x + 2 print(y) y 由操作创建,所以它有 grad_fn 属性. print(y.grad_fn) y 的更多操作 z = y * y * 3 out = z.mean() print(z, out) 梯度 我们现在开始了解反向传播, out.backward() 与 out.backward(torch.Tensor([1.0])) 这样的方式一样 out.backward() 但因 d(out)/dx 的梯度 print(x.grad) 你应该得到一个 4.5 的矩阵. 让我们推导出 out Variable “”. 我们有 , 和 . 因此, , 所以 . 你可以使用自动求导来做很多有趣的事情 x = torch.randn(3) x = Variable(x, requires_grad = True) y = x * 2 while y.data.norm() gradients = torch.FloatTensor([0.1, 1.0, 0.0001]) y.backward(gradients) print(x.grad) 稍候阅读: Variable 和 Function 的文档请参阅 http://pytorch.apachecn.org/cn/docs/0.3.0/autograd.html 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"blitz_neural_networks_tutorial.html":{"url":"blitz_neural_networks_tutorial.html","title":"神经网络","keywords":"","body":"神经网络 译者：@小王子 校对者：@李子文 神经网络可以使用 torch.nn 包构建. autograd 实现了反向传播功能, 但是直接用来写深度学习的代码在很多情况下还是稍显复杂, torch.nn 是专门为神经网络设计的模块化接口. nn 构建于 Autograd 之上, 可用来定义和运行神经网络. nn.Module 是 nn 中最重要的类, 可把它看成是一个网络的封装, 包含网络各层定义以及 forward 方法, 调用 forward(input) 方法, 可返回前向传播的结果. 例如, 看看这个分类数字图像的网络: convnet 这是一个基础的前向传播(feed-forward)网络: 接收输入, 经过层层传递运算, 得到输出. 一个典型的神经网络训练过程如下: 定义具有一些可学习参数(或权重)的神经网络 迭代输入数据集 通过网络处理输入 计算损失(输出的预测值与实际值之间的距离) 将梯度传播回网络 更新网络的权重, 通常使用一个简单的更新规则: weight = weight - learning_rate * gradient 定义网络 让我们来定义一个网络: import torch from torch.autograd import Variable import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() # 卷积层 '1'表示输入图片为单通道, '6'表示输出通道数, '5'表示卷积核为5*5 # 核心 self.conv1 = nn.Conv2d(1, 6, 5) self.conv2 = nn.Conv2d(6, 16, 5) # 仿射层/全连接层: y = Wx + b self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): #在由多个输入平面组成的输入信号上应用2D最大池化. # (2, 2) 代表的是池化操作的步幅 x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # 如果大小是正方形, 则只能指定一个数字 x = F.max_pool2d(F.relu(self.conv2(x)), 2) x = x.view(-1, self.num_flat_features(x)) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x def num_flat_features(self, x): size = x.size()[1:] # 除批量维度外的所有维度 num_features = 1 for s in size: num_features *= s return num_features net = Net() print(net) 你只要在 nn.Module 的子类中定义了 forward 函数, backward 函数就会自动被实现(利用 autograd ). 在 forward 函数中可使用任何 Tensor 支持的操作. 网络的可学习参数通过 net.parameters() 返回, net.named_parameters 可同时返回学习的参数以及名称. params = list(net.parameters()) print(len(params)) print(params[0].size()) # conv1的weight 向前的输入是一个 autograd.Variable, 输出也是如此. 注意: 这个网络(LeNet)的预期输入大小是 32x32, 使用这个网上 MNIST 数据集, 请将数据集中的图像调整为 32x32. input = Variable(torch.randn(1, 1, 32, 32)) out = net(input) print(out) 将网络中所有参数的梯度清零. net.zero_grad() out.backward(torch.randn(1, 10)) 注解： torch.nn 只支持小批量(mini-batches), 不支持一次输入一个样本, 即一次必须是一个 batch. 例如, nn.Conv2d 的输入必须是 4 维的, 形如 nSamples x nChannels x Height x Width. 如果你只想输入一个样本, 需要使用 input.unsqueeze(0) 将 batch_size 设置为 1. 在继续之前, 让我们回顾一下迄今为止所有见过的类. 概括: torch.Tensor - 一个 多维数组. autograd.Variable - 包装张量并记录应用于其上的历史操作. 具有和 Tensor 相同的 API ,还有一些补充, 如 backward(). 另外 拥有张量的梯度. nn.Module - 神经网络模块. 方便的方式封装参数, 帮助将其移动到GPU, 导出, 加载等. nn.Parameter - 一种变量, 当被指定为 Model 的属性时, 它会自动注册为一个参数. autograd.Function - 实现 autograd 操作的向前和向后定义 . 每个 Variable 操作, 至少创建一个 Function 节点, 连接到创建 Variable 的函数, 并 编码它的历史. 在这一点上, 我们涵盖: 定义一个神经网络 处理输入并反向传播 还剩下: 计算损失函数 更新网络的权重 损失函数 损失函数采用 (output,target) 输入对, 并计算预测输出结果与实际目标的距离. 在 nn 包下有几种不同的 损失函数 . 一个简单的损失函数是: nn.MSELoss 计算输出和目标之间的均方误差 例如: output = net(input) target = Variable(torch.arange(1, 11)) # 一个虚拟的目标 criterion = nn.MSELoss() loss = criterion(output, target) print(loss) 现在, 如果你沿着 loss 反向传播的方向使用 .grad_fn 属性, 你将会看到一个如下所示的计算图: input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d -> view -> linear -> relu -> linear -> relu -> linear -> MSELoss -> loss 所以, 当我们调用 loss.backward(), 整个图与损失是有区别的, 图中的所有变量都将用 .grad 梯度累加它们的变量. 为了说明, 让我们向后走几步: print(loss.grad_fn) # MSELoss print(loss.grad_fn.next_functions[0][0]) # Linear print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) # ReLU 反向传播 为了反向传播误差, 我们所要做的就是 loss.backward(). 你需要清除现有的梯度, 否则梯度会累加之前的梯度. 现在我们使用 loss.backward(), 看看反向传播之前和之后 conv1 的梯度. net.zero_grad() # 把之前的梯度清零 print('conv1.bias.grad before backward') print(net.conv1.bias.grad) loss.backward() print('conv1.bias.grad after backward') print(net.conv1.bias.grad) 现在, 我们已经看到了如何使用损失函数. 稍后阅读: 神经网络包包含各种模块和损失函数, 形成深度神经网络的构建模块. 完整的文件列表 在这里 接下来学习的唯一东西是: 更新网络的权重 更新权重 实践中使用的最简单的更新规则是随机梯度下降( SGD ): weight = weight - learning_rate * gradient 我们可以使用简单的 python 代码来实现这个: learning_rate = 0.01 for f in net.parameters(): f.data.sub_(f.grad.data * learning_rate) 然而, 当你使用神经网络时, 你需要使用各种不同的更新规则, 比如 SGD, Nesterov-SGD, Adam, RMSProp等. 为了实现这个功能, 我们建立了一个包: torch.optim 实现所有这些方法. 使用它非常的简单: import torch.optim as optim # 新建一个优化器, 指定要调整的参数和学习率 optimizer = optim.SGD(net.parameters(), lr = 0.01) # 在训练过程中: optimizer.zero_grad() # 首先梯度清零(与 net.zero_grad() 效果一样) output = net(input) loss = criterion(output, target) loss.backward() optimizer.step() # 更新参数 注解： 观察如何使用手动设置梯度清零 optimizer.zero_grad() . 需要手动清零的原因在 Backprop_ 中已经说明了(梯度会累加之前的梯度). 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"blitz_cifar10_tutorial.html":{"url":"blitz_cifar10_tutorial.html","title":"训练一个分类器","keywords":"","body":"训练一个分类器 译者：@小王子 校对者：@李子文 就是这个, 你已经看到了如何定义神经网络, 计算损失并更新网络的权重. 现在你可能会想, 数据呢? 一般来说, 当你不得不处理图像, 文本, 音频或者视频数据时, 你可以使用标准的 Python 包将数据加载到一个 numpy 数组中. 然后你可以将这个数组转换成一个 torch.*Tensor. 对于图像, 会用到的包有 Pillow, OpenCV . 对于音频, 会用的包有 scipy 和 librosa. 对于文本, 原始 Python 或基于 Cython 的加载, 或者 NLTK 和 Spacy 都是有用的. 特别是对于 vision, 我们已经创建了一个叫做 torchvision, 其中有对普通数据集如 Imagenet, CIFAR10, MNIST 等和用于图像数据的转换器, 即 torchvision.datasets 和 torch.utils.data.DataLoader. 这提供了巨大的便利, 避免了编写重复代码. 在本教程中, 我们将使用 CIFAR10 数据集. 它有: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’ 这些类别. CIFAR10 中的图像大小为 3x32x32 , 即 32x32 像素的 3 通道彩色图像. cifar10 训练一个图像分类器 我们将按顺序执行以下步骤: 加载 CIFAR10 测试和训练数据集并规范化 torchvision 定义一个卷积神经网络 定义一个损失函数 在训练数据上训练网络 在测试数据上测试网络 1. 加载并规范化 CIFAR10 使用 torchvision, 加载 CIFAR10 非常简单. import torch import torchvision import torchvision.transforms as transforms torchvision 数据集的输出是范围 [0, 1] 的 PILImage 图像. 我们将它们转换为归一化范围是[-1,1]的张量 transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2) testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2) classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') 让我们展示一些训练图像, 只是为了好玩 (0.0). import matplotlib.pyplot as plt import numpy as np # 定义函数来显示图像 def imshow(img): img = img / 2 + 0.5 # 非标准化 npimg = img.numpy() plt.imshow(np.transpose(npimg, (1, 2, 0))) # 得到一些随机的训练图像 dataiter = iter(trainloader) images, labels = dataiter.next() # 显示图像 imshow(torchvision.utils.make_grid(images)) # 输出类别 print(' '.join('%5s' % classes[labels[j]] for j in range(4))) 2. 定义一个卷积神经网络 从神经网络部分复制神经网络, 并修改它以获取 3 通道图像(而不是定义的 1 通道图像). from torch.autograd import Variable import torch.nn as nn import torch.nn.functional as F class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 6, 5) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(6, 16, 5) self.fc1 = nn.Linear(16 * 5 * 5, 120) self.fc2 = nn.Linear(120, 84) self.fc3 = nn.Linear(84, 10) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 16 * 5 * 5) x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x net = Net() 3. 定义一个损失函数和优化器 我们使用交叉熵损失函数( CrossEntropyLoss )和随机梯度下降( SGD )优化器. import torch.optim as optim criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) 4. 训练网络 这是事情开始变得有趣的时候. 我们只需循环遍历数据迭代器, 并将输入提供给网络和优化器. for epoch in range(2): # 循环遍历数据集多次 running_loss = 0.0 for i, data in enumerate(trainloader, 0): # 得到输入数据 inputs, labels = data # 包装数据 inputs, labels = Variable(inputs), Variable(labels) # 梯度清零 optimizer.zero_grad() # forward + backward + optimize outputs = net(inputs) loss = criterion(outputs, labels) loss.backward() optimizer.step() # 打印信息 running_loss += loss.data[0] if i % 2000 == 1999: # 每2000个小批量打印一次 print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000)) running_loss = 0.0 print('Finished Training') 5. 在测试数据上测试网络 我们在训练数据集上训练了2遍网络, 但是我们需要检查网络是否学到了什么. 我们将通过预测神经网络输出的类标签来检查这个问题, 并根据实际情况进行检查. 如果预测是正确的, 我们将样本添加到正确预测的列表中. 好的, 第一步. 让我们显示测试集中的图像以便熟悉. dataiter = iter(testloader) images, labels = dataiter.next() # 打印图像 imshow(torchvision.utils.make_grid(images)) print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4))) 好的, 现在让我们看看神经网络认为这些例子是什么: outputs = net(Variable(images)) 输出的是10个类别的能量. 一个类别的能量越高, 则可以理解为网络认为越多的图像是该类别的. 那么, 让我们得到最高能量的索引: _, predicted = torch.max(outputs.data, 1) print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4))) 结果看起来不错. 让我们看看网络如何在整个数据集上执行. correct = 0 total = 0 for data in testloader: images, labels = data outputs = net(Variable(images)) _, predicted = torch.max(outputs.data, 1) total += labels.size(0) correct += (predicted == labels).sum() print('Accuracy of the network on the 10000 test images: %d %%' % ( 100 * correct / total)) 训练的准确率远比随机猜测(准确率10%)好, 证明网络确实学到了东西. 嗯, 我们来看看哪些类别表现良好, 哪些类别表现不佳: class_correct = list(0. for i in range(10)) class_total = list(0. for i in range(10)) for data in testloader: images, labels = data outputs = net(Variable(images)) _, predicted = torch.max(outputs.data, 1) c = (predicted == labels).squeeze() for i in range(4): label = labels[i] class_correct[label] += c[i] class_total[label] += 1 for i in range(10): print('Accuracy of %5s : %2d %%' % ( classes[i], 100 * class_correct[i] / class_total[i])) 好的, 接下来呢? 我们如何在 GPU 上运行这些神经网络? 在 GPU 上训练 就像你如何将一个张量传递给GPU一样, 你将神经网络转移到GPU上. 这将递归遍历所有模块, 并将其参数和缓冲区转换为CUDA张量: net.cuda() 请记住, 您必须将输入和目标每一步都发送到GPU: inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda()) 如果发现在 GPU 上并没有比 CPU 提速很多, 实际上是因为网络比较小, GPU 没有完全发挥自己的真正实力. 练习: 尝试增加网络的宽度(第一个 nn.Conv2d 的参数2和第二个 nn.Conv2d 的参数1 它们需要是相同的数字), 看看你得到什么样的加速. 目标达成: 深入了解PyTorch的张量库和神经网络. 训练一个小的神经网络来分类图像. 在多个GPU上进行训练 如果你希望使用所有 GPU 来看更多的 MASSIVE 加速, 请查看可选 可选: 数据并行. 我下一步去哪里? 训练神经网络玩电子游戏 在 imagenet 上培训最先进的 ResNet 网络 利用生成对抗网络训练人脸生成器 使用 Recurrent LSTM 网络训练单词语言模型 更多的例子 更多教程 在论坛上讨论 PyTorch 与 Slack 上与其他用户聊天 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"blitz_data_parallel_tutorial.html":{"url":"blitz_data_parallel_tutorial.html","title":"可选: 数据并行","keywords":"","body":"可选: 数据并行 译者：@小王子 校对者：@李子文 作者: Sung Kim 和 Jenny Kang 在这个教程中, 我们将会学习如何在多个GPU上使用 DataParallel . 在 PyTorch 中使用 GPU 是一件很容易的事情.你可以像下面这样轻松的将一个模型分配到一个 GPU 上. model.gpu() 随后, 你可以将你的所有张量拷贝到上面的GPU: mytensor = my_tensor.gpu() 此处请注意: 如果只是调用 mytensor.gpu() 是不会将张量拷贝到 GPU 的.你需要将它赋给一个 新的张量, 这个张量就能在 GPU 上使用了. 在多个 GPU 上运行前向、反向传播是一件很自然的事情, 然而, PyTorch 默认情况下只会用到一个GPU, 可以通过使用 DataParallel 使你的模型并行运行, 在多个GPU上运行这些操作也将变得非常简单: model = nn.DataParallel(model) 这是教程的核心内容, 我们将在随后进行详细讲解 导入和参数 导入PyTorch模块和参数定义 import torch import torch.nn as nn from torch.autograd import Variable from torch.utils.data import Dataset, DataLoader # 参数和数据加载 input_size = 5 output_size = 2 batch_size = 30 data_size = 100 伪数据集 只需要实现 getitem 就可以轻松的生成一个（随机）伪数据集, 如下代码所示: class RandomDataset(Dataset): def __init__(self, size, length): self.len = length self.data = torch.randn(length, size) def __getitem__(self, index): return self.data[index] def __len__(self): return self.len rand_loader = DataLoader(dataset=RandomDataset(input_size, 100), batch_size=batch_size, shuffle=True) 简单模型 在下面的示例中, 我们的模型只需要一个输入并且完成一个线性操作, 最后得 到一个输出.当然, 你可以在任意模型 (CNN,RNN,Capsule Net等) 运用 DataParallel 我们在模型中设置了打印指令来监控输入和输出的张量大小, 请注意批数据次序为0时的输出. class Model(nn.Module): # Our model def __init__(self, input_size, output_size): super(Model, self).__init__() self.fc = nn.Linear(input_size, output_size) def forward(self, input): output = self.fc(input) print(\" In Model: input size\", input.size(), \"output size\", output.size()) return output 创建模型和 DataParallel 这是本教程的核心部分. 首先, 我们需要生成一个模型的实例并且检测我们是否拥有多个 GPU.如果有多个GPU , 我们可以使用 nn.DataParallel 来包装我们的模型, 然后我们 就可以将我们的模型通过 model.gpu() 施加于这些GPU上. model = Model(input_size, output_size) if torch.cuda.device_count() > 1: print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\") # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs model = nn.DataParallel(model) if torch.cuda.is_available(): model.cuda() 运行模型 现在我们可以看到输入和输出张量的大小了. for data in rand_loader: if torch.cuda.is_available(): input_var = Variable(data.cuda()) else: input_var = Variable(data) output = model(input_var) print(\"Outside: input size\", input_var.size(), \"output_size\", output.size()) 结果 当我们将输入设置为30批, 模型也产生了30批的输出.但是当我们使用多个GPU, 然后你 会得到类似下面这样的输出. 2 GPUs 如果有2个GPU, 我们将会看到这样的结果: # on 2 GPUs Let's use 2 GPUs! In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) In Model: input size torch.Size([15, 5]) output size torch.Size([15, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2]) In Model: input size torch.Size([5, 5]) output size torch.Size([5, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) 3 GPUs 如果有3个GPU, 我们将会看到这样的结果: Let's use 3 GPUs! In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) In Model: input size torch.Size([10, 5]) output size torch.Size([10, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) 8 GPUs 如果有8个GPU, 我们将会看到这样的结果: Let's use 8 GPUs! In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([4, 5]) output size torch.Size([4, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([30, 5]) output_size torch.Size([30, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) In Model: input size torch.Size([2, 5]) output size torch.Size([2, 2]) Outside: input size torch.Size([10, 5]) output_size torch.Size([10, 2]) 总结 DataParallel 自动地将数据分割并且将任务送入多个GPU上的多个模型中进行处理. 在每个模型完成任务后, DataParallel 采集和合并所有结果, 并将最后的结果呈现给你. 想了解更多信息, 请点击: https://pytorch.org/tutorials/beginner/former_torchies/parallelism_tutorial.html. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"former_torchies_tutorial.html":{"url":"former_torchies_tutorial.html","title":"PyTorch for former Torch users","keywords":"","body":"PyTorch for former Torch users 译者：@unknown 校对者：@bringtree Author: Soumith Chintala 在本教程中, 你将学习到以下内容: 使用 torch Tensors, 它和 (Lua)Torch 有很大的不同 使用 autograd package 构建神经网络 构建一个 ConvNet 构建一个 Recurrent Net 使用多个 GPUs Tensors Autograd (自动求导) nn package Multi-GPU examples 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"former_torchies_tensor_tutorial.html":{"url":"former_torchies_tensor_tutorial.html","title":"Tensors","keywords":"","body":"Tensors 译者：@unknown 校对者：@bringtree Tensors 在 PyTorch 中的操作方式 与 Torch 几乎完全相同. 用未初始化的内存创建一个大小为 (5 x 7) 的 tensor: import torch a = torch.FloatTensor(5, 7) 用 mean=0, var=1 的正态分布随机初始化一个tensor: a = torch.randn(5, 7) print(a) print(a.size()) 注解： torch.Size 实际上是一个 tuple, 因此它支持相同的操作 Inplace / Out-of-place 第一个不同点在于 tensor 上的所有操作, 如果想要在 tensor 自身上进行的操作 (in-place) 就要加上一个 _ 作为后缀. 例如, add 是一个 out-of-place 的 version ,而 add_ 是一个 in-place 的 version . a.fill_(3.5) # a 的值现在变为 3.5 b = a.add(4.0) # a 的值仍然是 3.5 # 返回的值 3.5 + 4.0 = 7.5 将作为b的值. print(a, b) 还有一些像 narrow 的操作是没有 in-place version , 所以也就不存在 .narrow_ . 同样的, 也有像 fill_ 的一些操作没有 out-of-place version . 因此, .fill 也同样不存在. Zero Indexing (零索引) Tensors 是 zero-indexed (索引从零开始)这是另外一个不同点. (在 lua 中, tensors 是 one-indexed (索引从一开始)) b = a[0, 3] # 从 a 中选择第一行第四列的值. Tensors 也可以用 Python 的切片索引 b = a[:, 3:5] # 从 a 中选择所有行中第四列和第五列的值. No camel casing 接下来一个小的不同是所有的函数都不是 camelCase 了. 例如 indexAdd 现在被称为 index_add_ x = torch.ones(5, 5) print(x) z = torch.Tensor(5, 2) z[:, 0] = 10 z[:, 1] = 100 print(z) x.index_add_(1, torch.LongTensor([4, 0]), z) print(x) Numpy Bridge 将 torch Tensor 转换为一个 numpy array, 反之亦然. Torch Tensor 和 numpy array 将会共用底层的内存, 改变其中一个, 另外一个也会随之改变. 将 torch Tensor 转换为 numpy Array a = torch.ones(5) print(a) b = a.numpy() print(b) a.add_(1) print(a) print(b) # 看一下 numpy array 值的变化 将 numpy Array 转换为 torch Tensor import numpy as np a = np.ones(5) b = torch.from_numpy(a) np.add(a, 1, out=a) print(a) print(b) # 看一下通过改变 np array 来自动的改变 torch Tensor 除了 CharTensor 之外, 所有 CPU 上的 Tensors 支持转变为 NumPy 并且 转换回来. CUDA Tensors CUDA Tensors 在 pytorch 中非常好用, 并且一个 CUDA tensor 从 CPU 转换到 GPU 仍将保持它底层的类型. # 让我们在 CUDA 可用的时候运行这个单元 if torch.cuda.is_available(): # 创建一个 LongTensor 并且将其转换使用 GPU # 的 torch.cuda.LongTensor 类型 a = torch.LongTensor(10).fill_(3).cuda() print(type(a)) b = a.cpu() # 将它转换到 CPU # 类型变回 torch.LongTensor 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"former_torchies_autograd_tutorial.html":{"url":"former_torchies_autograd_tutorial.html","title":"Autograd (自动求导)","keywords":"","body":"Autograd (自动求导) 译者：@unknown 校对者：@bringtree Autograd 现在是 torch 自动微分的核心包 . 它是使用基于 tape 的系统来进行自动微分的. 在前向阶段, autograd tape 会记住它执行的所有操作, 在反向阶段, 它将重放这些操作 Variable (变量) 在 autograd 中, 我们引入了一个 Variable 类, 它是一个非常单薄 的 Tensor 包装器. 你可以通过 .data 访问到原始 tensor, 并在计算完反向之后, 求出这个变量的梯度, 并将这个梯度累加到 .grad 属性中. Variable 还有一个对于 autograd 的使用非常重要的类 - Function 类. Variable 和 Function 是相互关联的, 并创建了一张无环图, 它记录一个完整的计算历史. 每个 Variable 的 .grad_fn 属性都引用了一个计算出这个Variable的函数 (除了用户创建的变量外 - 这些变量的 .grad_fn 为 None ). 如果你想要计算导数, 你可以在 Variable 上调用 .backward(). 如果 Variable 是一个标量 (i.e. 它拥有一个tensor元素), 则不需要为 backward() 指定任何参数, 但是如果它包含许多的元素, 则需要指定一个 grad_output 参数, 来匹配 tensor 的 shape. import torch from torch.autograd import Variable x = Variable(torch.ones(2, 2), requires_grad=True) print(x) # 注意 \"Variable containing\" 行 print(x.data) print(x.grad) print(x.grad_fn) # 我们自己创建的 x 对 x 做一个操作: y = x + 2 print(y) y 是由前面计算返回的结果创建的, 因此它有一个 grad_fn print(y.grad_fn) 对 y 做更多的操作: z = y * y * 3 out = z.mean() print(z, out) 梯度 现在, 让我们来反向传播, 并打印出 d(out)/dx 的梯度 out.backward() print(x.grad) 在默认情况下, 梯度计算会刷新计算图中包含的所有内部缓冲区, 所以如果您想要在图的某个部分向后执行两次梯度计算,则需要在 第一次传递过程中设置参数为 retain_variables = True. x = Variable(torch.ones(2, 2), requires_grad=True) y = x + 2 y.backward(torch.ones(2, 2), retain_graph=True) # retain_variables 标志将阻止内部缓冲区被释放 print(x.grad) z = y * y print(z) 只是反向传播随机梯度 gradient = torch.randn(2, 2) # 如果我们没有指定我们想保留变量, 这将会失败 y.backward(gradient) print(x.grad) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"former_torchies_nn_tutorial.html":{"url":"former_torchies_nn_tutorial.html","title":"nn package","keywords":"","body":"nn package 译者：@unknown 校对者：@bringtree 我们重新设计了 nn package, 以便与 autograd 完全集成. 让我们来回顾一下这些变化. 用 autograd 替换 containers: 你不再需要使用像 ConcatTable 这样的 Containers, 或者像 CAddTable 这样的模块, 或者使用 nngraph 并且 debug. 我们将无缝地使用 autograd 来定义我们的神经网络. 例如, output = nn.CAddTable():forward({input1, input2}) 简化为 output = input1 + input2 output = nn.MulConstant(0.5):forward(input) 简化为 output = input * 0.5 中间状态不再存放在上述提到的那些模块中, 而是存放在计算图中: 因为这个原因, 所以使用循环网络变得更加简单. 如果你想创建一个循环网络, 只需多次使用相同的 Linear 层, 而不必考虑共享权重. torch-nn-vs-pytorch-nn Simplified debugging: 使用Python的pdb调试器进行调试是直观的, 调试器和堆栈跟踪在发生错误的地方停止. What you see is what you get(所见即所得, 译者注:应该是说可视化吧). Example 1: ConvNet 让我们来创建一个小的 ConvNet. 你所有的网络都来自 nn.Module 基类: 在构造函数中, 声明你想要使用的所有层. 在 forward 函数中, 你可以定义模型从输入到输出将如何运行 import torch from torch.autograd import Variable import torch.nn as nn import torch.nn.functional as F class MNISTConvNet(nn.Module): def __init__(self): # 这是你实例化所有模块的地方 # 你可以稍后使用你在此给出的相同名称访问它们 super(MNISTConvNet, self).__init__() self.conv1 = nn.Conv2d(1, 10, 5) self.pool1 = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(10, 20, 5) self.pool2 = nn.MaxPool2d(2, 2) self.fc1 = nn.Linear(320, 50) self.fc2 = nn.Linear(50, 10) # 这是 forward 函数, 它定义了只接受一个输入的网络结构, # 如果你愿意, 可以随意定义支持使用更多输入的网络结构. def forward(self, input): x = self.pool1(F.relu(self.conv1(input))) x = self.pool2(F.relu(self.conv2(x))) # 在你的创建模型的过程中, 你可以疯狂地使用任意的python代码创建你的模型结构, # 这些操作都是完全合法的, 并且会被autograd正确处理: # if x.gt(0) > x.numel() / 2: # ... # # 你甚至可以做一个循环来重复使用相同的模块, 模块内部的模块不再 # 处于临时状态, 所以你可以在 forward 时多次使用它们. # while x.norm(2) 现在让我们来使用定义好的 ConvNet. 你应该先创建一个类的实例. net = MNISTConvNet() print(net) 注解： torch.nn 只支持 mini-batches , 整个 torch.nn package 只支持输入 mini-batch 格式的样本, 而不支持输入单个样本. 例如, nn.Conv2d 将采用 nSamples x nChannels x Height x Width 的 4D Tensor. 如果你有一个单个的样本, 只需使用 input.unsqueeze(0) 添加一个 虚假的 batch 维度. 创建一个包含随机数据的单个样本的 mini-batch, 并将该样本传入到 ConvNet . input = Variable(torch.randn(1, 1, 28, 28)) out = net(input) print(out.size()) 定义一个虚拟目标标签, 并使用损失函数来计算 error. target = Variable(torch.LongTensor([3])) loss_fn = nn.CrossEntropyLoss() # LogSoftmax + ClassNLL Loss err = loss_fn(out, target) err.backward() print(err) ConvNet 的 out 是一个 Variable. 我们使用它来计算损失, 计算结果 err 也是一个 Variable. 调用 err 的 .backward 方法将会通过 ConvNet 将梯度传播到它的权重. 让我们来访问单个层的权重和梯度: print(net.conv1.weight.grad.size()) print(net.conv1.weight.data.norm()) # norm of the weight print(net.conv1.weight.grad.data.norm()) # norm of the gradients Forward and Backward Function Hooks 我们已经检查了权重和梯度. 但是如何检查 / 修改一个层的输出和 grad_output? 我们为此引出了 hooks. 你可以在一个 Module 或一个 Variable 上注册一个函数. hook 可以是 forward hook 也可以是一个 backward hook. 当 forward 被执行后 forward hook 将会被执行. backward hook 将在执行 backward 阶段被执行. 让我们来看一个例子. 我们在 conv2 注册一个 forward hook 来打印一些信息 def printnorm(self, input, output): # input是将输入打包成的 tuple 的input # 输出是一个 Variable. output.data 是我们感兴趣的 Tensor print('Inside ' + self.__class__.__name__ + ' forward') print('') print('input: ', type(input)) print('input[0]: ', type(input[0])) print('output: ', type(output)) print('') print('input size:', input[0].size()) print('output size:', output.data.size()) print('output norm:', output.data.norm()) net.conv2.register_forward_hook(printnorm) out = net(input) 我们在 conv2 注册一个 backward hook 来打印一些信息 def printgradnorm(self, grad_input, grad_output): print('Inside ' + self.__class__.__name__ + ' backward') print('Inside class:' + self.__class__.__name__) print('') print('grad_input: ', type(grad_input)) print('grad_input[0]: ', type(grad_input[0])) print('grad_output: ', type(grad_output)) print('grad_output[0]: ', type(grad_output[0])) print('') print('grad_input size:', grad_input[0].size()) print('grad_output size:', grad_output[0].size()) print('grad_input norm:', grad_input[0].data.norm()) net.conv2.register_backward_hook(printgradnorm) out = net(input) err = loss_fn(out, target) err.backward() 一个完整的可以运行的 MNIST 例子在此链接中 https://github.com/pytorch/examples/tree/master/mnist Example 2: Recurrent Net 接下来, 让我们看一下用 PyTorch 创建 recurrent nets. 由于网络的状态是保存在图中, 而不是在 layer 中, 所以您可以简单地 创建一个 nn.Linear 并重复使用它. class RNN(nn.Module): # 你也可以在你模型的构造函数中传入参数 def __init__(self, data_size, hidden_size, output_size): super(RNN, self).__init__() self.hidden_size = hidden_size input_size = data_size + hidden_size self.i2h = nn.Linear(input_size, hidden_size) self.h2o = nn.Linear(hidden_size, output_size) def forward(self, data, last_hidden): input = torch.cat((data, last_hidden), 1) hidden = self.i2h(input) output = self.h2o(hidden) return hidden, output rnn = RNN(50, 20, 10) 更完整的使用 LSTMs 和 Penn Tree-bank 的语言模型位于 here PyTorch 默认已经为 ConvNets 和 Recurrent Nets 提供了无缝的 CuDNN 集成. loss_fn = nn.MSELoss() batch_size = 10 TIMESTEPS = 5 # 创建一些假数据 batch = Variable(torch.randn(batch_size, 50)) hidden = Variable(torch.zeros(batch_size, 20)) target = Variable(torch.zeros(batch_size, 10)) loss = 0 for t in range(TIMESTEPS): # 是的! 你可以多次使用同一个网络, # 将损失相加, 并且调用 call backward! hidden, output = rnn(batch, hidden) loss += loss_fn(output, target) loss.backward() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"former_torchies_parallelism_tutorial.html":{"url":"former_torchies_parallelism_tutorial.html","title":"Multi-GPU examples","keywords":"","body":"Multi-GPU examples 译者：@unknown 校对者：@bringtree 数据并行是指当我们将 mini-batch 的样本分成更小的 mini-batches, 并行地计算每个更小的 mini-batches. 数据并行通过使用 torch.nn.DataParallel 实现. 我们可以用 DataParallel 包装一个模块, 然后它将在 batch 维度(默认是0轴) 平分数据给多个 GPUs 进行并行计算. DataParallel import torch.nn as nn class DataParallelModel(nn.Module): def __init__(self): super().__init__() self.block1 = nn.Linear(10, 20) # 用 DataParallel 包装 block2 self.block2 = nn.Linear(20, 20) self.block2 = nn.DataParallel(self.block2) self.block3 = nn.Linear(20, 20) def forward(self, x): x = self.block1(x) x = self.block2(x) x = self.block3(x) return x 这个代码不做任何修改, 在 CPU 模式下也能运行. DataParallel 的文档为 here. 在其上实现 DataParallel 的基元: 通常, pytorch 的 nn.parallel 原函数可以单独使用. 我们实现了简单的类似 MPI 的原函数: replicate: 在多个设备上复制模块 scatter: 在第一维中分配输入 gather: 在第一维 gather 和 concatenate 输入 parallel_apply: 将一组已经分配的输入应用于一组已经分配的模型. 为了更清晰起见, 这里使用这些集合组成的函数 data_parallel def data_parallel(module, input, device_ids, output_device=None): if not device_ids: return module(input) if output_device is None: output_device = device_ids[0] replicas = nn.parallel.replicate(module, device_ids) inputs = nn.parallel.scatter(input, device_ids) replicas = replicas[:len(inputs)] outputs = nn.parallel.parallel_apply(replicas, inputs) return nn.parallel.gather(outputs, output_device) Part of the model on CPU and part on the GPU 让我们来看一个网络模型, 他的网络一部分用 CPU 运算, 另一部分用 GPU 运算. class DistributedModel(nn.Module): def __init__(self): super().__init__( embedding=nn.Embedding(1000, 10), rnn=nn.Linear(10, 10).cuda(0), ) def forward(self, x): # 在 CPU 上计算 embedding x = self.embedding(x) # 迁移到 GPU x = x.cuda(0) # 在 GPU 上运行 RNN x = self.rnn(x) return x 这是面向 Torch 使用者的 PyTorch 的简短介绍. 当然还有更多东西需要学习. 看完这部分教程, 也可以看看我们更全面的入门教程, 它介绍了 optim package, data loaders 等.: PyTorch 深度学习: 60 分钟极速入门教程. 也可以看看 训练一个会玩视频游戏的神经网络 使用 imagenet 图像数据来训练一个现在最热门的模型 训练一个 GAN 网络来生成人脸 使用循环神经网络 LSTM 来训练单词级语言模型 了解更多的例子 了解更多的教程 在论坛上讨论 PyTorch 在 slack 和其他用户讨论 PyTorch 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"pytorch_with_examples.html":{"url":"pytorch_with_examples.html","title":"跟着例子学习 PyTorch","keywords":"","body":"跟着例子学习 PyTorch 译者：@yongjay13、@speedmancs 校对者：@bringtree Author: Justin Johnson 这个教程通过一些单独的示例介绍了 PyTorch 的基本概念. PyTorch 的核心部分提供了两个主要功能: 一个类似于 numpy 的n维张量, 但可以在 GPU 上运行 为建立和训练神经网络自动微分 我们将使用全连接的 ReLU 网络作为我们的运行示例. 该网络将有一个隐藏层, 并将使用梯度下降训练去最小化随机数字的预测输出和真实输出之间的欧式距离. 注解： 你可以下载这些单独的例子在页面的底端 . 本章内容目录 Tensors Warm-up: numpy PyTorch: Tensors Autograd PyTorch: Variables and autograd PyTorch: Defining new autograd functions TensorFlow: Static Graphs nn module PyTorch: nn PyTorch: optim PyTorch: Custom nn Modules PyTorch: Control Flow + Weight Sharing Examples Tensors Autograd nn module Tensors Warm-up: numpy 在介绍 PyTorch 之前, 我们先使用 numpy 实现网络. Numpy 提供了一个n维的数组对象, 并提供了许多操纵这个数组对象的函数. Numpy 是科学计算的通用框架; Numpy 数组没有计算图, 也没有深度学习, 也没有梯度下降等方法实现的接口. 但是我们仍然可以很容易地使用 numpy 生成随机数据 并将产生的数据传入双层的神经网络, 并使用 numpy 来实现这个网络的正向传播和反向传播: # -*- coding: utf-8 -*- import numpy as np # N 是一个batch的样本数量; D_in是输入维度; # H 是隐藏层向量的维度; D_out是输出维度. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机的输入输出数据 x = np.random.randn(N, D_in) y = np.random.randn(N, D_out) # 随机初始化权重参数 w1 = np.random.randn(D_in, H) w2 = np.random.randn(H, D_out) learning_rate = 1e-6 for t in range(500): # 前向计算, 算出y的预测值 h = x.dot(w1) h_relu = np.maximum(h, 0) y_pred = h_relu.dot(w2) # 计算并打印误差值 loss = np.square(y_pred - y).sum() print(t, loss) # 在反向传播中, 计算出误差关于w1和w2的导数 grad_y_pred = 2.0 * (y_pred - y) grad_w2 = h_relu.T.dot(grad_y_pred) grad_h_relu = grad_y_pred.dot(w2.T) grad_h = grad_h_relu.copy() grad_h[h PyTorch: Tensors Numpy 是一个伟大的框架, 但它不能利用 GPU 加速它数值计算. 对于现代的深度神经网络, GPU 往往是提供 50倍或更大的加速, 所以不幸的是, numpy 不足以满足现在深度学习的需求. 这里我们介绍一下最基本的 PyTorch 概念: Tensor . PyTorch Tensor 在概念上与 numpy 数组相同: Tensor 是一个n维数组, PyTorch 也提供了很多能在这些 Tensor 上操作的函数. 像 numpy 数组一样, PyTorch Tensor 也和numpy的数组对象一样不了解深度学习,计算图和梯度下降；它们只是科学计算的通用工具. 然而不像 numpy, PyTorch Tensor 可以利用 GPU 加速他们的数字计算. 要在 GPU 上运行 PyTorch 张量, 只需将其转换为新的数据类型. 在这里, 我们将 PyTorch Tensor 生成的随机数据传入双层的神经网络. 就像上面的 numpy 例子一样, 我们需要手动实现网络的正向传播和反向传播: # -*- coding: utf-8 -*- import torch dtype = torch.FloatTensor # dtype = torch.cuda.FloatTensor # 取消注释以在GPU上运行 # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机输入和输出数据 x = torch.randn(N, D_in).type(dtype) y = torch.randn(N, D_out).type(dtype) # 随机初始化权重 w1 = torch.randn(D_in, H).type(dtype) w2 = torch.randn(H, D_out).type(dtype) learning_rate = 1e-6 for t in range(500): # 正向传递：计算预测y h = x.mm(w1) h_relu = h.clamp(min=0) y_pred = h_relu.mm(w2) # 计算并打印loss loss = (y_pred - y).pow(2).sum() print(t, loss) # 反向传播计算关于损失的w1和w2的梯度 grad_y_pred = 2.0 * (y_pred - y) grad_w2 = h_relu.t().mm(grad_y_pred) grad_h_relu = grad_y_pred.mm(w2.t()) grad_h = grad_h_relu.clone() grad_h[h Autograd PyTorch: Variables and autograd 在上面的例子中, 我们不得不手写实现神经网络的正反向传播的代码. 而手写实现反向传播的代码对于一个 小型的双层网络来说是没什么大问题的, 但是在面对大型复杂网络手写方向传播代码就会变得很棘手. 谢天谢地, 我们可以使用 自动微分 来自动化的计算神经网络中的后向传播. PyTorch 中的 autograd 包提供自动微分了这个功能. 使用 autograd 时, 网络的正向传播将定义一个 计算图 ; Tensor 将会成为图中的节点,从输入 Tensor 产生输出 Tensor 的函数将会用图中的( Edge )依赖边表示. 通过计算图来反向传播可以让您轻松计算梯度. 这听起来很复杂, 但是在实践中使用起来相当简单. 我们将 PyTorch 的 Tensor 包装成在 Variable 对象； 一个 Variable 代表一个计算图中的节点. 如果 x 是一个 Variable , 则 x.data 是一个 Tensor , 而 x.grad 是另外一个包含关于 x 的梯度的 Variable . PyTorch Variable 与 PyTorch Tensor 具有相同的 API: (几乎) 任何您可以在 Tensor 上执行的 操作也适用于 Variable ；该区别在于如果你使用 Variable 定义了一个计算图, Pytorch 允许您自动计算梯度. 这里我们使用 PyTorch 的 Variable 和自动微分来实现我们的双层网络；现在我们不再需要手写任何关于 计算网络反向传播的代码: # -*- coding: utf-8 -*- import torch from torch.autograd import Variable dtype = torch.FloatTensor # dtype = torch.cuda.FloatTensor # 取消注释以在GPU上运行 # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机张量来保存输入和输出,并将它们包装在变量中. # 设置requires_grad = False, 因为在后向传播时, 我们并不需要计算关于这些变量的梯度 x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False) y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False) # 为权重创建随机张量,并将其包装在变量中. # 设置requires_grad = True, 因为在后向传播时, 我们需要计算关于这些变量的梯度 w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True) w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True) learning_rate = 1e-6 for t in range(500): # 正向传递:使用变量上的运算来计算预测的y; 这些 # 与我们用于计算使用张量的正向传递完全相同, # 但我们不需要保留对中间值的引用, # 因为我们没有实现向后传递. y_pred = x.mm(w1).clamp(min=0).mm(w2) # 使用变量上的操作计算和打印损失. # 现在损失是形状变量 (1,) 并且 loss.data 是形状的张量 # (1,); loss.data[0] 是持有损失的标量值. loss = (y_pred - y).pow(2).sum() print(t, loss.data[0]) # 使用autograd来计算反向传递. # 该调用将使用requires_grad = True来计算相对于所有变量的损失梯度. # 在这次调用之后 w1.grad 和 w2.grad 将是变量 # 它们分别相对于w1和w2保存损失的梯度. loss.backward() # 使用梯度下降更新权重; w1.data 和 w2.data 是张量, # w1.grad 和 w2.grad 是变量并且 w1.grad.data 和 w2.grad.data # 是张量. w1.data -= learning_rate * w1.grad.data w2.data -= learning_rate * w2.grad.data # 更新权重后手动将梯度归零 w1.grad.data.zero_() w2.grad.data.zero_() PyTorch: Defining new autograd functions 在这层覆盖下, 每个原始的 autograd 操作符实际上是两个函数在张量上运行. 前向传播 函数从输入的 Tensor 计算将要输出的 Tensor . 后向传播 函数接收上一个 Tensor 关于 scalar 的梯度, 以 及计算当前输入 Tensor 对相同 scalar 值的梯度. 在 PyTorch 中, 我们可以通过定义一个 torch.autograd.Function 的子类和 实现 前向传播 和 后向传播 函数来轻松定义自己的 autograd 操作符. 然后我们可以 使用我们新的 autograd 操作符构造一个实例并将其作为一个函数调用, 传递用 Variable 包装了的输入数据的. 在这个例子中我们定义了我们自己的 autograd 函数来执行 ReLU 非线性函数, 并用它来实现我们的双层网络: # -*- coding: utf-8 -*- import torch from torch.autograd import Variable class MyReLU(torch.autograd.Function): \"\"\" 我们可以通过子类实现我们自己定制的autograd函数 torch.autograd.Function和执行在Tensors上运行的向前和向后通行证. \"\"\" @staticmethod def forward(ctx, input): \"\"\" 在正向传递中,我们收到一个包含输入和返回张量的张量,其中包含输出. ctx是一个上下文对象,可用于存储反向计算的信息. 您可以使用ctx.save_for_backward方法缓存任意对象以用于后向传递. \"\"\" ctx.save_for_backward(input) return input.clamp(min=0) @staticmethod def backward(ctx, grad_output): \"\"\" 在后向传递中,我们收到一个张量,其中包含相对于输出的损失梯度, 我们需要计算相对于输入的损失梯度. \"\"\" input, = ctx.saved_tensors grad_input = grad_output.clone() grad_input[input TensorFlow: Static Graphs Pytorch 的 autograd 看上去有点像 TensorFlow .两个框架的共同点是他们都是定义了自己的计算图. 和使用自动求微分的方法来计算梯度. 两者之间最大的不同在于 TensorFlow 的计算图是 静态的 和 PyTorch 的计算图是 动态的 . 在 TensorFlow 中, 我们只定义了一次计算图,然后重复执行同一张计算图, 只是输入计算图的数据不同而已. 而在 PyTorch 中, 每个正向传播都会定义一个新的计算图. 静态图很好, 因为您可以预先优化计算图；例如一个框架可能会为了计算效率决定融合一些计算图操作(像:Fused Graph), 或提出 一个多卡或者多机的分布式计算图的策略. 如果您正在重复使用相同的计算图, 那么这个潜在的 昂贵的前期优化可以使用静态图来得以减轻. 一方面来说, 静态图和动态图的控制流是不同的. 对于有些模型我们可能希望对每个数据点执行不同 的计算；例如循环神经网络可能会被展开为对每个数据的不同的长度的时间步数；这个展开可以用循 环来实现. 循环结构的静态图需要成为计算图的一部分；为此 TensorFlow 提供 tf.scan 操作符 用于将重复的结构嵌入到计算图中. 而动态计算图的情况比较简单: 因为我们设计的计算图可以对每个不同长度的输入随机应变. 我们可以使用正常的命令式代码对每个不同长度的输入执行计算. 为了与上面的 PyTorch autograd 例子进行对比, 我们在这里也使用 TensorFlow 创建简单的两层神经网络: # -*- coding: utf-8 -*- import tensorflow as tf import numpy as np # 首先我们设置计算图: # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 为输入数据和目标数据创建占位符; # 当我们执行图时,这些将被填充真实的数据. x = tf.placeholder(tf.float32, shape=(None, D_in)) y = tf.placeholder(tf.float32, shape=(None, D_out)) # 为权重创建变量并用随机数据初始化它们. # 一个TensorFlow变量在图的执行中保持其值. w1 = tf.Variable(tf.random_normal((D_in, H))) w2 = tf.Variable(tf.random_normal((H, D_out))) # 正向传递:使用TensorFlow Tensors上的运算来计算预测的y. # 请注意此代码实际上并未执行任何数字操作; # 它只是设置我们稍后将执行的计算图. h = tf.matmul(x, w1) h_relu = tf.maximum(h, tf.zeros(1)) y_pred = tf.matmul(h_relu, w2) # 使用TensorFlow张量上的操作计算损失 loss = tf.reduce_sum((y - y_pred) ** 2.0) # 计算相对于w1和w2的损失梯度. grad_w1, grad_w2 = tf.gradients(loss, [w1, w2]) # 使用梯度下降更新权重. # 要实际更新权重,我们需要在执行图时评估new_w1和new_w2. # 请注意,在TensorFlow中,更新权值的行为是计算图的一部分 # 在PyTorch中,这发生在计算图之外. learning_rate = 1e-6 new_w1 = w1.assign(w1 - learning_rate * grad_w1) new_w2 = w2.assign(w2 - learning_rate * grad_w2) # 现在我们已经构建了计算图,所以我们输入一个TensorFlow会话来实际执行图. with tf.Session() as sess: # 运行一次图形初始化变量w1和w2. sess.run(tf.global_variables_initializer()) # 创建包含输入x和目标y的实际数据的numpy数组 x_value = np.random.randn(N, D_in) y_value = np.random.randn(N, D_out) for _ in range(500): # 多次执行图. 每次执行时, # 我们都想将x_value绑定到x,将y_value绑定到y,用feed_dict参数指定. # 每次我们执行图时,我们都想计算损失值new_w1 和 new_w2; # 这些张量的值作为numpy数组返回. loss_value, _, _ = sess.run([loss, new_w1, new_w2], feed_dict={x: x_value, y: y_value}) print(loss_value) nn module PyTorch: nn 计算图( Computational graphs )和 autograd 是一个非常强大的定义复杂的运算符并自动地导出的范式；然而对于 大型的神经网络, 原始的 autograd 仍然显得有点太低级. 当我们创建神经网络时, 我们经常思考如何设计安排 layer , 以及一些在训练过程中网络会学习到的 learnable parameters 在TensorFlow中, 像 Keras, TensorFlow-Slim, 和 TFLearn 通过构建对神经网络有用的原始计算图提供更高层次的抽象. 在 PyTorch 中, nn 包起了同样的作用. nn 包定义了一组 Modules , 大致相当于神经网络层. 模块接收输入变量并进行计算输出变量, 但也可以保持内部状态, 如 用 Variable 包装的 learnable parameters . nn 包 也定义了一系列在训练神经网络时比较常用的损失函数. 在这个例子中, 我们使用 nn 包来实现我们的双层神经网络: # -*- coding: utf-8 -*- import torch from torch.autograd import Variable # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机张量来保存输入和输出,并将它们包装在变量中. x = Variable(torch.randn(N, D_in)) y = Variable(torch.randn(N, D_out), requires_grad=False) # 使用nn包将我们的模型定义为一系列图层. # nn.Sequential是一个包含其他模块的模块,并将它们按顺序应用以产生其输出. # 每个线性模块使用线性函数计算来自输入的输出,并保存内部变量的权重和偏差. model = torch.nn.Sequential( torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out), ) # nn包还包含流行损失函数的定义; # 在这种情况下,我们将使用均方差(MSE)作为我们的损失函数. loss_fn = torch.nn.MSELoss(size_average=False) learning_rate = 1e-4 for t in range(500): # 正向传递:通过将x传递给模型来计算预测的y. # 模块对象会覆盖__call__运算符,因此您可以将它们称为函数. # 这样做时,您将输入数据的变量传递给模块,并生成输出数据的变量. y_pred = model(x) # 计算和打印损失. # 我们传递包含y的预测值和真值的变量,并且损失函数返回包含损失的变量. loss = loss_fn(y_pred, y) print(t, loss.data[0]) # 在运行反向传递之前将梯度归零. model.zero_grad() # 向后传递:计算相对于模型的所有可学习参数的损失梯度. # 在内部,每个模块的参数都存储在变量require_grad = True中, # 因此该调用将计算模型中所有可学习参数的梯度. loss.backward() # 使用梯度下降更新权重. # 每个参数都是一个变量,所以我们可以像我们以前那样访问它的数据和梯度. for param in model.parameters(): param.data -= learning_rate * param.grad.data PyTorch: optim 到目前为止, 我们一直通过手动更新的方法更新模型的可学习参数( learnable parameters )的权重 .data 这对于简单的优化算法像随机梯度下降来还算轻松, 但是在实际中我们经常使用更巧妙的 优化器来训练神经网络, 如 AdaGrad, RMSProp, Adam 等. PyTorch 中的 optim 包包含了一些优化器的算法, 并提供了一些常用优化器的使用. 在这个例子中, 虽然我们将像之前一样使用 nn 包来定义我们的模型, 但是我们这次将使用由 optim 包提供的Adam算法来更新模型: # -*- coding: utf-8 -*- import torch from torch.autograd import Variable # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机张量来保存输入和输出,并将它们包装在变量中. x = Variable(torch.randn(N, D_in)) y = Variable(torch.randn(N, D_out), requires_grad=False) # 使用nn包来定义我们的模型和损失函数. model = torch.nn.Sequential( torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out), ) loss_fn = torch.nn.MSELoss(size_average=False) # 使用优化包来定义一个优化器,它将为我们更新模型的权重. # 在这里,我们将使用 Adam;这个 optim 包包含许多其他优化算法. # Adam构造函数的第一个参数告诉优化器应该更新哪个Variables. learning_rate = 1e-4 optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) for t in range(500): # 正向传递:通过将x传递给模型来计算预测的y. y_pred = model(x) # 计算和打印损失函数. loss = loss_fn(y_pred, y) print(t, loss.data[0]) # 在向后传递之前,使用优化器对象为其要更新的变量（这是模型的可学习权重）的所有梯度归零. # 这是因为默认情况下,只要调用.backward(),梯度就会在缓冲区中累积(即不会被覆盖). # 查看torch.autograd.backward的文档以获取更多详细信息. optimizer.zero_grad() # 向后传递:计算损失函数相对于模型参数的梯度 loss.backward() # 在优化器上调用step函数会更新其参数 optimizer.step() PyTorch: Custom nn Modules 有时你会想要使用比现有模块组合更复杂的特殊模型；对于这些情况, 你可以 通过继承 nn.Module 来定义你自己的模块, 并定义一个 forward 来实现模块接收输入 Variable 并使用其他模块输出的 Variable 和 其他 autograd 操作. 在这个例子中, 我们使用了我们之前已经实现的双层网络来作为一个自定义的模块子类: # -*- coding: utf-8 -*- import torch from torch.autograd import Variable class TwoLayerNet(torch.nn.Module): def __init__(self, D_in, H, D_out): \"\"\" 在构造函数中,我们实例化两个nn.Linear模块并将它们分配为成员变量. \"\"\" super(TwoLayerNet, self).__init__() self.linear1 = torch.nn.Linear(D_in, H) self.linear2 = torch.nn.Linear(H, D_out) def forward(self, x): \"\"\" 在forward函数中,我们接受一个变量的输入数据,我们必须返回一个变量的输出数据. 我们可以使用构造函数中定义的模块以及变量上的任意运算符. \"\"\" h_relu = self.linear1(x).clamp(min=0) y_pred = self.linear2(h_relu) return y_pred # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机张量来保存输入和输出,并将它们包装在变量中. x = Variable(torch.randn(N, D_in)) y = Variable(torch.randn(N, D_out), requires_grad=False) # 通过实例化上面定义的类来构建我们的模型 model = TwoLayerNet(D_in, H, D_out) # 构建我们的损失函数和优化器. # 对SGD构造函数中的model.parameters()的调用将包含作为模型成员的两个nn.Linear模块的可学习参数. criterion = torch.nn.MSELoss(size_average=False) optimizer = torch.optim.SGD(model.parameters(), lr=1e-4) for t in range(500): # 正向传递：通过将x传递给模型来计算预测的y y_pred = model(x) # 计算和打印损失 loss = criterion(y_pred, y) print(t, loss.data[0]) # 梯度置零, 执行反向传递并更新权重. optimizer.zero_grad() loss.backward() optimizer.step() PyTorch: Control Flow + Weight Sharing 作为一个动态图和权值共享的例子, 我们实现一个奇葩的模型: 随机1-4次重复搭建同个正向传播的全连接 的 ReLU 网络, 并且多个隐藏层使用相同的权重来计算最内层隐藏层(译者注: 这里的相同权重,是指随机1-4次重复搭建的这个middle_linear). 对于这个模型, 我们可以使用普通的 Python 流程控制语句来实现循环, 而且我们可以在定义前向传 播时通过简单地重复使用相同的模块实现 middle_linear 层的权重共享. 我们可以很容易地将这个模型作为 Module 子类来实现: # -*- coding: utf-8 -*- import random import torch from torch.autograd import Variable class DynamicNet(torch.nn.Module): def __init__(self, D_in, H, D_out): \"\"\" 在构造函数中,我们构造了三个nn.Linear实例,我们将在正向传递中使用它们. \"\"\" super(DynamicNet, self).__init__() self.input_linear = torch.nn.Linear(D_in, H) self.middle_linear = torch.nn.Linear(H, H) self.output_linear = torch.nn.Linear(H, D_out) def forward(self, x): \"\"\" 对于模型的正向通道,我们随机选择0,1,2或3, 并重复使用多次计算隐藏层表示的middle_linear模块. 由于每个正向通道都会生成一个动态计算图,因此在定义模型的正向通道时, 我们可以使用普通的Python控制流操作符(如循环或条件语句). 在这里我们也看到,定义计算图时多次重复使用相同模块是完全安全的. 这是Lua Torch的一大改进,每个模块只能使用一次. \"\"\" h_relu = self.input_linear(x).clamp(min=0) for _ in range(random.randint(0, 3)): h_relu = self.middle_linear(h_relu).clamp(min=0) y_pred = self.output_linear(h_relu) return y_pred # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机张量来保存输入和输出,并将它们包装在变量中. x = Variable(torch.randn(N, D_in)) y = Variable(torch.randn(N, D_out), requires_grad=False) # 通过实例化上面定义的类来构建我们的模型 model = DynamicNet(D_in, H, D_out) # 构建我们的损失函数和优化器. # 用随机梯度下降训练这个奇怪的模型非常困难,所以我们使用动量 criterion = torch.nn.MSELoss(size_average=False) optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9) for t in range(500): # 正向传递:通过将x传递给模型来计算预测的y y_pred = model(x) # 计算和打印损失 loss = criterion(y_pred, y) print(t, loss.data[0]) # 零梯度执行反向传递并更新权重. optimizer.zero_grad() loss.backward() optimizer.step() Examples 你可以在这里浏览上网提到的例子 Tensors Warm-up: numpy PyTorch: Tensors Autograd PyTorch: 变量和autograd PyTorch: 定义新的autograd函数 TensorFlow: 静态图 nn module PyTorch: nn包 PyTorch: optim包 PyTorch: 定制化nn模块 PyTorch: 动态控制流程 + 权重共享 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"pytorch_with_examples_warm-up-numpy.html":{"url":"pytorch_with_examples_warm-up-numpy.html","title":"Warm-up: numpy","keywords":"","body":"Warm-up: numpy 译者：@yongjay13、@speedmancs 校对者：@bringtree 本例中的神经网络有一个隐藏层, 后接ReLU激活层, 并且不带偏置参数. 训练时使用欧几里得误差来学习从x到y的映射. 我们只用到了numpy, 完全手写实现神经网络, 包括前向计算, 误差计算和后向传播. numpy的数组类型是一种通用的N维数组; 它没有内置深度学习的函数, 既不知道怎么求导, 也没有计算图的概念, 只能做一些通用的数值计算. import numpy as np # N 是一个batch的样本数量; D_in是输入维度; # H 是隐藏层向量的维度; D_out是输出维度. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机的输入输出数据 x = np.random.randn(N, D_in) y = np.random.randn(N, D_out) # 随机初始化权重参数 w1 = np.random.randn(D_in, H) w2 = np.random.randn(H, D_out) learning_rate = 1e-6 for t in range(500): # 前向计算, 算出y的预测值 h = x.dot(w1) h_relu = np.maximum(h, 0) y_pred = h_relu.dot(w2) # 计算并打印误差值 loss = np.square(y_pred - y).sum() print(t, loss) # 在反向传播中, 计算出误差关于w1和w2的导数 grad_y_pred = 2.0 * (y_pred - y) grad_w2 = h_relu.T.dot(grad_y_pred) grad_h_relu = grad_y_pred.dot(w2.T) grad_h = grad_h_relu.copy() grad_h[h 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"pytorch_with_examples_pytorch-tensors.html":{"url":"pytorch_with_examples_pytorch-tensors.html","title":"PyTorch: Tensors","keywords":"","body":"PyTorch: Tensors 译者：@yongjay13、@speedmancs 校对者：@bringtree 本例中的全连接神经网络有一个隐藏层, 后接ReLU激活层, 并且不带偏置参数. 训练时使用欧式距离平方来学习从x到y的映射. 实现中我们使用了PyTorch的张量来进行前向计算, 误差计算和后向传播. PyTorch的张量Tensor基本上和numpy的数组一样, 也没有任何内置的深度学习函数, 不知道计算图的概念, 也无法求导, 作为一个通用的N维数组, 它只用做任意的数值计算. 和numpy数组最大的区别在于, PyTorch张量既可以跑在CPU上, 也可以在GPU上作运算. 为了在GPU上进行计算, 只要把张量类型转成cuda数据类型即可。 import torch dtype = torch.FloatTensor # dtype = torch.cuda.FloatTensor # 取消注释以在GPU上运行 # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机输入和输出数据 x = torch.randn(N, D_in).type(dtype) y = torch.randn(N, D_out).type(dtype) # 随机初始化权重 w1 = torch.randn(D_in, H).type(dtype) w2 = torch.randn(H, D_out).type(dtype) learning_rate = 1e-6 for t in range(500): # 正向传递：计算预测y h = x.mm(w1) h_relu = h.clamp(min=0) y_pred = h_relu.mm(w2) # 计算并打印loss loss = (y_pred - y).pow(2).sum() print(t, loss) # 反向传播计算关于损失的w1和w2的梯度 grad_y_pred = 2.0 * (y_pred - y) grad_w2 = h_relu.t().mm(grad_y_pred) grad_h_relu = grad_y_pred.mm(w2.t()) grad_h = grad_h_relu.clone() grad_h[h 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"pytorch_with_examples_pytorch-variables-and-autograd.html":{"url":"pytorch_with_examples_pytorch-variables-and-autograd.html","title":"PyTorch: 变量和autograd","keywords":"","body":"PyTorch: 变量和autograd 译者：@yongjay13、@speedmancs 校对者：@bringtree 本例中的全连接神经网络有一个隐藏层, 后接ReLU激活层, 并且不带偏置参数. 训练时通过最小化欧式距离的平方, 来学习从x到y的映射. 在实现中, 我们将使用PyTorch变量的函数来进行前向计算, 并用PyTorch的autograd计算梯度 PyTorch变量是PyTorch张量的封装, 表示计算图中的一个节点. 如果x是变量, 那么x.data就是 表示其值的张量, 而x.grad则是另一个变量, 其中包含某个标量关于x的梯度. PyTorch变量的API和张量是一样的: 几乎所有Tensor上能做的操作, 你在变量上也可以调用. 区别 在于用变量时, autograd可以自动计算梯度. import torch from torch.autograd import Variable dtype = torch.FloatTensor # dtype = torch.cuda.FloatTensor # 取消注释以在GPU上运行 # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机张量来保存输入和输出,并将它们包装在变量中. # 设置requires_grad = False, 因为在后向传播时, 我们并不需要计算关于这些变量的梯度 x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False) y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False) # 为权重创建随机张量,并将其包装在变量中. # 设置requires_grad = True, 因为在后向传播时, 我们需要计算关于这些变量的梯度 w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True) w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True) learning_rate = 1e-6 for t in range(500): # 正向传递:使用变量上的运算来计算预测的y; 这些 # 与我们用于计算使用张量的正向传递完全相同, # 但我们不需要保留对中间值的引用, # 因为我们没有实现向后传递. y_pred = x.mm(w1).clamp(min=0).mm(w2) # 使用变量上的操作计算和打印损失. # 现在损失是形状变量 (1,) 并且 loss.data 是形状的张量 # (1,); loss.data[0] 是持有损失的标量值. loss = (y_pred - y).pow(2).sum() print(t, loss.data[0]) # 使用autograd来计算反向传递. # 该调用将使用requires_grad = True来计算相对于所有变量的损失梯度. # 在这次调用之后 w1.grad 和 w2.grad 将是变量 # 它们分别相对于w1和w2保存损失的梯度. loss.backward() # 使用梯度下降更新权重; w1.data 和 w2.data 是张量, # w1.grad 和 w2.grad 是变量并且 w1.grad.data 和 w2.grad.data # 是张量. w1.data -= learning_rate * w1.grad.data w2.data -= learning_rate * w2.grad.data # 更新权重后手动将梯度归零 w1.grad.data.zero_() w2.grad.data.zero_() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"pytorch_with_examples_pytorch-defining-new-autograd-functions.html":{"url":"pytorch_with_examples_pytorch-defining-new-autograd-functions.html","title":"PyTorch: 定义新的autograd函数","keywords":"","body":"PyTorch: 定义新的autograd函数 译者：@yongjay13、@speedmancs 校对者：@bringtree 本例中的全连接神经网络有一个隐藏层, 后接ReLU激活层, 并且不带偏置参数. 训练时通过最小化欧式距离的平方, 来学习从x到y的映射. 在此实现中, 我们使用PyTorch变量上的函数来进行前向计算, 然后用PyTorch的autograd计算梯度 我们还实现了一个定制化的autograd函数, 用于ReLU函数. import torch from torch.autograd import Variable class MyReLU(torch.autograd.Function): \"\"\" 我们可以通过子类实现我们自己定制的autograd函数 torch.autograd.Function和执行在Tensors上运行的向前和向后通行证. \"\"\" @staticmethod def forward(ctx, input): \"\"\" 在正向传递中,我们收到一个包含输入和返回张量的张量,其中包含输出. ctx是一个上下文对象,可用于存储反向计算的信息. 您可以使用ctx.save_for_backward方法缓存任意对象以用于后向传递. \"\"\" ctx.save_for_backward(input) return input.clamp(min=0) @staticmethod def backward(ctx, grad_output): \"\"\" 在后向传递中,我们收到一个张量,其中包含相对于输出的损失梯度, 我们需要计算相对于输入的损失梯度. \"\"\" input, = ctx.saved_tensors grad_input = grad_output.clone() grad_input[input 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"pytorch_with_examples_tensorflow-static-graphs.html":{"url":"pytorch_with_examples_tensorflow-static-graphs.html","title":"TensorFlow: 静态图","keywords":"","body":"TensorFlow: 静态图 译者：@yongjay13、@speedmancs 校对者：@bringtree 本例中的全连接神经网络有一个隐藏层, 后接ReLU激活层, 并且不带偏置参数. 训练时通过最小化欧式距离的平方, 来学习从x到y的映射. 在实现中, 我们会用基本的TensorFlow操作来建立一个计算图, 随后多次执行这个图来训练网络. TensorFlow和PyTorch有一个很大的区别, 就是TensorFlow用的是静态计算图, 而PyTorch则用动态计算图. 用TensorFlow我们先建立计算图, 然后在多次执行过程中, 计算图固定不变. import tensorflow as tf import numpy as np # 首先我们设置计算图: # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 为输入数据和目标数据创建占位符; # 当我们执行图时,这些将被填充真实的数据. x = tf.placeholder(tf.float32, shape=(None, D_in)) y = tf.placeholder(tf.float32, shape=(None, D_out)) # 为权重创建变量并用随机数据初始化它们. # 一个TensorFlow变量在图的执行中保持其值. w1 = tf.Variable(tf.random_normal((D_in, H))) w2 = tf.Variable(tf.random_normal((H, D_out))) # 正向传递:使用TensorFlow Tensors上的运算来计算预测的y. # 请注意此代码实际上并未执行任何数字操作; # 它只是设置我们稍后将执行的计算图. h = tf.matmul(x, w1) h_relu = tf.maximum(h, tf.zeros(1)) y_pred = tf.matmul(h_relu, w2) # 使用TensorFlow张量上的操作计算损失 loss = tf.reduce_sum((y - y_pred) ** 2.0) # 计算相对于w1和w2的损失梯度. grad_w1, grad_w2 = tf.gradients(loss, [w1, w2]) # 使用梯度下降更新权重. # 要实际更新权重,我们需要在执行图时评估new_w1和new_w2. # 请注意,在TensorFlow中,更新权值的行为是计算图的一部分 # 在PyTorch中,这发生在计算图之外. learning_rate = 1e-6 new_w1 = w1.assign(w1 - learning_rate * grad_w1) new_w2 = w2.assign(w2 - learning_rate * grad_w2) # 现在我们已经构建了计算图,所以我们输入一个TensorFlow会话来实际执行图. with tf.Session() as sess: # 运行一次图形初始化变量w1和w2. sess.run(tf.global_variables_initializer()) # 创建包含输入x和目标y的实际数据的numpy数组 x_value = np.random.randn(N, D_in) y_value = np.random.randn(N, D_out) for _ in range(500): # 多次执行图. 每次执行时, # 我们都想将x_value绑定到x,将y_value绑定到y,用feed_dict参数指定. # 每次我们执行图时,我们都想计算损失值new_w1 和 new_w2; # 这些张量的值作为numpy数组返回. loss_value, _, _ = sess.run([loss, new_w1, new_w2], feed_dict={x: x_value, y: y_value}) print(loss_value) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"pytorch_with_examples_pytorch-nn.html":{"url":"pytorch_with_examples_pytorch-nn.html","title":"PyTorch: nn包","keywords":"","body":"PyTorch: nn包 译者：@yongjay13、@speedmancs 校对者：@bringtree 本例中的全连接神经网络有一个隐藏层, 后接ReLU激活层, 并且不带偏置参数. 训练时通过最小化欧式距离的平方, 来学习从x到y的映射. 实现中用PyTorch的nn包来搭建神经网络. 如果使用PyTorch的autograd包, 定义计算图和梯度计算将变得非常容易. 但是对于一些复杂的神经网络来说, 只用autograd还是有点底层了. 这正是nn包的用武之地. nn包定义了很多模块, 你可以把它们当作一个个的神经网络层. 每个模块都有输入输出, 并可能有一些可训练权重. import torch from torch.autograd import Variable # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机张量来保存输入和输出,并将它们包装在变量中. x = Variable(torch.randn(N, D_in)) y = Variable(torch.randn(N, D_out), requires_grad=False) # 使用nn包将我们的模型定义为一系列图层. # nn.Sequential是一个包含其他模块的模块,并将它们按顺序应用以产生其输出. # 每个线性模块使用线性函数计算来自输入的输出,并保存内部变量的权重和偏差. model = torch.nn.Sequential( torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out), ) # nn包还包含流行损失函数的定义; # 在这种情况下,我们将使用均方差(MSE)作为我们的损失函数. loss_fn = torch.nn.MSELoss(size_average=False) learning_rate = 1e-4 for t in range(500): # 正向传递:通过将x传递给模型来计算预测的y. # 模块对象会覆盖__call__运算符,因此您可以将它们称为函数. # 这样做时,您将输入数据的变量传递给模块,并生成输出数据的变量. y_pred = model(x) # 计算和打印损失. # 我们传递包含y的预测值和真值的变量,并且损失函数返回包含损失的变量. loss = loss_fn(y_pred, y) print(t, loss.data[0]) # 在运行反向传递之前将梯度归零. model.zero_grad() # 向后传递:计算相对于模型的所有可学习参数的损失梯度. # 在内部,每个模块的参数都存储在变量require_grad = True中, # 因此该调用将计算模型中所有可学习参数的梯度. loss.backward() # 使用梯度下降更新权重. # 每个参数都是一个变量,所以我们可以像我们以前那样访问它的数据和梯度. for param in model.parameters(): param.data -= learning_rate * param.grad.data 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"pytorch_with_examples_pytorch-optim.html":{"url":"pytorch_with_examples_pytorch-optim.html","title":"PyTorch: optim包","keywords":"","body":"PyTorch: optim包 译者：@yongjay13、@speedmancs 校对者：@bringtree 本例中的全连接神经网络有一个隐藏层, 后接ReLU激活层, 并且不带偏置参数. 训练时通过最小化欧式距离的平方, 来学习从x到y的映射 在此实现中, 我们将弃用之前手工更新权值的做法, 转而用PyTorch的nn包来搭建神经网络. optim包则用来定义更新权值的优化器. optim包有众多深度学习常用的优化算法, 包括SGD+momentum, RMSProp, Adam等. import torch from torch.autograd import Variable # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机张量来保存输入和输出,并将它们包装在变量中. x = Variable(torch.randn(N, D_in)) y = Variable(torch.randn(N, D_out), requires_grad=False) # 使用nn包来定义我们的模型和损失函数. model = torch.nn.Sequential( torch.nn.Linear(D_in, H), torch.nn.ReLU(), torch.nn.Linear(H, D_out), ) loss_fn = torch.nn.MSELoss(size_average=False) # 使用优化包来定义一个优化器,它将为我们更新模型的权重. # 在这里,我们将使用 Adam;这个 optim 包包含许多其他优化算法. # Adam构造函数的第一个参数告诉优化器应该更新哪个Variables. learning_rate = 1e-4 optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) for t in range(500): # 正向传递:通过将x传递给模型来计算预测的y. y_pred = model(x) # 计算和打印损失函数. loss = loss_fn(y_pred, y) print(t, loss.data[0]) # 在向后传递之前,使用优化器对象为其要更新的变量（这是模型的可学习权重）的所有梯度归零. # 这是因为默认情况下,只要调用.backward(),梯度就会在缓冲区中累积(即不会被覆盖). # 查看torch.autograd.backward的文档以获取更多详细信息. optimizer.zero_grad() # 向后传递:计算损失函数相对于模型参数的梯度 loss.backward() # 在优化器上调用step函数会更新其参数 optimizer.step() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"pytorch_with_examples_pytorch-custom-nn-modules.html":{"url":"pytorch_with_examples_pytorch-custom-nn-modules.html","title":"PyTorch: 定制化nn模块","keywords":"","body":"PyTorch: 定制化nn模块 译者：@yongjay13、@speedmancs 校对者：@bringtree 本例中的全连接神经网络有一个隐藏层, 后接ReLU激活层, 并且不带偏置参数. 训练时通过最小化欧式距离的平方, 来学习从x到y的映射. 在实现中我们将定义一个定制化的模块子类. 如果已有模块串起来不能满足你的复杂需求, 那么你就能以这种方式来定义自己的模块。 import torch from torch.autograd import Variable class TwoLayerNet(torch.nn.Module): def __init__(self, D_in, H, D_out): \"\"\" 在构造函数中,我们实例化两个nn.Linear模块并将它们分配为成员变量. \"\"\" super(TwoLayerNet, self).__init__() self.linear1 = torch.nn.Linear(D_in, H) self.linear2 = torch.nn.Linear(H, D_out) def forward(self, x): \"\"\" 在forward函数中,我们接受一个变量的输入数据,我们必须返回一个变量的输出数据. 我们可以使用构造函数中定义的模块以及变量上的任意运算符. \"\"\" h_relu = self.linear1(x).clamp(min=0) y_pred = self.linear2(h_relu) return y_pred # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机张量来保存输入和输出,并将它们包装在变量中. x = Variable(torch.randn(N, D_in)) y = Variable(torch.randn(N, D_out), requires_grad=False) # 通过实例化上面定义的类来构建我们的模型 model = TwoLayerNet(D_in, H, D_out) # 构建我们的损失函数和优化器. # 对SGD构造函数中的model.parameters()的调用将包含作为模型成员的两个nn.Linear模块的可学习参数. criterion = torch.nn.MSELoss(size_average=False) optimizer = torch.optim.SGD(model.parameters(), lr=1e-4) for t in range(500): # 正向传递：通过将x传递给模型来计算预测的y y_pred = model(x) # 计算和打印损失 loss = criterion(y_pred, y) print(t, loss.data[0]) # 梯度置零, 执行反向传递并更新权重. optimizer.zero_grad() loss.backward() optimizer.step() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"pytorch_with_examples_pytorch-control-flow-weight-sharing.html":{"url":"pytorch_with_examples_pytorch-control-flow-weight-sharing.html","title":"PyTorch: 动态控制流程 + 权重共享","keywords":"","body":"PyTorch: 动态控制流程 + 权重共享 译者：@yongjay13、@speedmancs 校对者：@bringtree 为了展示PyTorch的动态图的强大, 我们实现了一个非常奇异的模型: 一个全连接的ReLU激活的神经网络, 每次前向计算时都随机选一个1到4之间的数字n, 然后接下来就有n层隐藏层, 每个隐藏层的连接权重共享. import random import torch from torch.autograd import Variable class DynamicNet(torch.nn.Module): def __init__(self, D_in, H, D_out): \"\"\" 在构造函数中,我们构造了三个nn.Linear实例,我们将在正向传递中使用它们. \"\"\" super(DynamicNet, self).__init__() self.input_linear = torch.nn.Linear(D_in, H) self.middle_linear = torch.nn.Linear(H, H) self.output_linear = torch.nn.Linear(H, D_out) def forward(self, x): \"\"\" 对于模型的正向通道,我们随机选择0,1,2或3, 并重复使用多次计算隐藏层表示的middle_linear模块. 由于每个正向通道都会生成一个动态计算图,因此在定义模型的正向通道时, 我们可以使用普通的Python控制流操作符(如循环或条件语句). 在这里我们也看到,定义计算图时多次重复使用相同模块是完全安全的. 这是Lua Torch的一大改进,每个模块只能使用一次. \"\"\" h_relu = self.input_linear(x).clamp(min=0) for _ in range(random.randint(0, 3)): h_relu = self.middle_linear(h_relu).clamp(min=0) y_pred = self.output_linear(h_relu) return y_pred # N 批量大小; D_in是输入尺寸; # H是隐藏尺寸; D_out是输出尺寸. N, D_in, H, D_out = 64, 1000, 100, 10 # 创建随机张量来保存输入和输出,并将它们包装在变量中. x = Variable(torch.randn(N, D_in)) y = Variable(torch.randn(N, D_out), requires_grad=False) # 通过实例化上面定义的类来构建我们的模型 model = DynamicNet(D_in, H, D_out) # 构建我们的损失函数和优化器. # 用随机梯度下降训练这个奇怪的模型非常困难,所以我们使用动量 criterion = torch.nn.MSELoss(size_average=False) optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9) for t in range(500): # 正向传递:通过将x传递给模型来计算预测的y y_pred = model(x) # 计算和打印损失 loss = criterion(y_pred, y) print(t, loss.data[0]) # 零梯度执行反向传递并更新权重. optimizer.zero_grad() loss.backward() optimizer.step() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"transfer_learning_tutorial.html":{"url":"transfer_learning_tutorial.html","title":"迁移学习教程","keywords":"","body":"迁移学习教程 译者：@Sylvester 校对者：@Archie Yu 作者: Sasank Chilamkurthy 这个教程将教你如何使用迁移学习训练你的网络. 你可以在 cs231n 笔记 中 阅读更多有关迁移学习的信息. 引用自该笔记, 事实上, 很少有人从头(随机初始化)开始训练一个卷积网络, 因为拥有一个足够大的数据库是比较少见的. 替代的是, 通常会从一个大的数据集(例如 ImageNet, 包含120万的图片和1000个分类)预训练一个卷积网络, 然后将这个卷积网络作为初始化的网络, 或者是感兴趣任务的固定的特征提取器. 如下是两种主要的迁移学习的使用场景: 微调卷积网络: 取代随机初始化网络, 我们从一个预训练的网络初始化, 比如从 imagenet 1000 数据集预训练的网络. 其余的训练就像往常一样. 卷积网络作为固定的特征提取器: 在这里, 我们固定网络中的所有权重, 最后的全连接层除外. 最后的全连接层被新的随机权重替换, 并且, 只有这一层是被训练的. # License: BSD # Author: Sasank Chilamkurthy from __future__ import print_function, division import torch import torch.nn as nn import torch.optim as optim from torch.optim import lr_scheduler from torch.autograd import Variable import numpy as np import torchvision from torchvision import datasets, models, transforms import matplotlib.pyplot as plt import time import os import copy plt.ion() # interactive mode 加载数据 我们用 torchvision 和 torch.utils.data 包加载数据. 我们今天要解决的问题是, 训练一个可以区分 ants (蚂蚁) 和 bees (蜜蜂) 的模型. 用于训练的 ants 和 bees 图片各120张. 每一类用于验证的图片各75张. 通常, 如果从头开始训练, 这个非常小的数据集不足以进行泛化. 但是, 因为我们使用迁移学习, 应该可以取得很好的泛化效果. 这个数据集是一个非常小的 imagenet 子集 注解： 从这里 &lt;[https://download.pytorch.org/tutorial/hymenoptera_data.zip](https://download.pytorch.org/tutorial/hymenoptera_data.zip)&gt;_ 下载数据, 然后解压到当前目录. # 训练要做数据增强和数据标准化 # 验证只做数据标准化 data_transforms = { 'train': transforms.Compose([ transforms.RandomSizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), 'val': transforms.Compose([ transforms.Scale(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]), } data_dir = 'hymenoptera_data' image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']} dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']} dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']} class_names = image_datasets['train'].classes use_gpu = torch.cuda.is_available() 显示一些图片 让我们显示一些训练中的图片, 以便了解数据增强. def imshow(inp, title=None): \"\"\"Imshow for Tensor.\"\"\" inp = inp.numpy().transpose((1, 2, 0)) mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) inp = std * inp + mean inp = np.clip(inp, 0, 1) plt.imshow(inp) if title is not None: plt.title(title) plt.pause(0.001) # 暂停一会, 让 plots 更新 # 获得一批训练数据 inputs, classes = next(iter(dataloaders['train'])) # 从这批数据生成一个方格 out = torchvision.utils.make_grid(inputs) imshow(out, title=[class_names[x] for x in classes]) 训练模型 现在, 让我们写一个通用的函数来训练模型. 这里, 我们将会举例说明: 调度学习率 保存最佳的学习模型 下面函数中, scheduler 参数是 torch.optim.lr_scheduler 中的 LR scheduler 对象. def train_model(model, criterion, optimizer, scheduler, num_epochs=25): since = time.time() best_model_wts = copy.deepcopy(model.state_dict()) best_acc = 0.0 for epoch in range(num_epochs): print('Epoch {}/{}'.format(epoch, num_epochs - 1)) print('-' * 10) # 每一个迭代都有训练和验证阶段 for phase in ['train', 'val']: if phase == 'train': scheduler.step() model.train(True) # 设置 model 为训练 (training) 模式 else: model.train(False) # 设置 model 为评估 (evaluate) 模式 running_loss = 0.0 running_corrects = 0 # 遍历数据 for data in dataloaders[phase]: # 获取输入 inputs, labels = data # 用 Variable 包装输入数据 if use_gpu: inputs = Variable(inputs.cuda()) labels = Variable(labels.cuda()) else: inputs, labels = Variable(inputs), Variable(labels) # 设置梯度参数为 0 optimizer.zero_grad() # 正向传递 outputs = model(inputs) _, preds = torch.max(outputs.data, 1) loss = criterion(outputs, labels) # 如果是训练阶段, 向后传递和优化 if phase == 'train': loss.backward() optimizer.step() # 统计 running_loss += loss.data[0] * inputs.size(0) running_corrects += torch.sum(preds == labels.data) epoch_loss = running_loss / dataset_sizes[phase] epoch_acc = running_corrects / dataset_sizes[phase] print('{} Loss: {:.4f} Acc: {:.4f}'.format( phase, epoch_loss, epoch_acc)) # 深拷贝 model if phase == 'val' and epoch_acc > best_acc: best_acc = epoch_acc best_model_wts = copy.deepcopy(model.state_dict()) print() time_elapsed = time.time() - since print('Training complete in {:.0f}m {:.0f}s'.format( time_elapsed // 60, time_elapsed % 60)) print('Best val Acc: {:4f}'.format(best_acc)) # 加载最佳模型的权重 model.load_state_dict(best_model_wts) return model 显示模型的预测结果 写一个处理少量图片, 并显示预测结果的通用函数 def visualize_model(model, num_images=6): images_so_far = 0 fig = plt.figure() for i, data in enumerate(dataloaders['val']): inputs, labels = data if use_gpu: inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda()) else: inputs, labels = Variable(inputs), Variable(labels) outputs = model(inputs) _, preds = torch.max(outputs.data, 1) for j in range(inputs.size()[0]): images_so_far += 1 ax = plt.subplot(num_images//2, 2, images_so_far) ax.axis('off') ax.set_title('predicted: {}'.format(class_names[preds[j]])) imshow(inputs.cpu().data[j]) if images_so_far == num_images: return 调整卷积网络 加载一个预训练的网络, 并重置最后一个全连接层. model_ft = models.resnet18(pretrained=True) num_ftrs = model_ft.fc.in_features model_ft.fc = nn.Linear(num_ftrs, 2) if use_gpu: model_ft = model_ft.cuda() criterion = nn.CrossEntropyLoss() # 如你所见, 所有参数都将被优化 optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9) # 每 7 个迭代, 让 LR 衰减 0.1 因素 exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) 训练和评估 如果使用 CPU, 这将花费 15-25 分钟. 但使用 GPU 的话, 需要的时间将少于1分钟. model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25) visualize_model(model_ft) 卷积网络作为固定的特征提取器 这里, 我们固定网络中除最后一层外的所有权重. 为了固定这些参数, 我们需要设置 requires_grad == False , 然后在 backward() 中就不会计算梯度. 你可以在 这里 阅读更多相关信息. model_conv = torchvision.models.resnet18(pretrained=True) for param in model_conv.parameters(): param.requires_grad = False # 新构建的 module 的参数中, 默认设置了 requires_grad=True. num_ftrs = model_conv.fc.in_features model_conv.fc = nn.Linear(num_ftrs, 2) if use_gpu: model_conv = model_conv.cuda() criterion = nn.CrossEntropyLoss() # 如你所见, 和我们前面提出的一样, 只有最后一层的参数被优化. optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9) # 每 7 个迭代, 让 LR 衰减 0.1 因素 exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1) 训练和评估 在使用 CPU 的情况下, 和前一个方案相比, 这将花费的时间是它的一半. 期望中, 网络的大部分是不需要计算梯度的. 前向传递依然要计算梯度. model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler, num_epochs=25) visualize_model(model_conv) plt.ioff() plt.show() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"data_loading_tutorial.html":{"url":"data_loading_tutorial.html","title":"数据加载和处理教程","keywords":"","body":"数据加载和处理教程 译者：@distant1219 校对者：@bringtree 作者: Sasank Chilamkurthy 在解决机器学习问题时, 我们需要付出很多努力来准备数据, 为了使代码更具可读性, PyTorch提供了许多工具来使数据加载变得简单易行. 在本教程中, 我们将要学习如何对 一个重要的数据集进行加载、预处理数据增强. 为了运行本教程, 请确保以下包已经安装: scikit-image: 用来读取图片和图像变换 pandas: 更方便地解析csv文件 from __future__ import print_function, division import os import torch import pandas as pd from skimage import io, transform import numpy as np import matplotlib.pyplot as plt from torch.utils.data import Dataset, DataLoader from torchvision import transforms, utils # 忽略警告 import warnings warnings.filterwarnings(\"ignore\") plt.ion() # 交互模式 我们将要处理的是面部姿态的数据集, 其中一张人脸图像如下图一样被标注出来. 下面是一张脸的标注: 每张人脸图像上, 总共有68个不同的标注点被标记出来. 注解： 点击 这里 下载数据集, 这些图像在目录 ‘ faces/ ‘下. 这个数据集实际上是从imagenet数据集中选取标记为人脸的一些图片, 使用dlib’s pose estimation 方法生成的. 数据集中的csv文件记录着标注信息, 像下面这样: image_name,part_0_x,part_0_y,part_1_x,part_1_y,part_2_x, ... ,part_67_x,part_67_y 0805personali01.jpg,27,83,27,98, ... 84,134 1084239450_e76e00b7e7.jpg,70,236,71,257, ... ,128,312 让我们快速地读取CSV文件, 以(N,2)的数组形式获得标记点, 其中N表示标记点的个数. landmarks_frame = pd.read_csv('faces/face_landmarks.csv') n = 65 img_name = landmarks_frame.iloc[n, 0] landmarks = landmarks_frame.iloc[n, 1:].as_matrix() landmarks = landmarks.astype('float').reshape(-1, 2) print('Image name: {}'.format(img_name)) print('Landmarks shape: {}'.format(landmarks.shape)) print('First 4 Landmarks: {}'.format(landmarks[:4])) 我们写一个函数来显示一张图片和它的标记点, 然后用这个函数来显示一个样本. def show_landmarks(image, landmarks): \"\"\"显示带标记点的图片\"\"\" plt.imshow(image) plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r') plt.pause(0.001) # 暂停一下, 使plots更新 plt.figure() show_landmarks(io.imread(os.path.join('faces/', img_name)), landmarks) plt.show() Dataset类 torch.utils.data.Dataset 是一个表示数据集的抽象类. 你自己的数据集一般应该继承Dataset, 并且重写下面的方法: __len__ 使用len(dataset) 可以返回数据集的大小 __getitem__ 支持索引, 以便于使用 dataset[i] 可以 获取第i个样本(0索引) 我们为我们的人脸数据集创建一个数据集类. 我们使用 __init__方法来读取csv文件, 使用 __getitem__读取图片. 这样可以使内存高效利用, 因为我们并不需要在内存中一次存储所有图片, 而是按照需要读取. 数据集的一个样例是一个{‘image’: image, ‘landmarks’: landmarks}样的字典. 数据集类中有一个可选的参数 transform 这样可以对数据集做任何需要的处理. 我们将在下节看到 transform 的用处. class FaceLandmarksDataset(Dataset): \"\"\"人脸标记数据集\"\"\" def __init__(self, csv_file, root_dir, transform=None): \"\"\" Args: csv_file (string): 带有标记点的csv文件路径 root_dir (string): 图片路径 transform (callable, 可选):可选择进行的图像变换 \"\"\" self.landmarks_frame = pd.read_csv(csv_file) self.root_dir = root_dir self.transform = transform def __len__(self): return len(self.landmarks_frame) def __getitem__(self, idx): img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, 0]) image = io.imread(img_name) landmarks = self.landmarks_frame.iloc[idx, 1:].as_matrix() landmarks = landmarks.astype('float').reshape(-1, 2) sample = {'image': image, 'landmarks': landmarks} if self.transform: sample = self.transform(sample) return sample 让我们实例化这个类 并且迭代所有的数据样本. 我们将打印前4个样本, 并显示它们的标记点. face_dataset = FaceLandmarksDataset(csv_file='faces/face_landmarks.csv', root_dir='faces/') fig = plt.figure() for i in range(len(face_dataset)): sample = face_dataset[i] print(i, sample['image'].shape, sample['landmarks'].shape) ax = plt.subplot(1, 4, i + 1) plt.tight_layout() ax.set_title('Sample #{}'.format(i)) ax.axis('off') show_landmarks(**sample) if i == 3: plt.show() break Transforms 我们可以看到上面输出的样例中的图像并不是同一尺寸的图片. 大多数神经网络需要输入 一个固定大小的图像, 因此我们需要写代码来处理. 让我们创建三个transform操作: Rescale: 修改图片尺寸 RandomCrop: 随机裁切图片, 这是数据增强的方法 ToTensor: 将numpy格式的图片转为torch格式的图片（我们需要交换坐标轴） 我们不将它们写成简单的函数, 而是写成可以调用的类, 这样transform的参数不需要每次都传递 如果需要的话, 我们只需实现 __call__ 方法和__init__ 方法.之后我们可以像下面这 样使用transform: tsfm = Transform(params) transformed_sample = tsfm(sample) 观察下面这些变换如何同时对图像和标记点改变的. class Rescale(object): \"\"\"按照给定尺寸更改一个图像的尺寸 Args: output_size (tuple or int): 要求输出的尺寸. 如果是个元组类型, 输出 和output_size匹配. 如果时int类型,图片的短边和output_size匹配, 图片的 长宽比保持不变. \"\"\" def __init__(self, output_size): assert isinstance(output_size, (int, tuple)) self.output_size = output_size def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] h, w = image.shape[:2] if isinstance(self.output_size, int): if h > w: new_h, new_w = self.output_size * h / w, self.output_size else: new_h, new_w = self.output_size, self.output_size * w / h else: new_h, new_w = self.output_size new_h, new_w = int(new_h), int(new_w) img = transform.resize(image, (new_h, new_w)) # 对于标记点, h和w需要交换位置, 因为对于图像, x和y分别时第1维和第0维 landmarks = landmarks * [new_w / w, new_h / h] return {'image': img, 'landmarks': landmarks} class RandomCrop(object): \"\"\"随机裁剪图片 Args: output_size (tuple or int): 期望输出的尺寸, 如果时int类型, 裁切成正方形. \"\"\" def __init__(self, output_size): assert isinstance(output_size, (int, tuple)) if isinstance(output_size, int): self.output_size = (output_size, output_size) else: assert len(output_size) == 2 self.output_size = output_size def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] h, w = image.shape[:2] new_h, new_w = self.output_size top = np.random.randint(0, h - new_h) left = np.random.randint(0, w - new_w) image = image[top: top + new_h, left: left + new_w] landmarks = landmarks - [left, top] return {'image': image, 'landmarks': landmarks} class ToTensor(object): \"\"\"将ndarrays的样本转化为Tensors的样本\"\"\" def __call__(self, sample): image, landmarks = sample['image'], sample['landmarks'] # 交换颜色通道, 因为 # numpy图片: H x W x C # torch图片 : C X H X W image = image.transpose((2, 0, 1)) return {'image': torch.from_numpy(image), 'landmarks': torch.from_numpy(landmarks)} Compose transforms 现在我们就将 transform 应用在一个样本上. 如果我们想将图片的短边变为256像素, 并且随后随机裁切成224像素的正方形. i.e, 我们可以组合Rescale和RandomCrop变换. torchvision.transforms.Compose 就是一个可以做这样一个组合的可调用的类. scale = Rescale(256) crop = RandomCrop(128) composed = transforms.Compose([Rescale(256), RandomCrop(224)]) # 对每个样本进行上面的每一个操作. fig = plt.figure() sample = face_dataset[65] for i, tsfrm in enumerate([scale, crop, composed]): transformed_sample = tsfrm(sample) ax = plt.subplot(1, 3, i + 1) plt.tight_layout() ax.set_title(type(tsfrm).__name__) show_landmarks(**transformed_sample) plt.show() 迭代整个数据集 让我们进行所有操作, 来创建结合了图像变换的数据集 总之, 每次迭代的数据: 从文件中读取图像 对所读的图像上应用变换 其中一个变换是随机的, 所以可以增强数据样本 我们可以像之前一样用 for i in range 循环从已创建的数据集中迭代 transformed_dataset = FaceLandmarksDataset(csv_file='faces/face_landmarks.csv', root_dir='faces/', transform=transforms.Compose([ Rescale(256), RandomCrop(224), ToTensor() ])) for i in range(len(transformed_dataset)): sample = transformed_dataset[i] print(i, sample['image'].size(), sample['landmarks'].size()) if i == 3: break 然而我们用简单的for循环来迭代整个数据集会丢失很多特点, 特别地, 我们会丢失: 批读取数据 打乱数据顺序 使用multiprocessing并行加载数据 torch.utils.data.DataLoader 是提供了所有上述特点的迭代器. 下面使用的参数应该很清晰. 其中一个有趣的参数是collate_fn. 你可以使用collate_fn来指定如何精确地读取一批的样本. 然而, 默认的collate在大部分的情况下都表现得很好 dataloader = DataLoader(transformed_dataset, batch_size=4, shuffle=True, num_workers=4) # 定义一个函数来查看某个 batch 的数据样本图片和标记点 def show_landmarks_batch(sample_batched): \"\"\"显示指定 batch 的数据样本的图片和标记点\"\"\" images_batch, landmarks_batch = \\ sample_batched['image'], sample_batched['landmarks'] batch_size = len(images_batch) im_size = images_batch.size(2) grid = utils.make_grid(images_batch) plt.imshow(grid.numpy().transpose((1, 2, 0))) for i in range(batch_size): plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size, landmarks_batch[i, :, 1].numpy(), s=10, marker='.', c='r') plt.title('Batch from dataloader') for i_batch, sample_batched in enumerate(dataloader): print(i_batch, sample_batched['image'].size(), sample_batched['landmarks'].size()) # 观察到第四批数据时停止 if i_batch == 3: plt.figure() show_landmarks_batch(sample_batched) plt.axis('off') plt.ioff() plt.show() break 后记: torchvision 在这个教程中, 我们学习了如何写和使用数据集, 图像变换和dataloder. torchvision 提供了常用的数据集和图像变换, 或许你甚至不必写自定义的类和变换. 在torchvision中一个最经常用的数据集是ImageFolder. 它要求数据按下面的形式存放: root/ants/xxx.png root/ants/xxy.jpeg root/ants/xxz.png . . . root/bees/123.jpg root/bees/nsdf3.png root/bees/asd932_.png ‘ants’, ‘bees’ 等是图像的类标. 同样, PIL.Image 中出现的一般的图像变换像 RandomHorizontalFlip, Scale 也是可以使用的. 你可以像下面这样用这些函数来写dataloader: import torch from torchvision import transforms, datasets data_transform = transforms.Compose([ transforms.RandomSizedCrop(224), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ]) hymenoptera_dataset = datasets.ImageFolder(root='hymenoptera_data/train', transform=data_transform) dataset_loader = torch.utils.data.DataLoader(hymenoptera_dataset, batch_size=4, shuffle=True, num_workers=4) 关于训练代码的例子, 请看 迁移学习教程. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"deep_learning_nlp_tutorial.html":{"url":"deep_learning_nlp_tutorial.html","title":"针对NLP的Pytorch深度学习","keywords":"","body":"针对NLP的Pytorch深度学习 译者：@JingTao、@friedhelm739 作者: Robert Guthrie 本教程将带你浏览基于Pytorch深度学习编程的核心思想.其中很多思想(例如计算图形抽象化以及自动求导) 并不是Pytorch特有的,他们和任何深度学习工具包都是相关的. 本教程针对那些从未在任何深度学习框架下编写过代码的人(例如TensorFlow,Theano, Keras, Dynet),并 专注于NLP.它提出了应用知识中NLP的核心问题:词性标注,语言建模等.它同样提出了在AI入门级别熟悉神经 网络(例如Russel和Norvig的书).通常情况下, 这些课程包括了基于前馈神经网络的基本的反向传播算法, 并使你了解到它们是线性和非线性组成的链条.本教程目的使你开始编写深度学习代码并给你首要必备的知识. 提示一下, 这仅关乎于 模型 , 并非是数据.针对所有模型,我仅仅提出了一些低纬度的例子 以便于你可以观察当训练时权重的变化.如果你有一些真实数据去尝试,可以将本教程中模型 复制下并将数据应用到模型上. PyTorch介绍 PyTorch深度学习 词汇嵌入:编码词汇语义 序列模型和 LSTM 网络（长短记忆网络） 高级教程: 作出动态决策和 Bi-LSTM CRF 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"nlp_pytorch_tutorial.html":{"url":"nlp_pytorch_tutorial.html","title":"PyTorch介绍","keywords":"","body":"PyTorch介绍 译者：@JingTao、@friedhelm739 Torch张量库介绍 所有的深度学习都是在张量上计算的,其中张量是一个可以被超过二维索引的矩阵的一般化. 稍后我们将详细讨论这意味着什么.首先,我们先来看一下我们可以用张量来干什么. # 作者: Robert Guthrie import torch import torch.autograd as autograd import torch.nn as nn import torch.nn.functional as F import torch.optim as optim torch.manual_seed(1) Creating Tensors(创建张量) 张量可以在Python list形式下通过torch.Tensor()函数创建. # 利用给定数据创建一个torch.Tensor对象.这是一个一维向量 V_data = [1., 2., 3.] V = torch.Tensor(V_data) print(V) # 创建一个矩阵 M_data = [[1., 2., 3.], [4., 5., 6]] M = torch.Tensor(M_data) print(M) # 创建2x2x2形式的三维张量. T_data = [[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]]] T = torch.Tensor(T_data) print(T) 什么是三维张量? 让我们这样想象.如果你有一个向量,那么对向量索引就会得到一个标量. 如果你有一个矩阵,对矩阵索引那么就会得到一个向量.如果你有一个三维张量,那么对其索引 就会得到一个矩阵! 针对术语的说明: 当我在本教程内使用”tensor”,它针对的是所有torch.Tensor对象.矩阵和向量是特殊的torch.Tensors, 他们的维度分别是1和2.当我说到三维张量,我会简洁的使用”3D tensor”. # 索引V得到一个标量 print(V[0]) # 索引M得到一个向量 print(M[0]) # 索引T得到一个矩阵 print(T[0]) 你也可以创建其他数据类型的tensors.默认的数据类型为Float(浮点型). 可以使用torch.LongTensor()来 创建一个整数类型的tensor.你可以在文件中寻找更多的数据类型,但是Float(浮点型)和Long(长整形)最常用的. 你可以使用torch.randn()创建一个随机数据和需要提供维度的tensor. x = torch.randn((3, 4, 5)) print(x) Operations with Tensors(对tensor进行操作) 你可以以你想要的方式操作tensor. x = torch.Tensor([1., 2., 3.]) y = torch.Tensor([4., 5., 6.]) z = x + y print(z) 可以查阅 文档 获取大量可用操作的完整列表, 扩展到了非数学操作. 接下来一个很有帮助的操作就是连接. # 默认情况下, 它沿着第一轴连接 (连接行) x_1 = torch.randn(2, 5) y_1 = torch.randn(3, 5) z_1 = torch.cat([x_1, y_1]) print(z_1) # 连接列: x_2 = torch.randn(2, 3) y_2 = torch.randn(2, 5) # 第二个数指定了沿着哪条轴连接 z_2 = torch.cat([x_2, y_2], 1) print(z_2) # 如果你的tensors是不兼容的,torch会报错.取消注释来查看错误. # torch.cat([x_1, x_2]) Reshaping Tensors(重构Tensors) 使用.view()去重构tensor.这是一个高频方法, 因为许多神经网络的神经元对输入格式 有明确的要求. 你通常需要先将数据重构再输入到神经元中. x = torch.randn(2, 3, 4) print(x) print(x.view(2, 12)) # 重构为2行12列 # 同上.如果维度为-1,那么它的维度根据数据推断出来 print(x.view(2, -1)) Computation Graphs and Automatic Differentiation(计算图和自动求导) 计算图的思想对于有效率的深度学习编程是很重要的, 因为它允许你不必去自己写反向梯度传播. 计算图只是简单地说明了如何将数据组合在一起以输出结果.因为图完全指定了操作所包含的参数, 因此它包含了足够的信息去求导.这可能听起来很模糊, 所以让我们看看使用Pytorch的基本类: autograd.Variable. 首先, 从程序员的角度来思考.在torch中存储了什么, 是我们在上面创建的Tensor对象吗? 显然, 是数据和 结构, 也很可能是其他的东西. 但是当我们将两个tensors相加后, 我们得到了一个输出tensor.这个输出所能 体现出的只有数据和结构, 并不能体现出是由两个tensors加和得到的(因为它可能是从一个文件中读取的, 也可能是 其他操作的结果等). 变量类别可以一直跟踪它是如何创建的.让我们在实际中来看. # 变量围绕tensor对象 x = autograd.Variable(torch.Tensor([1., 2., 3]), requires_grad=True) # 您可以使用.data属性访问数据. print(x.data) # 你也可以用变量来做与张量相同的运算. y = autograd.Variable(torch.Tensor([4., 5., 6]), requires_grad=True) z = x + y print(z.data) # 但是z知道一些额外的东西. print(z.grad_fn) 既然变量知道怎么创建的它们. z知道它并非是从文件读取的, 也不是乘法或指数或其他运算的结果. 如果你继续跟踪 z.grad_fn, 你会从中找到x和y的痕迹. 但是它如何帮助我们计算梯度? # 我们来将z中所有项作和运算 s = z.sum() print(s) print(s.grad_fn) 那么这个计算和对x的第一个分量的导数等于多少? 在数学上,我们求 s知道它是被tensor z的和创建的.z 知道它是x+y的和 z_0z_1z_2 并且s包含了足够的信息去决定我们需要的导数为1! 当然它掩盖了如何计算导数的挑战.这是因为s携带了足够多的信息所以导数可以被计算.现实中,Pytorch 程序的开发人员用程序指令sum()和 + 操作以知道如何计算它们的梯度并且运行反向传播算法.深入讨论此算法 超出了本教程的范围. 让我们用Pytorch计算梯度,发现我们是对的:(如果你运行这个方块很多次,梯度会上升,这是因为Pytorch accumulates (累积) 渐变为.grad属性, 因为对于很多模型它是很方便的.) # 在任意变量上使用 .backward()将会运行反向,从它开始. s.backward() print(x.grad) 对于一个成功的深度学习程序员了解下面的方块如何运行是至关重要的. x = torch.randn((2, 2)) y = torch.randn((2, 2)) z = x + y # 这些是Tensor类型,反向是不可能的 var_x = autograd.Variable(x, requires_grad=True) var_y = autograd.Variable(y, requires_grad=True) # var_z 包含了足够的信息去计算梯度,如下所示 var_z = var_x + var_y print(var_z.grad_fn) var_z_data = var_z.data # 从 var_z中得到包裹Tensor对象... # 在一个新的变量中重新包裹tensor new_var_z = autograd.Variable(var_z_data) # new_var_z 有去反向x和y的信息吗? # 没有! print(new_var_z.grad_fn) # 怎么会这样? 我们将 tensor 从 var_z 中提取 (提取为var_z.data). 这个张量不知道它是如 # 何计算的.我们把它传递给 new_var_z. # 这就是new_var_z得到的所有信息. 如果 var_z_data 不知道它是如何计算的, 那么就不会有 new_var_z 的方法. # 从本质上讲, 我们已经把这个变量从过去的历史中分离出来了. # 这就是基础的,但是对于计算自动求导是特别重要的规则 (这比Pytorch更通用,在每个主要的深度学习工具箱中都有一个相同的对象): 如果你想要从损失函数返回到神经网络的某个神经元得到错误,那么你就不能将断开从该组件到你的丢失变量的变量链.如果你这样做, 损失将不知道你的组件存在, 并且它的参数不能被更新. 我用粗体表示, 因为这个错误会在不经意间发生(我将在下面展示一些这样的方法), 并且它不会导致您的代码崩溃或报错, 所以您必须小心. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"nlp_deep_learning_tutorial.html":{"url":"nlp_deep_learning_tutorial.html","title":"PyTorch深度学习","keywords":"","body":"PyTorch深度学习 译者：@JingTao、@friedhelm739 深度学习构建模块: Affine maps, non-linearities and objectives 深度学习以巧妙的方式将non-linearities和linearities组合在一起.non-linearities的引入允许强大的模型. 在本节中, 我们将使用这些核心组件, 构建一个objective函数, 并且看看模型是如何训练的. Affine Maps 深度学习的核心工作之一是affine map, 这是一个函数 其中 对于矩阵 和向量 . 这里学习的参数是 and . 通常, 被称为 偏差 项. Pytorch和大多数其他深度学习框架与传统的线性代数有所不同.它映射输入的是行而不是列. 也就是说, 下面的输出的第 行是 的输入的第 行加上偏置项的映射. 看下面的例子. # 作者: Robert Guthrie import torch import torch.autograd as autograd import torch.nn as nn import torch.nn.functional as F import torch.optim as optim torch.manual_seed(1) lin = nn.Linear(5, 3) # 从 R^5 映射到 R^3, 参数 A, b # 数据是 2x5\\. A 是从 5 映射到 3... 我们能在A下映射得到想要的数据吗? data = autograd.Variable(torch.randn(2, 5)) print(lin(data)) # 是的 Non-Linearities(非线性) 首先, 注意以下将解释为什么我们首先需要 non-linearities.假设我们有两个 affine maps and . 什么是 ? 是一个矩阵, 是一个向量, 所以我们看到组合两个affine maps会得到一个affine map 由此可以看出, 如果你想让你的神经网络成为affine 组合的长链条, 那么相比于做一个简单的affine map, 此举不会给你的模型增加新的作用. 如果我们在affine层之间引入non-linearities, 则不再是这种情况, 我们可以构建更强大的模型. 接下来有一些重要的non-linearities. 是最常见的. 你可能想知道: “为什么这些函数？我可以想到很多其他的non-linearities 函数.” 其原因是他们的梯度容易计算, 并且计算梯度对学习是必不可少的. 例如 一个简单的提示: 虽然你可能已经在入门AI中学习到了一些神经网络, 其中 是默认的non-linearity, 但通常人们在实践中会避免它. 这是因为随着参数绝对值的增长, 梯度会很快 消失 . 小梯度意味着很难学习. 大多数人默认tanh或ReLU. # 在pytorch中, 很多的non-linearities是在torch中.是功能性的 (我们将它记为 F) # 这意味着 non-linearites 不像 affine maps 一样拥有参数.也意味着它们再训练时没有可以更新的参数. # data = autograd.Variable(torch.randn(2, 2)) print(data) print(F.relu(data)) Softmax and Probabilities(Softmax和概率分布) 函数 也是一个 non-linearity, 但它的特殊之处在于它通常是网络中一次操作. 这是因为它接受了一个实数向量并返回一个概率分布.其定义如下. 定义 是一个实数的向量(正数或负数都无所谓, 没有限制). 然后, 第i个 的组成是 应该清楚的是, 输出是一个概率分布: 每个元素都是非负的, 并且所有元素的总和都是1. 你也可以把它看作只是将一个元素明确的指数运算符应用于输入, 以使所有内容都为非负值, 然后除以归一化常数. # Softmax也在 torch.nn.functional data = autograd.Variable(torch.randn(5)) print(data) print(F.softmax(data, dim=0)) print(F.softmax(data, dim=0).sum()) #总和为一因为他是概率分布! print(F.log_softmax(data, dim=0)) # 他也是 log_softmax Objective Functions(目标函数) Objective function 是一个目标函数，你训练网络的目的是使其最小(在这种情况下, 它通常被称为 损失函数 或 成本函数 ). 首先选择一个训练实例, 通过神经网络运行它, 计算输出的损失. 然后利用损失函数的导数来更新模型的参数. 直观地说, 如果你的模型对答案完全有信心, 但答案是错误的, 你的损失就会很高. 如果它的答案非常有信心, 而且答案是正确的, 那么损失就会很低. 将训练样例的损失函数最小化的想法是, 你的网络希望能够很好地产生, 并且在开发集, 测试集或生产环境中未知的示例有小的损失. 一个示例损失函数是 负对数似然损失 , 这是多类分类的一个非常普遍的目标函数. 对于有监督的多类别分类, 这意味着训练网络以最小化正确输出的负对数概率(或等同地, 最大化正确输出的对数概率). Optimization and Training(优化和训练) 那么我们可以计算一个实例的损失函数?我们该怎么做?我们之前看到autograd.变量知道如何计算与计算梯度有关的事物.那么, 因为我们的损失是一个 autograd. 对于 Variable, 我们可以对所有用于计算的参数计算梯度！然后我们可以执行标准渐变更新. 令 是我们的参数, 损失函数, 以及: 是一个正的的学习率. 然后: 有大量的算法和积极的研究去尝试比vanilla梯度更新更出色的方法. 许多人试图根据训练的情况改变学习率. 除非你真的感兴趣, 否则你不必担心这些算法具体做什么. Torch提供了许多 torch.optim 包, 它们都是开源的.使用最简单的梯度更新与更复杂的算法效果相同.尝试不同的更新算法和更新算法的不同参数(如不同的初始学习速率)对于优化网络性能非常重要. 通常, 只需用Adam或RMSProp等优化器替换vanilla SGD 即可显着提升性能. Creating Network Components in Pytorch(在Pytorch中创建神经元) 在我们开始关注NLP之前, 让我们做一个注释的例子, 在Pytorch中只使用affine maps和non-linearities构建网络.我们还将看到如何使用Pytorch建立的负对数似然计算损失函数, 并通过反向传播更新参数. 所有神经元都应该从nn.Module继承并覆盖forward()方法.就样板而言就是这样.从nn.Module继承能为你的神经元提供功能.例如, 它可以跟踪其可训练的参数, 可以使用.cuda()或.cpu()函数等在CPU和GPU之间交换, 等等. 我们来编写一个带有注释的网络示例, 该网络采用稀疏的词袋表示法, 并输出概率分布在两个标签上: “英语”和“西班牙语”.使用的模型是逻辑回归. 示例： Logistic Regression Bag-of-Words classifier(例子: 基于词袋表示法的逻辑斯蒂回归分类器) 我们的模型将映射一个稀疏的BOW表示来记录标签上的概率.我们为词汇表中的每个单词分配一个索引. 例如, 我们的完整的词汇表有两个单词: “你好” 和 “世界”, 这两个单词的索引分别为0和1. 句子为 “hello hello hello hello” 的BoW向量为 对于 “hello world world hello” , 它是 等等.一般来说, 它是 将这个BOW向量表示为 . 我们的网络输出是: 也就是说, 我们通过affine map传递输入, 然后进行softmax. data = [(\"me gusta comer en la cafeteria\".split(), \"SPANISH\"), (\"Give it to me\".split(), \"ENGLISH\"), (\"No creo que sea una buena idea\".split(), \"SPANISH\"), (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\")] test_data = [(\"Yo creo que si\".split(), \"SPANISH\"), (\"it is lost on me\".split(), \"ENGLISH\")] # word_to_ix 将在词汇中的单词映射为一个特征数, # 这个特征数就是单词在词袋中的索引 word_to_ix = {} for sent, _ in data + test_data: for word in sent: if word not in word_to_ix: word_to_ix[word] = len(word_to_ix) print(word_to_ix) VOCAB_SIZE = len(word_to_ix) NUM_LABELS = 2 class BoWClassifier(nn.Module): # 从 nn.Module继承! def __init__(self, num_labels, vocab_size): # 在 nn.Module中调用初始化函数. 不要被这个困惑, # 这个做法经常在 nn.Module见到 super(BoWClassifier, self).__init__() # 定义你需要的变量. 在本例中, 我们需要affine mapping的系数 A 和 b. # Torch 定义了可提供 affine map的nn.Linear(). # 确定你理解了为什么输入矩阵的维度是 vocab_size而输出的是num_labels! self.linear = nn.Linear(vocab_size, num_labels) # 注意! non-linearity log softmax 没有系数! # 所以我们在这并不需要担心 def forward(self, bow_vec): # 将输入引入到线性神经元层中, 随后引入到log_softmax. # 在torch.nn.functional中有很多非线性和其他的函数 return F.log_softmax(self.linear(bow_vec), dim=1) def make_bow_vector(sentence, word_to_ix): vec = torch.zeros(len(word_to_ix)) for word in sentence: vec[word_to_ix[word]] += 1 return vec.view(1, -1) def make_target(label, label_to_ix): return torch.LongTensor([label_to_ix[label]]) model = BoWClassifier(NUM_LABELS, VOCAB_SIZE) # model知道它的系数.第一个输出的是A, 第二个是b. # 当你在模块__init__函数中指定一个神经元去分类变量, self.linear = nn.Linear(...)被执行 # 随后从Pytorch devs通过Python magic, 你的模块(在本例中, BoWClassifier) 将会存储 nn.Linear的系数 for param in model.parameters(): print(param) # 要运行该模型, 请传入一个BoW vector, 但要将其封装在一个autograd.Variable中. sample = data[0] bow_vector = make_bow_vector(sample[0], word_to_ix) log_probs = model(autograd.Variable(bow_vector)) print(log_probs) 以上哪个值对应于”英语”的概率, 以及哪个值是”西班牙语”?我们从来没有定义过它, 但如果我们想要训练这个模型, 我们需要去定义. label_to_ix = {\"SPANISH\": 0, \"ENGLISH\": 1} 来做训练吧！要做到这一点, 我们通过实例来获取概率, 计算损失函数, 计算损失函数的梯度, 然后用梯度步骤更新参数.Torch在nn软件包中提供了损失函数.nn.NLLLoss()是我们想要的负对数似然损失.它还定义了torch.optim中的优化函数.在这里, 我们只使用SGD. 请注意, NLLLoss 的 输入 是一个对数概率向量和一个目标标签. 它不会为我们计算对数概率. 这就是为什么我们网络的最后一层是log softmax. 损失函数 nn.CrossEntropyLoss() 与 NLLLoss() 相同, 唯一的不同是它为你去做 softmax. # 在我们训练前运行训练集, 去看看前后的变化 for instance, label in test_data: bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix)) log_probs = model(bow_vec) print(log_probs) # 在矩阵中输出\"creo\"列 print(next(model.parameters())[:, word_to_ix[\"creo\"]]) loss_function = nn.NLLLoss() optimizer = optim.SGD(model.parameters(), lr=0.1) # 通常你想要多次浏览训练集.100比起实际数据集是很多的, 但实际数据集会多于2个实例. # 通常, 在5到30之间是合理的. for epoch in range(100): for instance, label in data: # 步骤 1\\. 牢记 Pytorch 会积累梯度. # 我们需要在每一例前清理掉 model.zero_grad() # 步骤 2\\. 制作我们的 BOW 向量 并且我们必须将目标封装在变量中并且为整数 . # 例如, 如果目标是\"西班牙语\", 则封装为整数0.对于损失函数而言, 概率分布的 # 第0列对应的是\"西班牙语\"的损失函数. # bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix)) target = autograd.Variable(make_target(label, label_to_ix)) # 步骤 3\\. Run our forward pass. log_probs = model(bow_vec) # 步骤 4\\. 计算损失, 梯度, 通过调用optimizer.step()来更新系数 # loss = loss_function(log_probs, target) loss.backward() optimizer.step() for instance, label in test_data: bow_vec = autograd.Variable(make_bow_vector(instance, word_to_ix)) log_probs = model(bow_vec) print(log_probs) # 对应于西班牙语上升, 英语下降! print(next(model.parameters())[:, word_to_ix[\"creo\"]]) 我们得到了正确的答案! 你可以看到, 第一个示例中西班牙语的概率要高得多, 而测试数据的第二个英语概率应该高得多. 现在你看到了如何制作一个Pytorch组件, 通过它传递一些数据并做梯度更新.我们准备深入挖掘NLP所能提供的内容. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"nlp_word_embeddings_tutorial.html":{"url":"nlp_word_embeddings_tutorial.html","title":"词汇嵌入:编码词汇语义","keywords":"","body":"词汇嵌入:编码词汇语义 译者：@JingTao、@friedhelm739 单词嵌入是真实数字的密集向量,在你的词汇表中每一个单词都是. 在NLP中, 通常情况下, 您的特性就是单词!但是你应该怎么在你的电脑中表示一个单词?可以存储它的ascii字符表示, 但那仅仅告诉你单词 是 什么,没有说太多它 意味 着什么 (你也许可以从它的词缀中派生出它的词性, 或者从它的大小写中得到它的属性,但并不多.). 更重要的是, 在什么意义上你能把这些表象结合起来? 我们经常需要神经网络的密集输出, 输入为 维, 其中 是我们的词汇表, 但经常输出是更小维度的 (如果我们只预测少量的标签的话). 我们如何从一个大的维度空间得到一个更小的维度空间? 如果我们不用 ascii 字符表示, 而使用one-hot encoding呢? 那就是, 我们用如下所示表示 字符 其中 1 是 的特征位置.其他的单词也是在其他位置有一个1, 在另外的位置都是0. 除了巨大的占用空间外,这种表述有一个巨大的缺陷. 它仅仅简单的把所有的单词都看作独立实体认 为它们彼此之间毫无关联.我们真正想要的是单词之间有一些 相似 .为什么? 让我们来看一下例子. 假设我们正在搭建一个语言模型. 假设我们在训练集中看到了如下语句. The mathematician ran to the store. The physicist ran to the store. The mathematician solved the open problem. 现在假设我们得到了一个在训练集从未看到过的新句子: The physicist solved the open problem. 我们的语言模型对此句可能运行的不错, 但如果我们能使用以下两个事实,情况会好得多吗: 我们看到数学家和物理学家在句子中有着相同的作用.它们之间有一个语义关系. 我们已经看到数学家在这个新的没看过的的句子中扮演着同样的角色, 就像我们现在看到的物理学家一样. 然后我们就推断物理学家在这个句子里是很合适的?这就是我们指的相似的意思:我们指的是 语义相似度, 不仅仅是拼字一样的表示. 它是一种通过连接我们所看到的和我们没有看到的东西之间的点来对抗语言数据稀疏性的技术. 这个例子当然要依赖于一个基本的语言假设:在相似的语境中出现的单词在语义上是相互关联的. 这被叫做 distributional hypothesis. Getting Dense Word Embeddings(密集字嵌入) 我们如何来解决那个问题?我们怎么能在单词中编码语义相似呢? 也许我们会想出一些语义属性. 举个例子, 我们看到了, 数学家和物理学家都会跑, 也许我们可以把”能跑”这个语义属性给一个高分. 考虑一下其他的属性, 想象一下, 你可能会在这些属性上给一些普通的单词得分. 如果每一个属性都是一维, 那我们可以给一个向量代表一个单词, 像这样: 这样我们就可以通过如下来得到这些单词之间的相似度: 尽管通常情况下需要归一化: 其中 是两个向量的角度. 这就意味着,极端相似的单词(嵌入方向是同一个) 会得到相似度为1.反之为 -1. 你可以认为本章刚开始的稀疏one-hot 向量是我们刚定义向量的特殊形式,其中单词的相似度为 0, 然后我们可以给每一个单词一些独特的语义属性.这些向量是 密集的 , 也就是说他们是非零的. 但是这些新的向量是一种巨大的痛苦:你可以想到数千种不同的语义属性,它们可能与决定相似性有关, 而且究竟你怎样把它们设置成不同的属性? 深度学习的中心思想是比起需要程序员去自己设计特征, 神经网络学习特征的表示. 所以为什么不在我们的模型中让单词嵌入到系数中,然后让它们在训练中更新呢? 这就是我们要做的. 我们会有一些 潜在的语义属性 网络可以, 严肃来讲, 学习. 注意, 嵌入词可能无法解释. 那就是尽管如上所示我们手工制作的矢量图,我们可以看到数学家和物理学家的相似之处是他们都喜欢咖啡. 如果我们允许神经网络学习嵌入, 并看到数学家和物理学家在第二个维度中有很大的价值, 但是它意味着什么很不清晰. 在潜在语义来讲它们是相似的, 但是对我们来说是无法解释的. 总结一下, 单词嵌入是一个单词 语义 的表示,语义信息的有效编码可能与手头任务相关. 你也可以嵌入其他的东西: 部分的语音标签, 解析树, 其他任何东西! 特征嵌入是这个领域的核心思想. Word Embeddings in Pytorch（Pytorch中的单词嵌入） 在我们举例或练习之前, 关于如何在Pytorch中使用嵌入以及在一般的深度学习编程中,有一些快速 的说明.与制作one-hot向量时我们对每一个单词定义一个特别的索引相似,单词嵌入时同样需要对每 一个单词定义一个特别的索引. 这些将是查找表中的键. 意思是,嵌入被储存为一个 矩阵, 其中 是嵌入的维度, 这样的词被赋予了索引 它的嵌入被储存在矩阵的 第 行. 在所有的代码中, 从单词到索引的映射是一个命名的字典 word_to_ix. 允许你使用嵌入的模块式 torch.nn.Embedding,这需要两个参数:词汇量和嵌入的维度. 为了索引到这个表中,你需要使用 torch.LongTensor (索引为整数,不能为浮点数). # 作者: Robert Guthrie import torch import torch.autograd as autograd import torch.nn as nn import torch.nn.functional as F import torch.optim as optim torch.manual_seed(1) word_to_ix = {\"hello\": 0, \"world\": 1} embeds = nn.Embedding(2, 5) # 2 单词, 5 维嵌入 lookup_tensor = torch.LongTensor([word_to_ix[\"hello\"]]) hello_embed = embeds(autograd.Variable(lookup_tensor)) print(hello_embed) 例子: N-Gram 语言模型 回想一下 在n-gram语言模型中,给定一系列单词 , 我们需要计算 是句子中第i个单词. 本例中, 我们将计算一些训练集的损失函数并且用反向传播更新系数. CONTEXT_SIZE = 2 EMBEDDING_DIM = 10 # 我们将使用 Shakespeare Sonnet 2 test_sentence = \"\"\"When forty winters shall besiege thy brow, And dig deep trenches in thy beauty's field, Thy youth's proud livery so gazed on now, Will be a totter'd weed of small worth held: Then being asked, where all thy beauty lies, Where all the treasure of thy lusty days; To say, within thine own deep sunken eyes, Were an all-eating shame, and thriftless praise. How much more praise deserv'd thy beauty's use, If thou couldst answer 'This fair child of mine Shall sum my count, and make my old excuse,' Proving his beauty by succession thine! This were to be new made when thou art old, And see thy blood warm when thou feel'st it cold.\"\"\".split() # 我们应该对输入进行标记,但是我们将忽略它 # 建造一系列元组. 每个元组 ([ word_i-2, word_i-1 ], 都是目标单词) trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2]) for i in range(len(test_sentence) - 2)] # 输出前 3, 为了让你看到他的各式 print(trigrams[:3]) vocab = set(test_sentence) word_to_ix = {word: i for i, word in enumerate(vocab)} class NGramLanguageModeler(nn.Module): def __init__(self, vocab_size, embedding_dim, context_size): super(NGramLanguageModeler, self).__init__() self.embeddings = nn.Embedding(vocab_size, embedding_dim) self.linear1 = nn.Linear(context_size * embedding_dim, 128) self.linear2 = nn.Linear(128, vocab_size) def forward(self, inputs): embeds = self.embeddings(inputs).view((1, -1)) out = F.relu(self.linear1(embeds)) out = self.linear2(out) log_probs = F.log_softmax(out, dim=1) return log_probs losses = [] loss_function = nn.NLLLoss() model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE) optimizer = optim.SGD(model.parameters(), lr=0.001) for epoch in range(10): total_loss = torch.Tensor([0]) for context, target in trigrams: # 步骤 1\\. 准备好进入模型的数据 (例如将单词转换成整数索引,并将其封装在变量中) context_idxs = [word_to_ix[w] for w in context] context_var = autograd.Variable(torch.LongTensor(context_idxs)) # 步骤 2\\. 回调 *积累* 梯度. 在进入一个实例前,需要将之前的实力梯度置零 model.zero_grad() # 步骤 3\\. 运行反向传播,得到单词的概率分布 log_probs = model(context_var) # 步骤 4\\. 计算损失函数. (再次注意, Torch需要将目标单词封装在变量中) loss = loss_function(log_probs, autograd.Variable( torch.LongTensor([word_to_ix[target]]))) # 步骤 5\\. 反向传播并更新梯度 loss.backward() optimizer.step() total_loss += loss.data losses.append(total_loss) print(losses) # 在训练集中每次迭代损失都会减小! Exercise: Computing Word Embeddings: Continuous Bag-of-Words(练习: 计算单词嵌入: 连续单词包) 连续单词包模型 (CBOW) 在NLP深度学习中使用的很频繁. 这个模型尝试去预测文中目标单词的 前后一些单词. 它有别于语言建模, 因为CBOW不是顺序的, 也不需要是概率性的.CBOW被用来快 速训练单词嵌入,而这些嵌入被用来初始化一些复杂模型的嵌入.通常情况下, 这被称为 预训练嵌入 . 它几乎总是能帮助提升百分之几的性能. CBOW模型如下所示.给定一个目标单词 和 代表单词每一遍的滑窗距, 和 , 将所有上下文词统称为 ,CBOW试图去最小化如下 其中 是单词 的嵌入. 在Pytorch中通过填充下面的类来实现这个模型. 一些建议: 想好你需要定义的系数. 确保你知道每一步操作后的构造. 如果想要重构请使用 .view(). CONTEXT_SIZE = 2 # 左右各2个单词 raw_text = \"\"\"We are about to study the idea of a computational process. Computational processes are abstract beings that inhabit computers. As they evolve, processes manipulate other abstract things called data. The evolution of a process is directed by a pattern of rules called a program. People create programs to direct processes. In effect, we conjure the spirits of the computer with our spells.\"\"\".split() # 通过从 `raw_text` 得到一组单词, 进行去重操作 vocab = set(raw_text) vocab_size = len(vocab) word_to_ix = {word: i for i, word in enumerate(vocab)} data = [] for i in range(2, len(raw_text) - 2): context = [raw_text[i - 2], raw_text[i - 1], raw_text[i + 1], raw_text[i + 2]] target = raw_text[i] data.append((context, target)) print(data[:5]) class CBOW(nn.Module): def __init__(self): pass def forward(self, inputs): pass # 创建模型并且训练. 这里有一些函数可以在使用模型之前帮助你准备数据 def make_context_vector(context, word_to_ix): idxs = [word_to_ix[w] for w in context] tensor = torch.LongTensor(idxs) return autograd.Variable(tensor) make_context_vector(data[0][0], word_to_ix) # 例子 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"nlp_sequence_models_tutorial.html":{"url":"nlp_sequence_models_tutorial.html","title":"序列模型和 LSTM 网络（长短记忆网络）","keywords":"","body":"序列模型和 LSTM 网络（长短记忆网络） 译者：@JingTao、@friedhelm739 之前我们已经学过了许多的前馈网络. 所谓前馈网络, 就是网络中不会保存状态. 然而有时 这并不是我们想要的效果. 在自然语言处理 (NLP, Natural Language Processing) 中, 序列模型是一个核心的概念. 所谓序列模型, 即输入依赖于时间信息的模型. 一个典型 的序列模型是隐马尔科夫模型 (HMM, Hidden Markov Model). 另一个序列模型的例子 是条件随机场 (CRF, Conditional Random Field). 递归神经网络是指可以保存某种状态的神经网络. 比如说, 网络上个时刻的输出可以作为下个 时刻的输入, 这样信息就可以通过序列在网络中一直往后传递. 对于LSTM (Long-Short Term Memory) 来说, 序列中的每个元素都有一个相应的隐状态 , 该隐状态 原则上可以包含序列当前结点之前的任一节点的信息. 我们可以使用隐藏状态来预测语言模型 中的单词, 词性标签以及其他各种各样的东西. Pytorch 中的 LSTM 开始例子之前,有几个点说明一下. Pytorch 中, LSTM 的所有的形式固定为3D 的 tensor. 每个维度有固定的语义含义, 不能乱掉. 其中第一维是序列本身, 第二维以 mini-batch 形式 来索引实例, 而第三维则索引输入的元素. 因为我们没有讨论过 mini-batch, 所以在这里我们 假设第二维的维度总是1. 如果我们想在句子 “The cow jumped” 上运行一个序列模型, 模型 的输入类似这样: 除了有一个额外的大小为1的第二维度. 此外, 你还可以向网络逐个输入序列, 在这种情况下, 第一个轴的大小也是1. 来看一个简单的例子. # 作者: Robert Guthrie import torch import torch.autograd as autograd import torch.nn as nn import torch.nn.functional as F import torch.optim as optim torch.manual_seed(1) lstm = nn.LSTM(3, 3) # 输入维度是3, 输出维度也是3 inputs = [autograd.Variable(torch.randn((1, 3))) for _ in range(5)] # 构造一个长度为5的序列 # 初始化隐藏状态 hidden = (autograd.Variable(torch.randn(1, 1, 3)), autograd.Variable(torch.randn((1, 1, 3)))) for i in inputs: # 将序列的元素逐个输入到LSTM # 经过每步操作,hidden 的值包含了隐藏状态的信息 out, hidden = lstm(i.view(1, 1, -1), hidden) # 另外, 我们还可以一次对整个序列进行训练. LSTM 返回的第一个值表示所有时刻的隐状态值, # 第二个值表示最近的隐状态值 (因此下面的 \"out\"的最后一个值和 \"hidden\" 的值是一样的). # 之所以这样设计, 是为了通过 \"out\" 的值来获取所有的隐状态值, 而用 \"hidden\" 的值来 # 进行序列的反向传播运算, 具体方式就是将它作为参数传入后面的 LSTM 网络. # 增加额外的第二个维度 inputs = torch.cat(inputs).view(len(inputs), 1, -1) hidden = (autograd.Variable(torch.randn(1, 1, 3)), autograd.Variable( torch.randn((1, 1, 3)))) # 清空输出隐状态 out, hidden = lstm(inputs, hidden) print(out) print(hidden) 例子: 用 LSTM 来进行词性标注 在这部分, 我们将会使用一个 LSTM 网络来进行词性标注. 在这里我们不会用到维特比算法, 前向后向算法或者任何类似的算法, 而是将这部分内容作为一个 (有挑战) 的练习留给读者, 希望读者在了解了这部分的内容后能够实现如何将维特比算法应用到 LSTM 网络中来. 整个模型的参数定义如下: 输入的句子定义为 , 其中动词定义 为 , 标签集合定义为 , 单词 的实际 标签为 . 定义单词 的预测标签为 . 这是一个结构预测模型, 我们的输出是一个序列 , 其中 . 在进行预测时, 需将句子每个词输入到一个 LSTM 网络中. 将时刻 的隐状态标记 为 . 同样地, 对每个标签赋一个独一无二的索引 (类似 word embeddings 部分 word_to_ix 的设置). 然后就得到了 的预测规则: 即先对隐状态进行一个仿射变换, 然后计算一个对数 softmax, 最后得到的预测标签即为对数 softmax 中最大的值对应的标签. 注意, 这也意味着 空间的维度是 . 准备数据: def prepare_sequence(seq, to_ix): idxs = [to_ix[w] for w in seq] tensor = torch.LongTensor(idxs) return autograd.Variable(tensor) training_data = [ (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]), (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"]) ] word_to_ix = {} for sent, tags in training_data: for word in sent: if word not in word_to_ix: word_to_ix[word] = len(word_to_ix) print(word_to_ix) tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2} # 实际中通常使用更大的维度如32维, 64维. # 这里我们使用小的维度, 为了方便查看训练过程中权重的变化. EMBEDDING_DIM = 6 HIDDEN_DIM = 6 构造模型: class LSTMTagger(nn.Module): def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size): super(LSTMTagger, self).__init__() self.hidden_dim = hidden_dim self.word_embeddings = nn.Embedding(vocab_size, embedding_dim) # LSTM 以 word_embeddings 作为输入, 输出维度为 hidden_dim 的隐状态值 self.lstm = nn.LSTM(embedding_dim, hidden_dim) # 线性层将隐状态空间映射到标注空间 self.hidden2tag = nn.Linear(hidden_dim, tagset_size) self.hidden = self.init_hidden() def init_hidden(self): # 开始时刻, 没有隐状态 # 关于维度设置的详情,请参考 Pytorch 文档 # 各个维度的含义是 (num_layers, minibatch_size, hidden_dim) return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)), autograd.Variable(torch.zeros(1, 1, self.hidden_dim))) def forward(self, sentence): embeds = self.word_embeddings(sentence) lstm_out, self.hidden = self.lstm( embeds.view(len(sentence), 1, -1), self.hidden) tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1)) tag_scores = F.log_softmax(tag_space, dim=1) return tag_scores 训练模型: model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix)) loss_function = nn.NLLLoss() optimizer = optim.SGD(model.parameters(), lr=0.1) # 查看下训练前得分的值 # 注意: 输出的 i,j 元素的值表示单词 i 的 j 标签的得分 inputs = prepare_sequence(training_data[0][0], word_to_ix) tag_scores = model(inputs) print(tag_scores) for epoch in range(300): # 再次说明下, 实际情况下你不会训练300个周期, 此例中我们只是构造了一些假数据 for sentence, tags in training_data: # Step 1\\. 请记住 Pytorch 会累加梯度 # 每次训练前需要清空梯度值 model.zero_grad() # 此外还需要清空 LSTM 的隐状态 # 将其从上个实例的历史中分离出来 model.hidden = model.init_hidden() # Step 2\\. 准备网络输入, 将其变为词索引的 Variables 类型数据 sentence_in = prepare_sequence(sentence, word_to_ix) targets = prepare_sequence(tags, tag_to_ix) # Step 3\\. 前向传播 tag_scores = model(sentence_in) # Step 4\\. 计算损失和梯度值, 通过调用 optimizer.step() 来更新梯度 loss = loss_function(tag_scores, targets) loss.backward() optimizer.step() # 查看训练后得分的值 inputs = prepare_sequence(training_data[0][0], word_to_ix) tag_scores = model(inputs) # 句子是 \"the dog ate the apple\", i,j 表示对于单词 i, 标签 j 的得分. # 我们采用得分最高的标签作为预测的标签. 从下面的输出我们可以看到, 预测得 # 到的结果是0 1 2 0 1\\. 因为 索引是从0开始的, 因此第一个值0表示第一行的 # 最大值, 第二个值1表示第二行的最大值, 以此类推. 所以最后的结果是 DET # NOUN VERB DET NOUN, 整个序列都是正确的! print(tag_scores) 练习: 使用字符级特征来增强 LSTM 词性标注器 在上面的例子中, 每个词都有一个词嵌入, 作为序列模型的输入. 接下来让我们使用每个的单词的 字符级别的表达来增强词嵌入. 我们期望这个操作对结果能有显著提升, 因为像词缀这样的字符级 信息对于词性有很大的影响. 比如说, 像包含词缀 -ly 的单词基本上都是被标注为副词. 具体操作如下. 用 来表示单词 的字符级表达, 同之前一样, 我们使 用 来表示词嵌入. 序列模型的输入就变成了 和 的拼接. 因此, 如果 的维度是5, 的维度是3, 那么我们的 LSTM 网络的输入维度大小就是8. 为了得到字符级别的表达, 将单词的每个字符输入一个 LSTM 网络, 而 则为这个 LSTM 网络最后的隐状态. 一些提示: 新模型中需要两个 LSTM, 一个跟之前一样, 用来输出词性标注的得分, 另外一个新增加的用来 获取每个单词的字符级别表达. 为了在字符级别上运行序列模型, 你需要用嵌入的字符来作为字符 LSTM 的输入. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"nlp_advanced_tutorial.html":{"url":"nlp_advanced_tutorial.html","title":"高级教程: 作出动态决策和 Bi-LSTM CRF","keywords":"","body":"高级教程: 作出动态决策和 Bi-LSTM CRF 译者：@JingTao、@friedhelm739 动态 VS 静态深度学习工具集 Pytorch 是一个 动态 神经网络工具包. 另一个动态工具包的例子是 Dynet (我之所以提这个是因为使用 Pytorch 和 Dynet 是十分类似的. 如果你看过 Dynet 中的例子, 那么它将有可能对你在 Pytorch 下实现它有帮助). 与动态相反的是 静态 工具包, 包括了 Theano, Keras, TensorFlow 等等. 下面是这两者核心的一些区别: 在一个静态工具包中, 你一次性定义好一个计算图, 接着编译它, 然后把数据流输实例送进去. 在一个动态工具包中, 你 为每一个实例 定义一个计算图, 它完全不需要被编译并且是在运行中实时执行的. 若没有丰富的经验, 你很难体会出其中的差别. 举一个例子, 假设我们想要构建一个深度句法分析器. 那么我们的模型需要下列的一些步骤: 我们从下往上构建树 标注根节点(句子中的词语) 从那儿开始, 使用一个神经网络和词向量来找到组成句法的不同组合. 一旦当你形成了一个新的句法, 使用某种方式得到句法的嵌入表示 (embedding). 在这个例子里, 我们的网络架构将会 完全的依赖于输入的句子. 来看这个句子: “绿色猫抓了墙”, 在这个模型的某一节点, 我们想要把范围 合并起来(即, 一个 NP 句法范围跨越词1到词3, 在这个例子中是”绿色猫”). 然而, 另一个句子可能是”某处, 那个大肥猫抓了墙.” 在这个句子中, 我们想要在某点形成句法 . 我们想要形成的句法将会依赖于这个实例. 如果仅仅编译这个计算图一次, 就像在静态工具包中那样, 那么我们给这个逻辑编程将会变得十分困难或者根本不可能. 然而, 在一个动态工具包中, 并不仅仅只有一个预定义的计算图. 对于每一个实例, 都能够有一个新的计算图, 所以上面的问题就不复存在了. 动态工具包也具有更容易调试和更接近所使用的编程语言的特点(我的意思是 Pytorch 和 Dynet 看上去 比 Keras 和 Theano 更像 Python). Bi-LSTM CRF (条件随机场) 讨论 在这一部分, 我们将会看到一个完整且复杂的 Bi-LSTM CRF (条件随机场)用来命名实体识别 (NER) 的例子. 上面的 LSTM 标注工具通常情况下对词性标注已经足够用了, 但一个序列模型比如 CRF 对于在 NER 下取得 强劲的表现是至关重要的. 假设熟悉 CRF. 尽管这个名字听上去吓人, 但所有的模型只是一个由 LSTM 提供 特征的 CRF. 但这是一个高级的模型, 远比这个教程中的其它早期的模型更加复杂. 如果你要跳过这一部分, 没有关系. 想要确定你是否准备好, 那看看你是不是能够: 复现标签 k 的第 i 步维特比变量的算法. 修改上述循环来计算正向变量. 再一次修改上述复现来在对数空间中计算正向变量. (提示: 对数-求和-指数) 如果你能够完成以上三件事, 那么你就不难理解下面的代码了. 回想一下, CRF 计算的是一个条件概率. 让 作为一个标注序列, 作为某个词的输入序列. 接下来我们计算: 上面的分数 Score 是由定义一些对数势能 而决定的. 进而 要使分割函数易于掌控, 势能必须只能集中于局部的特征. 在 Bi-LSTM CRF 中, 我们定义两种势能 (potential): 释放 (emission) 和过渡 (transition). 索引 处字的释放势能来自于 时间处的 Bi-LSTM 的隐藏状态. 过渡势能的分数储存在 矩阵 , 其中 是标注集合. 在我的实现中, 是从标注 过渡到 标注 的得分. 因此: 在上面第二个表达式中, 我们认为标签被分配了独一无二的非负索引. 如果上面的讨论太简短了, 你还可以看看 这个 由 Michael Collins 写的关于 CRFs 的文章. 具体实现笔记 下面的例子实现了在对数空间中的前向算法来计算出分割函数和维特比算法来进行译码. 反向传播将会为我们自动计算出梯度. 我们不需要手动去实现这个. 这个代码中的实现并没有优化过. 如果你理解下面的过程, 也许你会觉得下面的代码中, 前向算法中 的迭代下一次标注可以在一次大的运算中完成. 虽然有简化的余地, 但我想的是让代码可读性更好. 如果你想进行相关的修改, 也许你可以在一些真实的任务中使用这个标注器. # 作者: Robert Guthrie import torch import torch.autograd as autograd import torch.nn as nn import torch.optim as optim torch.manual_seed(1) 一些帮助函数, 使代码可读性更好 def to_scalar(var): # 返回 python 浮点数 (float) return var.view(-1).data.tolist()[0] def argmax(vec): # 以 python 整数的形式返回 argmax _, idx = torch.max(vec, 1) return to_scalar(idx) def prepare_sequence(seq, to_ix): idxs = [to_ix[w] for w in seq] tensor = torch.LongTensor(idxs) return autograd.Variable(tensor) # 使用数值上稳定的方法为前向算法计算指数和的对数 def log_sum_exp(vec): max_score = vec[0, argmax(vec)] max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1]) return max_score + \\ torch.log(torch.sum(torch.exp(vec - max_score_broadcast))) 创建模型 class BiLSTM_CRF(nn.Module): def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim): super(BiLSTM_CRF, self).__init__() self.embedding_dim = embedding_dim self.hidden_dim = hidden_dim self.vocab_size = vocab_size self.tag_to_ix = tag_to_ix self.tagset_size = len(tag_to_ix) self.word_embeds = nn.Embedding(vocab_size, embedding_dim) self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=1, bidirectional=True) # 将LSTM的输出映射到标记空间 self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size) # 过渡参数矩阵. 条目 i,j 是 # *从* j *到* i 的过渡的分数 self.transitions = nn.Parameter( torch.randn(self.tagset_size, self.tagset_size)) # 这两句声明强制约束了我们不能 # 向开始标记标注传递和从结束标注传递 self.transitions.data[tag_to_ix[START_TAG], :] = -10000 self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000 self.hidden = self.init_hidden() def init_hidden(self): return (autograd.Variable(torch.randn(2, 1, self.hidden_dim // 2)), autograd.Variable(torch.randn(2, 1, self.hidden_dim // 2))) def _forward_alg(self, feats): # 执行前向算法来计算分割函数 init_alphas = torch.Tensor(1, self.tagset_size).fill_(-10000.) # START_TAG 包含所有的分数 init_alphas[0][self.tag_to_ix[START_TAG]] = 0. # 将其包在一个变量类型中继而得到自动的反向传播 forward_var = autograd.Variable(init_alphas) # 在句子中迭代 for feat in feats: alphas_t = [] # 在这个时间步的前向变量 for next_tag in range(self.tagset_size): # 对 emission 得分执行广播机制: 它总是相同的, # 不论前一个标注如何 emit_score = feat[next_tag].view( 1, -1).expand(1, self.tagset_size) # trans_score 第 i 个条目是 # 从i过渡到 next_tag 的分数 trans_score = self.transitions[next_tag].view(1, -1) # next_tag_var 第 i 个条目是在我们执行 对数-求和-指数 前 # 边缘的值 (i -> next_tag) next_tag_var = forward_var + trans_score + emit_score # 这个标注的前向变量是 # 对所有的分数执行 对数-求和-指数 alphas_t.append(log_sum_exp(next_tag_var)) forward_var = torch.cat(alphas_t).view(1, -1) terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]] alpha = log_sum_exp(terminal_var) return alpha def _get_lstm_features(self, sentence): self.hidden = self.init_hidden() embeds = self.word_embeds(sentence).view(len(sentence), 1, -1) lstm_out, self.hidden = self.lstm(embeds, self.hidden) lstm_out = lstm_out.view(len(sentence), self.hidden_dim) lstm_feats = self.hidden2tag(lstm_out) return lstm_feats def _score_sentence(self, feats, tags): # 给出标记序列的分数 score = autograd.Variable(torch.Tensor([0])) tags = torch.cat([torch.LongTensor([self.tag_to_ix[START_TAG]]), tags]) for i, feat in enumerate(feats): score = score + \\ self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]] score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]] return score def _viterbi_decode(self, feats): backpointers = [] # 在对数空间中初始化维特比变量 init_vvars = torch.Tensor(1, self.tagset_size).fill_(-10000.) init_vvars[0][self.tag_to_ix[START_TAG]] = 0 # 在第 i 步的 forward_var 存放第 i-1 步的维特比变量 forward_var = autograd.Variable(init_vvars) for feat in feats: bptrs_t = [] # 存放这一步的后指针 viterbivars_t = [] # 存放这一步的维特比变量 for next_tag in range(self.tagset_size): # next_tag_var[i] 存放先前一步标注i的 # 维特比变量, 加上了从标注 i 到 next_tag 的过渡 # 的分数 # 我们在这里并没有将 emission 分数包含进来, 因为 # 最大值并不依赖于它们(我们在下面对它们进行的是相加) next_tag_var = forward_var + self.transitions[next_tag] best_tag_id = argmax(next_tag_var) bptrs_t.append(best_tag_id) viterbivars_t.append(next_tag_var[0][best_tag_id]) # 现在将所有 emission 得分相加, 将 forward_var # 赋值到我们刚刚计算出来的维特比变量集合 forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1) backpointers.append(bptrs_t) # 过渡到 STOP_TAG terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]] best_tag_id = argmax(terminal_var) path_score = terminal_var[0][best_tag_id] # 跟着后指针去解码最佳路径 best_path = [best_tag_id] for bptrs_t in reversed(backpointers): best_tag_id = bptrs_t[best_tag_id] best_path.append(best_tag_id) # 弹出开始的标签 (我们并不希望把这个返回到调用函数) start = best_path.pop() assert start == self.tag_to_ix[START_TAG] # 健全性检查 best_path.reverse() return path_score, best_path def neg_log_likelihood(self, sentence, tags): feats = self._get_lstm_features(sentence) forward_score = self._forward_alg(feats) gold_score = self._score_sentence(feats, tags) return forward_score - gold_score def forward(self, sentence): # 不要把这和上面的 _forward_alg 混淆 # 得到 BiLSTM 输出分数 lstm_feats = self._get_lstm_features(sentence) # 给定特征, 找到最好的路径 score, tag_seq = self._viterbi_decode(lstm_feats) return score, tag_seq 运行训练 START_TAG = \"\" STOP_TAG = \"\" EMBEDDING_DIM = 5 HIDDEN_DIM = 4 # 制造一些训练数据 training_data = [( \"the wall street journal reported today that apple corporation made money\".split(), \"B I I I O O O B I O O\".split() ), ( \"georgia tech is a university in georgia\".split(), \"B I O O O O B\".split() )] word_to_ix = {} for sentence, tags in training_data: for word in sentence: if word not in word_to_ix: word_to_ix[word] = len(word_to_ix) tag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4} model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM) optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4) # 在训练之前检查预测结果 precheck_sent = prepare_sequence(training_data[0][0], word_to_ix) precheck_tags = torch.LongTensor([tag_to_ix[t] for t in training_data[0][1]]) print(model(precheck_sent)) # 确认从之前的 LSTM 部分的 prepare_sequence 被加载了 for epoch in range( 300): # 又一次, 正常情况下你不会训练300个 epoch, 这只是示例数据 for sentence, tags in training_data: # 第一步: 需要记住的是Pytorch会累积梯度 # 我们需要在每次实例之前把它们清除 model.zero_grad() # 第二步: 为我们的网络准备好输入, 即 # 把它们转变成单词索引变量 (Variables) sentence_in = prepare_sequence(sentence, word_to_ix) targets = torch.LongTensor([tag_to_ix[t] for t in tags]) # 第三步: 运行前向传递. neg_log_likelihood = model.neg_log_likelihood(sentence_in, targets) # 第四步: 计算损失, 梯度以及 # 使用 optimizer.step() 来更新参数 neg_log_likelihood.backward() optimizer.step() # 在训练之后检查预测结果 precheck_sent = prepare_sequence(training_data[0][0], word_to_ix) print(model(precheck_sent)) # 我们完成了! 练习: 为区别性标注定义一个新的损失函数 在解码的时候, 我们不一定需要创建一个计算图, 因为我们并不从维特比路径分数中做反向传播. 不管怎样, 既然我们有了它, 尝试训练这个标注器, 使其损失函数是维特比路径分数和黄金标准分数之差. 需要弄清楚的是, 这个函数在预测标注序列是正确的时候应当大于等于0. 这本质上是 结构化感知机 . 这个改动应当是很简短的, 因为 Viterbi 和 scoresentence 是已经实现好了的. 这是 依赖于训练实例的_ 计算图的形状的一个例子. 但我们并没有尝试过在一个静态工具包上实现过, 我想象中这是可行的但并不是很显而易见. 找一些真实数据做一下比较吧! 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"intermediate_tutorials.html":{"url":"intermediate_tutorials.html","title":"中级教程","keywords":"","body":"中级教程 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"char_rnn_classification_tutorial.html":{"url":"char_rnn_classification_tutorial.html","title":"用字符级RNN分类名称","keywords":"","body":"用字符级RNN分类名称 译者：@孙永杰 作者: Sean Robertson 我们将建立和训练一个基本的字符级RNN进行分类单词. 字符级别的RNN将单词读为一系列字符 - 在每个步骤输出一个预测和“隐藏状态”, 将先前的隐藏状态作为下一步的输入. 我们采取最后的预测作为输出,即该单词属于哪一类. 具体来说,我们将用18种语言的几千个姓氏作为训练集并根据拼写预测名称来自哪种语言: $ python predict.py Hinton (-0.47) Scottish (-1.52) English (-3.57) Irish $ python predict.py Schmidhuber (-0.19) German (-2.48) Czech (-2.68) Dutch 推荐阅读: 假设你至少已经安装了PyTorch,知道Python和了解张量: http://pytorch.org/ 安装步骤 PyTorch 深度学习: 60 分钟极速入门教程 大体了解PyTorch 跟着例子学习 PyTorch 深入概括 PyTorch for former Torch users 假设你是前Lua Torch用户 了解RNN及其工作方式也很有用: 递归神经网络的不合理有效性 展示了一堆真实生活的例子 理解LSTM网络 是关于LSTM的具体内容,但也包含有关RNN的一般信息 准备数据 在 data/names 目录中包含18个名为as的文本文件 “[Language].txt” . 每个文件都包含一堆名称,每个名称一行大多是罗马化（但我们仍然需要从Unicode转换为ASCII）. 我们最终会得到每种语言的名称列表字典 {language: [names ...]} 通用变量“类别”和“行” （在我们的例子中用于语言和名称）用于以后的扩展性. from __future__ import unicode_literals, print_function, division from io import open import glob def findFiles(path): return glob.glob(path) print(findFiles('data/names/*.txt')) import unicodedata import string all_letters = string.ascii_letters + \" .,;'\" n_letters = len(all_letters) # 将 Unicode 字符串转换为纯 ASCII 编码, 这里感谢 http://stackoverflow.com/a/518232/2809427 def unicodeToAscii(s): return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn' and c in all_letters ) print(unicodeToAscii('Ślusàrski')) # 构建category_lines字典, 每种语言的名称列表 category_lines = {} all_categories = [] # 读取一个文件并分成几行 def readLines(filename): lines = open(filename, encoding='utf-8').read().strip().split('\\n') return [unicodeToAscii(line) for line in lines] for filename in findFiles('data/names/*.txt'): category = filename.split('/')[-1].split('.')[0] all_categories.append(category) lines = readLines(filename) category_lines[category] = lines n_categories = len(all_categories) 现在我们有 category_lines, 这是一个映射每个类别的字典 (语言) 到行列表 (名称). 我们也跟踪 all_categories (只是一个语言列表) 和 n_categories 为以后做参考. print(category_lines['Italian'][:5]) 将名字转化为张量 现在我们已经组织了所有的名字,我们需要将它们变成张量以便使用它们. 为了表示单个字母,我们使用大小为 &lt;1 x n_letters&gt; 的”单热矢量”. 除了当前字母的索引处的1以外,单热矢量剩余填充0, e.g. \"b\" = &lt;0 1 0 0 0 ...&gt;. 为了说出一个词,我们将其中的一部分加入到二维矩阵中 &lt;line_length x 1 x n_letters&gt;. 额外的1维度是因为PyTorch假定所有内容都是批量的 - 我们在这里只使用1的批量大小. import torch # 从all_letters中查找字母索引, e.g. \"a\" = 0 def letterToIndex(letter): return all_letters.find(letter) # 只是为了演示, 把一个字母变成一个 张量 def letterToTensor(letter): tensor = torch.zeros(1, n_letters) tensor[0][letterToIndex(letter)] = 1 return tensor # 把一行变成一个 , # 或一批单热字符向量 def lineToTensor(line): tensor = torch.zeros(len(line), 1, n_letters) for li, letter in enumerate(line): tensor[li][0][letterToIndex(letter)] = 1 return tensor print(letterToTensor('J')) print(lineToTensor('Jones').size()) 创建网络 在autograd之前, 在Torch中创建一个循环神经网络涉及到克隆几个步骤一个图层的参数. 图层保持隐藏状态和渐变, 现在完全由图形本身处理. 这意味着您可以以非常“纯粹”的方式实现RNN, 作为常规的前馈层. 这个RNN模块 (大部分都是复制 the PyTorch for Torch users tutorial) 只有2个线性层可以在输入和隐藏状态下运行, 在输出之后有一个LogSoftmax层. import torch.nn as nn from torch.autograd import Variable class RNN(nn.Module): def __init__(self, input_size, hidden_size, output_size): super(RNN, self).__init__() self.hidden_size = hidden_size self.i2h = nn.Linear(input_size + hidden_size, hidden_size) self.i2o = nn.Linear(input_size + hidden_size, output_size) self.softmax = nn.LogSoftmax(dim=1) def forward(self, input, hidden): combined = torch.cat((input, hidden), 1) hidden = self.i2h(combined) output = self.i2o(combined) output = self.softmax(output) return output, hidden def initHidden(self): return Variable(torch.zeros(1, self.hidden_size)) n_hidden = 128 rnn = RNN(n_letters, n_hidden, n_categories) 为了运行这个网络的一个步骤, 我们需要传递一个输入 (在我们的例子中是当前字母的张量) 和一个先前的隐藏状态 (我们首先初始化为零) . 我们将返回输出 (每种语言的概率) 和下一个隐藏状态 (我们为下一步保留). 请记住, PyTorch模块对变量进行操作, 而不是直接对张量进行操作. input = Variable(letterToTensor('A')) hidden = Variable(torch.zeros(1, n_hidden)) output, next_hidden = rnn(input, hidden) 为了提高效率我们不希望为每一步创建一个新的张量, 所以我们使用 lineToTensor 而不是 letterToTensor 并使用切片. 这可以通过预先计算批次的张量进一步优化. input = Variable(lineToTensor('Albert')) hidden = Variable(torch.zeros(1, n_hidden)) output, next_hidden = rnn(input[0], hidden) print(output) 正如你所看到的输出是一个 &lt;1 x n_categories&gt; 张量, 每个项目都是该类别的可能性 (越高越有可能). 训练 准备训练 在训练之前,我们应该做一些辅助功能. 首先是解释网络的输出, 我们知道这是每个类别的可能性. 我么可以使用 Tensor.topk 得到最大价值的指数: def categoryFromOutput(output): top_n, top_i = output.data.topk(1) # Tensor out of Variable with .data category_i = top_i[0][0] return all_categories[category_i], category_i print(categoryFromOutput(output)) 我们也希望能够快速获得训练示例 (名称及其语言): import random def randomChoice(l): return l[random.randint(0, len(l) - 1)] def randomTrainingExample(): category = randomChoice(all_categories) line = randomChoice(category_lines[category]) category_tensor = Variable(torch.LongTensor([all_categories.index(category)])) line_tensor = Variable(lineToTensor(line)) return category, line, category_tensor, line_tensor for i in range(10): category, line, category_tensor, line_tensor = randomTrainingExample() print('category =', category, '/ line =', line) 训练网络 现在训练这个网络所需要的就是向大家展示一些例子, 让它猜测, 并告诉它是否是错误的. 对于损失函数 nn.NLLLoss 是适当的, 因为RNN的最后一层是 nn.LogSoftmax. criterion = nn.NLLLoss() 每个训练循环都会: 创建输入和目标张量 创建一个归零的初始隐藏状态 读入每个字母 为下一个字母保持隐藏状态 比较最终输出与目标 反向传播 返回输出和损失 learning_rate = 0.005 # 如果设置得太高, 可能会爆炸. 如果太低, 可能无法学习. def train(category_tensor, line_tensor): hidden = rnn.initHidden() rnn.zero_grad() for i in range(line_tensor.size()[0]): output, hidden = rnn(line_tensor[i], hidden) loss = criterion(output, category_tensor) loss.backward() # 将参数梯度添加到它们的值,再乘以学习速率 for p in rnn.parameters(): p.data.add_(-learning_rate, p.grad.data) return output, loss.data[0] 现在我们只需要运行一些例子. 由于 train 函数返回输出和损失,我们可以打印它的猜测,并记录绘图的损失 既然有1000个例子, 我们只打印每个 print_every 的例子, 并取平均的损失. import time import math n_iters = 100000 print_every = 5000 plot_every = 1000 # 跟踪绘图的损失 current_loss = 0 all_losses = [] def timeSince(since): now = time.time() s = now - since m = math.floor(s / 60) s -= m * 60 return '%dm %ds' % (m, s) start = time.time() for iter in range(1, n_iters + 1): category, line, category_tensor, line_tensor = randomTrainingExample() output, loss = train(category_tensor, line_tensor) current_loss += loss # 打印循环数,损失,名称和猜测 if iter % print_every == 0: guess, guess_i = categoryFromOutput(output) correct = '✓' if guess == category else '✗ (%s)' % category print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct)) # 将当前损失平均值添加到损失清单 if iter % plot_every == 0: all_losses.append(current_loss / plot_every) current_loss = 0 绘制结果 从 all_losses 绘制历史损失显示网络学习: import matplotlib.pyplot as plt import matplotlib.ticker as ticker plt.figure() plt.plot(all_losses) 评估结果 要查看网络在不同类别中的表现如何, 我们将创建一个混淆矩阵, 为每个实际语言 (行) 指示网络猜测哪种语言 (列). 为了计算混淆矩阵,一堆样本通过网络运行 evaluate(), 这和 train() 减去反向传播是一样的. # 在混淆矩阵中跟踪正确的猜测 confusion = torch.zeros(n_categories, n_categories) n_confusion = 10000 # 只要返回给定一行的输出即可 def evaluate(line_tensor): hidden = rnn.initHidden() for i in range(line_tensor.size()[0]): output, hidden = rnn(line_tensor[i], hidden) return output # 通过一堆示例并记录哪些是正确的猜测 for i in range(n_confusion): category, line, category_tensor, line_tensor = randomTrainingExample() output = evaluate(line_tensor) guess, guess_i = categoryFromOutput(output) category_i = all_categories.index(category) confusion[category_i][guess_i] += 1 # 通过将每一行除以其总和来标准化 for i in range(n_categories): confusion[i] = confusion[i] / confusion[i].sum() # 设置绘图 fig = plt.figure() ax = fig.add_subplot(111) cax = ax.matshow(confusion.numpy()) fig.colorbar(cax) # 设置轴 ax.set_xticklabels([''] + all_categories, rotation=90) ax.set_yticklabels([''] + all_categories) # Force label at every tick ax.xaxis.set_major_locator(ticker.MultipleLocator(1)) ax.yaxis.set_major_locator(ticker.MultipleLocator(1)) # sphinx_gallery_thumbnail_number = 2 plt.show() 您可以从主轴上选取显示错误猜测哪些语言的亮点, e.g. Chinese for Korean, and Spanish for Italian. 它似乎与希腊语很好,英语很差 (可能是因为与其他语言重叠). 在用户输入上运行 def predict(input_line, n_predictions=3): print('\\n> %s' % input_line) output = evaluate(Variable(lineToTensor(input_line))) # 获取前N个类别 topv, topi = output.data.topk(n_predictions, 1, True) predictions = [] for i in range(n_predictions): value = topv[0][i] category_index = topi[0][i] print('(%.2f) %s' % (value, all_categories[category_index])) predictions.append([value, all_categories[category_index]]) predict('Dovesky') predict('Jackson') predict('Satoshi') 脚本的最终版本 in the Practical PyTorch repo 将上面的代码分成几个文件: data.py (加载文件) model.py (定义RNN) train.py (运行训练) predict.py (用命令行参数运行 predict() ) server.py (使用bottle.py将预测用作JSON API) 运行 train.py 来训练和保存网络. 运行具有名称的 predict.py 来查看预测: $ python predict.py Hazaki (-0.42) Japanese (-1.39) Polish (-3.51) Czech 运行 server.py 和查看 http://localhost:5533/Yourname 获取预测的JSON输出. 练习 尝试使用不同的数据集 线条 -> 类别, 例如: 任何单词 -> 语言 姓 -> 性别 角色名字 -> 作家 页面标题 -> 博客或subreddit 通过更大和/或更好的形状网络获得更好的结果 添加更多线性图层 试试 nn.LSTM 和 nn.GRU 图层 将多个这些RNN组合为更高级别的网络 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"char_rnn_generation_tutorial.html":{"url":"char_rnn_generation_tutorial.html","title":"基与字符级RNN（Char-RNN）的人名生成","keywords":"","body":"基与字符级RNN（Char-RNN）的人名生成 译者：@jianchengss 作者: Sean Robertson 在 上一个教程 里我们使用RNN把名字分类到它所属的语言中, 这次我们改变一下来学习从语言中生成名字. > python sample.py Russian RUS Rovakov Uantov Shavakov > python sample.py German GER Gerren Ereng Rosher > python sample.py Spanish SPA Salla Parer Allan > python sample.py Chinese CHI Chan Hang Iun 我们仍然手工搭建一个包含几个线性层的小的RNN. 这次的最大的不同是输入一个类别, 每次输出一个字母, 而不是读入所有名字的字母来预测一个类别. 循环的预测每一个字母来构成语言（也可以用文 字或者其他更高级的结构完成）, 通常被称为“语言模型”. 推荐阅读: 假设你至少安装了PyTorch, 熟悉Python, 理解Tensors: http://pytorch.org/ : 安装说明 PyTorch 深度学习: 60 分钟极速入门教程 获取一般的 PyTorch 入门 跟着例子学习 PyTorch 广泛且深入的概述 PyTorch for former Torch users 如果曾经是 Lua Torch 的用户 下面这些对了解 RNNs 和其工作原理也是很有用的: The Unreasonable Effectiveness of Recurrent Neural Networks 展示了一系列真实生活中的例子 Understanding LSTM Networks 是一篇特别关于LSTMs的文章, 但是对于一般的RNNs也很有益的 还建议上一个教程: 用字符级RNN分类名称 数据准备 注解： 从 这里 下载数据, 并解压到当前目录. 更多的细节参考上一个教程, 总之, 数据含有一批纯文本文件: data/names/[Language].txt 每一行一个人名. 将行分割成数组, 并把 Unicode 转换成 ASCII 编码, 最后放进一个字典里 {language: [names ...]}. from __future__ import unicode_literals, print_function, division from io import open import glob import unicodedata import string all_letters = string.ascii_letters + \" .,;'-\" n_letters = len(all_letters) + 1 # 添加 EOS 标记 def findFiles(path): return glob.glob(path) # 将 Unicode 字符串转换为纯 ASCII 编码, 感谢 http://stackoverflow.com/a/518232/2809427 def unicodeToAscii(s): return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn' and c in all_letters ) # 读取文件并分割成行 def readLines(filename): lines = open(filename, encoding='utf-8').read().strip().split('\\n') return [unicodeToAscii(line) for line in lines] # 构建映射字典 category_lines , 每个类别是由很多个行组成的list category_lines = {} all_categories = [] for filename in findFiles('data/names/*.txt'): category = filename.split('/')[-1].split('.')[0] all_categories.append(category) lines = readLines(filename) category_lines[category] = lines n_categories = len(all_categories) print('# categories:', n_categories, all_categories) print(unicodeToAscii(\"O'Néàl\")) 创建网络 这个网络扩展了 上一个教程的RNN , 为类别张量添加了一个额外的参数, 并和其他的参数串联在一起. 类别张量 和字母的输入一样是 one-hot 向量. 我们将输出解释成为下一个字母的概率, 采样的时候, 最有可能的输出被当做下一个输入. 为了让网络更加有效工作, 我添加了第二个线性层 o2o （在合并了隐藏层和输出层的后面）. 还有一个 Dropout 层, 使输入的部分值以给定的概率值随机的变成 0 （这里概率取0.1）, 这样做通常是为了模糊输入以防止过拟合. 这里我们在网络的最末端使用它, 从而故意添加一些混乱和增加采样的多样化. import torch import torch.nn as nn from torch.autograd import Variable class RNN(nn.Module): def __init__(self, input_size, hidden_size, output_size): super(RNN, self).__init__() self.hidden_size = hidden_size self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size) self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size) self.o2o = nn.Linear(hidden_size + output_size, output_size) self.dropout = nn.Dropout(0.1) self.softmax = nn.LogSoftmax(dim=1) def forward(self, category, input, hidden): input_combined = torch.cat((category, input, hidden), 1) hidden = self.i2h(input_combined) output = self.i2o(input_combined) output_combined = torch.cat((hidden, output), 1) output = self.o2o(output_combined) output = self.dropout(output) output = self.softmax(output) return output, hidden def initHidden(self): return Variable(torch.zeros(1, self.hidden_size)) 训练 训练前的准备 首先, 利用辅助函数产生随机的（category, line）对: import random # 从list中随机选取项 def randomChoice(l): return l[random.randint(0, len(l) - 1)] # 获取随机的类别和该类别中随机的行 def randomTrainingPair(): category = randomChoice(all_categories) line = randomChoice(category_lines[category]) return category, line 对每一个时间点（也就是说在训练集中词的每个字母）网络的输入是 (类别, 当前字母, 隐藏层状态) , 输出是 (下一个字母, 下一个隐藏层状态) . 对于每一个训练集, 我们需要的是类别、输入的字母集、输出/目标字母集. 因为在每一步, 我们从当前的字母预测下一个字母, 这样的字母对是在原有行中连续字母的集合, 例如, 对于 \"ABCD&lt;EOS&gt;\" 将会产生 (“A”, “B”), (“B”, “C”), (“C”, “D”), (“D”, “EOS”). 类别张量是一个大小为 &lt;1 x n_categories&gt; 的 one-hot tensor 张量, 在训练的每一个时间点把它喂给网络 —— 这是一个设计的选择, 它可以被当作为初始隐藏状或其他策略的一部分. # 类别的 one-hot 向量 def categoryTensor(category): li = all_categories.index(category) tensor = torch.zeros(1, n_categories) tensor[0][li] = 1 return tensor # 输入串从第一个字母到最后一个字母（不包括 EOS ）的 one-hot 矩阵 def inputTensor(line): tensor = torch.zeros(len(line), 1, n_letters) for li in range(len(line)): letter = line[li] tensor[li][0][all_letters.find(letter)] = 1 return tensor # 目标的第二个字母到结尾（EOS）的 LongTensor def targetTensor(line): letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))] letter_indexes.append(n_letters - 1) # EOS return torch.LongTensor(letter_indexes) 为了训练过程的便利, 添加一个 randomTrainingExample 函数, 获取随机的 (category, line) 对, 并把他们转换成需要的 (category, input, target) 张量. # 从随机的（category, line）对中生成 category, input, and target 张量 def randomTrainingExample(): category, line = randomTrainingPair() category_tensor = Variable(categoryTensor(category)) input_line_tensor = Variable(inputTensor(line)) target_line_tensor = Variable(targetTensor(line)) return category_tensor, input_line_tensor, target_line_tensor 网络的训练 与分类相比, 分类只用到了最后的输出, 而这里每个步都会产生一个预测, 所以我们需要计算每一步的损失. 自动求导（autograd）的魔力就在于, 它允许将每一步的损失简单的加和, 并在最后调用 backward criterion = nn.NLLLoss() learning_rate = 0.0005 def train(category_tensor, input_line_tensor, target_line_tensor): hidden = rnn.initHidden() rnn.zero_grad() loss = 0 for i in range(input_line_tensor.size()[0]): output, hidden = rnn(category_tensor, input_line_tensor[i], hidden) loss += criterion(output, target_line_tensor[i]) loss.backward() for p in rnn.parameters(): p.data.add_(-learning_rate, p.grad.data) return output, loss.data[0] / input_line_tensor.size()[0] 为了跟踪训练花费了多长时间, 这里添加一个 timeSince(timestamp) 函数, 返回一个人们易读的字符串: import time import math def timeSince(since): now = time.time() s = now - since m = math.floor(s / 60) s -= m * 60 return '%dm %ds' % (m, s) 训练和往常一样, 不停的调用 train 并等待一会, 打印当前时间, 每隔 print_every 个例子打印 loss, 将每 plot_every 个例子的平均损失保存在 all_losses 中以便后面画图. rnn = RNN(n_letters, 128, n_letters) n_iters = 100000 print_every = 5000 plot_every = 500 all_losses = [] total_loss = 0 # 每 plot_every 次迭代需要重置 start = time.time() for iter in range(1, n_iters + 1): output, loss = train(*randomTrainingExample()) total_loss += loss if iter % print_every == 0: print('%s (%d %d%%) %.4f' % (timeSince(start), iter, iter / n_iters * 100, loss)) if iter % plot_every == 0: all_losses.append(total_loss / plot_every) total_loss = 0 绘制损失 从 all_losses 中绘制历史损失, 以展现网络的学习过程 import matplotlib.pyplot as plt import matplotlib.ticker as ticker plt.figure() plt.plot(all_losses) 网络采样 为了采样, 我们给网络一个字母并问下一个字母是什么, 重复这个过程直到 EOS 标记. 创建输入类别、起始字母和隐藏层状态的张量 创建一个带有起始字母的 output_name 串 直到最大的输出长度, 当前字母喂给网络 从最高的输出获取下一个字母和下一个隐藏层状态 如果输出字母是 EOS, 算法结束 如果输出是常规字母, 将其加入到 output_name 并继续 返回最终的名字 注解： 与给定起始字母不同的是, 有其他的策略是在训练的时候包含一个“串起始”标记, 让网络选择属于自己的起始字母. max_length = 20 # 从类别和起始字母采样 def sample(category, start_letter='A'): category_tensor = Variable(categoryTensor(category)) input = Variable(inputTensor(start_letter)) hidden = rnn.initHidden() output_name = start_letter for i in range(max_length): output, hidden = rnn(category_tensor, input[0], hidden) topv, topi = output.data.topk(1) topi = topi[0][0] if topi == n_letters - 1: break else: letter = all_letters[topi] output_name += letter input = Variable(inputTensor(letter)) return output_name # 给定一个类别和多个起始字母 获取个采样结果 def samples(category, start_letters='ABC'): for start_letter in start_letters: print(sample(category, start_letter)) samples('Russian', 'RUS') samples('German', 'GER') samples('Spanish', 'SPA') samples('Chinese', 'CHI') 练习 尝试使用不同 类别->行 数据集, 例如: 小说系列 -> 角色名字 词性 -> 词语 国家 -> 城市 使用“串起始”标记, 使采样的时候不用给定起始字母 使用更大和/或更好的网络结构获取更好的结果 尝试一下 nn.LSTM 和 nn.GRU 层 将这些 RNNs 组合成更高级的网络 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"seq2seq_translation_tutorial.html":{"url":"seq2seq_translation_tutorial.html","title":"用基于注意力机制的seq2seq神经网络进行翻译","keywords":"","body":"用基于注意力机制的seq2seq神经网络进行翻译 译者：@EWilsen 作者: Sean Robertson 这个教程主要讲解用一个神经网络将法语翻译成英语. [KEY: > input, = target, il est en train de peindre un tableau . = he is painting a picture . pourquoi ne pas essayer ce vin delicieux ? = why not try that delicious wine ? elle n est pas poete mais romanciere . = she is not a poet but a novelist . vous etes trop maigre . = you re too skinny . … 取得不同阶段的成功. 这是通过seq2seq网络 &lt;[http://arxiv.org/abs/1409.3215](http://arxiv.org/abs/1409.3215)&gt;__实现的简单却强大的想法, 通过两个递归神经网络一起工作实现将一个序列转换为另一个.一个编码器网络将输入序列压 缩成向量,解码器网络将该矢量展开为新的序列. 为了改进这个模型,我们将使用一种注意力机制&lt;[https://arxiv.org/abs/1409.0473](https://arxiv.org/abs/1409.0473)&gt;__, 它可以让解码器学习将注意力集中在输入序列的特定范围上. 推荐阅读: 我们假设你至少已经安装了PyTorch,了解Python,并且了解张量: http://pytorch.org/ PyTorch安装说明 PyTorch 深度学习: 60 分钟极速入门教程 开始使用PyTorch 跟着例子学习 PyTorch 进行广泛而深入的了解 PyTorch for former Torch users 如果你是前Lua Torch用户 这些内容也有利于了解seq2seq网络和其工作机制: 用RNN编码器 - 解码器来学习用于统计机器翻译的短语表示 用神经网络进行seq2seq学习 神经网络机器翻译联合学习对齐和翻译 神经会话模型 你还可以找到以前的教程关于Character-Level RNN名称分类 用字符级RNN分类名称 和生成名称 基与字符级RNN（Char-RNN）的人名生成 这些概念与编码器和解码器模型非常相似. 更多内容请阅读介绍这些主题的论文: 用RNN编码器 - 解码器来学习用于统计机器翻译的短语表示 用神经网络进行seq2seq学习 神经网络机器翻译联合学习对齐和翻译 神经会话模型 要求 from __future__ import unicode_literals, print_function, division from io import open import unicodedata import string import re import random import torch import torch.nn as nn from torch.autograd import Variable from torch import optim import torch.nn.functional as F use_cuda = torch.cuda.is_available() 加载数据文件 这个项目的数据是一组数以千计的英语到法语的翻译对. 这个问题在 Open Data Stack Exchange上 __ 指导我们使用开放的翻译网站 http://tatoeba.org/ 可下载地址为 http://tatoeba.org/eng/downloads - 更好的是, 有人做了额外的工作,切分语言对到单个文本文件中: http://www.manythings.org/anki/ 英文到法文对太大而不能包含在repo中,因此开始前请下载 data/eng-fra.txt. 该文件是一个制表符分隔的翻译对列表: : I am cold. Je suis froid. 注解： 下载数据文件在 这里 并解压到正确的路径. 与character-level RNN教程中使用的字符编码类似,我们将用语言中的每个单词 作为独热向量,或者除了单个单词之外(在单词的索引处)的大的零向量. 相较于可能 存在于一种语言中仅有十个字符相比,多数都是有大量的字,因此编码向量很大. 然而,我们会欺骗性的做一些数据修剪,保证每种语言只使用几千字. 我们需要每个单词对应唯一的索引作为稍后的网络输入和目标.为了追踪这些索引我们使用一个帮助类 Lang 类中有 词 → 索引 (word2index) 和 索引 → 词 (index2word) 的字典, 以及每个词word2count 用来替换稀疏词汇. SOS_token = 0 EOS_token = 1 class Lang: def __init__(self, name): self.name = name self.word2index = {} self.word2count = {} self.index2word = {0: \"SOS\", 1: \"EOS\"} self.n_words = 2 # Count SOS and EOS def addSentence(self, sentence): for word in sentence.split(' '): self.addWord(word) def addWord(self, word): if word not in self.word2index: self.word2index[word] = self.n_words self.word2count[word] = 1 self.index2word[self.n_words] = word self.n_words += 1 else: self.word2count[word] += 1 这些文件全部采用Unicode编码,为了简化我们将Unicode字符转换为ASCII, 使所有内容小写,并修剪大部分标点符号. # 感谢您将Unicode字符串转换为纯ASCII # http://stackoverflow.com/a/518232/2809427 def unicodeToAscii(s): return ''.join( c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn' ) # 小写,修剪和删除非字母字符 def normalizeString(s): s = unicodeToAscii(s.lower().strip()) s = re.sub(r\"([.!?])\", r\" \\1\", s) s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s) return s 要读取数据文件,我们将把文件分成行,然后将行成对分开. 这些文件都是英文→其他语言,所以如果我们想从其他语言翻译→英文,我们添加了 翻转标志 reverse来翻转词语对. def readLangs(lang1, lang2, reverse=False): print(\"Reading lines...\") # 读取文件并按行分开 lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\ read().strip().split('\\n') # 将每一行分成两列并进行标准化 pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines] # 翻转对,Lang实例化 if reverse: pairs = [list(reversed(p)) for p in pairs] input_lang = Lang(lang2) output_lang = Lang(lang1) else: input_lang = Lang(lang1) output_lang = Lang(lang2) return input_lang, output_lang, pairs 由于有很多例句,我们希望快速训练,我们会将数据集裁剪为相对简短的句子. 这里的单词的最大长度是10词(包括结束标点符号),我们正在过滤到翻译 成”I am”或”He is”等形式的句子.(考虑到先前替换了撇号). MAX_LENGTH = 10 eng_prefixes = ( \"i am \", \"i m \", \"he is\", \"he s \", \"she is\", \"she s\", \"you are\", \"you re \", \"we are\", \"we re \", \"they are\", \"they re \" ) def filterPair(p): return len(p[0].split(' ')) 完整的准备数据的过程: 加载文本文件切分成行,并切分成单词对: 文本归一化, 按照长度和内容过滤 从成对的句子中制作单词列表 def prepareData(lang1, lang2, reverse=False): input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse) print(\"Read %s sentence pairs\" % len(pairs)) pairs = filterPairs(pairs) print(\"Trimmed to %s sentence pairs\" % len(pairs)) print(\"Counting words...\") for pair in pairs: input_lang.addSentence(pair[0]) output_lang.addSentence(pair[1]) print(\"Counted words:\") print(input_lang.name, input_lang.n_words) print(output_lang.name, output_lang.n_words) return input_lang, output_lang, pairs input_lang, output_lang, pairs = prepareData('eng', 'fra', True) print(random.choice(pairs)) Seq2Seq模型 递归神经网络(RNN),是一个按照一个序列进行操作的网路,并 将其自己的输出用作后续步骤的输入. 一个 序列到序列网络, 或 seq2seq 网络, 或 编码解码器网络, 是由两个称为编码器和解码器的RNN组成的模型. 编码器读取输入序列并输出单个向量, 解码器读取该向量以产生输出序列. 与单个RNN的序列预测不同,每个输入对应一个输出, seq2seq模型将我们从序列长度和顺序中解放出来, 这使得它成为两种语言之间翻译的理想选择. 考虑这句话 “Je ne suis pas le chat noir” → “I am not the black cat”. 输入句子中的大部分单词在输出句子中有直接翻译, 但顺序略有不同,例如: “chat noir” 和 “black cat”. 由于 “ne/pas”结构, 其中另一个单词在输入的句子中. 直接从输入词的序列中直接生成正确的翻译是很困难的. 使用seq2seq模型,编码器会创建一个单独的向量, 在理想情况下,它将输入序列的”含义”编码为单个向量 - 句子的N维空间中的一个点. 编码器 seq2seq网络的编码器是一个RNN,它为输入句子中的每个单词输出一些值. 对于每个输入字,编码器输出一个向量和一个隐藏状态,并将隐藏状态用于下一个输入字. class EncoderRNN(nn.Module): def __init__(self, input_size, hidden_size): super(EncoderRNN, self).__init__() self.hidden_size = hidden_size self.embedding = nn.Embedding(input_size, hidden_size) self.gru = nn.GRU(hidden_size, hidden_size) def forward(self, input, hidden): embedded = self.embedding(input).view(1, 1, -1) output = embedded output, hidden = self.gru(output, hidden) return output, hidden def initHidden(self): result = Variable(torch.zeros(1, 1, self.hidden_size)) if use_cuda: return result.cuda() else: return result 解码器 解码器是另一个RNN,它接收编码器输出向量并输出一个单词序列来创建翻译. 简单的解码器 在最简单的seq2seq解码器中,我们只使用编码器的最后一个输出. 这个最后的输出有时称为上下文向量,因为它从整个序列编码上下文. 该上下文向量被用作解码器的初始隐藏状态. 在解码的每一步,解码器都被赋予一个输入指令和隐藏状态. 初始输入指令字符串开始的&lt;SOS&gt;指令,第一个隐藏状态是上下文向量(编码器的最后隐藏状态). class DecoderRNN(nn.Module): def __init__(self, hidden_size, output_size): super(DecoderRNN, self).__init__() self.hidden_size = hidden_size self.embedding = nn.Embedding(output_size, hidden_size) self.gru = nn.GRU(hidden_size, hidden_size) self.out = nn.Linear(hidden_size, output_size) self.softmax = nn.LogSoftmax(dim=1) def forward(self, input, hidden): output = self.embedding(input).view(1, 1, -1) output = F.relu(output) output, hidden = self.gru(output, hidden) output = self.softmax(self.out(output[0])) return output, hidden def initHidden(self): result = Variable(torch.zeros(1, 1, self.hidden_size)) if use_cuda: return result.cuda() else: return result 我们鼓励你训练和观察这个模型的结果,但为了节省空间,我们将直接进正题引入注意力机制. 注意力解码器 如果仅在编码器和解码器之间传递上下文向量,则该单个向量承担编码整个句子的负担. 注意力允许解码器网络针对解码器自身输出的每一步”聚焦”编码器输出的不同部分. 首先我们计算一组注意力权重. 这些将被乘以编码器输出矢量获得加权的组合. 结果(在代码中为attn_applied) 应该包含关于输入序列的特定部分的信息, 从而帮助解码器选择正确的输出单词. 使用解码器的输入和隐藏状态作为输入,利用另一个前馈层 attn计算注意力权重, 由于训练数据中有各种大小的句子,为了实际创建和训练此层, 我们必须选择最大长度的句子(输入长度,用于编码器输出),以适用于此层. 最大长度的句子将使用所有注意力权重,而较短的句子只使用前几个. class AttnDecoderRNN(nn.Module): def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH): super(AttnDecoderRNN, self).__init__() self.hidden_size = hidden_size self.output_size = output_size self.dropout_p = dropout_p self.max_length = max_length self.embedding = nn.Embedding(self.output_size, self.hidden_size) self.attn = nn.Linear(self.hidden_size * 2, self.max_length) self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size) self.dropout = nn.Dropout(self.dropout_p) self.gru = nn.GRU(self.hidden_size, self.hidden_size) self.out = nn.Linear(self.hidden_size, self.output_size) def forward(self, input, hidden, encoder_outputs): embedded = self.embedding(input).view(1, 1, -1) embedded = self.dropout(embedded) attn_weights = F.softmax( self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1) attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0)) output = torch.cat((embedded[0], attn_applied[0]), 1) output = self.attn_combine(output).unsqueeze(0) output = F.relu(output) output, hidden = self.gru(output, hidden) output = F.log_softmax(self.out(output[0]), dim=1) return output, hidden, attn_weights def initHidden(self): result = Variable(torch.zeros(1, 1, self.hidden_size)) if use_cuda: return result.cuda() else: return result 注解： 还有其他形式的注意力通过使用相对位置方法来解决长度限制. 阅读关于 “local attention” 在 基于注意力的神经机器翻译的有效途径.为了训练,对于每一对我们将需要输入的张量(输入句子中的词的索引)和 目标张量(目标语句中的词的索引). 在创建这些向量时,我们会将EOS标记添加到两个序列中. def indexesFromSentence(lang, sentence): return [lang.word2index[word] for word in sentence.split(' ')] def variableFromSentence(lang, sentence): indexes = indexesFromSentence(lang, sentence) indexes.append(EOS_token) result = Variable(torch.LongTensor(indexes).view(-1, 1)) if use_cuda: return result.cuda() else: return result def variablesFromPair(pair): input_variable = variableFromSentence(input_lang, pair[0]) target_variable = variableFromSentence(output_lang, pair[1]) return (input_variable, target_variable) 训练模型 为了训练我们通过编码器运行输入句子,并跟踪每个输出和最新的隐藏状态. 然后解码器被赋予&lt;SOS&gt; 指令作为其第一个输入, 并将编码器的最后一个隐藏状态作为其第一个隐藏状态. “Teacher forcing” 是将实际目标输出用作每个下一个输入的概念,而不是将解码器的 猜测用作下一个输入.使用教师强迫会使其更快地收敛,但是 当训练好的网络被利用时,它可能表现出不稳定性.. 你可以观察教师强迫网络的输出,这些网络是用连贯的语法阅读的,但却远离了正确的翻译 - 直观地来看它已经学会了代表输出语法,并且一旦老师告诉它前几个单词,就可以”拾取”它的意思, 但它没有适当地学会如何从翻译中创建句子. 由于PyTorch的autograd给我们的自由,我们可以随意选择使用老师强制或不使用简单的if语句. 打开teacher_forcing_ratio更多的使用它. teacher_forcing_ratio = 0.5 def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH): encoder_hidden = encoder.initHidden() encoder_optimizer.zero_grad() decoder_optimizer.zero_grad() input_length = input_variable.size()[0] target_length = target_variable.size()[0] encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size)) encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs loss = 0 for ei in range(input_length): encoder_output, encoder_hidden = encoder( input_variable[ei], encoder_hidden) encoder_outputs[ei] = encoder_output[0][0] decoder_input = Variable(torch.LongTensor([[SOS_token]])) decoder_input = decoder_input.cuda() if use_cuda else decoder_input decoder_hidden = encoder_hidden use_teacher_forcing = True if random.random() 根据当前时间和进度百分比,这是一个帮助功能,用于打印经过的时间和估计的剩余时间. import time import math def asMinutes(s): m = math.floor(s / 60) s -= m * 60 return '%dm %ds' % (m, s) def timeSince(since, percent): now = time.time() s = now - since es = s / (percent) rs = es - s return '%s (- %s)' % (asMinutes(s), asMinutes(rs)) 整个训练过程如下所示: 启动一个计时器 初始化优化器和标准 创建一组训练对 为绘图建空损失数组 然后我们多次调用train,偶尔打印进度(样本的百分比,到目前为止的时间,估计的时间)和平均损失. def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01): start = time.time() plot_losses = [] print_loss_total = 0 # Reset every print_every plot_loss_total = 0 # Reset every plot_every encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate) decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate) training_pairs = [variablesFromPair(random.choice(pairs)) for i in range(n_iters)] criterion = nn.NLLLoss() for iter in range(1, n_iters + 1): training_pair = training_pairs[iter - 1] input_variable = training_pair[0] target_variable = training_pair[1] loss = train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion) print_loss_total += loss plot_loss_total += loss if iter % print_every == 0: print_loss_avg = print_loss_total / print_every print_loss_total = 0 print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg)) if iter % plot_every == 0: plot_loss_avg = plot_loss_total / plot_every plot_losses.append(plot_loss_avg) plot_loss_total = 0 showPlot(plot_losses) 绘制结果 使用matplotlib完成绘图, 使用训练时保存的损失值plot_losses数组. import matplotlib.pyplot as plt import matplotlib.ticker as ticker import numpy as np def showPlot(points): plt.figure() fig, ax = plt.subplots() # 这个定位器会定期发出提示信息 loc = ticker.MultipleLocator(base=0.2) ax.yaxis.set_major_locator(loc) plt.plot(points) 评估 评估与训练大部分相同,但没有目标,因此我们只是将解码器的每一步预测反馈给它自身. 每当它预测到一个单词时,我们就会将它添加到输出字符串中,并且如果它预测到我们在那里停止的EOS指令. 我们还存储解码器的注意力输出以供稍后显示. def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH): input_variable = variableFromSentence(input_lang, sentence) input_length = input_variable.size()[0] encoder_hidden = encoder.initHidden() encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size)) encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs for ei in range(input_length): encoder_output, encoder_hidden = encoder(input_variable[ei], encoder_hidden) encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0] decoder_input = Variable(torch.LongTensor([[SOS_token]])) # SOS decoder_input = decoder_input.cuda() if use_cuda else decoder_input decoder_hidden = encoder_hidden decoded_words = [] decoder_attentions = torch.zeros(max_length, max_length) for di in range(max_length): decoder_output, decoder_hidden, decoder_attention = decoder( decoder_input, decoder_hidden, encoder_outputs) decoder_attentions[di] = decoder_attention.data topv, topi = decoder_output.data.topk(1) ni = topi[0][0] if ni == EOS_token: decoded_words.append('') break else: decoded_words.append(output_lang.index2word[ni]) decoder_input = Variable(torch.LongTensor([[ni]])) decoder_input = decoder_input.cuda() if use_cuda else decoder_input return decoded_words, decoder_attentions[:di + 1] 我们可以从训练集中评估随机的句子并打印出输入,目标和输出以作出一些主观质量判断: def evaluateRandomly(encoder, decoder, n=10): for i in range(n): pair = random.choice(pairs) print('>', pair[0]) print('=', pair[1]) output_words, attentions = evaluate(encoder, decoder, pair[0]) output_sentence = ' '.join(output_words) print(' 训练和评估 有了所有这些辅助功能(它看起来像是额外的工作,但它使运行多个实验更容易), 我们就立马可以初始化网络并开始培训. 请记住输入句子被严重过滤, 对于这个小数据集,我们可以使用包含256个隐藏节点 和单个GRU层的相对较小的网络.在MacBook CPU上约40分钟后,我们会得到一些合理的结果. 注解： 如果你运行这个notebook,你可以训练,打断内核,评估并在以后继续训练. 注释编码器和解码器初始化的行并再次运行 trainIters . hidden_size = 256 encoder1 = EncoderRNN(input_lang.n_words, hidden_size) attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1) if use_cuda: encoder1 = encoder1.cuda() attn_decoder1 = attn_decoder1.cuda() trainIters(encoder1, attn_decoder1, 75000, print_every=5000) evaluateRandomly(encoder1, attn_decoder1) 可视化注意力 注意力机制的一个有用特性是其高度可解释的输出. 由于它用于对输入序列的特定编码器输出进行加权,因此我们可以想象在每个时间步骤中查看网络最关注的位置. 您可以简单地运行 plt.matshow(attentions),将注意力输出显示为矩阵, 其中列是输入步骤,行是输出步骤. output_words, attentions = evaluate( encoder1, attn_decoder1, \"je suis trop froid .\") plt.matshow(attentions.numpy()) 为了获得更好的观看体验,我们将额外添加轴和标签: def showAttention(input_sentence, output_words, attentions): # 用颜色条设置图形 fig = plt.figure() ax = fig.add_subplot(111) cax = ax.matshow(attentions.numpy(), cmap='bone') fig.colorbar(cax) # 设置轴 ax.set_xticklabels([''] + input_sentence.split(' ') + [''], rotation=90) ax.set_yticklabels([''] + output_words) # 在每个打勾处显示标签 ax.xaxis.set_major_locator(ticker.MultipleLocator(1)) ax.yaxis.set_major_locator(ticker.MultipleLocator(1)) plt.show() def evaluateAndShowAttention(input_sentence): output_words, attentions = evaluate( encoder1, attn_decoder1, input_sentence) print('input =', input_sentence) print('output =', ' '.join(output_words)) showAttention(input_sentence, output_words, attentions) evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\") evaluateAndShowAttention(\"elle est trop petit .\") evaluateAndShowAttention(\"je ne crains pas de mourir .\") evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\") 练习 尝试使用不同的数据集 另一种语言对 人 → 机器 (例如. IOT 命令) 聊天 → 响应 问题 → 回答 用预先训练的词嵌入替换嵌入,例如word2vec或GloVe 尝试更多图层,更多隐藏单位和更多句子. 比较训练时间和结果. 如果您使用的翻译文件对中有两个相同的短语(I am test \\t I am test), 您可以使用它作为自动编码器.尝试这个: - 训练自编码器 - 只保存编码器网络 - 从那里训练一个新的解码器进行翻译 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"reinforcement_q_learning.html":{"url":"reinforcement_q_learning.html","title":"强化学习（DQN）教程","keywords":"","body":"强化学习（DQN）教程 译者：@Lisanaaa 作者: Adam Paszke 本教程演示如何使用 PyTorch 对任务 CartPole-v0 训练 Deep Q Learning（DQN）代理（即一个算法黑箱）, 该任务来自于 OpenAI Gym. 任务 该代理需要决定将小车往左还是往右推, 因此小车上的杆子始终保持竖直. 你可以在 Gym website 找到一个官方的公示榜单, 其罗列了不同的算法和可视化. 代理通过观察当前环境（小车和杆子的组合体）下的状态选择一个合适的行为（往左还是往右推）, 随后环境状态得到转变, 并返回一个回馈因子来量化该行为所带来的后果（好处或是坏处）. 在这个任务中, 如果杆子移动太远则整个代理环境终止. 小车推杆任务被设计为有4个输入参数传给代理, 它们是环境状态, 环境位置, 环境速率等. 然而, 神经网络单靠观察这个场景就可以解决该任务, 因此我们用一些以小车为中心的屏幕图作为输入参数就行了. 正因为此, 我们并不能仅仅凭借将我们所得结果与公示榜单上的结果对比来得出结论, 我们的任务远比这个难. 不幸的是, 这将会导致我们的训练速度变慢, 因为我们必须得渲染屏幕图所有的帧数. 严格来说, 我们将状态定义为前一个屏幕图与当前屏幕图之间的差别. 这也会使得代理将图中推杆的速率也考虑进去. 包 首先, 我们导入一些需要用到的包. 第一, 我们需要 gym包 环境需要这个包（使用 ‘pip install gym’ 安装该包). 我们也会使用来自于 PyTorch 的以下包: 神经网络 neural networks (torch.nn) 优化 optimization (torch.optim) 自微分 automatic differentiation (torch.autograd) 视觉任务工具 (torchvision - 一个独立的包). import gym import math import random import numpy as np import matplotlib import matplotlib.pyplot as plt from collections import namedtuple from itertools import count from copy import deepcopy from PIL import Image import torch import torch.nn as nn import torch.optim as optim import torch.nn.functional as F from torch.autograd import Variable import torchvision.transforms as T env = gym.make('CartPole-v0').unwrapped # 设置 matplotlib is_ipython = 'inline' in matplotlib.get_backend() if is_ipython: from IPython import display plt.ion() # 如果要使用 gpu 的话 use_cuda = torch.cuda.is_available() FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor Tensor = FloatTensor 重播记忆 (Replay Memory) 我们将使用体验重播记忆来训练我们的DQN. 它存储了代理观察到的变化过程, 允许我们之后能够 重复使用这些数据. 通过对重播记忆随机取样, 建立了批处理的变化过程将会被解耦合. 这一机制 也被证明能够大幅度地提高和优化 DNQ 训练步骤的稳定性. 对此, 我们将需要两个类: Transition - 一个命名元祖（tuple）, 代表了环境的单次变化 ReplayMemory - 一个有限大小的循环缓冲区, 用于保存最近观察到的转换过程. 它也实现了.sample（）方法, 用于选择随机批次的转换进行训练 Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward')) class ReplayMemory(object): def __init__(self, capacity): self.capacity = capacity self.memory = [] self.position = 0 def push(self, *args): \"\"\"Saves a transition.\"\"\" if len(self.memory) 现在, 让我们开始构建我们的模型. 但是在此之前我们首先得重新定义什么是 DNQ. DQN 算法 我们的环境是确定性的, 所以这里提出的所有方程也都是为简单起见而确定性地制定的. 在强化学习概念中, 其还会包含有对环境中随机变化过程的期望值. 我们的目标是训练出一个机制, 尽可能做到最大化折扣因子和累积回馈因子. , 也被称为 回馈因子. 折扣因子 应该是一个 位于 和 之间的常量, 且确保了其总和是收敛的. 它的存在意义是让 回馈的重要程度与时间成正比, 即离现在1分钟的回馈比离现在1小时的回馈要更重要, 因为离当前时间越近, 我们的预测值可以更准确, 更可信. Q-learning 的主要原理是, 假如我们有一个函数, , 这将会定义返回值, 如果我们在给定状态下做出动作, 那么我们将会更容易据此训练出一个机制, 并做到最大化回馈因子. 由于我们对整个环境一无所知, 我们不需要知道确定的 . 但是, 因为神经网络 是一个泛化的逼近函数, 所以我们可以直接构造一个网络并训练它去模拟Q^*即可. 对于我们训练的更新规则来说, 我们只需要让每一个 遵从贝尔曼方程 (Bellman equation) 就可以了. 方程两边的实际差值即为时间差分误差 (temporal difference error), : 为了使得该误差值最小化, 我们要使用 Huber loss. 当时间差分误差较小时, Huber loss 表现地与均方误差 (mean squared error) 一样, 而当时间差分误差较大时, Huber loss 表现地与绝对均差 (mean absolute error) 一样. 这一性质使得它在预测带有较多噪音的 值上更具有鲁棒性. 我们通过从重播记忆中取出一批样本来计算 . Q-network 我们的模型是一个卷积神经网络 (CNN), 将当前屏幕图与之前屏幕图的差值作为唯一输入, 输出值有两个, 分别代表 和 (其中 是网络的输入). 从效果上来看, 我们的神经网络模型可以预测在当前输入下采取特定行为带来的 quality, 即对整个环境的影响. class DQN(nn.Module): def __init__(self): super(DQN, self).__init__() self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2) self.bn1 = nn.BatchNorm2d(16) self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2) self.bn2 = nn.BatchNorm2d(32) self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2) self.bn3 = nn.BatchNorm2d(32) self.head = nn.Linear(448, 2) def forward(self, x): x = F.relu(self.bn1(self.conv1(x))) x = F.relu(self.bn2(self.conv2(x))) x = F.relu(self.bn3(self.conv3(x))) return self.head(x.view(x.size(0), -1)) 获取输入 以下代码用来获取和处理来自环境中的被渲染的图像. 其中使用了 torchvision 包, 这使得图像变换变得更加简单. 只要运行该代码块就会显示当前所提取图像. resize = T.Compose([T.ToPILImage(), T.Scale(40, interpolation=Image.CUBIC), T.ToTensor()]) # This is based on the code from gym. screen_width = 600 def get_cart_location(): world_width = env.x_threshold * 2 scale = screen_width / world_width return int(env.state[0] * scale + screen_width / 2.0) # MIDDLE OF CART def get_screen(): screen = env.render(mode='rgb_array').transpose( (2, 0, 1)) # transpose into torch order (CHW) # Strip off the top and bottom of the screen screen = screen[:, 160:320] view_width = 320 cart_location = get_cart_location() if cart_location (screen_width - view_width // 2): slice_range = slice(-view_width, None) else: slice_range = slice(cart_location - view_width // 2, cart_location + view_width // 2) # Strip off the edges, so that we have a square image centered on a cart screen = screen[:, :, slice_range] # Convert to float, rescare, convert to torch tensor # (this doesn't require a copy) screen = np.ascontiguousarray(screen, dtype=np.float32) / 255 screen = torch.from_numpy(screen) # 调整大小并添加批量维度 (BCHW) return resize(screen).unsqueeze(0).type(Tensor) env.reset() plt.figure() plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(), interpolation='none') plt.title('Example extracted screen') plt.show() 训练 超参数和函数 这一代码块实例化我们的模型和优化器, 并且定义了一些函数. 函数: Variable - 这是一个对 torch.autograd.Variable 的简单包装器, 它会在我们每次构建变量时自动将数据发送到GPU. select_action - 根据ε贪婪法则选择后续行动. 简而言之, 我们有时会使用 我们的模型来选择动作, 有时我们仅均匀采样. 选择随机动作的 概率大小将从 “EPS_START” 开始, 并沿着到 “EPS_END” 的方向 呈指数衰减. EPS_DECAY 控制衰减速度. plot_durations - 一个协助绘制动态帧持续时间的函数, 以及过去100动态帧（官方 评估中使用的测量方法）的平均值. 绘制的图像将会显示在包含 主要训练循环的单元代码块下面, 并且在每节动态帧之后更新. BATCH_SIZE = 128 GAMMA = 0.999 EPS_START = 0.9 EPS_END = 0.05 EPS_DECAY = 200 model = DQN() if use_cuda: model.cuda() optimizer = optim.RMSprop(model.parameters()) memory = ReplayMemory(10000) steps_done = 0 def select_action(state): global steps_done sample = random.random() eps_threshold = EPS_END + (EPS_START - EPS_END) * \\ math.exp(-1. * steps_done / EPS_DECAY) steps_done += 1 if sample > eps_threshold: return model( Variable(state, volatile=True).type(FloatTensor)).data.max(1)[1].view(1, 1) else: return LongTensor([[random.randrange(2)]]) episode_durations = [] def plot_durations(): plt.figure(2) plt.clf() durations_t = torch.FloatTensor(episode_durations) plt.title('Training...') plt.xlabel('Episode') plt.ylabel('Duration') plt.plot(durations_t.numpy()) # Take 100 episode averages and plot them too if len(durations_t) >= 100: means = durations_t.unfold(0, 100, 1).mean(1).view(-1) means = torch.cat((torch.zeros(99), means)) plt.plot(means.numpy()) plt.pause(0.001) # pause a bit so that plots are updated if is_ipython: display.clear_output(wait=True) display.display(plt.gcf()) 训练循环 最终用于训练模型的代码 在下面代码中有一个 optimize_model 函数, 它用于实现优化过程的其中一步. 它首先 取出一个批次的样本, 然后将所有的张量全部合并到一个中, 并计算 和 , 最终将这些结果全都融入到loss中去. 假如 是一个终止状态, 则 . last_sync = 0 def optimize_model(): global last_sync if len(memory) 下面代码中包含主要的训练循环. 首先, 我们重新设置环境, 并实例化 state 变量. 然后, 我们对动作取样并执行, 观察下一屏幕图并得到回馈因子 (通常为1), 同时优化一次模型. 当动态帧结束时 (即我们的模型fail了), 开始新一轮的循环. 下面的 num_episodes 变量设置的很小. 你可以把这个 notebook 下载下来然后运行更多帧. num_episodes = 10 for i_episode in range(num_episodes): # Initialize the environment and state env.reset() last_screen = get_screen() current_screen = get_screen() state = current_screen - last_screen for t in count(): # Select and perform an action action = select_action(state) _, reward, done, _ = env.step(action[0, 0]) reward = Tensor([reward]) # 观察记录新状态 last_screen = current_screen current_screen = get_screen() if not done: next_state = current_screen - last_screen else: next_state = None # 将变化过程存到内存中 memory.push(state, action, next_state, reward) # 转移到下一状态 state = next_state # 对目标神经网络执行一步优化 optimize_model() if done: episode_durations.append(t + 1) plot_durations() break print('Complete') env.render(close=True) env.close() plt.ioff() plt.show() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"dist_tuto.html":{"url":"dist_tuto.html","title":"Writing Distributed Applications with PyTorch","keywords":"","body":"Writing Distributed Applications with PyTorch 译者：@Sylvester Author: Séb Arnold In this short tutorial, we will be going over the distributed package of PyTorch. We’ll see how to set up the distributed setting, use the different communication strategies, and go over some the internals of the package. Setup The distributed package included in PyTorch (i.e., torch.distributed) enables researchers and practitioners to easily parallelize their computations across processes and clusters of machines. To do so, it leverages the messaging passing semantics allowing each process to communicate data to any of the other processes. As opposed to the multiprocessing (torch.multiprocessing) package, processes can use different communication backends and are not restricted to being executed on the same machine. In order to get started we need the ability to run multiple processes simultaneously. If you have access to compute cluster you should check with your local sysadmin or use your favorite coordination tool. (e.g., pdsh, clustershell, or others) For the purpose of this tutorial, we will use a single machine and fork multiple processes using the following template. \"\"\"run.py:\"\"\" #!/usr/bin/env python import os import torch import torch.distributed as dist from torch.multiprocessing import Process def run(rank, size): \"\"\" Distributed function to be implemented later. \"\"\" pass def init_processes(rank, size, fn, backend='tcp'): \"\"\" Initialize the distributed environment. \"\"\" os.environ['MASTER_ADDR'] = '127.0.0.1' os.environ['MASTER_PORT'] = '29500' dist.init_process_group(backend, rank=rank, world_size=size) fn(rank, size) if __name__ == \"__main__\": size = 2 processes = [] for rank in range(size): p = Process(target=init_processes, args=(rank, size, run)) p.start() processes.append(p) for p in processes: p.join() The above script spawns two processes who will each setup the distributed environment, initialize the process group (dist.init_process_group), and finally execute the given run function. Let’s have a look at the init_processes function. It ensures that every process will be able to coordinate through a master, using the same ip address and port. Note that we used the TCP backend, but we could have used MPI](https://en.wikipedia.org/wiki/Message_Passing_Interface) or Gloo instead. (c.f. [Section 5.1) We will go over the magic happening in dist.init_process_group at the end of this tutorial, but it essentially allows processes to communicate with each other by sharing their locations. Point-to-Point Communication Send and Recv A transfer of data from one process to another is called a point-to-point communication. These are achieved through the send and recv functions or their immediate counter-parts, isend and irecv. \"\"\"Blocking point-to-point communication.\"\"\" def run(rank, size): tensor = torch.zeros(1) if rank == 0: tensor += 1 # Send the tensor to process 1 dist.send(tensor=tensor, dst=1) else: # Receive tensor from process 0 dist.recv(tensor=tensor, src=0) print('Rank ', rank, ' has data ', tensor[0]) In the above example, both processes start with a zero tensor, then process 0 increments the tensor and sends it to process 1 so that they both end up with 1.0. Notice that process 1 needs to allocate memory in order to store the data it will receive. Also notice that send/recv are blocking: both processes stop until the communication is completed. On the other hand immediates are non-blocking; the script continues its execution and the methods return a DistributedRequest object upon which we can choose to wait(). \"\"\"Non-blocking point-to-point communication.\"\"\" def run(rank, size): tensor = torch.zeros(1) req = None if rank == 0: tensor += 1 # Send the tensor to process 1 req = dist.isend(tensor=tensor, dst=1) print('Rank 0 started sending') else: # Receive tensor from process 0 req = dist.irecv(tensor=tensor, src=0) print('Rank 1 started receiving') req.wait() print('Rank ', rank, ' has data ', tensor[0]) When using immediates we have to be careful about with our usage of the sent and received tensors. Since we do not know when the data will be communicated to the other process, we should not modify the sent tensor nor access the received tensor before req.wait() has completed. In other words, writing to tensor after dist.isend() will result in undefined behaviour. reading from tensor after dist.irecv() will result in undefined behaviour. However, after req.wait() has been executed we are guaranteed that the communication took place, and that the value stored in tensor[0] is 1.0. Point-to-point communication is useful when we want a fine-grained control over the communication of our processes. They can be used to implement fancy algorithms, such as the one used in Baidu’s DeepSpeech](https://github.com/baidu-research/baidu-allreduce) or Facebook’s large-scale experiments.(c.f. [Section 4.1) Collective Communication | Scatter | Gather | | Reduce | All-Reduce | | Broadcast | All-Gather | As opposed to point-to-point communcation, collectives allow for communication patterns across all processes in a group. A group is a subset of all our processes. To create a group, we can pass a list of ranks to dist.new_group(group). By default, collectives are executed on the all processes, also known as the world. For example, in order to obtain the sum of all tensors at all processes, we can use the dist.all_reduce(tensor, op, group) collective. \"\"\" All-Reduce example.\"\"\" def run(rank, size): \"\"\" Simple point-to-point communication. \"\"\" group = dist.new_group([0, 1]) tensor = torch.ones(1) dist.all_reduce(tensor, op=dist.reduce_op.SUM, group=group) print('Rank ', rank, ' has data ', tensor[0]) Since we want the sum of all tensors in the group, we use dist.reduce_op.SUM as the reduce operator. Generally speaking, any commutative mathematical operation can be used as an operator. Out-of-the-box, PyTorch comes with 4 such operators, all working at the element-wise level: dist.reduce_op.SUM, dist.reduce_op.PRODUCT, dist.reduce_op.MAX, dist.reduce_op.MIN. In addition to dist.all_reduce(tensor, op, group), there are a total of 6 collectives currently implemented in PyTorch. dist.broadcast(tensor, src, group): Copies tensor from src to all other processes. dist.reduce(tensor, dst, op, group): Applies op to all tensor and stores the result in dst. dist.all_reduce(tensor, op, group): Same as reduce, but the result is stored in all processes. dist.scatter(tensor, src, scatter_list, group): Copies the tensor scatter_list[i] to the process. dist.gather(tensor, dst, gather_list, group): Copies tensor from all processes in dst. dist.all_gather(tensor_list, tensor, group): Copies tensor from all processes to tensor_list, on all processes. Distributed Training Note: You can find the example script of this section in this GitHub repository. Now that we understand how the distributed module works, let us write something useful with it. Our goal will be to replicate the functionality of DistributedDataParallel. Of course, this will be a didactic example and in a real-world situtation you should use the official, well-tested and well-optimized version linked above. Quite simply we want to implement a distributed version of stochastic gradient descent. Our script will let all processes compute the gradients of their model on their batch of data and then average their gradients. In order to ensure similar convergence results when changing the number of processes, we will first have to partition our dataset. (You could also use tnt.dataset.SplitDataset, instead of the snippet below.) \"\"\" Dataset partitioning helper \"\"\" class Partition(object): def __init__(self, data, index): self.data = data self.index = index def __len__(self): return len(self.index) def __getitem__(self, index): data_idx = self.index[index] return self.data[data_idx] class DataPartitioner(object): def __init__(self, data, sizes=[0.7, 0.2, 0.1], seed=1234): self.data = data self.partitions = [] rng = Random() rng.seed(seed) data_len = len(data) indexes = [x for x in range(0, data_len)] rng.shuffle(indexes) for frac in sizes: part_len = int(frac * data_len) self.partitions.append(indexes[0:part_len]) indexes = indexes[part_len:] def use(self, partition): return Partition(self.data, self.partitions[partition]) With the above snippet, we can now simply partition any dataset using the following few lines: \"\"\" Partitioning MNIST \"\"\" def partition_dataset(): dataset = datasets.MNIST('./data', train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])) size = dist.get_world_size() bsz = 128 / float(size) partition_sizes = [1.0 / size for _ in range(size)] partition = DataPartitioner(dataset, partition_sizes) partition = partition.use(dist.get_rank()) train_set = torch.utils.data.DataLoader(partition, batch_size=bsz, shuffle=True) return train_set, bsz Assuming we have 2 replicas, then each process will have a train_set of 60000 / 2 = 30000 samples. We also divide the batch size by the number of replicas in order to maintain the overall batch size of 128. We can now write our usual forward-backward-optimize training code, and add a function call to average the gradients of our models. (The following is largely inspired from the official PyTorch MNIST example.) \"\"\" Distributed Synchronous SGD Example \"\"\" def run(rank, size): torch.manual_seed(1234) train_set, bsz = partition_dataset() model = Net() optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5) num_batches = ceil(len(train_set.dataset) / float(bsz)) for epoch in range(10): epoch_loss = 0.0 for data, target in train_set: data, target = Variable(data), Variable(target) optimizer.zero_grad() output = model(data) loss = F.nll_loss(output, target) epoch_loss += loss.data[0] loss.backward() average_gradients(model) optimizer.step() print('Rank ', dist.get_rank(), ', epoch ', epoch, ': ', epoch_loss / num_batches) It remains to implement the average_gradients(model) function, which simply takes in a model and averages its gradients across the whole world. \"\"\" Gradient averaging. \"\"\" def average_gradients(model): size = float(dist.get_world_size()) for param in model.parameters(): dist.all_reduce(param.grad.data, op=dist.reduce_op.SUM) param.grad.data /= size Et voilà! We successfully implemented distributed synchronous SGD and could train any model on a large computer cluster. Note: While the last sentence is technically true, there are a lot more tricks required to implement a production-level implementation of synchronous SGD. Again, use what has been tested and optimized. Our Own Ring-Allreduce As an additional challenge, imagine that we wanted to implement DeepSpeech’s efficient ring allreduce. This is fairly easily implemented using point-to-point collectives. \"\"\" Implementation of a ring-reduce with addition. \"\"\" def allreduce(send, recv): rank = dist.get_rank() size = dist.get_world_size() send_buff = th.zeros(send.size()) recv_buff = th.zeros(send.size()) accum = th.zeros(send.size()) accum[:] = send[:] left = ((rank - 1) + size) % size right = (rank + 1) % size for i in range(size - 1): if i % 2 == 0: # Send send_buff send_req = dist.isend(send_buff, right) dist.recv(recv_buff, left) accum[:] += recv[:] else: # Send recv_buff send_req = dist.isend(recv_buff, right) dist.recv(send_buff, left) accum[:] += send[:] send_req.wait() recv[:] = accum[:] In the above script, the allreduce(send, recv) function has a slightly different signature than the ones in PyTorch. It takes a recv tensor and will store the sum of all send tensors in it. As an exercise left to the reader, there is still one difference between our version and the one in DeepSpeech: their implementation divide the gradient tensor into chunks, so as to optimially utilize the communication bandwidth. (Hint: toch.chunk) Advanced Topics We are now ready to discover some of the more advanced functionalities of torch.distributed. Since there is a lot to cover, this section is divided into two subsections: Communication Backends: where we learn how to use MPI and Gloo for GPU-GPU communication. Initialization Methods: where we understand how to best setup the initial coordination phase in dist.init_process_group(). Communication Backends One of the most elegant aspects of torch.distributed is its ability to abstract and build on top of different backends. As mentioned before, there are currently three backends implemented in PyTorch: TCP, MPI, and Gloo. They each have different specifications and tradeoffs, depending on the desired use-case. A comparative table of supported functions can be found here. TCP Backend So far we have made extensive usage of the TCP backend. It is quite handy as a development platform, as it is guaranteed to work on most machines and operating systems. It also supports all point-to-point and collective functions on CPU. However, there is no support for GPUs and its communication routines are not as optimized as the MPI one. Gloo Backend The Gloo backend provides an optimized implementation of collective communication procedures, both for CPUs and GPUs. It particularly shines on GPUs as it can perform communication without transferring data to the CPU’s memory using GPUDirect. It is also capable of using NCCL to perform fast intra-node communication and implements its own algorithms for inter-node routines. Since version 0.2.0, the Gloo backend is automatically included with the pre-compiled binaries of PyTorch. As you have surely noticed, our distributed SGD example does not work if you put model on the GPU. Let’s fix it by first replacing backend='gloo' in init_processes(rank, size, fn, backend='tcp'). At this point, the script will still run on CPU but uses the Gloo backend behind the scenes. In order to use multiple GPUs, let us also do the following modifications: init_processes(rank, size, fn, backend='tcp') init_processes(rank, size, fn, backend='gloo') model = Net() model = Net().cuda(rank) data, target = Variable(data), Variable(target) data, target = Variable(data.cuda(rank)), Variable(target.cuda(rank)) With the above modifications, our model is now training on two GPUs and you can monitor their utilization with watch nvidia-smi. MPI Backend The Message Passing Interface (MPI) is a standardized tool from the field of high-performance computing. It allows to do point-to-point and collective communications and was the main inspiration for the API of torch.distributed. Several implementations of MPI exist (e.g. Open-MPI, MVAPICH2, Intel MPI) each optimized for different purposes. The advantage of using the MPI backend lies in MPI’s wide availability - and high-level of optimization - on large computer clusters. Some recent implementations are also able to take advantage of CUDA IPC and GPU Direct technologies in order to avoid memory copies through the CPU. Unfortunately, PyTorch’s binaries can not include an MPI implementation and we’ll have to recompile it by hand. Fortunately, this process is fairly simple given that upon compilation, PyTorch will look by itself for an available MPI implementation. The following steps install the MPI backend, by installing PyTorch from sources. Create and activate your Anaconda environment, install all the pre-requisites following the guide, but do not run python setup.py install yet. Choose and install your favorite MPI implementation. Note that enabling CUDA-aware MPI might require some additional steps. In our case, we’ll stick to Open-MPI without GPU support: conda install -c conda-forge openmpi Now, go to your cloned PyTorch repo and execute python setup.py install. In order to test our newly installed backend, a few modifications are required. Replace the content under if __name__ == '__main__': with init_processes(0, 0, run, backend='mpi'). Run mpirun -n 4 python myscript.py. The reason for these changes is that MPI needs to create its own environment before spawning the processes. MPI will also spawn its own processes and perform the handshake described in Initialization Methods, making the rankand size arguments of init_process_group superfluous. This is actually quite powerful as you can pass additional arguments to mpirun in order to tailor computational resources for each process. (Things like number of cores per process, hand-assigning machines to specific ranks, and some more) Doing so, you should obtain the same familiar output as with the other communication backends. Initialization Methods To finish this tutorial, let’s talk about the very first function we called: dist.init_process_group(backend, init_method). In particular, we will go over the different initialization methods which are responsible for the initial coordination step between each process. Those methods allow you to define how this coordination is done. Depending on your hardware setup, one of these methods should be naturally more suitable than the others. In addition to the following sections, you should also have a look at the official documentation. Before diving into the initialization methods, let’s have a quick look at what happens behind init_process_group from the C/C++ perspective. First, the arguments are parsed and validated. The backend is resolved via the name2channel.at() function. A Channel class is returned, and will be used to perform the data transmission. The GIL is dropped, and THDProcessGroupInit() is called. This instantiates the channel and adds the address of the master node. The process with rank 0 will execute the master procedure, while all other ranks will be workers. The master Creates sockets for all workers. Waits for all workers to connect. Sends them information about the location of the other processes. Each worker Creates a socket to the master. Sends their own location information. Receives information about the other workers. Opens a socket and handshakes with all other workers. The initialization is done, and everyone is connected to everyone. Environment Variable We have been using the environment variable initialization method throughout this tutorial. By setting the following four environment variables on all machines, all processes will be able to properly connect to the master, obtain information about the other processes, and finally handshake with them. MASTER_PORT: A free port on the machine that will host the process with rank 0. MASTER_ADDR: IP address of the machine that will host the process with rank 0. WORLD_SIZE: The total number of processes, so that the master knows how many workers to wait for. RANK: Rank of each process, so they will know whether it is the master of a worker. Shared File System The shared filesystem requires all processes to have access to a shared file system, and will coordinate them through a shared file. This means that each process will open the file, write its information, and wait until everybody did so. After what all required information will be readily available to all processes. In order to avoid race conditions, the file system must support locking through fcntl. Note that you can specify ranks manually or let the processes figure it out by themselves. Be defining a unique groupname per job you can use the same file path for multiple jobs and safely avoid collision. dist.init_process_group(init_method='file:///mnt/nfs/sharedfile', world_size=4, group_name='mygroup') TCP Init & Multicast Initializing via TCP can be achieved in two different ways: By providing the IP address of the process with rank 0 and the world size. By providing any valid IP multicast address and the world size. In the first case, all workers will be able to connect to the process with rank 0 and follow the procedure described above. dist.init_process_group(init_method='tcp://10.1.1.20:23456', rank=args.rank, world_size=4) In the second case, the multicast address specifies the group of nodes who might potentially be active and the coordination can be handled by allowing each process to have an initial handshake before following the above procedure. In addition TCP multicast initialization also supports a group_name argument (as with the shared file method) allowing multiple jobs to be scheduled on the same cluster. dist.init_process_group(init_method='tcp://[ff15:1e18:5d4c:4cf0:d02d:b659:53ba:b0a7]:23456', world_size=4) **Acknowledgements** I’d like to thank the PyTorch developers for doing such a good job on their implementation, documentation, and tests. When the code was unclear, I could always count on the docs or the tests to find an answer. In particular, I’d like to thank Soumith Chintala, Adam Paszke, and Natalia Gimelshein for providing insightful comments and answering questions on early drafts. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"spatial_transformer_tutorial.html":{"url":"spatial_transformer_tutorial.html","title":"空间转换网络 (Spatial Transformer Networks) 教程","keywords":"","body":"空间转换网络 (Spatial Transformer Networks) 教程 译者：@Twinkle 原作者: Ghassen HAMROUNI 在这篇教程中, 你会学到如何用名为空间转换网络 (spatial transformer networks) 的视觉注意力结构来加强你的网络. 你可以从这篇论文上看到更多关于空间转换网络 (spatial transformer networks)的知识: DeepMind paper 空间转换网络 (spatial transformer networks) 是对关注空间变换可区分性的一种推广 形式. 短空间转换网络 (STN for short) 允许一个神经网络学习如何在输入图像上表现出空 间变换, 以此来增强模型的几何不变性. 例如, 它可以裁剪一个感兴趣的区域, 缩放和修正图像的方向. 由于卷积神经网络对旋转、缩放 和更普遍仿射变换并不具有不变性, 因此它相对来说是一种有用的结构. STN (空间转换网络) 最好的一点是它能在非常小的改动之后, 被简单地嵌入到任何已存在的卷积神 经网络中. # 许可协议: BSD # 作者: Ghassen Hamrouni from __future__ import print_function import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim import torchvision from torchvision import datasets, transforms from torch.autograd import Variable import matplotlib.pyplot as plt import numpy as np plt.ion() # 交互模式 读数据 在这里我们用经典的 MNIST 数据集做试验. 使用一个被空间转换网络增强的标准卷积神经 网络. use_cuda = torch.cuda.is_available() # 训练集 train_loader = torch.utils.data.DataLoader( datasets.MNIST(root='.', train=True, download=True, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=64, shuffle=True, num_workers=4) # 测试集 test_loader = torch.utils.data.DataLoader( datasets.MNIST(root='.', train=False, transform=transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,)) ])), batch_size=64, shuffle=True, num_workers=4) 描述空间转换网络 (spatial transformer networks) 空间转换网络 (spatial transformer networks) 归纳为三个主要的部件 : 本地网络 (The localization network) 是一个常规CNN, 它可以回归转换参数. 这种空间转换不是简单地从数据集显式学习到的, 而是自动地学习以增强全局准确率. 网格生成器 (The grid generator) 在输入图像中生成对应于来自输出图像的每个像 素的坐标网格. 采样器 (The sampler) 将转换的参数应用于输入图像. 注解： 我们需要包含 affine_grid 和 grid_sample 模块的 PyTorch 最新版本. class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(1, 10, kernel_size=5) self.conv2 = nn.Conv2d(10, 20, kernel_size=5) self.conv2_drop = nn.Dropout2d() self.fc1 = nn.Linear(320, 50) self.fc2 = nn.Linear(50, 10) # 空间转换本地网络 (Spatial transformer localization-network) self.localization = nn.Sequential( nn.Conv2d(1, 8, kernel_size=7), nn.MaxPool2d(2, stride=2), nn.ReLU(True), nn.Conv2d(8, 10, kernel_size=5), nn.MaxPool2d(2, stride=2), nn.ReLU(True) ) # 3 * 2 仿射矩阵 (affine matrix) 的回归器 self.fc_loc = nn.Sequential( nn.Linear(10 * 3 * 3, 32), nn.ReLU(True), nn.Linear(32, 3 * 2) ) # 用身份转换 (identity transformation) 初始化权重 (weights) / 偏置 (bias) self.fc_loc[2].weight.data.fill_(0) self.fc_loc[2].bias.data = torch.FloatTensor([1, 0, 0, 0, 1, 0]) # 空间转换网络的前向函数 (Spatial transformer network forward function) def stn(self, x): xs = self.localization(x) xs = xs.view(-1, 10 * 3 * 3) theta = self.fc_loc(xs) theta = theta.view(-1, 2, 3) grid = F.affine_grid(theta, x.size()) x = F.grid_sample(x, grid) return x def forward(self, x): # 转换输入 x = self.stn(x) # 执行常规的正向传递 x = F.relu(F.max_pool2d(self.conv1(x), 2)) x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) x = x.view(-1, 320) x = F.relu(self.fc1(x)) x = F.dropout(x, training=self.training) x = self.fc2(x) return F.log_softmax(x, dim=1) model = Net() if use_cuda: model.cuda() 训练模型 现在, 让我们用 SGD 算法来训练模型. 这个网络用监督学习的方式学习分类任务. 同时, 这个模型以端到端的方式自动地学习空间转换网络 (STN) . optimizer = optim.SGD(model.parameters(), lr=0.01) def train(epoch): model.train() for batch_idx, (data, target) in enumerate(train_loader): if use_cuda: data, target = data.cuda(), target.cuda() data, target = Variable(data), Variable(target) optimizer.zero_grad() output = model(data) loss = F.nll_loss(output, target) loss.backward() optimizer.step() if batch_idx % 500 == 0: print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format( epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.data[0])) # # 一个简单的测试程序来测量空间转换网络 (STN) 在 MNIST 上的表现. # def test(): model.eval() test_loss = 0 correct = 0 for data, target in test_loader: if use_cuda: data, target = data.cuda(), target.cuda() data, target = Variable(data, volatile=True), Variable(target) output = model(data) # 累加批loss test_loss += F.nll_loss(output, target, size_average=False).data[0] # 得到最大对数几率 (log-probability) 的索引. pred = output.data.max(1, keepdim=True)[1] correct += pred.eq(target.data.view_as(pred)).cpu().sum() test_loss /= len(test_loader.dataset) print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n' .format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset))) 可视化空间转换网络 (STN) 的结果 现在, 我们要检查学到的视觉注意力机制的结果. 我们定义一个小的辅助函数, 以在训练过程中可视化转换过程. def convert_image_np(inp): \"\"\"Convert a Tensor to numpy image.\"\"\" inp = inp.numpy().transpose((1, 2, 0)) mean = np.array([0.485, 0.456, 0.406]) std = np.array([0.229, 0.224, 0.225]) inp = std * inp + mean inp = np.clip(inp, 0, 1) return inp # 我们想要在训练之后可视化空间转换层 (spatial transformers layer) 的输出, 我们 # 用 STN 可视化一批输入图像和相对于的转换后的数据. def visualize_stn(): # 得到一批输入数据 data, _ = next(iter(test_loader)) data = Variable(data, volatile=True) if use_cuda: data = data.cuda() input_tensor = data.cpu().data transformed_input_tensor = model.stn(data).cpu().data in_grid = convert_image_np( torchvision.utils.make_grid(input_tensor)) out_grid = convert_image_np( torchvision.utils.make_grid(transformed_input_tensor)) # 并行地 (side-by-side) 画出结果 f, axarr = plt.subplots(1, 2) axarr[0].imshow(in_grid) axarr[0].set_title('Dataset Images') axarr[1].imshow(out_grid) axarr[1].set_title('Transformed Images') for epoch in range(1, 20 + 1): train(epoch) test() # 在一些输入批次中可视化空间转换网络 (STN) 的转换 visualize_stn() plt.ioff() plt.show() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"advanced_tutorials.html":{"url":"advanced_tutorials.html","title":"高级教程","keywords":"","body":"高级教程 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"neural_style_tutorial.html":{"url":"neural_style_tutorial.html","title":"用 PyTorch 做 神经转换 (Neural Transfer)","keywords":"","body":"用 PyTorch 做 神经转换 (Neural Transfer) 译者：@Twinkle 原作者: Alexis Jacq 介绍 欢迎观看! 这篇教程解释了如何实现 Leon A. Gatys, Alexander S. Ecker 和 Matthias Bethge 几位学者发明的 Neural-Style 算法 . 题中的神经描述的是什么? 神经风格, 或者说神经转换是一种算法, 它输入一张内容图像 (例如海龟), 一张风格图像 (例如艺术波浪), 然后返回内容图像的内容, 此时返回的内容像是被艺术风格图像的风格渲染过: 它是如何工作的? 原理很简单: 我们定义两个距离, 一个是关于内容的 () , 另一个是关于风格的 () . 衡量两张图像的内容有多么不同, 而 衡量两张图像的风格有多么不同. 接着我们拿出我们的输入, 也就是第三张图像 (例如全噪声), 然后我们转换它, 同时最小化它与内容图像的内容距离和它与风格图像的风格距离. 好吧, 它具体是怎么工作的? 继续深入需要一些数学知识. 令 代表一个预训练好的深度卷积神经网络, 代表任何图像. 是神经网络输入 后的结果 (包括在所有层的特征映射). 令 代表在深度为 层处的特征映射, 都矢量化和级联为一个单一矢量. 我们简单地用 定义 在 层的内容. 如果 是另一张和 相同大小的图像, 我们定义这两张图像在 层的内容距离如下: 式中 是 的第 个元素. 定义风格要更繁琐一些. 令满足 的 代表 层矢量化的 个特征映射中的第 个. 图像 在 层的风格 定义为满足 的所有矢量化特征映射 的克产物 (Gram produce). 换句话说, 是一个 x 的矩阵, 其在 行和 列的每个元素 是 和 之间的矢量产物 : 式中 是 的第 个元素. 我们可以把 当做特征映射 和 相关性的衡量. 那样的话, 代表了 在 层特征向量的相关性矩阵. 注意 的尺寸只决定于特征映射的数量, 不被 的尺寸所影响. 然后如果 是 任意尺寸 的另一张图像, 我们定义在 层的风格距离如下: 要想一次性地在一些层最小化一个可变图像 与目标内容图像 间的 , 和 与目标风格图像 间的 , 我们计算并加和每个目标层每个距离的梯度 (对 求导). 式中 和 分别是内容和风格的目标层(任意陈述), 和 是风格和内容关于每个目标层的权重(任意陈述). 然后我们对 进行梯度下降: 好吧, 数学的部分就到此为止. 如果你想要更加深入(比如怎么计算梯度), 我们推荐你阅读原始论文 (作者是 Leon A. Gatys 和 AL), 论文中这部分解释地更好更清晰. 对于在 PyTorch 中的实现, 我们已经有了我们需要的一切: 事实上就是 PyTorch, 所有的梯度都被为你自动且动态地计算(当你从库中使用函数时). 这就是为什么算法的实现在 PyTorch 中变得非常轻松. PyTorch 实现 如果你不确定是否理解了以上数学公式, 你也可以通过实现它, 在过程中有所领悟. 如果你正在探索 PyTorch , 我们推荐你先阅读这篇教程 Introduction to PyTorch. 包 我们将会依赖下列这些包: torch, torch.nn, numpy (indispensables packages for neural networks with PyTorch) torch.autograd.Variable (dynamic computation of the gradient wrt a variable) torch.optim (efficient gradient descents) PIL, PIL.Image, matplotlib.pyplot (load and display images) torchvision.transforms (treat PIL images and transform into torch tensors) torchvision.models (train or load pre-trained models) copy (to deep copy the models; system package) from __future__ import print_function import torch import torch.nn as nn from torch.autograd import Variable import torch.optim as optim from PIL import Image import matplotlib.pyplot as plt import torchvision.transforms as transforms import torchvision.models as models import copy Cuda 如果你的计算机里有 GPU, 推荐在上面运行算法, 尤其是当你要尝试 大型网络时 (就像 VGG). 有鉴于此, 我们有 torch.cuda.is_available(), 如果你的计算机有可用 GPU 则会返回 True. 然后我们用 .cuda() 方法 将可分配的进程和模块从 CPU 移动到 GPU. 当我们想将这些模块重新移回 CPU 的时候(比如要用 numpy), 我们用 .cpu() 方法. 最后, .type(dtype) 会用来将一个 torch.FloatTensor 转化为 用于 GPU 进程输入的 torch.cuda.FloatTensor. use_cuda = torch.cuda.is_available() dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor 读取图像 为了简化其实现, 让我们从导入一个相同维度的风格和内容图像开始. 然后我们将它们缩放到想要的输入图像尺寸 (在例子中是 128 和 512, 取决你的 GPU 是否可用) 然后把它们转化为 torch 张量, 以待喂入一个神经网络. 注解： 这里是教程需要的图像的下载链接: picasso.jpg 和 dancing.jpg. 下载这两张图像然后把它们加入到名为 images 的目录中. # 想要的输出图像尺寸 imsize = 512 if use_cuda else 128 # 如果没有 GPU 则使用小尺寸 loader = transforms.Compose([ transforms.Scale(imsize), # 缩放图像 transforms.ToTensor()]) # 将其转化为 torch 张量 def image_loader(image_name): image = Image.open(image_name) image = Variable(loader(image)) # 由于神经网络输入的需要, 添加 batch 的维度 image = image.unsqueeze(0) return image style_img = image_loader(\"images/picasso.jpg\").type(dtype) content_img = image_loader(\"images/dancing.jpg\").type(dtype) assert style_img.size() == content_img.size(), \\ \"we need to import style and content images of the same size\" 导入的 PIL 图像像素值的范围为 0 到 255. 转化为 torch 张量后, 它们的值范围变为了 0 到and 1. 这是个重要的细节: torch 库中的神经网络被使用 0-1 的张量图像训练. 如果你尝试用 0-255 的张量图像喂入神经网络, 激活的特征映射就没用了. 这不是 使用 Caffe 库中预训练的神经网络, Caffe 中是用 0-255 的张量图像训练的. 显示图像 我们将使用 plt.imshow 来显示图像. 所以我们需要先把它们转回 PIL 图像. unloader = transforms.ToPILImage() # 转回 PIL 图像 plt.ion() def imshow(tensor, title=None): image = tensor.clone().cpu() # 克隆是为了不改变它 image = image.view(3, imsize, imsize) # 移除 batch 维度 image = unloader(image) plt.imshow(image) if title is not None: plt.title(title) plt.pause(0.001) # 暂停一会, 让绘图更新 plt.figure() imshow(style_img.data, title='Style Image') plt.figure() imshow(content_img.data, title='Content Image') 内容损失 内容损失是一个在网络输入为 的层 输入特征映射 的函数, 返回此图像与内容图像间的加权内容距离 . 之后, 权重 和目标内容 就成为了函数的参数. 我们把这个函数作为 torch 模块来实现, 把这些参 数作为构造器的输入. 这个距离 是两个特征映射集的 均方误差, 可以用作为第三个参数的标准的 nn.MSELoss 来计算. 我们会在每个目标层加入我们的内容损失作为额外的神经网络模块. 这样, 每次我们都会给神经 网络投喂一张输入图像 , 所有的损失都会在目标层被计算, 多亏了自动梯度计算, 所有梯度都会被搞定. 要实现, 我们只需写出转换模块的 forward 方法, 这个模块就变 成了网络的 ‘’transparent layer (透明层)’‘, 计算好的损失被存为模块的参数. 最后, 我们定义一个假的 backward 方法, 它仅仅只调用后向方法 nn.MSELoss 来重构梯度. 这个方法返回计算好的损失: 运行梯度下降时要想显示风格和内容损失的变化, 这会非常有用. class ContentLoss(nn.Module): def __init__(self, target, weight): super(ContentLoss, self).__init__() # 我们会从所使用的树中“分离”目标内容 self.target = target.detach() * weight # 动态地计算梯度: 它是个状态值, 不是变量. # 否则评价指标的前向方法会抛出错误. self.weight = weight self.criterion = nn.MSELoss() def forward(self, input): self.loss = self.criterion(input * self.weight, self.target) self.output = input return self.output def backward(self, retain_graph=True): self.loss.backward(retain_graph=retain_graph) return self.loss 注解： 重要细节: 这个模块虽然叫做 ContentLoss, 却不是个真正的 Pytorch 损失函数. 如果你想像 Pytorch 损失一样定义你的内容损失, 你得新建一个 Pytorch 自动求导函数并手动得在 backward 方法中重算/实现梯度. 风格损失 对于风格损失, 我们首先需要定义一个给定输入 在 层的特征映射 时计算克产物 的模块. 令 表示 重变形为 x 的版本, 这里 是 层特征 映射的数量, 是任意矢量化特征映射 的长度. 的第 行是 . 可以验证 . 鉴于此, 实现我们的模块就很容易了: class GramMatrix(nn.Module): def forward(self, input): a, b, c, d = input.size() # a=batch size(=1) # b= 特征映射的数量 # (c,d)= 一个特征映射的维度 (N=c*d) features = input.view(a * b, c * d) # 将 F_XL 转换为 \\hat F_XL G = torch.mm(features, features.t()) # 计算克产物 (gram product) # 我们用除以每个特征映射元素数量的方法 # 标准化克矩阵 (gram matrix) 的值 return G.div(a * b * c * d) 特征映射的维度 越长, 则克矩阵 (gram matrix) 的值越大. 因此如果我们不用 来标准化, 在梯度下降过程中第一层 (在池化层之前) 的损失计算就会过于重要. 我们当然不希望这样, 因为我们感兴趣的风格特征都在最深的那些层! 接着, 风格损失模块被以和内容损失模块相同的方式实现, 但是我们还得把 gramMatrix 加入作为参数: class StyleLoss(nn.Module): def __init__(self, target, weight): super(StyleLoss, self).__init__() self.target = target.detach() * weight self.weight = weight self.gram = GramMatrix() self.criterion = nn.MSELoss() def forward(self, input): self.output = input.clone() self.G = self.gram(input) self.G.mul_(self.weight) self.loss = self.criterion(self.G, self.target) return self.output def backward(self, retain_graph=True): self.loss.backward(retain_graph=retain_graph) return self.loss 读取神经网络 现在, 我们要导入一个预训练好的神经网络. 和论文一样, 我们用预训练 的 19 层 VGG 网络 (VGG19). PyTorch对 VGG 的实现模块分为两个子 Sequential 模块: features (包括卷积和池化层) 和 classifier (包括全连接层). 我们只对 features 感兴趣: cnn = models.vgg19(pretrained=True).features # 可能的话将它移到 GPU 上: if use_cuda: cnn = cnn.cuda() Sequential (顺序) 模块包含一个子模块的列表. 比如, vgg19.features 包含一个以正确深度排列的序列 (Conv2d, ReLU, Maxpool2d, Conv2d, ReLU…), 就如我们在 Content loss 部分讲到的, 我们想要把我们的风格和内容损失模块以想要的深度作为 ‘透明层’ 加入到 我们的网络中. 为了这样, 我们建立了一个新的 Sequential (顺序) 模块, 在其中我们把 vgg19 和我们的损失模块以正确的顺序加入: # 希望计算风格/内容损失的层 : content_layers_default = ['conv_4'] style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5'] def get_style_model_and_losses(cnn, style_img, content_img, style_weight=1000, content_weight=1, content_layers=content_layers_default, style_layers=style_layers_default): cnn = copy.deepcopy(cnn) # 仅为了有一个可迭代的列表 内容/风格 损失 content_losses = [] style_losses = [] model = nn.Sequential() # 新建的 Sequential 网络模块 gram = GramMatrix() # 我们需要一个克模块 (gram module) 来计算风格目标 # 可能的话将这些模块移到 GPU 上: if use_cuda: model = model.cuda() gram = gram.cuda() i = 1 for layer in list(cnn): if isinstance(layer, nn.Conv2d): name = \"conv_\" + str(i) model.add_module(name, layer) if name in content_layers: # 加内容损失: target = model(content_img).clone() content_loss = ContentLoss(target, content_weight) model.add_module(\"content_loss_\" + str(i), content_loss) content_losses.append(content_loss) if name in style_layers: # 加风格损失: target_feature = model(style_img).clone() target_feature_gram = gram(target_feature) style_loss = StyleLoss(target_feature_gram, style_weight) model.add_module(\"style_loss_\" + str(i), style_loss) style_losses.append(style_loss) if isinstance(layer, nn.ReLU): name = \"relu_\" + str(i) model.add_module(name, layer) if name in content_layers: # 加内容损失: target = model(content_img).clone() content_loss = ContentLoss(target, content_weight) model.add_module(\"content_loss_\" + str(i), content_loss) content_losses.append(content_loss) if name in style_layers: # 加风格损失: target_feature = model(style_img).clone() target_feature_gram = gram(target_feature) style_loss = StyleLoss(target_feature_gram, style_weight) model.add_module(\"style_loss_\" + str(i), style_loss) style_losses.append(style_loss) i += 1 if isinstance(layer, nn.MaxPool2d): name = \"pool_\" + str(i) model.add_module(name, layer) # *** return model, style_losses, content_losses 注解： 在这篇论文中他们推荐将最大池化层更改为平均池化层. AlexNet是一个比 VGG19 更小的网络, 用它实现的话我们也不会看到 任何结果质量的不同. 而如果你想做这个替代的话, 可以用这些代码: # avgpool = nn.AvgPool2d(kernel_size=layer.kernel_size, # stride=layer.stride, padding = layer.padding) # model.add_module(name,avgpool) 输入图像 为了简化代码, 我们用与内容和风格图像同样尺寸的图像做输入. 这个图像可以是白噪声的, 也可以是一份内容图像的拷贝. input_img = content_img.clone() # 如果你想用白噪声做输入, 请取消下面的注释行: # input_img = Variable(torch.randn(content_img.data.size())).type(dtype) # 在绘图中加入原始的输入图像: plt.figure() imshow(input_img.data, title='Input Image') 梯度下降 由于本算法的作者 Leon Gatys 的建议 here, 我们将使用 L-BFGS 算法来跑我们的梯度下降. 和训练一个网络不同的是, 我们希望训练输入图像来最小化 内容/风格 损失. 我们想简单地建一个 PyTorch L-BFGS 优化器, 传入我们的图像作为变量进行优化. 但是 optim.LBFGS 的第一个形参是一个需要梯度的 PyTorch Variable . 我们的输入图像是一个 Variable , 但不是需要计算梯度的树的叶节点. 为了使这个变量需要梯度运算, 一个可能的方法是从输入图像构建一个 Parameter (参数) 对象. 然后我们只需给优化器的构造器传递一个 包含这个参数的列表: def get_input_param_optimizer(input_img): # 这行显示了输入是一个需要梯度计算的参数 input_param = nn.Parameter(input_img.data) optimizer = optim.LBFGS([input_param]) return input_param, optimizer 最后一步: 循环进行梯度下降. 每一步中我们必须喂给神经网络更新后 的输入以计算新的损失, 我们要运行每个损失的 backward 方法来动态 计算他们的梯度并呈现梯度下降的每一步. 这个优化器需要一个 “closure” : 一个重新评估模型并返回损失的函数. 然而, 这里有一个小问题. 被优化的图像的像素值会在 和 之间波动, 而不是继续保持在 0 到 1. 换句话说, 图像可能会被完美地优化成荒谬的值. 事实上, 我们必须在限制下使用 优化器来使我们的输入图像一直保持正确的值. 有一个简单的解决方案: 在每一步, 都校正图像使其保持 0-1 范围的值. def run_style_transfer(cnn, content_img, style_img, input_img, num_steps=300, style_weight=1000, content_weight=1): \"\"\"Run the style transfer.\"\"\" print('Building the style transfer model..') model, style_losses, content_losses = get_style_model_and_losses(cnn, style_img, content_img, style_weight, content_weight) input_param, optimizer = get_input_param_optimizer(input_img) print('Optimizing..') run = [0] while run[0] 最后, 运行算法 output = run_style_transfer(cnn, content_img, style_img, input_img) plt.figure() imshow(output, title='Output Image') # sphinx_gallery_thumbnail_number = 4 plt.ioff() plt.show() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"numpy_extensions_tutorial.html":{"url":"numpy_extensions_tutorial.html","title":"使用 numpy 和 scipy 创建扩展","keywords":"","body":"使用 numpy 和 scipy 创建扩展 译者：@飞龙 作者: Adam Paszke 这个教程中, 我们将完成以下两个任务: 创建不带参数的神经网络层 > 这会调用 *numpy, 作为其实现的一部分 创建带有可学习的权重的神经网络层 > 这会调用 *SciPy, 作为其实现的一部分 import torch from torch.autograd import Function from torch.autograd import Variable 无参示例 这一层并不做任何有用的, 或者数学上正确的事情. 它被恰当地命名为 BadFFTFunction 层的实现 from numpy.fft import rfft2, irfft2 class BadFFTFunction(Function): def forward(self, input): numpy_input = input.numpy() result = abs(rfft2(numpy_input)) return torch.FloatTensor(result) def backward(self, grad_output): numpy_go = grad_output.numpy() result = irfft2(numpy_go) return torch.FloatTensor(result) # 由于这一层没有任何参数, 我们可以 # 仅仅将其声明为一个函数, 而不是 nn.Module 类 def incorrect_fft(input): return BadFFTFunction()(input) 所创建的层的使用示例: input = Variable(torch.randn(8, 8), requires_grad=True) result = incorrect_fft(input) print(result.data) result.backward(torch.randn(result.size())) print(input.grad) 参数化示例 它实现了带有可学习的权重的层. 它使用可学习的核, 实现了互相关. 在深度学习文献中, 它容易和卷积混淆. 反向过程计算了输入和滤波的梯度. 实现: 要注意, 实现作为一个演示, 我们并不验证它的正确性 from scipy.signal import convolve2d, correlate2d from torch.nn.modules.module import Module from torch.nn.parameter import Parameter class ScipyConv2dFunction(Function): @staticmethod def forward(ctx, input, filter): result = correlate2d(input.numpy(), filter.numpy(), mode='valid') ctx.save_for_backward(input, filter) return torch.FloatTensor(result) @staticmethod def backward(ctx, grad_output): input, filter = ctx.saved_tensors grad_output = grad_output.data grad_input = convolve2d(grad_output.numpy(), filter.t().numpy(), mode='full') grad_filter = convolve2d(input.numpy(), grad_output.numpy(), mode='valid') return Variable(torch.FloatTensor(grad_input)), \\ Variable(torch.FloatTensor(grad_filter)) class ScipyConv2d(Module): def __init__(self, kh, kw): super(ScipyConv2d, self).__init__() self.filter = Parameter(torch.randn(kh, kw)) def forward(self, input): return ScipyConv2dFunction.apply(input, self.filter) 示例用法: module = ScipyConv2d(3, 3) print(list(module.parameters())) input = Variable(torch.randn(10, 10), requires_grad=True) output = module(input) print(output) output.backward(torch.randn(8, 8)) print(input.grad) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"super_resolution_with_caffe2.html":{"url":"super_resolution_with_caffe2.html","title":"使用 ONNX 将模型从 PyTorch 迁移到 Caffe2 和 Mobile","keywords":"","body":"使用 ONNX 将模型从 PyTorch 迁移到 Caffe2 和 Mobile 译者：@片刻 在本教程中, 我们将介绍如何使用 ONNX 将 PyTorch 中定义的模型转换为 ONNX 格式, 然后将其加载到 Caffe2 中. 一旦进入 Caffe2 , 我们可以运行该模型以仔细检查它是否正确导出, 然后演示如何使用 Caffe2 功能（例如移动导出器）在移动设备上执行模型. 在本教程中, 您需要安装 onnx, onnx-caffe2 和 Caffe2. 你可以通过 conda install -c ezyang onnx onnx-caffe2 用 onnx 和 onnx-caffe2 获得二进制版本. NOTE: 本教程需要 PyTorch 主分支, 可以按照 here 的说明进行安装 # Some standard imports import io import numpy as np from torch import nn from torch.autograd import Variable import torch.utils.model_zoo as model_zoo import torch.onnx Super-resolution 是提高图像, 视频分辨率的一种方式, 广泛用于图像处理或视频编辑. 对于本教程, 我们将首先使用带有虚拟输入的小型 super-resolution 模型. 首先, 让我们在 PyTorch 中创建一个 SuperResolution 模型. 这个模型 直接来自 PyTorch 的例子而没有修改: # Super Resolution model definition in PyTorch import torch.nn as nn import torch.nn.init as init class SuperResolutionNet(nn.Module): def __init__(self, upscale_factor, inplace=False): super(SuperResolutionNet, self).__init__() self.relu = nn.ReLU(inplace=inplace) self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2)) self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1)) self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1)) self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1)) self.pixel_shuffle = nn.PixelShuffle(upscale_factor) self._initialize_weights() def forward(self, x): x = self.relu(self.conv1(x)) x = self.relu(self.conv2(x)) x = self.relu(self.conv3(x)) x = self.pixel_shuffle(self.conv4(x)) return x def _initialize_weights(self): init.orthogonal(self.conv1.weight, init.calculate_gain('relu')) init.orthogonal(self.conv2.weight, init.calculate_gain('relu')) init.orthogonal(self.conv3.weight, init.calculate_gain('relu')) init.orthogonal(self.conv4.weight) # Create the super-resolution model by using the above model definition. torch_model = SuperResolutionNet(upscale_factor=3) 通常, 你现在要训练这个模型; 但是, 对于本教程, 我们将下载一些预先训练的权重. 请注意, 该模型没有得到充分训练以获得良好的准确性, 因此仅用于演示目的. # Load pretrained model weights model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth' batch_size = 1 # just a random number # Initialize model with the pretrained weights map_location = lambda storage, loc: storage if torch.cuda.is_available(): map_location = None torch_model.load_state_dict(model_zoo.load_url(model_url, map_location=map_location)) # set the train mode to false since we will only run the forward pass. torch_model.train(False) 在PyTorch中导出模型通过跟踪工作.要导出模型, 请调用该 torch.onnx._export() 函数. 这将执行模型, 记录运算符用于计算输出的轨迹.由于 _export 运行模型, 我们需要提供一个输入张量 x. 这个张量中的值并不重要; 只要尺寸合适, 它可以是图像或随机张量. 要了解更多关于 PyTorch 导出界面的细节, 请查看 torch.onnx文档. # Input to the model x = Variable(torch.randn(batch_size, 1, 224, 224), requires_grad=True) # Export the model torch_out = torch.onnx._export(torch_model, # model being run x, # model input (or a tuple for multiple inputs) \"super_resolution.onnx\", # where to save the model (can be a file or file-like object) export_params=True) # store the trained parameter weights inside the model file torch_out 是执行模型后的输出.通常情况下, 您可以忽略此输出, 但在此我们将使用它来验证我们导出的模型在 Caffe2 中运行时计算相同的值. 现在我们来看看 ONNX 表示法, 并在 Caffe2 中使用它. 这部分通常可以在单独的进程或另一台机器上完成, 但我们将继续使用相同的过程, 以便我们可以验证 Caffe2 和 PyTorch 是否为网络计算相同的值: import onnx import onnx_caffe2.backend # Load the ONNX ModelProto object. model is a standard Python protobuf object model = onnx.load(\"super_resolution.onnx\") # prepare the caffe2 backend for executing the model this converts the ONNX model into a # Caffe2 NetDef that can execute it. Other ONNX backends, like one for CNTK will be # availiable soon. prepared_backend = onnx_caffe2.backend.prepare(model) # run the model in Caffe2 # Construct a map from input names to Tensor data. # The graph of the model itself contains inputs for all weight parameters, after the input image. # Since the weights are already embedded, we just need to pass the input image. # Set the first input. W = {model.graph.input[0].name: x.data.numpy()} # Run the Caffe2 net: c2_out = prepared_backend.run(W)[0] # Verify the numerical correctness upto 3 decimal places np.testing.assert_almost_equal(torch_out.data.cpu().numpy(), c2_out, decimal=3) print(\"Exported model has been executed on Caffe2 backend, and the result looks good!\") 我们应该看到 PyTorch 和 Caffe2 的输出在数字上匹配达到3位小数. 作为旁注, 如果它们不匹配, 那么 Caffe2 和 PyTorch 中的操作符的实现方式会有所不同, 请在此情况下与我们联系. 使用 ONNX 迁移到 SRResNet 使用与上述相同的过程, 我们还为 本文 提出了一个有趣的新的 super-resolution 模式 “SRResNet” (感谢 Twitter 上的作者为我们提供了代码和预训练参数, 以用于本教程). 模型定义和预先训练的模型可以在 这里 找到. 以下是 SRResNet 模型输入, 输出的样子. 在移动设备上运行模型 到目前为止, 我们已经从 PyTorch 中导出了一个模型, 并展示了如何加载它并在 Caffe2 中运行它. 现在该模型已经加载到 Caffe2 中, 我们可以将其转换为适合 在移动设备上运行 的格式. 我们将使用 Caffe2 的 mobile_exporter 来生成可以在移动设备上运行的两个模型 protobufs. 第一个用于使用正确的权重初始化网络, 第二个实际运行用于执行模型. 我们将继续在本教程的其余部分使用小型 super-resolution 模型. # extract the workspace and the model proto from the internal representation c2_workspace = prepared_backend.workspace c2_model = prepared_backend.predict_net # Now import the caffe2 mobile exporter from caffe2.python.predictor import mobile_exporter # call the Export to get the predict_net, init_net. These nets are needed for running things on mobile init_net, predict_net = mobile_exporter.Export(c2_workspace, c2_model, c2_model.external_input) # Let's also save the init_net and predict_net to a file that we will later use for running them on mobile with open('init_net.pb', \"wb\") as fopen: fopen.write(init_net.SerializeToString()) with open('predict_net.pb', \"wb\") as fopen: fopen.write(predict_net.SerializeToString()) init_net 将模型参数和模型输入嵌入其中, predict_net 并将用于 init_net 在运行时指导执行. 在本文中, 我们将使用 init_net 与 predict_net 上面生成和在正常 Caffe2 后端和移动运行它们, 并验证在两个试验中产生的输出的高分辨率图像猫是相同的. 在本教程中, 我们将使用一个广泛使用的著名的猫咪图像, 如下所示: # Some standard imports from caffe2.proto import caffe2_pb2 from caffe2.python import core, net_drawer, net_printer, visualize, workspace, utils import numpy as np import os import subprocess from PIL import Image from matplotlib import pyplot from skimage import io, transform 首先, 我们加载图像, 使用标准的 skimage python 库对其进行预处理. 请注意, 这种预处理是 training/testing 神经网络处理数据的标准实践. # load the image img_in = io.imread(\"./_static/img/cat.jpg\") # resize the image to dimensions 224x224 img = transform.resize(img_in, [224, 224]) # save this resized image to be used as input to the model io.imsave(\"./_static/img/cat_224x224.jpg\", img) 现在, 作为下一步, 我们来调整大小的猫图像, 并在 Caffe2 后端运行 super-resolution 模型并保存输出图像. 图像处理步骤如下已从 PyTorch 实现 super-resolution 模型采用 这里 # load the resized image and convert it to Ybr format img = Image.open(\"./_static/img/cat_224x224.jpg\") img_ycbcr = img.convert('YCbCr') img_y, img_cb, img_cr = img_ycbcr.split() # Let's run the mobile nets that we generated above so that caffe2 workspace is properly initialized workspace.RunNetOnce(init_net) workspace.RunNetOnce(predict_net) # Caffe2 has a nice net_printer to be able to inspect what the net looks like and identify # what our input and output blob names are. print(net_printer.to_string(predict_net)) 从上面的输出中, 我们可以看到输入名为 “9”, 输出名为 “27”(有点奇怪, 我们将数字作为 blob 名称, 但这是因为跟踪 JIT 会为模型生成编号条目) # Now, let's also pass in the resized cat image for processing by the model. workspace.FeedBlob(\"9\", np.array(img_y)[np.newaxis, np.newaxis, :, :].astype(np.float32)) # run the predict_net to get the model output workspace.RunNetOnce(predict_net) # Now let's get the model output blob img_out = workspace.FetchBlob(\"27\") 现在, 我们将返回参考 PyTorch 执行 super-resolution 模型的后处理步骤, 在这里 构建回最终输出的图像并保存图像. img_out_y = Image.fromarray(np.uint8((img_out[0, 0]).clip(0, 255)), mode='L') # get the output image follow post-processing step from PyTorch implementation final_img = Image.merge( \"YCbCr\", [ img_out_y, img_cb.resize(img_out_y.size, Image.BICUBIC), img_cr.resize(img_out_y.size, Image.BICUBIC), ]).convert(\"RGB\") # Save the image, we will compare this with the output image from mobile device final_img.save(\"./_static/img/cat_superres.jpg\") 我们已经完成了在纯 Caffe2 后端运行我们的移动网络, 现在, 让我们在 Android 设备上执行模型并获取模型输出. NOTE: 对于 Android 开发, adb 需要使用 shell, 否则以下部分教程将无法运行. 在我们的移动设备 runnig 模型的第一步中, 我们将把移动设备的本地速度基准二进制文件推送到 adb. 这个二进制文件可以在移动设备上执行模型, 也可以导出稍后可以检索的模型输出. 二进制文件 在这里 可用. 为了构建二进制文件, 请 build_android.sh 按照 此处 的说明执行脚本. NOTE: 您需要 ANDROID_NDK 安装并设置您的 env 变量 ANDROID_NDK=path to ndk root # let's first push a bunch of stuff to adb, specify the path for the binary CAFFE2_MOBILE_BINARY = ('caffe2/binaries/speed_benchmark') # we had saved our init_net and proto_net in steps above, we use them now. # Push the binary and the model protos os.system('adb push ' + CAFFE2_MOBILE_BINARY + ' /data/local/tmp/') os.system('adb push init_net.pb /data/local/tmp') os.system('adb push predict_net.pb /data/local/tmp') # Let's serialize the input image blob to a blob proto and then send it to mobile for execution. with open(\"input.blobproto\", \"wb\") as fid: fid.write(workspace.SerializeBlob(\"9\")) # push the input image blob to adb os.system('adb push input.blobproto /data/local/tmp/') # Now we run the net on mobile, look at the speed_benchmark --help for what various options mean os.system( 'adb shell /data/local/tmp/speed_benchmark ' # binary to execute '--init_net=/data/local/tmp/super_resolution_mobile_init.pb ' # mobile init_net '--net=/data/local/tmp/super_resolution_mobile_predict.pb ' # mobile predict_net '--input=9 ' # name of our input image blob '--input_file=/data/local/tmp/input.blobproto ' # serialized input image '--output_folder=/data/local/tmp ' # destination folder for saving mobile output '--output=27,9 ' # output blobs we are interested in '--iter=1 ' # number of net iterations to execute '--caffe2_log_level=0 ' ) # get the model output from adb and save to a file os.system('adb pull /data/local/tmp/27 ./output.blobproto') # We can recover the output content and post-process the model using same steps as we followed earlier blob_proto = caffe2_pb2.BlobProto() blob_proto.ParseFromString(open('./output.blobproto').read()) img_out = utils.Caffe2TensorToNumpyArray(blob_proto.tensor) img_out_y = Image.fromarray(np.uint8((img_out[0,0]).clip(0, 255)), mode='L') final_img = Image.merge( \"YCbCr\", [ img_out_y, img_cb.resize(img_out_y.size, Image.BICUBIC), img_cr.resize(img_out_y.size, Image.BICUBIC), ]).convert(\"RGB\") final_img.save(\"./_static/img/cat_superres_mobile.jpg\") 现在, 您可以比较图像 cat_superres.jpg (来自纯 caffe2 后端执行的 cat_superres_mobile.jpg 模型输出) 和 (来自移动执行的模型输出) 并查看这两个图像看起来相同. 如果它们看起来不一样, 那么在移动设备上执行就会出现问题, 在这种情况下, 请联系 Caffe2 社区. 您应该期望看到输出图像如下所示: 使用上述步骤, 您可以轻松地在移动设备上部署模型. 另外, 有关 caffe2 移动后端的更多信息, 请查看 caffe2-android-demo. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"c_extension.html":{"url":"c_extension.html","title":"为 pytorch 自定义 C 扩展","keywords":"","body":"为 pytorch 自定义 C 扩展 译者：@飞龙 作者: Soumith Chintala 第一步. 准备你的 C 代码 首先, 你需要编写你的 C 函数. 下面你可以找到模块的正向和反向函数的示例实现, 它将两个输入相加. 在你的 .c 文件中, 你可以使用 #include &lt;TH/TH.h&gt; 直接包含 TH, 以及使用 #include &lt;THC/THC.h&gt; 包含 THC. ffi (外来函数接口) 工具会确保编译器可以在构建过程中找到它们. /* src/my_lib.c */ #include int my_lib_add_forward(THFloatTensor *input1, THFloatTensor *input2, THFloatTensor *output) { if (!THFloatTensor_isSameSizeAs(input1, input2)) return 0; THFloatTensor_resizeAs(output, input1); THFloatTensor_cadd(output, input1, 1.0, input2); return 1; } int my_lib_add_backward(THFloatTensor *grad_output, THFloatTensor *grad_input) { THFloatTensor_resizeAs(grad_input, grad_output); THFloatTensor_fill(grad_input, 1); return 1; } 代码没有任何限制, 除了你必须准备单个头文件, 它会列出所有你想要从 Python 调用的函数. 它会由 ffi 用于生成合适的包装. /* src/my_lib.h */ int my_lib_add_forward(THFloatTensor *input1, THFloatTensor *input2, THFloatTensor *output); int my_lib_add_backward(THFloatTensor *grad_output, THFloatTensor *grad_input); 现在, 你需要一个超短的文件, 它会构建你的自定义扩展: # build.py from torch.utils.ffi import create_extension ffi = create_extension( name='_ext.my_lib', headers='src/my_lib.h', sources=['src/my_lib.c'], with_cuda=False ) ffi.build() 第二步: 在你的 Python 代码中包含它 你运行它之后, pytorch 会创建一个 _ext 目录, 并把 my_lib 放到里面. 包名称可以在最终模块名称之前, 包含任意数量的包 (包括没有). 如果构建成功, 你可以导入你的扩展, 就像普通的 Python 文件. # functions/add.py import torch from torch.autograd import Function from _ext import my_lib class MyAddFunction(Function): def forward(self, input1, input2): output = torch.FloatTensor() my_lib.my_lib_add_forward(input1, input2, output) return output def backward(self, grad_output): grad_input = torch.FloatTensor() my_lib.my_lib_add_backward(grad_output, grad_input) return grad_input # modules/add.py from torch.nn import Module from functions.add import MyAddFunction class MyAddModule(Module): def forward(self, input1, input2): return MyAddFunction()(input1, input2) # main.py import torch import torch.nn as nn from torch.autograd import Variable from modules.add import MyAddModule class MyNetwork(nn.Module): def __init__(self): super(MyNetwork, self).__init__() self.add = MyAddModule() def forward(self, input1, input2): return self.add(input1, input2) model = MyNetwork() input1, input2 = Variable(torch.randn(5, 5)), Variable(torch.randn(5, 5)) print(model(input1, input2)) print(input1 + input2) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"doc.html":{"url":"doc.html","title":"中文文档","keywords":"","body":"中文文档 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes.html":{"url":"notes.html","title":"介绍","keywords":"","body":"介绍 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes_autograd.html":{"url":"notes_autograd.html","title":"自动求导机制","keywords":"","body":"自动求导机制 译者： @那伊抹微笑 校对者：@Twinkle 本文将介绍 autograd (自动求导) 如何工作并记录操作. 理解这一切并不是必须的, 但我们建议您熟悉它, 因为它会帮助您编写出更高效, 更简洁的程序, 并且可以帮助您进行调试. 反向排除 subgraphs (子图) 每一个变量都有两个标记: requires_grad 和 volatile. 它们都允许从梯度计算中精细地排除 subgraphs (子图) , 并且可以提高效率. requires_grad 如果有一个单一的输入操作需要梯度, 则其输出也需要梯度. 相反, 只有当所有输入都不需要梯度时, 输出也才不需要它. 当所有的变量都不需要梯度时, 则反向计算不会在 subgraphs (子图) 中执行. >>> x = Variable(torch.randn(5, 5)) >>> y = Variable(torch.randn(5, 5)) >>> z = Variable(torch.randn(5, 5), requires_grad=True) >>> a = x + y >>> a.requires_grad False >>> b = a + z >>> b.requires_grad True 当您想要冻结模型的一部分, 或者您事先知道不会使用某些参数的梯度时, 这个标记是特别有用的. 例如, 如果要对预先训练的 CNN 进行微优化, 只需在冻结模型的基础上切换 requires_grad 标记就可以了, 直到计算到最后一层时, 才会保存中间缓冲区, 其中的 affine transform (仿射变换) 将使用需要梯度的权重, 并且网络的输出也将需要它们. model = torchvision.models.resnet18(pretrained=True) for param in model.parameters(): param.requires_grad = False # 替换最后一个 fully-connected layer (全连接层) # 新构造的模块默认情况下参数默认 requires_grad=True model.fc = nn.Linear(512, 100) # 仅用于分类器的优化器 optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9) volatile 如果您确定不会调用 .backward(), 则推荐在纯粹的 inference mode (推断模式) 中使用 Volatile. 它比任何其它的 autograd (自动求导) 设置更高效 - 它将使用绝对最小量的内存来评估模型. volatile 也会确定 require_grad 为 False. Volatile 不同于 requires_grad 的标记传播方式. 即使一个操作只有一个单一的 volatile 输入, 它的输出也将会是 volatile 这样的. Volatility 在整个图中比 non-requiring 梯度更容易传播 - 您只需要一个 单个 volatile 叶子即可得到一个 volatile 输出, 相对的, 您需要 所有 叶子以 non-requiring 的方式, 来产生一个 non-requiring 的输出. 使用 volatile 标记, 您不需要更改模型参数的任何参数, 以便将其用于推断. 创建一个 volatile 输入已经足够了, 这种方式也将确保没有中间状态被保存. >>> regular_input = Variable(torch.randn(1, 3, 227, 227)) >>> volatile_input = Variable(torch.randn(1, 3, 227, 227), volatile=True) >>> model = torchvision.models.resnet18(pretrained=True) >>> model(regular_input).requires_grad True >>> model(volatile_input).requires_grad False >>> model(volatile_input).volatile True >>> model(volatile_input).grad_fn is None True autograd (自动求导) 如何编码 history (历史信息) Autograd (自动求导) 是一个反向自动微分的系统. 从概念上来说, autograd (自动求导) 记录一个 graph (图) , 它记录了在执行操作时创建数据的所有操作, 然后给出一个 DAG (有向无环图) , 其中 leaves (叶子) 是输入变量, roots (根) 是输出变量. 通过追踪这个从 roots (根) 到 leaves (叶子) 的 graph (图) , 您可以使用 chain rule (链式规则) 来自动计算梯度. 在其内部, autograd (自动求导) 将这个 graph (图) 形象的表示为 Function 对象 (真正的表达式) , 可以通过 apply() 方法来计算评估 graph (图) 的结果. 当计算 forwards pass (前向传递) 时, autograd (自动求导) 同时执行所需要的计算, 并且构建一个图以表示计算梯度的函数 ( 每个 Variable 类的 .grad_fn 属性是该 graph 的入口点) . 当 forwards pass (前向传递) 计算完成时, 我们通过 backwards pass (方向传递) 评估该 graph (图) 来计算梯度. 很重要的一点需要注意, 就是每次迭代都会重新创建一个 graph (图) , 这正是允许使用任意 Python 控制流语句 的原因, 这样可以在每次迭代中改变 graph (图) 的整体形状和大小. 在开始训练之前, 您不必编码所有可能的路径 - 您运行的即是您所微分的. 变量上的 In-place Operations (就地操作) 在 autograd (自动求导) 中支持 In-place Operations (就地操作) 是一件很难的事情, 我们不鼓励在大多数情况下使用它们. Autograd (自动求导) 主动的 缓存区释放 和 重用 使其非常高效, 而且 In-place Operations (就地操作) 实际上很少能降低大量的内存使用. 除非您在内存压力很大的情况下操作, 否则您可能永远不需要使用它们. 限制 In-place Operations (就地操作) 适用性的主要原因有两个: 覆盖梯度计算所需的值. 这就是为什么变量不支持 log_ 的原因. 它的梯度公式需要原始输入, 虽然可以通过计算反向操作可以重新创建它, 但它在数值上是不稳定的, 并且需要额外的工作, 这往往会使这些功能的使用得不偿失. 每一个 in-place Operations (就地操作) 实际上都需要实现重写计算图. Out-of-place (当前通用的) 的版本只是简单的分配新的对象, 并保持旧图的引用, 而 in-place Operations (就地操作) 需要将所有输入的 creator 更改为表示此操作的 Function. 这可能会很棘手, 特别是如果有许多变量引用相同的存储 (例如通过索引或转置创建的) , 并且如果修改了输入的存储被任何其它的 Variable (变量) 所引用, 则 in-place Functions (就地函数) 实际上会抛出错误. In-place Operations (就地操作) 的正确性检查 每一个变量都保留有一个 version counter (版本计数器) , 每一次的任何操作被标记为 dirty 时候都会进行递增. 当一个 Function 保存了任何用于 backward (方向的) tensor 时, 还会保存其包含变量的 version counter (版本计数器) . 一旦您访问 self.saved_tensors 时它将被检查, 如果它大于已保存的值, 则会引起错误. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes_broadcasting.html":{"url":"notes_broadcasting.html","title":"广播语义","keywords":"","body":"广播语义 译者：@谢家柯 @Twinkle 一些 PyTorch 的操作支持基于 NumPy Broadcasting Semantics. 简而言之, 如果一个 PyTorch 操作支持广播语义, 那么它的张量参数可以自动扩展为相同的大小 (不需要复制数据) 一般语义 如果两个张量满足如下规则, 那么就认为其是 broadcastable : 每个张量至少存在维度. 在遍历维度大小时, 从尾部维度开始遍历, 并且二者维度必须相等, 它们其中一个要么是1要么不存在. 示例: >>> x=torch.FloatTensor(5,7,3) >>> y=torch.FloatTensor(5,7,3) # 相同的形状总是满足的(上述规则总是成立的) >>> x=torch.FloatTensor() >>> y=torch.FloatTensor(2,2) # x和y不是满足广播语义的,因为x要求至少为1维. # 可以排列尾部维度 >>> x=torch.FloatTensor(5,3,4,1) >>> y=torch.FloatTensor( 3,1,1) # x和y是满足广播语义的. # 尾列第一维 : 都包含1. # 尾列第二维 : y的维度值为1. # 尾列第三维 : x size == y size. # 尾列第四维 : y维度不存在尾列第四维. # 但是: >>> x=torch.FloatTensor(5,2,4,1) >>> y=torch.FloatTensor( 3,1,1) # x 和 y 是不满足广播语义的, 因为尾列第三维中 2 != 3 . 如果两个张量 x, y 是 broadcastable, 则结果张量的大小由如下方式计算: - 如果维度的数量 x 和 y 不相等, 在维度较少的张量的维度前置 1 - 然后, 对于每个维度的大小, 生成维度的大小是 attr:x 和 y 的最大值 示例 # 可以排列尾部维度, 使阅读更容易 >>> x=torch.FloatTensor(5,1,4,1) >>> y=torch.FloatTensor( 3,1,1) >>> (x+y).size() torch.Size([5, 3, 4, 1]) # 但是也可不必排列 >>> x=torch.FloatTensor(1) >>> y=torch.FloatTensor(3,1,7) >>> (x+y).size() torch.Size([3, 1, 7]) >>> x=torch.FloatTensor(5,2,4,1) >>> y=torch.FloatTensor(3,1,1) >>> (x+y).size() RuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1 直接语义 (In-place semantics) 直接 (就地) 操作 (in-place operations) 的一个复杂问题就是不能像广播那样直接操作两个张量使其改变维度满足条件 示例 >>> x=torch.FloatTensor(5,3,4,1) >>> y=torch.FloatTensor(3,1,1) >>> (x.add_(y)).size() torch.Size([5, 3, 4, 1]) # but: >>> x=torch.FloatTensor(1,3,1) >>> y=torch.FloatTensor(3,1,7) >>> (x.add_(y)).size() RuntimeError: The expanded size of the tensor (1) must match the existing size (7) at non-singleton dimension 2. 向后兼容 以前版本的 PyTorch 只要张量中的元素数目是相等的, 便允许某些点状函数在不同的形状的张量上执行, 其中点状操作是通过将每个张量视为 1 维执行 现今 PyTorch 支持广播语义和不推荐使用点状函数操作向量, 并且将在具有相同数量的元素但不支持广播语义的张量操作生成一个 Python 警告 注意, 广播语义的引入可能会导致向后不兼容的情况, 即两个张量形状不同, 但是数量相同且支持广播语义. 示例 >>> torch.add(torch.ones(4,1), torch.randn(4)) 本预生成一个: torch.Size([4,1]) 的张量,但是现在会生成一个: torch.Size([4,4]) 的张量. 为了帮助使用者识别代码中可能存在由引入广播语义的向后不兼容情况, 你可以将 torch.utils.backcompat.broadcast_warning.enabled 设置为 True, 在这种情况下会生成一个 Python 警告 示例 >>> torch.utils.backcompat.broadcast_warning.enabled=True >>> torch.add(torch.ones(4,1), torch.ones(4)) __main__:1: UserWarning: self and other do not have the same shape, but are broadcastable, and have the same number of elements. Changing behavior in a backwards incompatible manner to broadcasting rather than viewing as 1-dimensional. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes_cuda.html":{"url":"notes_cuda.html","title":"CUDA 语义","keywords":"","body":"CUDA 语义 译者：@Chris 校对者：@Twinkle torch.cuda 被用于设置和运行 CUDA 操作. 它会记录当前选择的 GPU, 并且分配的所有 CUDA 张量将默认在上面创建. 可以使用 torch.cuda.device 上下文管理器更改所选设备. 但是, 一旦张量被分配, 您可以直接对其进行操作, 而不需要考虑已选择的设备, 结果将始终放在与张量相关的设备上. 默认情况下, 不支持跨 GPU 操作, 唯一的例外是 copy_(). 除非启用对等存储器访问, 否则对分布在不同设备上的张量尝试进行任何启动操作都将引发错误. 下面我们用一个小例子来展示: x = torch.cuda.FloatTensor(1) # x.get_device() == 0 y = torch.FloatTensor(1).cuda() # y.get_device() == 0 with torch.cuda.device(1): # allocates a tensor on GPU 1 a = torch.cuda.FloatTensor(1) # transfers a tensor from CPU to GPU 1 b = torch.FloatTensor(1).cuda() # a.get_device() == b.get_device() == 1 c = a + b # c.get_device() == 1 z = x + y # z.get_device() == 0 # 即使在上下文里面, 你也可以在 .cuda 的参数中传入设备id d = torch.randn(2).cuda(2) # d.get_device() == 2 内存管理 PyTorch 使用缓存内存分配器来加速内存分配. 这允许在没有设备同步的情况下快速释放内存. 但是, 由分配器管理的未使用的内存仍将显示为在 nvidia-smi 中使用. 调用 empty_cache() 可以从 PyTorch 中释放所有未使用的缓存内存, 以便其他 GPU 应用程序使用这些内存. 最佳实践 设备无关代码 由于 PyTorch 的架构, 你可能需要明确写入设备无关 (CPU 或 GPU) 代码; 举个例子, 创建一个新的张量作为循环神经网络的初始隐藏状态. 第一步先确定是否使用 GPU. 一个常见的方式是使用 Python 的 argparse 模块来读入用户参数, 并且有一个可以用来禁用 CUDA、能与 is_available() 结合使用的标志. 在下面的例子中, args.cuda 会产生一个当需要时能将张量和模块转换为 CUDA 的标志: import argparse import torch parser = argparse.ArgumentParser(description='PyTorch Example') parser.add_argument('--disable-cuda', action='store_true', help='Disable CUDA') args = parser.parse_args() args.cuda = not args.disable_cuda and torch.cuda.is_available() 如果需要将模块和张量发送到 GPU, args.cuda 可以使用如下: x = torch.Tensor(8, 42) net = Network() if args.cuda: x = x.cuda() net.cuda() 创建张量时, 可以定义一个默认的数据类型来替代 if 语句, 并使用它来转换所有的张量. 使用 dataLoader 的例子如下: dtype = torch.cuda.FloatTensor for i, x in enumerate(train_loader): x = Variable(x.type(dtype)) 在系统上使用多个 GPU 时, 您可以使用 CUDA_VISIBLE_DEVICES 环境标志来管理哪些 GPU 可用于 PyTorch. 如上所述, 要手动控制在哪个 GPU 上创建张量, 最好的方法是使用 torch.cuda.device 上下文管理器: print(\"Outside device is 0\") # On device 0 (default in most scenarios) with torch.cuda.device(1): print(\"Inside device is 1\") # On device 1 print(\"Outside device is still 0\") # On device 0 如果您有一个张量, 并且想在同一个设备上创建一个相同类型的张量, 那么您可以使用 new() 方法, 它的使用和普通的张量构造函数一样. 虽然前面提到的方法取决于当前的 GPU 环境, 但是 new() 保留了原始张量的设备信息. 当创建在向前传递期间需要在内部创建新的张量/变量的模块时, 建议使用这种做法: x_cpu = torch.FloatTensor(1) x_gpu = torch.cuda.FloatTensor(1) x_cpu_long = torch.LongTensor(1) y_cpu = x_cpu.new(8, 10, 10).fill_(0.3) y_gpu = x_gpu.new(x_gpu.size()).fill_(-5) y_cpu_long = x_cpu_long.new([[1, 2, 3]]) 如果你想创建一个与另一个张量有着相同类型和大小、并用 1 或 0 填充的张量, ones_like() 或 zeros_like() 可提供方便的辅助功能 (同时保留设备信息) x_cpu = torch.FloatTensor(1) x_gpu = torch.cuda.FloatTensor(1) y_cpu = torch.ones_like(x_cpu) y_gpu = torch.zeros_like(x_gpu) 使用固定的内存缓冲区 当副本来自固定 (页锁) 内存时, 主机到 GPU 的复制速度要快很多. CPU 张量和存储开放了一个 pin_memory() 方法, 它返回该对象的副本, 而它的数据放在固定区域中. 另外, 一旦固定了张量或存储, 就可以使用异步的 GPU 副本. 只需传递一个额外的 async=True 参数给 cuda() 调用. 这可以用于重叠数据传输与计算. 通过将 pin_memory=True 传递给其构造函数, 可以使 DataLoader 将 batch 返回到固定内存中. 使用 nn.DataParallel 替代 multiprocessing 大多数涉及批量输入和多个 GPU 的情况应默认使用 DataParallel 来使用多个 GPU. 尽管有 GIL 的存在, 单个 Python 进程也可能使多个 GPU 饱和. 从 0.1.9 版本开始, 大量的 GPU (8+) 可能未被充分利用. 然而, 这是一个已知的问题, 也正在积极开发中. 和往常一样, 测试您的用例吧. 调用 multiprocessing 使用 CUDA 模型存在显著的注意事项; 除非您足够谨慎以满足数据处理需求, 否则您的程序很可能会出现错误或未定义的行为. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes_extending.html":{"url":"notes_extending.html","title":"扩展 PyTorch","keywords":"","body":"扩展 PyTorch 译者：@那伊抹微笑 校对者：@Twinkle 在本文中, 我们将介绍如何扩展 torch.nn, torch.autograd 模块, 并且使用我们的 C 库来编写自定义的 C 扩展工具. 扩展 torch.autograd 模块 将操作添加到 autograd 模块需要为每一个操作实现一个新的 Function 类的子类. 回想一下, Function 函数是 autograd 模块用来计算结果和梯度, 并对操作历史进行编码的. 每一个新的函数需要你来实现两个方法: forward() - 进行操作的代码. 如果您指定默认值, 则可以根据需要使用任意数量的参数, 其中一些参数是可选的. 参数可接收各种类型的 Python 对象. Variable 参数在被调用之前将被转换为 Tensor 对象, 并且它们的使用情况将会被注册到 graph (图) 中. 请注意, 这个逻辑不会遍历 lists, dicts, 和任何其它的数据结构, 只会考虑被调用为直接参数的变量. 如果有多个输出, 则可以考虑返回单个的 Tensor 类格式的输出, 或者 Tensor 类的 tuple 类格式输出. 此外, 请参阅 Function 类的文档来查找只能从 forward() 调用的有用方法的描述. backward() - 计算梯度的公式. 它将被赋予与输出一样多的 Variable 参数, 其中的每一个表示对应梯度的输出. 它应该返回与输入一样多的 Variable, 其中的每一个表示都包含其相应输入的梯度. 如果输入不需要计算梯度 (请参阅 needs_input_grad 属性), 或者是非 Variable 对象, 则可返回 None 类. 此外, 如果你在 forward() 方法中有可选的参数, 则可以返回比输入更多的梯度, 只要它们都是 None 类型即可. 下面你可以找到来自 torch.nn 模块的 Linear 函数代码, 以及注解 # 继承自 Function class LinearFunction(Function): # Note that both forward and backward are @staticmethods @staticmethod # bias is an optional argument def forward(ctx, input, weight, bias=None): ctx.save_for_backward(input, weight, bias) output = input.mm(weight.t()) if bias is not None: output += bias.unsqueeze(0).expand_as(output) return output # This function has only a single output, so it gets only one gradient @staticmethod def backward(ctx, grad_output): # This is a pattern that is very convenient - at the top of backward # unpack saved_tensors and initialize all gradients w.r.t. inputs to # None. Thanks to the fact that additional trailing Nones are # ignored, the return statement is simple even when the function has # optional inputs. input, weight, bias = ctx.saved_variables grad_input = grad_weight = grad_bias = None # These needs_input_grad checks are optional and there only to # improve efficiency. If you want to make your code simpler, you can # skip them. Returning gradients for inputs that don't require it is # not an error. if ctx.needs_input_grad[0]: grad_input = grad_output.mm(weight) if ctx.needs_input_grad[1]: grad_weight = grad_output.t().mm(input) if bias is not None and ctx.needs_input_grad[2]: grad_bias = grad_output.sum(0).squeeze(0) return grad_input, grad_weight, grad_bias 现在, 为了更方便地使用这些自定义操作, 我们推荐使用 apply 方法 linear = LinearFunction.apply 在这里, 我们给出了一个由非变量参数参数化的函数的例子 class MulConstant(Function): @staticmethod def forward(ctx, tensor, constant): # ctx is a context object that can be used to stash information # for backward computation ctx.constant = constant return tensor * constant @staticmethod def backward(ctx, grad_output): # We return as many input gradients as there were arguments. # Gradients of non-Tensor arguments to forward must be None. return grad_output * ctx.constant, None 你可能想要检测你刚刚实现的 backward 方法是否正确的计算了梯度. 你可以使用小而有限的微分进行数值估计 from torch.autograd import gradcheck # gradchek takes a tuple of tensor as input, check if your gradient # evaluated with these tensors are close enough to numerical # approximations and returns True if they all verify this condition. input = (Variable(torch.randn(20,20).double(), requires_grad=True), Variable(torch.randn(30,20).double(), requires_grad=True),) test = gradcheck(Linear.apply, input, eps=1e-6, atol=1e-4) print(test) 扩展 torch.nn 模块 nn 模块有两种类型的接口 - modules 和 their functional versions. 你可以用两种方法扩展它, 但是我们推荐使用各种层的模块, 用来存放任何 parameters(参数) 或者 buffers(缓冲), 并且推荐使用一个函数形式的无参数操作, 比如激活函数, 池化等等. 添加操作的函数版本已经在上面的章节中完整的介绍了. 添加 Module 类 由于 nn 模块大量的利用了 autograd 模块, 添加一个新的 Module 类需要实现一个 Function 类, 它会执行对应的操作并且计算梯度. 从现在开始, 假设我们想要实现一个 Linear 模块, 并且我们具有如上所列实现的功能. 有很少的代码需要添加这个. 现在有两个函数需要实现: __init__ (optional) - 接收诸如 kernel sizes (核大小) , numbers of features (特征数量) 等参数, 并初始化 parameters(参数) 和 buffers(缓冲区). forward() - 实例化一个 Function 类, 并且用于执行操作. 这与上面的 functional wrapper (函数的包装) 非常相似. 这就是 Linear 模块的实现方式 class Linear(nn.Module): def __init__(self, input_features, output_features, bias=True): super(Linear, self).__init__() self.input_features = input_features self.output_features = output_features # nn.Parameter is a special kind of Variable, that will get # automatically registered as Module's parameter once it's assigned # as an attribute. Parameters and buffers need to be registered, or # they won't appear in .parameters() (doesn't apply to buffers), and # won't be converted when e.g. .cuda() is called. You can use # .register_buffer() to register buffers. # nn.Parameters can never be volatile and, different than Variables, # they require gradients by default. self.weight = nn.Parameter(torch.Tensor(output_features, input_features)) if bias: self.bias = nn.Parameter(torch.Tensor(output_features)) else: # You should always register all possible parameters, but the # optional ones can be None if you want. self.register_parameter('bias', None) # Not a very smart way to initialize weights self.weight.data.uniform_(-0.1, 0.1) if bias is not None: self.bias.data.uniform_(-0.1, 0.1) def forward(self, input): # See the autograd section for explanation of what happens here. return LinearFunction.apply(input, self.weight, self.bias) 编写自定义的 C 扩展 现在你可以在 GitHub 中找到一些例子. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes_multiprocessing.html":{"url":"notes_multiprocessing.html","title":"多进程的最佳实践","keywords":"","body":"多进程的最佳实践 译者：@冯斐 校对者：@Twinkle torch.multiprocessing 是 Python 中 multiprocessing 模块的替代. 它支持完全相同的操作, 但进一步扩展了它的功能, 使得所有张量可以通过 multiprocessing.Queue 传输, 将其数据移动到共享内存中, 并且只会向其他进程发送一个句柄. 注解： 当一个 Variable 被发送到另一个进程中, Variable.data 和 Variable.grad.data 都将被共享. 这里允许实现各种训练方法, 例如 Hogwild, A3C, 或者其他需要异步操作的方法. 共享 CUDA 向量 只有 Python 3 支持使用 spawn 或 forkserver 启动方法在进程中共享 CUDA 向量. multiprocessing 在 Python 2 使用 fork 只能创建子进程, 但是在 CUDA 运行时不被支持. 警告： CUDA API 要求被导出到其他进程的分配只要被使用, 就要一直保持有效. 您应该小心, 确保您共享的CUDA张量只要有必要就不要超出范围. 这不是共享模型参数的问题, 但传递其他类型的数据应该小心. 注意, 此限制不适用于共享 CPU 内存. 参考: 使用 nn.DataParallel 替代 multiprocessing 最佳实践和提示 避免和抵制死锁 当新进程被创建时, 可能会发生很多错误, 最常见的原因就是后台线程. 如果有任何线程持有锁或导入模块, 并且fork 已被调用, 则子进程很有可能将会处于毁坏的状态, 并导致死锁或在其他地方失败. 注意即使你自己没有这样做, Python 内置的库也会这样做 - 不需要比 multiprocessing 看得更远. multiprocessing.Queue 事实上是一个非常复杂的库, 它可以创建多个线程, 用于序列化, 发送和接收对象, 但是它们也有可能引起前面提到的问题. 如果你遇到这样的问题, 可以尝试使用 multiprocessing.queues.SimpleQueue, 它不会使用其他额外的线程. 我们正在竭尽全力把它设计得更简单, 并确保这些死锁不会发生, 但有些事情无法控制. 如果有任何问题您一时无法解决, 请尝试在论坛上提出, 我们将看看是否可以解决. 重用经过队列的缓冲区 请记住当每次将 Tensor 放入 multiprocessing.Queue, 它必须被移至共享内存中. 如果它已经被共享, 它是一个无效操作, 否则会产生一个额外的内存副本, 这会减缓整个进程. 即使你有一个进程池来发送数据到一个进程, 也应该先把它送回缓冲区 —— 这几乎是没有损失的, 并且允许你在发送下一个 batch 时避免产生副本. 异步多进程训练 (例如 Hogwild) 使用 torch.multiprocessing 可以异步地训练模型, 其中参数可以一直共享, 或定期同步. 对于第一种情况, 我们建议传输整个模型对象, 而对于第二种情况, 我们建议只传输 state_dict(). 我们建议使用 multiprocessing.Queue 来在进程之间传输各种 PyTorch 对象. 例如, 当使用 fork 启动方法, 有可能会继承共享内存中的张量和存储量. 但这是非常容易出错的, 应谨慎使用, 最好是成为深度用户以后, 再使用这个方法. 队列虽然有时是一个较不优雅的解决方案, 但基本上能在所有情况下都正常工作. 警告： 当使用全局的声明时, 你应该注意, 因为它们没有被 if __name__ == '__main__' 限制. 如果使用与 fork 不同的启动方法, 它们将在所有子进程中被执行. Hogwild 一个 Hogwild 的具体实现可以在 examples repository 中找到. 为了展示代码的整体结构, 下面有一个小例子: import torch.multiprocessing as mp from model import MyModel def train(model): # Construct data_loader, optimizer, etc. for data, labels in data_loader: optimizer.zero_grad() loss_fn(model(data), labels).backward() optimizer.step() # This will update the shared parameters if __name__ == '__main__': num_processes = 4 model = MyModel() # NOTE: this is required for the ``fork`` method to work model.share_memory() processes = [] for rank in range(num_processes): p = mp.Process(target=train, args=(model,)) p.start() processes.append(p) for p in processes: p.join() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"notes_serialization.html":{"url":"notes_serialization.html","title":"序列化语义","keywords":"","body":"序列化语义 译者：@胡东瑶 校对者：@Twinkle 最佳实践 保存模型的推荐方法 有两种主要的方法可以用来序列化和恢复模型. 第一种方法 (推荐) , 只保存和加载模型的参数: torch.save(the_model.state_dict(), PATH) 然后: the_model = TheModelClass(*args, **kwargs) the_model.load_state_dict(torch.load(PATH)) 第二种方法, 保存和加载整个模型: torch.save(the_model, PATH) 然后: the_model = torch.load(PATH) 但是在这种情况下, 序列化的数据与特定的类和固定的目录结构绑定, 所以当它被用于其他项目中, 或者经过一些重大的重构之后, 可能会以各种各样的方式崩掉. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"package_reference.html":{"url":"package_reference.html","title":"Package 参考","keywords":"","body":"Package 参考 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"torch.html":{"url":"torch.html","title":"torch","keywords":"","body":"torch 译者：@那伊抹微笑、@yudong、@小瑶、@片刻、@李雨龙、@K @devin、@张假飞、@rickllyxu 校对者：@张假飞、@飞龙 torch package 包含了多维张量的数据结构, 以及基于其上的多种数学操作. 此外, 它还提供了许多用于高效序列化 Tensor 和任意类型的实用工具包, 以及一起其它有用的实用工具包. 它有一个 CUDA 的对应实现, 它使您能够在计算能力 >=0.3 的 NVIDIA GPU 上进行张量运算. Tensors (张量) torch.is_tensor(obj) 如果 obj 是一个 pytorch tensor, 则返回True. 参数：obj (Object) – 用于测试的对象 torch.is_storage(obj) 如果 obj 是一个 pytorch storage object, 则返回True. 参数：obj (Object) – 用于测试的对象 torch.set_default_tensor_type(t) torch.numel(input) → int 返回 input Tensor 中的元素总数. 参数：input (Tensor) – 输入的 Tensor 示例： >>> a = torch.randn(1,2,3,4,5) >>> torch.numel(a) 120 >>> a = torch.zeros(4,4) >>> torch.numel(a) 16 torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None) 设置打印选项. 从 Numpy 中采集数据 参数： precision – 浮点输出精度的位数 (默认值为 8). threshold – 触发汇总显示而不是完全显示(repr)的数组元素的总数 (默认值为 1000). edgeitems – 每个维度开始和结束时总结的数组项数 (默认值为 3). linewidth – 插入换行符的每行字符数 (默认值为 80). Thresholded matricies(阈值矩阵) 将忽略这个参数. profile – 用于漂亮格式的打印. 可以用以下任何选项来进行覆盖 (default, short, full) Creation Ops (创建操作) torch.eye(n, m=None, out=None) 返回对角线位置全为1, 其它位置全为0的二维 tensor. 参数： n (int) – 行数 m (int, 可选) – 列数. 如果为 None,则默认为 n out (Tensor, 可选) – 输出 tensor 返回值：一个对角线位置全为1, 其它位置全为0的二维 tensor. 返回类型：Tensor 示例： >>> torch.eye(3) 1 0 0 0 1 0 0 0 1 [torch.FloatTensor of size 3x3] torch.from_numpy(ndarray) → Tensor 从 numpy.ndarray 类 创建一个 Tensor 类. 返回 tensor 和 ndarray 共享相同的内存. 对 tensor 的修改将反映在 ndarray 中, 反之亦然. 返回 tensor 不可调整大小. 示例： >>> a = numpy.array([1, 2, 3]) >>> t = torch.from_numpy(a) >>> t torch.LongTensor([1, 2, 3]) >>> t[0] = -1 >>> a array([-1, 2, 3]) torch.linspace(start, end, steps=100, out=None) → Tensor 返回 start 和 end 之间等间隔 steps 点的一维 Tensor. 输出 是尺寸 steps 为一维 tensor 参数： start (float) – 点集合的起始值 end (float) – 点集合的结束值 steps (int) – 在 start 和 end 之间的样本数 out (Tensor, 可选) – 输出结果的 Tensor 示例： >>> torch.linspace(3, 10, steps=5) 3.0000 4.7500 6.5000 8.2500 10.0000 [torch.FloatTensor of size 5] >>> torch.linspace(-10, 10, steps=5) -10 -5 0 5 10 [torch.FloatTensor of size 5] >>> torch.linspace(start=-10, end=10, steps=5) -10 -5 0 5 10 [torch.FloatTensor of size 5] torch.logspace(start, end, steps=100, out=None) → Tensor 返回一个在 和 之间的对数间隔 steps 点的一维 Tensor 输出是长度为 steps 的一维 tensor 参数： start (float) – 点集合的起始值 end (float) – 点集合的结束值 steps (int) – 在 start 和 end 之间的样本数 out (Tensor, 可选) – 输出结果Tensor 示例： >>> torch.logspace(start=-10, end=10, steps=5) 1.0000e-10 1.0000e-05 1.0000e+00 1.0000e+05 1.0000e+10 [torch.FloatTensor of size 5] >>> torch.logspace(start=0.1, end=1.0, steps=5) 1.2589 2.1135 3.5481 5.9566 10.0000 [torch.FloatTensor of size 5] torch.ones(*sizes, out=None) → Tensor 返回填充了标量值 1 的 Tensor, 其形状由可变参数 sizes 定义. 参数： sizes (int...) – 一组定义输出 Tensor 形状的整数 out (Tensor, 可选) – 输出结果 Tensor 示例： >>> torch.ones(2, 3) 1 1 1 1 1 1 [torch.FloatTensor of size 2x3] >>> torch.ones(5) 1 1 1 1 1 [torch.FloatTensor of size 5] torch.ones_like(input, out=None) → Tensor 返回一个用标量值 1 填充的张量, 大小与 input 相同. 参数： input (Tensor) – 输入的大小将决定输出的大小. out (Tensor, 可选) – 输出结果 Tensor 示例： >>> input = torch.FloatTensor(2, 3) >>> torch.ones_like(input) 1 1 1 1 1 1 [torch.FloatTensor of size 2x3] torch.arange(start=0, end, step=1, out=None) → Tensor 从 start 用步长为 step 开始, 间隔在 [start, end) 中的值返回大小层次为 的一维 Tensor. 参数： start (float) – 点集合的起始值 end (float) – 点集合的结束值 step (float) – 每对相邻点之间的间隔 out (Tensor, 可选) – 输出结果 Tensor 示例： >>> torch.arange(5) 0 1 2 3 4 [torch.FloatTensor of size 5] >>> torch.arange(1, 4) 1 2 3 [torch.FloatTensor of size 3] >>> torch.arange(1, 2.5, 0.5) 1.0000 1.5000 2.0000 [torch.FloatTensor of size 3] torch.range(start, end, step=1, out=None) → Tensor 返回一个在 start 到 end 并且步长为 step 的区间内, 大小为 为一维 Tensor. step 是 tensor 中两个值之间的差距. 警告： 此功能已被弃用, 以支持 torch.arange(). 参数： start (float) – 点集合的起始值 end (float) – 点集合的结束值 step (float) – 每对相邻点之间的间隔 out (Tensor, 可选) – 输出结果 Tensor 示例： >>> torch.range(1, 4) 1 2 3 4 [torch.FloatTensor of size 4] >>> torch.range(1, 4, 0.5) 1.0000 1.5000 2.0000 2.5000 3.0000 3.5000 4.0000 [torch.FloatTensor of size 7] torch.zeros(*sizes, out=None) → Tensor 返回填充了标量值为 0 的 Tensor, 其形状由可变参量 sizes 定义. 参数： sizes (int...) – 定义输出 Tensor 形状的一组整数. out (Tensor, 可选) – 输出结果 Tensor 示例： >>> torch.zeros(2, 3) 0 0 0 0 0 0 [torch.FloatTensor of size 2x3] >>> torch.zeros(5) 0 0 0 0 0 [torch.FloatTensor of size 5] torch.zeros_like(input, out=None) → Tensor 返回一个用标量值 0 填充的 Tensor, 其大小与 input 相同. 参数： input (Tensor) – 输入的大小将决定输出的大小. out (Tensor, 可选) – 输出结果 Tensor 示例： >>> input = torch.FloatTensor(2, 3) >>> torch.zeros_like(input) 0 0 0 0 0 0 [torch.FloatTensor of size 2x3] Indexing, Slicing, Joining, Mutating Ops (索引, 切片, 连接, 换位) 操作 torch.cat(seq, dim=0, out=None) → Tensor 在给定维度上对输入的张量序列 seq 进行连接操作. 所有张量必须具有相同的形状(在 cat 维度中除外) 或为空. torch.cat() 可以看做是 torch.split() 和 torch.chunk() 的逆操作. cat() 可以通过下面的例子更好地理解. 参数： seq (_sequence of Tensors_) – 可以是任何相同类型的 Tensor 的 Python 序列. dim (int, 可选) – tensors 级联的维数 out (Tensor, 可选) – 输出参数 示例： >>> x = torch.randn(2, 3) >>> x 0.5983 -0.0341 2.4918 1.5981 -0.5265 -0.8735 [torch.FloatTensor of size 2x3] >>> torch.cat((x, x, x), 0) 0.5983 -0.0341 2.4918 1.5981 -0.5265 -0.8735 0.5983 -0.0341 2.4918 1.5981 -0.5265 -0.8735 0.5983 -0.0341 2.4918 1.5981 -0.5265 -0.8735 [torch.FloatTensor of size 6x3] >>> torch.cat((x, x, x), 1) 0.5983 -0.0341 2.4918 0.5983 -0.0341 2.4918 0.5983 -0.0341 2.4918 1.5981 -0.5265 -0.8735 1.5981 -0.5265 -0.8735 1.5981 -0.5265 -0.8735 [torch.FloatTensor of size 2x9] torch.chunk(tensor, chunks, dim=0) 在给定维度(轴)上将输入张量进行分块处理. 参数： tensor (Tensor) – 待分块的输入张量. chunks (int) – 要返回的分块的个数. dim (int) – 切分张量所需要沿着的维度. torch.gather(input, dim, index, out=None) → Tensor 沿给定轴 dim ,将输入索引张量 index 指定位置的值进行聚合. 对一个 3 维张量,输出可以定义为: out[i][j][k] = input[index[i][j][k]][j][k] # if dim == 0 out[i][j][k] = input[i][index[i][j][k]][k] # if dim == 1 out[i][j][k] = input[i][j][index[i][j][k]] # if dim == 2 如果 input 是 size 为 且 dim = i 的 n 维张量,则 index 必须是具有 size 为 的 n 维张量,其中 y >= 1 ,并且 out 将与 index 的 size 相同. 参数： input (Tensor) – 源张量 dim (int) – 索引的轴 index (LongTensor) – 聚合元素的下标 out (Tensor, 可选) – 目标张量 示例： >>> t = torch.Tensor([[1,2],[3,4]]) >>> torch.gather(t, 1, torch.LongTensor([[0,0],[1,0]])) 1 1 4 3 [torch.FloatTensor of size 2x2] torch.index_select(input, dim, index, out=None) → Tensor 沿着指定维度 dim 对输入进行切片,取 index 中指定的相应项 ( index 为一个 LongTensor ),然后返回到一个新的张量. 返回的张量与原始张量 Tensor 有相同的维度(在指定轴上). 注解： 返回的张量不与原始张量共享内存空间. 参数： input (Tensor) – 输入张量 dim (int) – 索引的轴 index (LongTensor) – 包含索引下标的一维张量 out (Tensor, 可选) – 输出参数/目标张量 示例： >>> x = torch.randn(3, 4) >>> x 1.2045 2.4084 0.4001 1.1372 0.5596 1.5677 0.6219 -0.7954 1.3635 -1.2313 -0.5414 -1.8478 [torch.FloatTensor of size 3x4] >>> indices = torch.LongTensor([0, 2]) >>> torch.index_select(x, 0, indices) 1.2045 2.4084 0.4001 1.1372 1.3635 -1.2313 -0.5414 -1.8478 [torch.FloatTensor of size 2x4] >>> torch.index_select(x, 1, indices) 1.2045 0.4001 0.5596 0.6219 1.3635 -0.5414 [torch.FloatTensor of size 3x2] torch.masked_select(input, mask, out=None) → Tensor 根据掩码张量 mask 中的二元值,取输入张量中的指定项 ( mask 为一个 ByteTensor ),将取值返回到一个新的一维张量. 张量 mask 与 input 的 shape 或维度不需要相同,但是他们必须是 broadcastable . 注解： 返回的张量不与原始张量共享内存空间. 参数： input (Tensor) – 输入张量 mask (ByteTensor) – 掩码张量,包含了二元索引值 out (Tensor, 可选) – 输出参数/目标张量 示例： >>> x = torch.randn(3, 4) >>> x 1.2045 2.4084 0.4001 1.1372 0.5596 1.5677 0.6219 -0.7954 1.3635 -1.2313 -0.5414 -1.8478 [torch.FloatTensor of size 3x4] >>> mask = x.ge(0.5) >>> mask 1 1 0 1 1 1 1 0 1 0 0 0 [torch.ByteTensor of size 3x4] >>> torch.masked_select(x, mask) 1.2045 2.4084 1.1372 0.5596 1.5677 0.6219 1.3635 [torch.FloatTensor of size 7] torch.nonzero(input, out=None) → LongTensor 返回一个包含输入 input 中非零元素索引的张量. 输出张量中的每行包含 input 中非零元素的索引. 如果输入张量 input 有 n 维,则输出的索引张量 out 的 size 为 z x n , 这里 z 是输入张量 input 中所有非零元素的个数. 参数： input (Tensor) – 输入张量/源张量 out (LongTensor, 可选) – 包含索引值的输出张量 示例： >>> torch.nonzero(torch.Tensor([1, 1, 1, 0, 1])) 0 1 2 4 [torch.LongTensor of size 4x1] >>> torch.nonzero(torch.Tensor([[0.6, 0.0, 0.0, 0.0], ... [0.0, 0.4, 0.0, 0.0], ... [0.0, 0.0, 1.2, 0.0], ... [0.0, 0.0, 0.0,-0.4]])) 0 0 1 1 2 2 3 3 [torch.LongTensor of size 4x2] torch.split(tensor, split_size, dim=0) 将输入张量分割成相等 size 的 chunks (如果可分). 如果沿指定维的张量形状大小不能被 split_size 整分, 则最后一个分块会小于其它分块. 参数： tensor (Tensor) – 待分割张量. split_size (int) – 单个分块的 size 大小. dim (int) – 沿着此维进行分割. torch.squeeze(input, dim=None, out=None) 将 input 张量 size 中的 1 去除并返回. 如果 input 的 shape 如 ,那么输出 shape 就为: 当给定 dim 时,那么挤压操作只在给定维度上.例如, input 的 shape 为: , squeeze(input, 0) 将会保持张量不变,只有用 squeeze(input, 1) , shape 会变成 . 注解： 作为上述的一个例外,size 为 1 的一维张量不会改变维度. 注解： 返回张量与输入张量共享内存,所以改变其中一个的内容会改变另一个. 参数： input (Tensor) – 输入张量 dim (int, 可选) – 如果给定 dim 时,则 input 只会在给定维度执行挤压 out (Tensor, 可选) – 结果张量 示例： >>> x = torch.zeros(2,1,2,1,2) >>> x.size() (2L, 1L, 2L, 1L, 2L) >>> y = torch.squeeze(x) >>> y.size() (2L, 2L, 2L) >>> y = torch.squeeze(x, 0) >>> y.size() (2L, 1L, 2L, 1L, 2L) >>> y = torch.squeeze(x, 1) >>> y.size() (2L, 2L, 1L, 2L) torch.stack(sequence, dim=0, out=None) 沿着一个新维度对输入张量序列进行连接. 序列中所有的张量都应该为相同 size . 参数： sequence (_Sequence_) – 待连接的张量序列. dim (int) – 插入的维度.必须介于 0 与待连接的张量序列数（包含）之间. torch.t(input, out=None) → Tensor 预期 input 为一个矩阵 (2 维张量), 并转置 0, 1 维. 可以被视为函数 transpose(input, 0, 1) 的简写函数. 参数： input (Tensor) – 输入张量 out (Tensor, 可选) – 结果张量 示例： >>> x = torch.randn(2, 3) >>> x 0.4834 0.6907 1.3417 -0.1300 0.5295 0.2321 [torch.FloatTensor of size 2x3] >>> torch.t(x) 0.4834 -0.1300 0.6907 0.5295 1.3417 0.2321 [torch.FloatTensor of size 3x2] torch.take(input, indices) → Tensor 在给定的索引处返回一个新的 Tensor ,其元素为 input . 输入张量被看作是一维张量.结果与索引具有相同的 shape . 参数： input (Tensor) – 输入张量 indices (LongTensor) – 进入 Tensor 的索引 示例： >>> src = torch.Tensor([[4, 3, 5], ... [6, 7, 8]]) >>> torch.take(src, torch.LongTensor([0, 2, 5])) 4 5 8 [torch.FloatTensor of size 3] torch.transpose(input, dim0, dim1, out=None) → Tensor 返回输入矩阵 input 的转置.交换给定维度 dim0 和 dim1 . out 张量与 input 张量共享内存,所以改变其中一个会导致另外一个也被修改. 参数： input (Tensor) – 输入张量 dim0 (int) – 转置的第一个维度 dim1 (int) – 转置的第二个维度 示例： >>> x = torch.randn(2, 3) >>> x 0.5983 -0.0341 2.4918 1.5981 -0.5265 -0.8735 [torch.FloatTensor of size 2x3] >>> torch.transpose(x, 0, 1) 0.5983 1.5981 -0.0341 -0.5265 2.4918 -0.8735 [torch.FloatTensor of size 3x2] torch.unbind(tensor, dim=0) 移除一个张量的维度. 移除指定维后,返回一个元组,包含了沿着指定维切片后的各个切片 (已经没有了移除的维度). 参数： tensor (Tensor) – 要执行 unbind 的张量/输入张量. dim (int) – 要移除的维度. torch.unsqueeze(input, dim, out=None) 返回在指定位置插入维度 size 为 1 的新张量. 返回张量与输入张量共享内存,所以改变其中一个的内容会改变另一个. 如果 dim 为负,则将会被转化 . 参数： input (Tensor) – 输入张量 dim (int) – 插入维度的索引 out (Tensor, 可选) – 结果张量 示例： >>> x = torch.Tensor([1, 2, 3, 4]) >>> torch.unsqueeze(x, 0) 1 2 3 4 [torch.FloatTensor of size 1x4] >>> torch.unsqueeze(x, 1) 1 2 3 4 [torch.FloatTensor of size 4x1] Random sampling (随机采样) torch.manual_seed(seed) 设置生成随机数的种子,并返回一个 torch._C.Generator 对象. 参数：seed (int 或 long) – 种子. torch.initial_seed() 返回用于生成随机数字的初始种子 (python long) . torch.get_rng_state() 以ByteTensor的形式返回随机数发生器的状态. torch.set_rng_state(new_state) 设置随机数发生器的参数. 参数：new_state (torch.ByteTensor) – 理想状态 torch.default_generator = torch.bernoulli(input, out=None) → Tensor 从伯努利分布中抽取二进制随机数 (0 或 1). The input 张量包含用于抽取二进制随机数的概率. 因此, input 中的所有值必须在这个范围内: 根据 input 张量第 i 个概率值, 输出张量的第 i 个元素将取值为1. 返回的 out 张量的值只有 0 或者 1 并且大小与 input 张量相同. 参数： input (Tensor) – 伯努利分布的概率值 out (Tensor, 可选) – 输出张量 示例： >>> a = torch.Tensor(3, 3).uniform_(0, 1) # generate a uniform random matrix with range [0, 1] >>> a 0.7544 0.8140 0.9842 0.5282 0.0595 0.6445 0.1925 0.9553 0.9732 [torch.FloatTensor of size 3x3] >>> torch.bernoulli(a) 1 1 1 0 0 1 0 1 1 [torch.FloatTensor of size 3x3] >>> a = torch.ones(3, 3) # probability of drawing \"1\" is 1 >>> torch.bernoulli(a) 1 1 1 1 1 1 1 1 1 [torch.FloatTensor of size 3x3] >>> a = torch.zeros(3, 3) # probability of drawing \"1\" is 0 >>> torch.bernoulli(a) 0 0 0 0 0 0 0 0 0 [torch.FloatTensor of size 3x3] torch.multinomial(input, num_samples, replacement=False, out=None) → LongTensor 返回一个张量, 其中每一行包含在 input 张量对应行中多项式分布取样的 num_samples 索引. 注解： input 的每行值不需要总和为 1 (我们只使用这些值作为权重), 但必须是非负且非零和的. 取样时从左向右排列(第一个样本在第一列). 如果 input 是一个向量, 则 out 是一个大小为 num_samples 的向量. 如果 input 是一个 m 行的矩阵, 则 out 是一个 m × n 的矩阵. 如果参数 replacement 是 True, 则可重复取样. 否则, 样本在每行不能被重复取样. 参数 num_samples 必须小于 input 长度 (如果是一个矩阵, 则是 input 的列数). 参数： input (Tensor) – 包含概率值的张量 num_samples (int) – 抽取的样本数 replacement (bool, 可选) – 是否重复抽取样本 out (Tensor, 可选) – 输出 Tensor 示例： >>> weights = torch.Tensor([0, 10, 3, 0]) # create a Tensor of weights >>> torch.multinomial(weights, 4) 1 2 0 0 [torch.LongTensor of size 4] >>> torch.multinomial(weights, 4, replacement=True) 1 2 1 2 [torch.LongTensor of size 4] torch.normal() torch.normal(means, std, out=None) 返回一个随机数张量, 随机数从给定平均值和标准差的离散正态分布中抽取. 参数 means 是一个包含每个输出元素的正态分布均值的张量. 参数 std 是一个包含每个输出元素的正态分布标准差的张量. 其中 means 和 std 的形状不需要匹配, 但是每个张量中的元素总数需要相同. 注解： 当形状不匹配时, means 的形状将作为返回输出张量的形状. 参数： means (Tensor) – 均值 std (Tensor) – 标准差 out (Tensor, 可选) – 输出张量 示例： torch.normal(means=torch.arange(1, 11), std=torch.arange(1, 0, -0.1)) 1.5104 1.6955 2.4895 4.9185 4.9895 6.9155 7.3683 8.1836 8.7164 9.8916 [torch.FloatTensor of size 10] torch.normal(mean=0.0, std, out=None) 功能与上面函数类似, 但所有被抽取的元素共享均值. 参数： means (float, 可选) – 所有分布的均值 std (Tensor) – 每个元素标准差的张量 out (Tensor, 可选) – 输出张量 示例： >>> torch.normal(mean=0.5, std=torch.arange(1, 6)) 0.5723 0.0871 -0.3783 -2.5689 10.7893 [torch.FloatTensor of size 5] torch.normal(means, std=1.0, out=None) 功能与上面函数类似, 但所有被抽取的元素共享标准差. 参数： means (Tensor) – 每个元素均值的张量 std (float, 可选) – 所有分布的标准差 out (Tensor, 可选) – 输出张量 示例： >>> torch.normal(means=torch.arange(1, 6)) 1.1681 2.8884 3.7718 2.5616 4.2500 [torch.FloatTensor of size 5] torch.rand(*sizes, out=None) → Tensor 在区间 ![0, 1) 中, 返回一个填充了均匀分布的随机数的张量. 这个张量的形状由可变参数 sizes 来定义. 参数： sizes (int...) – 定义输出张量形状的整数集. out (Tensor, 可选) – 结果张量 示例： >>> torch.rand(4) 0.9193 0.3347 0.3232 0.7715 [torch.FloatTensor of size 4] >>> torch.rand(2, 3) 0.5010 0.5140 0.0719 0.1435 0.5636 0.0538 [torch.FloatTensor of size 2x3] torch.randn(*sizes, out=None) → Tensor 返回一个从正态分布中填充随机数的张量, 其均值为 0 , 方差为 1 . 这个张量的形状被可变参数 sizes 定义. 参数： sizes (int...) – 定义输出张量形状的整数集. out (Tensor, 可选) – 结果张量 示例： >>> torch.randn(4) -0.1145 0.0094 -1.1717 0.9846 [torch.FloatTensor of size 4] >>> torch.randn(2, 3) 1.4339 0.3351 -1.0999 1.5458 -0.9643 -0.3558 [torch.FloatTensor of size 2x3] torch.randperm(n, out=None) → LongTensor 返回一个从 0 to n - 1 的整数的随机排列. 参数：n (int) – 上限 (唯一的) 示例： >>> torch.randperm(4) 2 1 3 0 [torch.LongTensor of size 4] In-place random sampling (直接随机采样) 在Tensors模块上还定义了许多 in-place 随机采样函数,可以点击参考它们的文档: torch.Tensor.bernoulli_()](tensors.html#torch.Tensor.bernoulli \"torch.Tensor.bernoulli\") - 是 [torch.bernoulli() 的 in-place 版本 torch.Tensor.cauchy_() - 从柯西分布中抽取数字 torch.Tensor.exponential_() - 从指数分布中抽取数字 torch.Tensor.geometric_() - 从几何分布中抽取元素 torch.Tensor.log_normal_() - 对数正态分布中的样本 torch.Tensor.normal_()](tensors.html#torch.Tensor.normal \"torch.Tensor.normal\") - 是 [torch.normal() 的 in-place 版本 torch.Tensor.random_() - 离散均匀分布中采样的数字 torch.Tensor.uniform_() - 正态分布中采样的数字 Serialization (序列化) torch.save(obj, f, pickle_module=, pickle_protocol=2) 将一个对象保存到一个磁盘文件中. 另见: 保存模型的推荐方法 参数: obj: 要保存的对象 f: 类文件对象 (必须实现返回文件描述符的 fileno 方法) 或包含文件名的字符串 pickle_module: 用于 pickling 元数据和对象的模块 pickle_protocol: 可以指定来覆盖默认协议 torch.load(f, map_location=None, pickle_module=) 从磁盘文件中加载一个用 torch.save() 保存的对象. Func: torch.load 使用 Python 的解封 (unpickling) 设施, 但特殊对待张量下的存储 (storages). 它们首先在 CPU 上反序列化, 然后移动到所保存的设备上. 如果这个过程失败了 (例如, 因为运行时的系统没有确定的设备), 将会抛出异常. 然而, 使用 map_location 参数, 存储可以被动态地重新映射到另一组设备上. 如果 map_location 是可调用对象, 则对于每个序列化存储, 它都将以两个参数调用一次: storage 和 location. 参数 storage 是驻留在 CPU 上的存储的初始反序列化. 每个序列化后的存储都有一个与之关联的位置标签, 它标识了保存它的设备, 而此标签是传递给 map_location 的第二个参数. 对于 CPU 张量, 内建的位置标签是 ‘cpu’, 对于 CUDA 张量, 内建的位置标签是 ‘cuda:device_id’ (例如 ‘cuda:2’). map_location 要么返回 None , 要么返回一个存储. 如果 map_location 返回存储, 它将用作已移动到正确设备上的, 最终反序列化的对象. 否则, 如果没有指明 map_location, 即返回 None, torch.load 会回落到默认的行为. 如果 map_location 是一个字典, 它用于将出现在文件 (键) 中的位置标签, 重新映射到另一个位置标签, 它出现在值中并指明在哪里存放存储. 用户扩展可以使用 register_package 来注册他们自己的位置标签, 以及标记和反序列化方法. 参数: f: 一个类文件对象 (必须实现返回文件描述符的 fileno, 以及 seek 方法), 或者包含文件名的字符串. map_location: 一个函数或者一个指明如何重新映射存储位置的字典 pickle_module: 用于解封 (unpickling) 元数据和对象的模块 (必须匹配用于序列化文件的 pickle_module) 示例: >>> torch.load('tensors.pt') # Load all tensors onto the CPU >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage) # Load all tensors onto GPU 1 >>> torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1)) # Map tensors from GPU 1 to GPU 0 >>> torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'}) Parallelism (并行化) torch.get_num_threads() → int 获得 OpenMP 并行化操作的线程数目 torch.set_num_threads(int) 设置 OpenMP 并行化操作的线程数目 Math operations (数学操作) Pointwise Ops (逐点操作) torch.abs(input, out=None) → Tensor 计算给定 input 张量的元素的绝对值. 示例： >>> torch.abs(torch.FloatTensor([-1, -2, 3])) FloatTensor([1, 2, 3]) torch.acos(input, out=None) → Tensor 用 input 元素的反余弦返回一个新的张量. 参数： input (Tensor) – the input Tensor out (Tensor, 可选) – The result Tensor 示例： >>> a = torch.randn(4) >>> a -0.6366 0.2718 0.4469 1.3122 [torch.FloatTensor of size 4] >>> torch.acos(a) 2.2608 1.2956 1.1075 nan [torch.FloatTensor of size 4] torch.add() torch.add(input, value, out=None) 将标量值 value 添加到输入张量 attr:input 的每个元素并返回一个新的结果张量. 如果输入张量 input 是 FloatTensor 或者 DoubleTensor 类型, 则 value 必须为实数, 否则为整数. 参数： input (Tensor) – 输入 Tensor value (Number) – 要添加到 input 每个元素的数 out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a 0.4050 -1.2227 1.8688 -0.4185 [torch.FloatTensor of size 4] >>> torch.add(a, 20) 20.4050 18.7773 21.8688 19.5815 [torch.FloatTensor of size 4] torch.add(input, value=1, other, out=None) 张量 other 的每个元素乘以标量值 value 并加到张量 input 上, 返回生成的张量 out . 张量 input 的形状与张量 other 的形状必须 broadcastable. 如果张量 other 是 FloatTensor 或者 DoubleTensor 类型, 则 value 必须为实数, 否则为整数. 参数： input (Tensor) – 第一个输入 Tensor value (Number) – 张量 other 的标量乘数 other (Tensor) – 第二个输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> import torch >>> a = torch.randn(4) >>> a -0.9310 2.0330 0.0852 -0.2941 [torch.FloatTensor of size 4] >>> b = torch.randn(2, 2) >>> b 1.0663 0.2544 -0.1513 0.0749 [torch.FloatTensor of size 2x2] >>> torch.add(a, 10, b) 9.7322 4.5770 -1.4279 0.4552 [torch.FloatTensor of size 4] torch.addcdiv(tensor, value=1, tensor1, tensor2, out=None) → Tensor 将张量 tensor1 逐元素除以张量 tensor2, 然后乘以标量值 value 并加到张量 tensor 上. 张量 tensor, 张量 tensor1, 张量 tensor2 的形状必须 broadcastable. 对于类型为 FloatTensor 或者 DoubleTensor 的张量输入, value 必须为实数, 否则为整数. 参数： tensor (Tensor) – 张量, 对 tensor1 ./ tensor2 进行相加 value (Number, 可选) – 标量, 对 tensor1 ./ tensor2 进行相乘 tensor1 (Tensor) – 分子张量, 即作为被除数 tensor2 (Tensor) – 分母张量, 即作为除数 out (Tensor, 可选) – 输出张量 示例： >>> t = torch.randn(2, 3) >>> t1 = torch.randn(1, 6) >>> t2 = torch.randn(6, 1) >>> torch.addcdiv(t, 0.1, t1, t2) 0.0122 -0.0188 -0.2354 0.7396 -1.5721 1.2878 [torch.FloatTensor of size 2x3] torch.addcmul(tensor, value=1, tensor1, tensor2, out=None) → Tensor 将张量 tensor1 逐元素与张量 tensor2 相乘, 然后乘以标量值 value 并加到张量 tensor 上. 张量 tensor, 张量 tensor1, 张量 tensor2 的形状必须 broadcastable. 对于类型为 FloatTensor 或者 DoubleTensor 的张量输入, value 必须为实数, 否则为整数. :param tensor: 张量, 对 tensor1 .* tensor2 进行相加 :type tensor: Tensor :param value: 标量, 对 tensor1 .* tensor2 进行相乘 :type value: Number, 可选 :param tensor1: 张量, 作为乘子1 :type tensor1: Tensor :param tensor2: 张量, 作为乘子2 :type tensor2: Tensor :param out: 输出张量 :type out: Tensor, 可选 示例： >>> t = torch.randn(2, 3) >>> t1 = torch.randn(1, 6) >>> t2 = torch.randn(6, 1) >>> torch.addcmul(t, 0.1, t1, t2) 0.0122 -0.0188 -0.2354 0.7396 -1.5721 1.2878 [torch.FloatTensor of size 2x3] torch.asin(input, out=None) → Tensor 返回一个新的 Tensor , 其元素为张量 input 的每个元素的反正弦. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a -0.6366 0.2718 0.4469 1.3122 [torch.FloatTensor of size 4] >>> torch.asin(a) -0.6900 0.2752 0.4633 nan [torch.FloatTensor of size 4] torch.atan(input, out=None) → Tensor 返回一个新的 Tensor , 其元素为张量 input 的每个元素的反正切. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a -0.6366 0.2718 0.4469 1.3122 [torch.FloatTensor of size 4] >>> torch.atan(a) -0.5669 0.2653 0.4203 0.9196 [torch.FloatTensor of size 4] torch.atan2(input1, input2, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是输入张量 input1 和输入张量 input2 元素的反正切. 输入张量 input1 的形状和输入张量 input2 的形状必须可 broadcastable. 参数： input1 (Tensor) – 第一个输入 Tensor input2 (Tensor) – 第二个输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a -0.6366 0.2718 0.4469 1.3122 [torch.FloatTensor of size 4] >>> torch.atan2(a, torch.randn(4)) -2.4167 2.9755 0.9363 1.6613 [torch.FloatTensor of size 4] torch.ceil(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 的元素向上取整(取不小于每个元素的最小整数). 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a 1.3869 0.3912 -0.8634 -0.5468 [torch.FloatTensor of size 4] >>> torch.ceil(a) 2 1 -0 -0 [torch.FloatTensor of size 4] torch.clamp(input, min, max, out=None) → Tensor 将输入张量 input 所有元素限制在区间 [min, max] 中并返回一个结果张量. | min, if x_i max 如果输入张量 input 的类型 FloatTensor 或者 DoubleTensor, 那么参数 min 和 max 必须为实数, 否则为整数. 参数： input (Tensor) – 输入 Tensor min (Number) – 限制范围下限 max (Number) – 限制范围上限 out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a 1.3869 0.3912 -0.8634 -0.5468 [torch.FloatTensor of size 4] >>> torch.clamp(a, min=-0.5, max=0.5) 0.5000 0.3912 -0.5000 -0.5000 [torch.FloatTensor of size 4] torch.clamp(input, *, min, out=None) → Tensor 张量 input 的所有元素值大于或者等于 min. 如果张量 input 的类型是 FloatTensor 或者 DoubleTensor, 则 value 必须是实数, 否则应该是整数. 参数： input (Tensor) – 输入 Tensor value (Number) – 输出中每个元素的最小值 out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a 1.3869 0.3912 -0.8634 -0.5468 [torch.FloatTensor of size 4] >>> torch.clamp(a, min=0.5) 1.3869 0.5000 0.5000 0.5000 [torch.FloatTensor of size 4] torch.clamp(input, *, max, out=None) → Tensor 张量 input 的所有元素值小于或者等于 max. 如果张量 input 的类型是 FloatTensor 或者 DoubleTensor, 则 value 必须是实数, 否则应该是整数. 参数： input (Tensor) – 输入 Tensor value (Number) – 输出中每个元素的最大值 out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a 1.3869 0.3912 -0.8634 -0.5468 [torch.FloatTensor of size 4] >>> torch.clamp(a, max=0.5) 0.5000 0.3912 -0.8634 -0.5468 [torch.FloatTensor of size 4] torch.cos(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 每个元素的余弦. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a -0.6366 0.2718 0.4469 1.3122 [torch.FloatTensor of size 4] >>> torch.cos(a) 0.8041 0.9633 0.9018 0.2557 [torch.FloatTensor of size 4] torch.cosh(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 每个元素的双曲余弦. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a -0.6366 0.2718 0.4469 1.3122 [torch.FloatTensor of size 4] >>> torch.cosh(a) 1.2095 1.0372 1.1015 1.9917 [torch.FloatTensor of size 4] torch.div() torch.div(input, value, out=None) 将张量 input 的元素逐一除以标量值 value , 其结果作为一个新的张量返回. 如果张量 input 的类型是 FloatTensor 或者 DoubleTensor, 则标量值 value 必须是实数, 否则应该是整数. 参数： input (Tensor) – 输入 Tensor value (Number) – 除数, 被张量 input 的元素除 out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(5) >>> a -0.6147 -1.1237 -0.1604 -0.6853 0.1063 [torch.FloatTensor of size 5] >>> torch.div(a, 0.5) -1.2294 -2.2474 -0.3208 -1.3706 0.2126 [torch.FloatTensor of size 5] torch.div(input, other, out=None) 张量 input 的元素与张量 other 的元素逐一相除. 返回一个新的结果张量 out . 张量 input 与张量 other 的形状必须可 broadcastable. 参数： input (Tensor) – 分子 Tensor (被除数) other (Tensor) – 分母 Tensor (除数) out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4,4) >>> a -0.1810 0.4017 0.2863 -0.1013 0.6183 2.0696 0.9012 -1.5933 0.5679 0.4743 -0.0117 -0.1266 -0.1213 0.9629 0.2682 1.5968 [torch.FloatTensor of size 4x4] >>> b = torch.randn(8, 2) >>> b 0.8774 0.7650 0.8866 1.4805 -0.6490 1.1172 1.4259 -0.8146 1.4633 -0.1228 0.4643 -0.6029 0.3492 1.5270 1.6103 -0.6291 [torch.FloatTensor of size 8x2] >>> torch.div(a, b) -0.2062 0.5251 0.3229 -0.0684 -0.9528 1.8525 0.6320 1.9559 0.3881 -3.8625 -0.0253 0.2099 -0.3473 0.6306 0.1666 -2.5381 [torch.FloatTensor of size 4x4] torch.erf(tensor, out=None) → Tensor 计算每个元素的误差函数. 示例： >>> torch.erf(torch.Tensor([0, -1., 10.])) torch.FloatTensor([0., -0.8427, 1.]) torch.erfinv(tensor, out=None) → Tensor 计算每个元素的反向误差函数. 示例： >>> torch.erfinv(torch.Tensor([0, 0.5., -1.])) torch.FloatTensor([0., 0.4769, -inf]) torch.exp(tensor, out=None) → Tensor 计算每个元素的指数. 示例： >>> torch.exp(torch.Tensor([0, math.log(2)])) torch.FloatTensor([1, 2]) torch.floor(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 的元素向下取整(取不大于每个元素的最大整数). 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a 1.3869 0.3912 -0.8634 -0.5468 [torch.FloatTensor of size 4] >>> torch.floor(a) 1 0 -1 -1 [torch.FloatTensor of size 4] torch.fmod(input, divisor, out=None) → Tensor 计算除法余数. 被除数和除数可能同时含有整数和浮点数. 这时余数的正负与被除数 tensor 相同. 当除数 divisor 是一个张量时r, 张量 input 和张量 divisor 的形状必须可 broadcastable. 参数： input (Tensor) – 被除数 divisor (Tensor 或 float) – 除数. 可能是一个数或者是一个与被除数相同形状的张量. out (Tensor, 可选) – 输出张量 示例： >>> torch.fmod(torch.Tensor([-3, -2, -1, 1, 2, 3]), 2) torch.FloatTensor([-1, -0, -1, 1, 0, 1]) >>> torch.fmod(torch.Tensor([1, 2, 3, 4, 5]), 1.5) torch.FloatTensor([1.0, 0.5, 0.0, 1.0, 0.5]) See also torch.remainder(), 其计算等价于 Python’s % 操作符的元素余数 torch.frac(tensor, out=None) → Tensor 计算张量 tensor 每个元素的分数部分. 示例： >>> torch.frac(torch.Tensor([1, 2.5, -3.2]) torch.FloatTensor([0, 0.5, -0.2]) torch.lerp(start, end, weight, out=None) 基于标量值 weight: , 在张量 start 与张量 end 之间做线性插值 并返回结果张量 out . 张量 start 和张量 end 的形状必须可 broadcastable. 参数： start (Tensor) – 起始点 Tensor end (Tensor) – 终点 Tensor weight (float) – 插值公式的权重 out (Tensor, 可选) – 结果 Tensor 示例： >>> start = torch.arange(1, 5) >>> end = torch.Tensor(4).fill_(10) >>> start 1 2 3 4 [torch.FloatTensor of size 4] >>> end 10 10 10 10 [torch.FloatTensor of size 4] >>> torch.lerp(start, end, 0.5) 5.5000 6.0000 6.5000 7.0000 [torch.FloatTensor of size 4] torch.log(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 所有元素的自然对数. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(5) >>> a -0.4183 0.3722 -0.3091 0.4149 0.5857 [torch.FloatTensor of size 5] >>> torch.log(a) nan -0.9883 nan -0.8797 -0.5349 [torch.FloatTensor of size 5] torch.log1p(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是(1 + input) 的自然对数. 注解： 对于较小的张量 input 的值, 此函数比 torch.log() 更精确. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(5) >>> a -0.4183 0.3722 -0.3091 0.4149 0.5857 [torch.FloatTensor of size 5] >>> torch.log1p(a) -0.5418 0.3164 -0.3697 0.3471 0.4611 [torch.FloatTensor of size 5] torch.mul() torch.mul(input, value, out=None) 将输入张量 input 的每个元素与标量值 value 相乘并返回一个新的结果张量. 如果张量 input 的类型为 FloatTensor or DoubleTensor, 则 value 应该是实数, 否则为整数. 参数： input (Tensor) – 输入 Tensor value (Number) – 与张量 input 每个元素相乘的数 out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(3) >>> a -0.9374 -0.5254 -0.6069 [torch.FloatTensor of size 3] >>> torch.mul(a, 100) -93.7411 -52.5374 -60.6908 [torch.FloatTensor of size 3] torch.mul(input, other, out=None) 张量 input 的元素与张量 other 的元素逐一相乘. 其结果作为一个新的张量返回. 张量 input 和张量 other 的形状必须可 broadcastable. 参数： input (Tensor) – 第一个乘数 Tensor other (Tensor) – 第二个乘数 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4,4) >>> a -0.7280 0.0598 -1.4327 -0.5825 -0.1427 -0.0690 0.0821 -0.3270 -0.9241 0.5110 0.4070 -1.1188 -0.8308 0.7426 -0.6240 -1.1582 [torch.FloatTensor of size 4x4] >>> b = torch.randn(2, 8) >>> b 0.0430 -1.0775 0.6015 1.1647 -0.6549 0.0308 -0.1670 1.0742 -1.2593 0.0292 -0.0849 0.4530 1.2404 -0.4659 -0.1840 0.5974 [torch.FloatTensor of size 2x8] >>> torch.mul(a, b) -0.0313 -0.0645 -0.8618 -0.6784 0.0934 -0.0021 -0.0137 -0.3513 1.1638 0.0149 -0.0346 -0.5068 -1.0304 -0.3460 0.1148 -0.6919 [torch.FloatTensor of size 4x4] torch.neg(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 的元素的负值. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(5) >>> a -0.4430 1.1690 -0.8836 -0.4565 0.2968 [torch.FloatTensor of size 5] >>> torch.neg(a) 0.4430 -1.1690 0.8836 0.4565 -0.2968 [torch.FloatTensor of size 5] torch.pow() torch.pow(input, exponent, out=None) 对输入张量 input 按元素求 exponent 次幂值并返回结果张量(其值作为结果张量的元素). 幂值 exponent 可以是一个单一的浮点数 float 或者是一个与张量 input 有相同元素数的张量 Tensor . 当指数 exponent 是一个标量时, 执行操作: 当指数 exponent 是一个张量, 执行操作: 当幂值 exponent 是一个张量, 张量 input 和张量 exponent 的形状必须可 broadcastable. 参数： input (Tensor) – 输入 Tensor exponent (float 或 Tensor) – 指数 out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a -0.5274 -0.8232 -2.1128 1.7558 [torch.FloatTensor of size 4] >>> torch.pow(a, 2) 0.2781 0.6776 4.4640 3.0829 [torch.FloatTensor of size 4] >>> exp = torch.arange(1, 5) >>> a = torch.arange(1, 5) >>> a 1 2 3 4 [torch.FloatTensor of size 4] >>> exp 1 2 3 4 [torch.FloatTensor of size 4] >>> torch.pow(a, exp) 1 4 27 256 [torch.FloatTensor of size 4] torch.pow(base, input, out=None) base 是一个标量浮点值, input 是一个张量. 返回的张量 out 的形状与张量 input 的形状相同. 执行操作: 参数： base (float) – 幂运算的底数 input (Tensor) – 指数 out (Tensor, 可选) – 结果 Tensor 示例： >>> exp = torch.arange(1, 5) >>> base = 2 >>> torch.pow(base, exp) 2 4 8 16 [torch.FloatTensor of size 4] torch.reciprocal(input, out=None) → Tensor 返回一个新的 Tensor , 其元素是张量 input 元素的倒数, i.e. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a 1.3869 0.3912 -0.8634 -0.5468 [torch.FloatTensor of size 4] >>> torch.reciprocal(a) 0.7210 2.5565 -1.1583 -1.8289 [torch.FloatTensor of size 4] torch.remainder(input, divisor, out=None) → Tensor 计算元素的除法的余数. 除数与被除数可能同时包含整数或浮点数. 余数与除数有相同的符号. 当除数 divisor 是一个张量, 张量 input 的形状和张量 divisor 得形状必须可 broadcastable. 参数： input (Tensor) – 被除数 divisor (Tensor 或 float) – 除数. 可能是一个数或者可能是一个与被除数大小相同的张量 out (Tensor, 可选) – 输出张量 示例： >>> torch.remainder(torch.Tensor([-3, -2, -1, 1, 2, 3]), 2) torch.FloatTensor([1, 0, 1, 1, 0, 1]) >>> torch.remainder(torch.Tensor([1, 2, 3, 4, 5]), 1.5) torch.FloatTensor([1.0, 0.5, 0.0, 1.0, 0.5]) See also torch.fmod() 同样计算除法余数, 等效于C库函数中的 fmod() torch.round(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是输入张量的元素四舍五入到最近的整数. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a 1.2290 1.3409 -0.5662 -0.0899 [torch.FloatTensor of size 4] >>> torch.round(a) 1 1 -1 -0 [torch.FloatTensor of size 4] torch.rsqrt(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 元素的平方根的倒数. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a 1.2290 1.3409 -0.5662 -0.0899 [torch.FloatTensor of size 4] >>> torch.rsqrt(a) 0.9020 0.8636 nan nan [torch.FloatTensor of size 4] torch.sigmoid(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 元素的sigmoid值. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a -0.4972 1.3512 0.1056 -0.2650 [torch.FloatTensor of size 4] >>> torch.sigmoid(a) 0.3782 0.7943 0.5264 0.4341 [torch.FloatTensor of size 4] torch.sign(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 元素的符号. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a -0.6366 0.2718 0.4469 1.3122 [torch.FloatTensor of size 4] >>> torch.sign(a) -1 1 1 1 [torch.FloatTensor of size 4] torch.sin(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 元素的正弦. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a -0.6366 0.2718 0.4469 1.3122 [torch.FloatTensor of size 4] >>> torch.sin(a) -0.5944 0.2684 0.4322 0.9667 [torch.FloatTensor of size 4] torch.sinh(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 元素的双曲正弦. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a -0.6366 0.2718 0.4469 1.3122 [torch.FloatTensor of size 4] >>> torch.sinh(a) -0.6804 0.2751 0.4619 1.7225 [torch.FloatTensor of size 4] torch.sqrt(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 元素的平方根. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a 1.2290 1.3409 -0.5662 -0.0899 [torch.FloatTensor of size 4] >>> torch.sqrt(a) 1.1086 1.1580 nan nan [torch.FloatTensor of size 4] torch.tan(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 元素的正切. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a -0.6366 0.2718 0.4469 1.3122 [torch.FloatTensor of size 4] >>> torch.tan(a) -0.7392 0.2786 0.4792 3.7801 [torch.FloatTensor of size 4] torch.tanh(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 元素的双曲正切. 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4) >>> a -0.6366 0.2718 0.4469 1.3122 [torch.FloatTensor of size 4] >>> torch.tanh(a) -0.5625 0.2653 0.4193 0.8648 [torch.FloatTensor of size 4] torch.trunc(input, out=None) → Tensor 返回一个新的张量 Tensor , 其元素是张量 input 元素的截断整数值 (直接去除小数部分) . 参数： input (Tensor) – 输入 Tensor out (Tensor, 可选) – 输出 Tensor 示例： >>> a = torch.randn(4) >>> a -0.4972 1.3512 0.1056 -0.2650 [torch.FloatTensor of size 4] >>> torch.trunc(a) -0 1 0 -0 [torch.FloatTensor of size 4] Reduction Ops (归约操作) torch.cumprod(input, dim, out=None) → Tensor 返回元素 input 在给定维度 dim 下的累积积. 例如, 如果 input 是一个N元张量, 结果也是一个N元张量, 元素为: 参数： input (Tensor) – 输入 Tensor dim (int) – 进行操作的维度 out (Tensor, 可选) – 输出 Tensor 示例： >>> a = torch.randn(10) >>> a 1.1148 1.8423 1.4143 -0.4403 1.2859 -1.2514 -0.4748 1.1735 -1.6332 -0.4272 [torch.FloatTensor of size 10] >>> torch.cumprod(a, dim=0) 1.1148 2.0537 2.9045 -1.2788 -1.6444 2.0578 -0.9770 -1.1466 1.8726 -0.8000 [torch.FloatTensor of size 10] >>> a[5] = 0.0 >>> torch.cumprod(a, dim=0) 1.1148 2.0537 2.9045 -1.2788 -1.6444 -0.0000 0.0000 0.0000 -0.0000 0.0000 [torch.FloatTensor of size 10] torch.cumsum(input, dim, out=None) → Tensor 返回元素 input 在给定维度 dim 下的累积和. 例如, 如果 input 是一个N元张量, 结果将也是一个N元张量, 元素为: 参数： input (Tensor) – 输入 Tensor dim (int) – 进行操作的维度 out (Tensor, 可选) – 输出 Tensor 示例： >>> a = torch.randn(10) >>> a -0.6039 -0.2214 -0.3705 -0.0169 1.3415 -0.1230 0.9719 0.6081 -0.1286 1.0947 [torch.FloatTensor of size 10] >>> torch.cumsum(a, dim=0) -0.6039 -0.8253 -1.1958 -1.2127 0.1288 0.0058 0.9777 1.5858 1.4572 2.5519 [torch.FloatTensor of size 10] torch.dist(input, other, p=2) → float 返回(input - other)的p-范数 input 和 other 的形状必须满足 broadcastable. 参数： input (Tensor) – 输入 Tensor other (Tensor) – 右侧输入 Tensor p (float, 可选) – 所计算的范数. 示例： >>> x = torch.randn(4) >>> x 0.2505 -0.4571 -0.3733 0.7807 [torch.FloatTensor of size 4] >>> y = torch.randn(4) >>> y 0.7782 -0.5185 1.4106 -2.4063 [torch.FloatTensor of size 4] >>> torch.dist(x, y, 3.5) 3.302832063224223 >>> torch.dist(x, y, 3) 3.3677282206393286 >>> torch.dist(x, y, 0) inf >>> torch.dist(x, y, 1) 5.560028076171875 torch.mean() torch.mean(input) → float 返回张量 input 所有元素的均值. 参数：input (Tensor) – 输入 Tensor 示例： >>> a = torch.randn(1, 3) >>> a -0.2946 -0.9143 2.1809 [torch.FloatTensor of size 1x3] >>> torch.mean(a) 0.32398951053619385 torch.mean(input, dim, keepdim=False, out=None) → Tensor 返回张量 input 在给定维度 dim 上每行的均值. 如果 keepdim 是 True, 输出张量的大小与输入张量 input 相同, 除了维度 dim 是1. 另外, dim 被挤压 (参看 torch.squeeze() ), 导致输出张量减少一维. 参数： input (Tensor) – 输入 Tensor dim (int) – 要减少的维度 keepdim (bool, 可选) – 输出张量的维度 dim 保持与否 out (Tensor) – 输出张量 示例： >>> a = torch.randn(4, 4) >>> a -1.2738 -0.3058 0.1230 -1.9615 0.8771 -0.5430 -0.9233 0.9879 1.4107 0.0317 -0.6823 0.2255 -1.3854 0.4953 -0.2160 0.2435 [torch.FloatTensor of size 4x4] >>> torch.mean(a, 1) -0.8545 0.0997 0.2464 -0.2157 [torch.FloatTensor of size 4] >>> torch.mean(a, 1, True) -0.8545 0.0997 0.2464 -0.2157 [torch.FloatTensor of size 4x1] torch.median() torch.median(input) → float 返回输出张量 input 所有元素的中位数. 参数：input (Tensor) – the input Tensor 示例： >>> a = torch.randn(1, 3) >>> a 0.4729 -0.2266 -0.2085 [torch.FloatTensor of size 1x3] >>> torch.median(a) -0.2085 torch.median(input, dim=-1, keepdim=False, values=None, indices=None) -> (Tensor, LongTensor) 返回输出张量 input 在给定维度 dim 下每行的中位数. 同时返回一个包含中位数的索引 LongTensor. dim 的缺省值为输入张量 input 的最后一维. 如果 keepdim 是 True, 输出张量与输入张量 input 形状相同, 除了维数 dim 是1. 另外, dim 被挤压 (参看 torch.squeeze() ), 导致输出张量比输入张量 input 少一维. 参数： input (Tensor) – 输入张量 Tensor dim (int) – 要减少的维度 keepdim (bool) – 输出张量的维度 dim 保留与否 values (Tensor, 可选) – 结果张量 indices (Tensor, 可选) – 结果张量索引 示例： >>> a -0.6891 -0.6662 0.2697 0.7412 0.5254 -0.7402 0.5528 -0.2399 [torch.FloatTensor of size 4x2] >>> a = torch.randn(4, 5) >>> a 0.4056 -0.3372 1.0973 -2.4884 0.4334 2.1336 0.3841 0.1404 -0.1821 -0.7646 -0.2403 1.3975 -2.0068 0.1298 0.0212 -1.5371 -0.7257 -0.4871 -0.2359 -1.1724 [torch.FloatTensor of size 4x5] >>> torch.median(a, 1) ( 0.4056 0.1404 0.0212 -0.7257 [torch.FloatTensor of size 4] , 0 2 4 1 [torch.LongTensor of size 4] ) torch.mode(input, dim=-1, keepdim=False, values=None, indices=None) -> (Tensor, LongTensor) 返回输入张量 input 在给定维数 dim 下每行元素的众数值. 同时也返回众数值的索引 LongTensor. 维度 dim 的缺省值是输入张量 input 的最后一维. . 如果 keepdim 是 True, 输出张量的大小与输入张量 input 相同, 除了维度 dim 是1. 另外, dim 被挤压 (参看 torch.squeeze() ), 导致输出张量减少一维. 注解： 这个函数至今没有为 torch.cuda.Tensor 定义. 参数： input (Tensor) – 输入张量 Tensor dim (int) – 要减少的维度 keepdim (bool) – 输出张量的维度 dim 保持与否 values (Tensor, 可选) – 结果张量 indices (Tensor, 可选) – 结果索引张量 示例： >>> a -0.6891 -0.6662 0.2697 0.7412 0.5254 -0.7402 0.5528 -0.2399 [torch.FloatTensor of size 4x2] >>> a = torch.randn(4, 5) >>> a 0.4056 -0.3372 1.0973 -2.4884 0.4334 2.1336 0.3841 0.1404 -0.1821 -0.7646 -0.2403 1.3975 -2.0068 0.1298 0.0212 -1.5371 -0.7257 -0.4871 -0.2359 -1.1724 [torch.FloatTensor of size 4x5] >>> torch.mode(a, 1) ( -2.4884 -0.7646 -2.0068 -1.5371 [torch.FloatTensor of size 4] , 3 4 2 0 [torch.LongTensor of size 4] ) torch.norm() torch.norm(input, p=2) → float 返回输入张量 input 的p-范数 参数： input (Tensor) – 输入张量 Tensor p (float, 可选) – 范数计算中的幂指数值 示例： >>> a = torch.randn(1, 3) >>> a -0.4376 -0.5328 0.9547 [torch.FloatTensor of size 1x3] >>> torch.norm(a, 3) 1.0338925067372466 torch.norm(input, p, dim, keepdim=False, out=None) → Tensor 返回输入张量 input 在给定维度 dim 下每行元素的p-范数. 如果 keepdim 是 True, 输出张量的大小与输入张量 input 相同, 除非维度 dim 是1. 另外, dim 被挤压 (参看 torch.squeeze() ), 导致输出张量减少一维. 参数： input (Tensor) – 输入张量 Tensor p (float) – 范数计算中的幂指数值 dim (int) – 要减少的维度 keepdim (bool) – 输出张量的维度 dim 保持与否 out (Tensor, 可选) – 结果张量 示例： >>> a = torch.randn(4, 2) >>> a -0.6891 -0.6662 0.2697 0.7412 0.5254 -0.7402 0.5528 -0.2399 [torch.FloatTensor of size 4x2] >>> torch.norm(a, 2, 1) 0.9585 0.7888 0.9077 0.6026 [torch.FloatTensor of size 4] >>> torch.norm(a, 0, 1, True) 2 2 2 2 [torch.FloatTensor of size 4x1] torch.prod() torch.prod(input) → float 返回输入张量 input 所有元素的乘积. 参数：input (Tensor) – 输入张量 Tensor 示例： >>> a = torch.randn(1, 3) >>> a 0.6170 0.3546 0.0253 [torch.FloatTensor of size 1x3] >>> torch.prod(a) 0.005537458061418483 torch.prod(input, dim, keepdim=False, out=None) → Tensor 返回输入张量 input 在给定维度 dim 下每行元素的积. 如果 keepdim 是 True, 输出张量的大小与输入张量 input 相同, 除了维度 dim 是1. 另外, dim 被挤压 (参看 torch.squeeze() ), 导致输出张量减少一维. 参数： input (Tensor) – 输入张量 Tensor dim (int) – 要减少的维度 keepdim (bool) – 输出张量的维度 dim 保持与否 out (Tensor, 可选) – 结果张量 示例： >>> a = torch.randn(4, 2) >>> a 0.1598 -0.6884 -0.1831 -0.4412 -0.9925 -0.6244 -0.2416 -0.8080 [torch.FloatTensor of size 4x2] >>> torch.prod(a, 1) -0.1100 0.0808 0.6197 0.1952 [torch.FloatTensor of size 4] torch.std() torch.std(input, unbiased=True) → float 返回输入张量 input 所有元素的标准差. 如果 unbiased 是 False , 那么标准差将通过有偏估计计算.否则, Bessel’s correction 将被使用. 参数： input (Tensor) – 输入 Tensor unbiased (bool) – 是否使用无偏估计 示例： >>> a = torch.randn(1, 3) >>> a -1.3063 1.4182 -0.3061 [torch.FloatTensor of size 1x3] >>> torch.std(a) 1.3782334731508061 torch.std(input, dim, keepdim=False, unbiased=True, out=None) → Tensor 返回输入张量 input 在给定维度 dim 下每行元素的标准差. 如果 keepdim 是 True, 输出张量的大小与输入张量 input 相同, 除了维度 dim 是 1. 另外, dim 被挤压 (参看 torch.squeeze() ), 导致输出张量减少一维. 如果 unbiased 是 False , 那么标准差将通过有偏估计来计算. 否则, Bessel’s correction 将被使用. 参数： input (Tensor) – 输入 Tensor dim (int) – 要减少的维度 keepdim (bool) – 输出张量的维度 dim 保持与否 unbiased (bool) – 是否使用无偏估计 out (Tensor, 可选) – 结果张量 示例： >>> a = torch.randn(4, 4) >>> a 0.1889 -2.4856 0.0043 1.8169 -0.7701 -0.4682 -2.2410 0.4098 0.1919 -1.1856 -1.0361 0.9085 0.0173 1.0662 0.2143 -0.5576 [torch.FloatTensor of size 4x4] >>> torch.std(a, dim=1) 1.7756 1.1025 1.0045 0.6725 [torch.FloatTensor of size 4] torch.sum() torch.sum(input) → float 返回输入张量 input 所有元素的和. 参数：input (Tensor) – 输入张量 Tensor 示例： >>> a = torch.randn(1, 3) >>> a 0.6170 0.3546 0.0253 [torch.FloatTensor of size 1x3] >>> torch.sum(a) 0.9969287421554327 torch.sum(input, dim, keepdim=False, out=None) → Tensor 返回输入张量 input 在给定维度 dim 下每行元素的和. 如果 keepdim 是 True, 输出张量的大小与输入张量 input 相同, 除了维度 dim 是 1. 另外, dim 被挤压 (参看 torch.squeeze() ), 导致输出张量减少一维. 参数： input (Tensor) – 输入张量 Tensor dim (int) – 要减少的维度 keepdim (bool) – 输出张量的维度 dim 保持与否 out (Tensor, 可选) – 结果张量 示例： >>> a = torch.randn(4, 4) >>> a -0.4640 0.0609 0.1122 0.4784 -1.3063 1.6443 0.4714 -0.7396 -1.3561 -0.1959 1.0609 -1.9855 2.6833 0.5746 -0.5709 -0.4430 [torch.FloatTensor of size 4x4] >>> torch.sum(a, 1) 0.1874 0.0698 -2.4767 2.2440 [torch.FloatTensor of size 4] torch.var() torch.var(input, unbiased=True) → float 返回输入张量 input 的方差. 如果 unbiased 是 False , 方差的计算将通过有偏估计计算. 否则, Bessel’s correction 将会被使用. 参数： input (Tensor) – 输入张量 Tensor unbiased (bool) – 是否使用无偏估计 示例： >>> a = torch.randn(1, 3) >>> a -1.3063 1.4182 -0.3061 [torch.FloatTensor of size 1x3] >>> torch.var(a) 1.899527506513334 torch.var(input, dim, keepdim=False, unbiased=True, out=None) → Tensor 返回输入张量 input 在给定维度 dim 下每行的方差. 如果 keepdim 是 True, 输出张量的大小与输入张量 input 相同, 除了维度 dim 是 1. 另外, dim 被挤压 (参看 torch.squeeze()), 导致输出张量减少一维. 如果 unbiased 是False, 方差的计算将通过有偏估计计算. 否则, Bessel’s correction 将会被使用. 参数： input (Tensor) – 输入张量 Tensor dim (int) – 要减少的维度 keepdim (bool) – 输出张量的维度 dim 保留与否 unbiased (bool) – 是否使用无偏估计 out (Tensor, 可选) – 结果张量 示例： >>> a = torch.randn(4, 4) >>> a -1.2738 -0.3058 0.1230 -1.9615 0.8771 -0.5430 -0.9233 0.9879 1.4107 0.0317 -0.6823 0.2255 -1.3854 0.4953 -0.2160 0.2435 [torch.FloatTensor of size 4x4] >>> torch.var(a, 1) 0.8859 0.9509 0.7548 0.6949 [torch.FloatTensor of size 4] Comparison Ops (比较操作) torch.eq(input, other, out=None) → Tensor 比较元素是否相等 第二个元素可以是一个数字或 broadcastable 为与第一个参数形状相同的张量. 参数： input (Tensor) – 待比较张量 other (Tensor 或 float) – 比较张量或数 out (Tensor, 可选) – 输出张量, 须为 ByteTensor 类型或与 input (Tensor) 同类型 返回值：一个 torch.ByteTensor 张量, 待比较和要比较张量逐位置比较, 相等为 1 , 不等为 0 示例： >>> torch.eq(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]])) 1 0 0 1 [torch.ByteTensor of size 2x2] torch.equal(tensor1, tensor2) → bool 如果两个张量有相同的形状和元素值, 则返回 True , 否则 False . 示例： >>> torch.equal(torch.Tensor([1, 2]), torch.Tensor([1, 2])) True torch.ge(input, other, out=None) → Tensor 逐元素比较 input 和 other , 即是否 input>=other . 第二个参数可以为一个数或形状可 broadcastable 为和第一个参数相同类型的张量. 参数： input (Tensor) – 待对比的张量 other (Tensor 或 float) – 对比的张量或 float 值 out (Tensor, 可选) – 输出张量. 必须为 ByteTensor 或者与第一个参数 tensor 相同类型. 返回值：一个 torch.ByteTensor 张量, 包含了每个位置的比较结果(是否 input >= other ). 返回类型：Tensor 示例： >>> torch.ge(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]])) 1 1 0 1 [torch.ByteTensor of size 2x2] torch.gt(input, other, out=None) → Tensor 逐元素比较 input 和 other , 即是否 input>other 如果两个张量有相同的形状和元素值, 则返回 True ,否则 False. 第二个参数可以为一个数或形状可 broadcastable 为和第一个参数相同类型的张量. 参数： input (Tensor) – 待对比的张量 other (Tensor 或 float) – 对比的张量或 float 值 out (Tensor, 可选) – 输出张量. 必须为 ByteTensor 或者与第一个参数 tensor 相同类型. 返回值：一个 torch.ByteTensor 张量, 包含了每个位置的比较结果(是否 input > other ). 返回类型：Tensor 示例： >>> torch.gt(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]])) 0 1 0 0 [torch.ByteTensor of size 2x2] torch.kthvalue(input, k, dim=None, keepdim=False, out=None) -> (Tensor, LongTensor) 取输入张量 input 指定维上第 k 个最小值. 如果不指定 dim , 则默认为 input 的最后一维. 返回一个元组 (values,indices) ,其中 indices 是原始输入张量 input 中沿 dim 维的第 k 个最小值下标. 如果 keepdim 为 True , values 和 indices 张量都和 input 大小相同, 除了在所有值都为1的 dim 维度上. 如果 keepdim 为 False , dim 被压缩. (参见 torch.squeeze() ), 使 values 和 indices 两个张量比 input 张量小一个的维度. 参数： input (Tensor) – 输入 Tensor k (int) – 第 k 个最小值 dim (int, 可选) – 沿着此维进行排序 keepdim (bool) – 输出张量是否保持维度 dim 不变 out (tuple, 可选) – 输出元组 ( Tensor, LongTensor ) 可选参数(作为输出 buffers ) 示例： >>> x = torch.arange(1, 6) >>> x 1 2 3 4 5 [torch.FloatTensor of size 5] >>> torch.kthvalue(x, 4) ( 4 [torch.FloatTensor of size 1] , 3 [torch.LongTensor of size 1] ) >>> x=torch.arange(1,7).resize_(2,3) >>> x 1 2 3 4 5 6 [torch.FloatTensor of size 2x3] >>> torch.kthvalue(x,2,0,True) ( 4 5 6 [torch.FloatTensor of size 1x3] , 1 1 1 [torch.LongTensor of size 1x3] ) torch.le(input, other, out=None) → Tensor 逐元素比较 input 和 other , 即是否 input 如果两个张量有相同的形状和元素值, 则返回 True ,否则 False . 第二个参数可以为一个数或形状可 broadcastable 为和第一个参数相同类型的张量. 参数： input (Tensor) – 待对比的张量 other (Tensor 或 float) – 对比的张量或 float 值 out (Tensor, 可选) – 输出张量. 必须为 ByteTensor 或者与第一个参数 tensor 相同类型. 返回值：一个 torch.ByteTensor 张量, 包含了每个位置的比较结果(是否 input 返回类型：Tensor 示例： >>> torch.le(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]])) 1 0 1 1 [torch.ByteTensor of size 2x2] torch.lt(input, other, out=None) → Tensor 逐元素比较 input 和 other , 即是否 input 如果两个张量有相同的形状和元素值, 则返回 True ,否则 False . 第二个参数可以为一个数或形状可 broadcastable 为和第一个参数相同类型的张量. 参数： input (Tensor) – 待对比的张量 other (Tensor 或 float) – 对比的张量或 float 值 out (Tensor, 可选) – 输出张量. 必须为 ByteTensor 或者与第一个参数 tensor 相同类型. 返回值：一个 torch.ByteTensor 张量, 包含了每个位置的比较结果(是否 input 返回类型：Tensor 示例： >>> torch.lt(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]])) 0 0 1 0 [torch.ByteTensor of size 2x2] torch.max() torch.max(input) → float 返回输入 input 张量所有元素的最大值. 参数：input (Tensor) – 输入 Tensor 示例： >>> a = torch.randn(1, 3) >>> a 0.4729 -0.2266 -0.2085 [torch.FloatTensor of size 1x3] >>> torch.max(a) 0.4729 torch.max(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor) 返回输入张量 input 在给定维度 dim 上每行的最大值, 并同时返回每个最大值的位置索引. 如果 keepdim 为 True , values 和 indices 张量都和 input 尺寸相同, 除了在所有值都为 1 的 dim 维度上. 如果 keepdim 为 False , dim 被压缩. (参见 torch.squeeze() ), 使 values 和 indices 两个张量比 input 张量小一个的维度. 参数： input (Tensor) – 输入 Tensor k (int) – 第 k 个最小值 dim (int, 可选) – 沿着此维进行排序 keepdim (bool) – 输出张量是否保持维度 dim 不变 out (tuple, 可选) – 输出元组 (max, max_indices) 示例： >> a = torch.randn(4, 4) >> a 0.0692 0.3142 1.2513 -0.5428 0.9288 0.8552 -0.2073 0.6409 1.0695 -0.0101 -2.4507 -1.2230 0.7426 -0.7666 0.4862 -0.6628 torch.FloatTensor of size 4x4] >>> torch.max(a, 1) ( 1.2513 0.9288 1.0695 0.7426 [torch.FloatTensor of size 4] , 2 0 0 0 [torch.LongTensor of size 4] ) torch.max(input, other, out=None) → Tensor 输入 input 每一个元素和对应的比较张量 other 进行比较, 留下较大的元素 max. 要比较的张量 input 与比较张量 other 不必大小一致, 但它们一定要能 broadcastable . 参数： input (Tensor) – 要比较张量 Tensor other (Tensor) – 比较张量 Tensor out (Tensor, 可选) – 输出张量 Tensor 示例： >>> a = torch.randn(4) >>> a 1.3869 0.3912 -0.8634 -0.5468 [torch.FloatTensor of size 4] >>> b = torch.randn(4) >>> b 1.0067 -0.8010 0.6258 0.3627 [torch.FloatTensor of size 4] >>> torch.max(a, b) 1.3869 0.3912 0.6258 0.3627 [torch.FloatTensor of size 4] torch.min() torch.min(input) → float 返回输入张量 input 所有元素的最小值. 参数：input (Tensor) – 输入 Tensor 示例： >>> a = torch.randn(1, 3) >>> a 0.4729 -0.2266 -0.2085 [torch.FloatTensor of size 1x3] >>> torch.min(a) -0.22663167119026184 torch.min(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor) 返回输入张量 input 在给定维度 dim 下每行元素的最小值. 其中第二个返回值是每个被找出的最小值的索引位置 ( argmin ) . 如果 keepdim 是 True, 输出张量的大小与输入张量 input 相同, 除了维数 dim 是 1 . 另外, dim 被挤压 (参看 torch.squeeze() ), 导致输出张量比输入张量 input 少一维. 参数： input (Tensor) – 输入张量 Tensor dim (int) – 要减少的维度 keepdim (bool) – 输出张量的维度 dim 保持与否 out (tuple, 可选) – 两个输出张量的结果元组 (min, min_indices) 示例： >> a = torch.randn(4, 4) >> a 0.0692 0.3142 1.2513 -0.5428 0.9288 0.8552 -0.2073 0.6409 1.0695 -0.0101 -2.4507 -1.2230 0.7426 -0.7666 0.4862 -0.6628 torch.FloatTensor of size 4x4] >> torch.min(a, 1) 0.5428 0.2073 2.4507 0.7666 torch.FloatTensor of size 4] 3 2 2 1 torch.LongTensor of size 4] torch.min(input, other, out=None) → Tensor 输入 input 每一个元素和对应的比较张量 other 进行比较, 留下较小的元素 min . 要比较的张量 input 与比较张量 other 不必尺寸一致, 但它们一定要能广播 broadcastable . 参数： input (Tensor) – 第一个张量 Tensor other (Tensor) – 第二个张量 Tensor out (Tensor, 可选) – 输出的张量 Tensor 示例： >>> a = torch.randn(4) >>> a 1.3869 0.3912 -0.8634 -0.5468 [torch.FloatTensor of size 4] >>> b = torch.randn(4) >>> b 1.0067 -0.8010 0.6258 0.3627 [torch.FloatTensor of size 4] >>> torch.min(a, b) 1.0067 -0.8010 -0.8634 -0.5468 [torch.FloatTensor of size 4] torch.ne(input, other, out=None) → Tensor 逐元素比较 input 和 other , 即是否 tensor != other 如果两个张量有相同的形状和元素值, 则返回 True , 否则 False . 第二个参数可以为一个数或形状广播 broadcastable 为和第一个参数相同类型的张量. 参数： input (Tensor) – 待对比的张量 other (Tensor 或 float) – 对比的张量或 float 值 out (Tensor, 可选) – 输出张量. 必须为 ByteTensor 或者与第一个参数 tensor 相同类型. 返回值：一个 torch.ByteTensor 张量, 包含了每个位置的比较结果 (是否 input != other ) . 返回类型：Tensor 示例： >>> torch.ne(torch.Tensor([[1, 2], [3, 4]]), torch.Tensor([[1, 1], [4, 4]])) 0 1 1 0 [torch.ByteTensor of size 2x2] torch.sort(input, dim=None, descending=False, out=None) -> (Tensor, LongTensor) 对输入张量 input 沿着指定维按升序排序. 如果不给定 dim ,则默认为输入的最后一维. 如果指定参数 descending 为 True , 则按降序排序. 返回元组 (sorted_tensor, sorted_indices) , sorted_indices 为原始输入中的下标. 参数： input (Tensor) – 要对比的张量 dim (int, 可选) – 沿着此维排序 descending (bool, 可选) – 布尔值, 控制升降排序 out (tuple, 可选) – 输出张量. 必须为 ByteTensor 或者与第一个参数 tensor 相同类型. 示例： >>> x = torch.randn(3, 4) >>> sorted, indices = torch.sort(x) >>> sorted -1.6747 0.0610 0.1190 1.4137 -1.4782 0.7159 1.0341 1.3678 -0.3324 -0.0782 0.3518 0.4763 [torch.FloatTensor of size 3x4] >>> indices 0 1 3 2 2 1 0 3 3 1 0 2 [torch.LongTensor of size 3x4] >>> sorted, indices = torch.sort(x, 0) >>> sorted -1.6747 -0.0782 -1.4782 -0.3324 0.3518 0.0610 0.4763 0.1190 1.0341 0.7159 1.4137 1.3678 [torch.FloatTensor of size 3x4] >>> indices 0 2 1 2 2 0 2 0 1 1 0 1 [torch.LongTensor of size 3x4] torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -> (Tensor, LongTensor) 沿给定 dim 维度返回输入张量 input 中 k 个最大值. 如果不指定 dim , 则默认为 input 的最后一维. 如果为 largest 为 False ,则返回最小的 k 个值. 返回一个元组 (values, indices) , 其中 indices 是原始输入张量 input 中测元素下标. 如果设定布尔值 sorted 为 True , 将会确保返回的 k 个值被排序. 参数： input (Tensor) – 输入张量 k (int) – “top-k” 中的 k dim (int, 可选) – 排序的维 largest (bool, 可选) – 布尔值, 控制返回最大或最小值 sorted (bool, 可选) – 布尔值, 控制返回值是否排序 out (tuple, 可选) – 可选输出张量 (Tensor, LongTensor) output buffers 示例： >>> x = torch.arange(1, 6) >>> x 1 2 3 4 5 [torch.FloatTensor of size 5] >>> torch.topk(x, 3) ( 5 4 3 [torch.FloatTensor of size 3] , 4 3 2 [torch.LongTensor of size 3] ) >>> torch.topk(x, 3, 0, largest=False) ( 1 2 3 [torch.FloatTensor of size 3] , 0 1 2 [torch.LongTensor of size 3] ) Other Operations (其它操作) torch.cross(input, other, dim=-1, out=None) → Tensor 返回沿着维度 dim 上, 两个张量 input 和 other 的向量积 (叉积), input 和 other 必须有相同的形状, 且指定的 dim 维上 size 必须为 3. 如果不指定 dim, 则默认为第一个尺度为 3 的维. 参数： input (Tensor) – 输入 Tensor other (Tensor) – 第二个输入 Tensor dim (int, 可选) – 沿着此维进行叉积操作. out (Tensor, 可选) – 结果 Tensor 示例： >>> a = torch.randn(4, 3) >>> a -0.6652 -1.0116 -0.6857 0.2286 0.4446 -0.5272 0.0476 0.2321 1.9991 0.6199 1.1924 -0.9397 [torch.FloatTensor of size 4x3] >>> b = torch.randn(4, 3) >>> b -0.1042 -1.1156 0.1947 0.9947 0.1149 0.4701 -1.0108 0.8319 -0.0750 0.9045 -1.3754 1.0976 [torch.FloatTensor of size 4x3] >>> torch.cross(a, b, dim=1) -0.9619 0.2009 0.6367 0.2696 -0.6318 -0.4160 -1.6805 -2.0171 0.2741 0.0163 -1.5304 -1.9311 [torch.FloatTensor of size 4x3] >>> torch.cross(a, b) -0.9619 0.2009 0.6367 0.2696 -0.6318 -0.4160 -1.6805 -2.0171 0.2741 0.0163 -1.5304 -1.9311 [torch.FloatTensor of size 4x3] torch.diag(input, diagonal=0, out=None) → Tensor 如果输入是一个向量( 1D 张量), 则返回一个以 input 为对角线元素的 2D 方阵. 如果输入是一个矩阵( 2D 张量), 则返回一个包含 input 对角线元素的1D张量. 参数 diagonal 指定对角线: diagonal = 0, 主对角线. diagonal > 0, 主对角线之上. diagonal 参数： input (Tensor) – 输入 Tensor diagonal (int, 可选) – 指定对角线 out (Tensor, 可选) – 输出 Tensor 示例： 获得以 input 为对角线的方阵: >>> a = torch.randn(3) >>> a 1.0480 -2.3405 -1.1138 [torch.FloatTensor of size 3] >>> torch.diag(a) 1.0480 0.0000 0.0000 0.0000 -2.3405 0.0000 0.0000 0.0000 -1.1138 [torch.FloatTensor of size 3x3] >>> torch.diag(a, 1) 0.0000 1.0480 0.0000 0.0000 0.0000 0.0000 -2.3405 0.0000 0.0000 0.0000 0.0000 -1.1138 0.0000 0.0000 0.0000 0.0000 [torch.FloatTensor of size 4x4] 获得给定矩阵的第k条对角线: >>> a = torch.randn(3, 3) >>> a -1.5328 -1.3210 -1.5204 0.8596 0.0471 -0.2239 -0.6617 0.0146 -1.0817 [torch.FloatTensor of size 3x3] >>> torch.diag(a, 0) -1.5328 0.0471 -1.0817 [torch.FloatTensor of size 3] >>> torch.diag(a, 1) -1.3210 -0.2239 [torch.FloatTensor of size 2] torch.histc(input, bins=100, min=0, max=0, out=None) → Tensor 计算输入张量的直方图. 以 min 和 max 为 range 边界, 将其均分成 bins 个直条, 然后将排序好的数据划分到各个直条 (bins) 中. 如果 min 和 max 都为 0, 则利用数据中的最大最小值作为边界. 参数： input (Tensor) – 输入张量 bins (int) – 直方图 bins (直条)的个数(默认100个) min (int) – range 的下边界(包含) max (int) – range 的上边界(包含) out (Tensor, 可选) – 结果张量 返回值：直方图 返回类型：Tensor 示例： >>> torch.histc(torch.FloatTensor([1, 2, 1]), bins=4, min=0, max=3) FloatTensor([0, 2, 1, 0]) torch.renorm(input, p, dim, maxnorm, out=None) → Tensor 返回一个张量, 包含规范化后的各个子张量, 使得沿着 dim 维划分的各子张量的 p 范数小于 maxnorm 注解： 如果 p 范数的值小于 maxnorm, 则当前子张量不需要修改. 参数： input (Tensor) – 输入 Tensor p (float) – 范数的 p dim (int) – 沿着此维切片, 得到张量子集 maxnorm (float) – 每个子张量的范数的最大值 out (Tensor, 可选) – 结果张量 示例： >>> x = torch.ones(3, 3) >>> x[1].fill_(2) >>> x[2].fill_(3) >>> x 1 1 1 2 2 2 3 3 3 [torch.FloatTensor of size 3x3] >>> torch.renorm(x, 1, 0, 5) 1.0000 1.0000 1.0000 1.6667 1.6667 1.6667 1.6667 1.6667 1.6667 [torch.FloatTensor of size 3x3] torch.trace(input) → float 返回输入 2 维矩阵对角线元素的和(迹). 示例： >>> x = torch.arange(1, 10).view(3, 3) >>> x 1 2 3 4 5 6 7 8 9 [torch.FloatTensor of size 3x3] >>> torch.trace(x) 15.0 torch.tril(input, diagonal=0, out=None) → Tensor 返回一个张量, 包含输入矩阵 ( 2D 张量)的下三角部分, 其余部分被设为 0. 这里所说的下三角部分为矩阵指定对角线 diagonal 在线里的和下面的元素. 参数 diagonal 控制对角线. diagonal = 0, 主对角线. diagonal > 0, 主对角线之上. diagonal 参数： input (Tensor) – 输入 Tensor diagonal (int, 可选) – 指定对角线 out (Tensor, 可选) – 输出 Tensor 示例： >>> a = torch.randn(3,3) >>> a 1.3225 1.7304 1.4573 -0.3052 -0.3111 -0.1809 1.2469 0.0064 -1.6250 [torch.FloatTensor of size 3x3] >>> torch.tril(a) 1.3225 0.0000 0.0000 -0.3052 -0.3111 0.0000 1.2469 0.0064 -1.6250 [torch.FloatTensor of size 3x3] >>> torch.tril(a, diagonal=1) 1.3225 1.7304 0.0000 -0.3052 -0.3111 -0.1809 1.2469 0.0064 -1.6250 [torch.FloatTensor of size 3x3] >>> torch.tril(a, diagonal=-1) 0.0000 0.0000 0.0000 -0.3052 0.0000 0.0000 1.2469 0.0064 0.0000 [torch.FloatTensor of size 3x3] torch.triu(input, diagonal=0, out=None) → Tensor 返回一个张量, 包含输入矩阵 ( 2D 张量)的上三角部分, 其余部分被设为 0. 这里所说的下三角部分为矩阵指定对角线 diagonal 在线里的和上面的元素. 参数 diagonal 控制对角线. diagonal = 0, 主对角线. diagonal > 0, 主对角线之上. diagonal 参数： input (Tensor) – 输入 Tensor diagonal (int, 可选) – 指定对角线 out (Tensor, 可选) – 输出 Tensor 示例： >>> a = torch.randn(3,3) >>> a 1.3225 1.7304 1.4573 -0.3052 -0.3111 -0.1809 1.2469 0.0064 -1.6250 [torch.FloatTensor of size 3x3] >>> torch.triu(a) 1.3225 1.7304 1.4573 0.0000 -0.3111 -0.1809 0.0000 0.0000 -1.6250 [torch.FloatTensor of size 3x3] >>> torch.triu(a, diagonal=1) 0.0000 1.7304 1.4573 0.0000 0.0000 -0.1809 0.0000 0.0000 0.0000 [torch.FloatTensor of size 3x3] >>> torch.triu(a, diagonal=-1) 1.3225 1.7304 1.4573 -0.3052 -0.3111 -0.1809 0.0000 0.0064 -1.6250 [torch.FloatTensor of size 3x3] BLAS and LAPACK Operations (BLAS和LAPACK操作) torch.addbmm(beta=1, mat, alpha=1, batch1, batch2, out=None) → Tensor 执行保存在 batch1 和 batch2 中的矩阵的批量点乘, 伴随着一个减少的相加步骤 (所有的矩阵乘法沿第一维累加). mat 被相加到最终的结果中. batch1 和 batch2 必须是三维的张量, 且每个包含相同数量的矩阵. 如果 batch1 是一个 b x n x m 的张量, batch2 是一个 b x m x p的张量, 那么 mat 必须是 broadcastable 且是一个 n x p 的张量, 同时 attr:out 将是一个 n x p 的张量. 换句话说, 对于 FloatTensor 或者 DoubleTensor 类型的输入, 参数 beta 和 alpha 必须是实数, 否则他们应该是整数. 参数： beta (Number, 可选) – 作用于 mat 的乘子 (系数) mat (Tensor) – 要被相加的矩阵 alpha (Number, 可选) – 作用于 batch1 @ batch2 的乘子 batch1 (Tensor) – 要相乘的第一批矩阵 batch2 (Tensor) – 要相乘的第二批矩阵 out (Tensor, 可选) – 输出的张量结果 示例： >>> M = torch.randn(3, 5) >>> batch1 = torch.randn(10, 3, 4) >>> batch2 = torch.randn(10, 4, 5) >>> torch.addbmm(M, batch1, batch2) -3.1162 11.0071 7.3102 0.1824 -7.6892 1.8265 6.0739 0.4589 -0.5641 -5.4283 -9.3387 -0.1794 -1.2318 -6.8841 -4.7239 [torch.FloatTensor of size 3x5] torch.addmm(beta=1, mat, alpha=1, mat1, mat2, out=None) → Tensor 执行矩阵 mat1 和 mat2 的相乘. 矩阵 mat 将与相乘的最终计算结果相加. 如果 mat1 是一个 n x m 的张量, mat2 是一个 m x p的张量, 那么 mat 必须是 broadcastable 且是一个 n x p 的张量, 同时 attr:out 将是一个 n x p 的张量. 换句话说, 对于 FloatTensor 或者 DoubleTensor 类型的输入, 参数 beta 和 alpha 必须是实数, 否则他们应该是整数. 参数： beta (Number, 可选) – 作用于mat的乘子 mat (Tensor) – 要被相加的矩阵 alpha (Number, 可选) – 作用于mat1 @ mat2的乘子 mat1 (Tensor) – 要相乘的第一个矩阵 mat2 (Tensor) – 要相乘的第二个矩阵 out (Tensor, 可选) – 输出结果 示例： >>> M = torch.randn(2, 3) >>> mat1 = torch.randn(2, 3) >>> mat2 = torch.randn(3, 3) >>> torch.addmm(M, mat1, mat2) -0.4095 -1.9703 1.3561 5.7674 -4.9760 2.7378 [torch.FloatTensor of size 2x3] torch.addmv(beta=1, tensor, alpha=1, mat, vec, out=None) → Tensor 执行矩阵 mat 和向量 vec 的相乘. 矩阵 tensor 将与相乘的最终计算结果相加. 如果 mat 是一个 n x m 的张量, vec 是一个长度为 m 的一维张量, 那么 :tensor 必须是 broadcastable 且是一个长度为 n 的一维张量, 同时 attr:out 将是一个长度为 n 的一维张量. alpha 和 beta 分别是 mat * vec 和 tensor 的缩放因子. 换句话说, 对于 FloatTensor 或者 DoubleTensor 类型的输入, 参数 beta 和 alpha 必须是实数, 否则他们应该是整数. 参数： beta (Number, 可选) – 作用于 tensor 的乘子 tensor (Tensor) – 要被相加的向量 alpha (Number, 可选) – 作用于 mat @ vec 的乘子 mat (Tensor) – 要被相乘的矩阵 vec (Tensor) – 要被要乘的向量 out (Tensor, 可选) – 输出结果 示例： >>> M = torch.randn(2) >>> mat = torch.randn(2, 3) >>> vec = torch.randn(3) >>> torch.addmv(M, mat, vec) -2.0939 -2.2950 [torch.FloatTensor of size 2] torch.addr(beta=1, mat, alpha=1, vec1, vec2, out=None) → Tensor 执行向量 vec1 和 vec2 的外积, 并把外积计算结果与矩阵 mat 相加. 可选值 beta 和 alpha 是标量, 分别与 mat 和 相乘. 换句话说, 如果 vec1 是一个长度为 n 的向量, vec2 是一个长度为 m 的向量, 那么 mat 必须是 broadcastable 且是一个大小为 n x m 的矩阵, 同时 out 将是一个大小为 n x m 的矩阵. 对于 FloatTensor 或者 DoubleTensor 类型的输入, 参数 beta 和 alpha 必须是实数, 否则他们应该是整数. 参数： beta (Number, 可选) – 作用于 mat 的乘子 mat (Tensor) – 要被相加的矩阵 alpha (Number, 可选) – 作用于 vec1 和 vec2 外积计算结果的乘子 vec1 (Tensor) – 外积计算的第一个向量 vec2 (Tensor) – 外积计算的第二个向量 out (Tensor, 可选) – 输出结果 示例： >>> vec1 = torch.arange(1, 4) >>> vec2 = torch.arange(1, 3) >>> M = torch.zeros(3, 2) >>> torch.addr(M, vec1, vec2) 1 2 2 4 3 6 [torch.FloatTensor of size 3x2] torch.baddbmm(beta=1, mat, alpha=1, batch1, batch2, out=None) → Tensor 执行保存在 batch1 和 batch2 中的矩阵的批量点乘. mat 被相加到最终的结果中. batch1 和 batch2 必须是三维的张量, 且每个包含相同数量的矩阵. 如果 batch1 是一个 b x n x m 的张量, batch2 是一个 b x m x p的张量, 那么 mat 必须是 broadcastable 且是一个 b x n x p 的张量, 同时 attr:out 将是一个 b x n x p 的张量. 换句话说, 对于 FloatTensor 或者 DoubleTensor 类型的输入, 参数 beta 和 alpha 必须是实数, 否则他们应该是整数. 参数： beta (Number, 可选) – 作用于 mat 的乘子 (系数) mat (Tensor) – 要被相加的张量 alpha (Number, 可选) – 作用于 batch1 @ batch2 的乘子 batch1 (Tensor) – 要相乘的第一批矩阵 batch2 (Tensor) – 要相乘的第二批矩阵 out (Tensor, 可选) – 输出的张量结果 示例： >>> M = torch.randn(10, 3, 5) >>> batch1 = torch.randn(10, 3, 4) >>> batch2 = torch.randn(10, 4, 5) >>> torch.baddbmm(M, batch1, batch2).size() torch.Size([10, 3, 5]) torch.bmm(batch1, batch2, out=None) → Tensor 执行保存在 batch1 和 batch2 中的矩阵的批量点乘. batch1 和 batch2 必须是三维的张量, 且每个包含相同数量的矩阵. 如果 batch1 是一个 b x n x m 的张量, batch2 是一个 b x m x p 的张量, out 将是一个 b x n x p 的张量. 注解： 这个函数不能参考 broadcast](notes/broadcasting.html#broadcasting-semantics). 对于广播矩阵相乘, 参见 [torch.matmul(). 参数： batch1 (Tensor) – 要相乘的第一批矩阵 batch2 (Tensor) – 要相乘的第二批矩阵 out (Tensor, 可选) – 输出结果 示例： >>> batch1 = torch.randn(10, 3, 4) >>> batch2 = torch.randn(10, 4, 5) >>> res = torch.bmm(batch1, batch2) >>> res.size() torch.Size([10, 3, 5]) torch.btrifact(A, info=None, pivot=True) → Tensor, IntTensor 批量 LU 分解. 返回一个包含 LU 分解和枢轴的元组. 对于每个 minibatch 示例, 如果分解成功, 可选参数 info 将提供分解信息. info 的值来自 dgetrf, 若是非零值, 则表示有错误发生. 如果 cuda 被使用的话, 具体的值来自 cublas, 否则来自 LAPACK. 如果设置了 pivot, 那么旋转操作将被执行. 参数：A (Tensor) – 要分解的张量. 示例： >>> A = torch.randn(2, 3, 3) >>> A_LU = A.btrifact() torch.btrisolve(b, LU_data, LU_pivots) → Tensor 批量 LU 解. 返回线性系统 Ax = b 的 LU 解. 参数： b (Tensor) – RHS tensor. LU_data (Tensor) – Pivoted LU factorization of A from btrifact. LU_pivots (IntTensor) – Pivots of the LU factorization. 示例： >>> A = torch.randn(2, 3, 3) >>> b = torch.randn(2, 3) >>> A_LU = torch.btrifact(A) >>> x = b.btrisolve(*A_LU) >>> torch.norm(A.bmm(x.unsqueeze(2)) - b) 6.664001874625056e-08 torch.dot(tensor1, tensor2) → float 计算两个张量的点乘 (内积). 注解： 这个函数不支持 broadcast. 示例： >>> torch.dot(torch.Tensor([2, 3]), torch.Tensor([2, 1])) 7.0 torch.eig(a, eigenvectors=False, out=None) -> (Tensor, Tensor) 计算实数方阵的特征值和特征向量. 参数： a (Tensor) – 一个要被计算特征值与特征向量的方阵 eigenvectors (bool) – 若为 True, 表示特征值与特征向量都被计算. 否则, 仅计算特征值. out (tuple, 可选) – 输出张量 返回值：包含以下的元组： e (Tensor): a 的左特征值 v (Tensor): 如果 eigenvectors 为 True, 表示 a 的特征向量; 否则是一个空的张量 返回类型：返回一个元组, (Tensor, Tensor) torch.gels(B, A, out=None) → Tensor 计算秩为 的， 大小为 m x n 的矩阵 最小二乘和最小范数问题的解 如果 !m >= n](img/tex-67ab86856a95fdd869cf2a0fff67d8be.gif), [gels() 求解最小二乘问题: 如果 !m gels() 求解最小范数问题: 返回的矩阵 的头 行包含解信息. 其余行包含剩余信息: 从第 行开始的每列的 euclidean 范数, 是对应列的剩余. 参数： B (Tensor) – The matrix A (Tensor) – The by matrix out (tuple, 可选) – Optional destination tensor 返回值：包含以下的元组： X (Tensor): 最小二乘解 qr (Tensor): QR 分解的详细信息 返回类型：(Tensor, Tensor) 注解： 不管输入矩阵的步长如何, 返回来的矩阵将总是被转置. 也就是, 他们的步长是 (1, m) 而不是 (m, 1). 示例： >>> A = torch.Tensor([[1, 1, 1], ... [2, 3, 4], ... [3, 5, 2], ... [4, 2, 5], ... [5, 4, 3]]) >>> B = torch.Tensor([[-10, -3], [ 12, 14], [ 14, 12], [ 16, 16], [ 18, 16]]) >>> X, _ = torch.gels(B, A) >>> X 2.0000 1.0000 1.0000 1.0000 1.0000 2.0000 [torch.FloatTensor of size 3x2] torch.geqrf(input, out=None) -> (Tensor, Tensor) 这是直接调用 LAPACK 的低层函数. 通常您应该使用 torch.qr() 来代替之. 计算 input 的 QR 分解, 但不构造 Q 和 R 作为显示分开的矩阵. 然而, 这样直接调用 LAPACK 的底层函数 ?geqrf, 会产生一连串的 ‘elementary reflectors’. 更多信息请参见 LAPACK documentation . 参数： input (Tensor) – the input matrix out (tuple, 可选) – The result tuple of (Tensor, Tensor) torch.ger(vec1, vec2, out=None) → Tensor 计算 vec1 和 vec2 的外积. 如果 vec1 是一个长度为 n 的向量, vec2 是一个长度为 m 的向量, 那么 out 必须是一个 n x m 的矩阵. 注解： 这个函数不支持 broadcast. 参数： vec1 (Tensor) – 1D input vector vec2 (Tensor) – 1D input vector out (Tensor, 可选) – optional output matrix 示例： >>> v1 = torch.arange(1, 5) >>> v2 = torch.arange(1, 4) >>> torch.ger(v1, v2) 1 2 3 2 4 6 3 6 9 4 8 12 [torch.FloatTensor of size 4x3] torch.gesv(B, A, out=None) -> (Tensor, Tensor) X, LU = torch.gesv(B, A) , 该函数返回线性系统 的解. LU 包含 A 的 LU 分解因子 L 和 U. A 必须是方阵, 且是非奇异的 (2维可逆张量). 如果 A 是一个 m x m 矩阵, B 是一个 m x k 的矩阵, 那么结果 LU 的大小为 m x m, X 的大小为 m x k . 注解： Irrespective of the original strides, the returned matrices X and LU will be transposed, i.e. with strides (1, m) instead of (m, 1). 参数： B (Tensor) – input matrix of m x k dimensions A (Tensor) – input square matrix of m x m dimensions out (Tensor, 可选) – optional output matrix 示例： >>> A = torch.Tensor([[6.80, -2.11, 5.66, 5.97, 8.23], ... [-6.05, -3.30, 5.36, -4.44, 1.08], ... [-0.45, 2.58, -2.70, 0.27, 9.04], ... [8.32, 2.71, 4.35, -7.17, 2.14], ... [-9.67, -5.14, -7.26, 6.08, -6.87]]).t() >>> B = torch.Tensor([[4.02, 6.19, -8.22, -7.57, -3.03], ... [-1.56, 4.00, -8.67, 1.75, 2.86], ... [9.81, -4.09, -4.57, -8.61, 8.99]]).t() >>> X, LU = torch.gesv(B, A) >>> torch.dist(B, torch.mm(A, X)) 9.250057093890353e-06 torch.inverse(input, out=None) → Tensor 计算方阵 input 的逆. 注解： Irrespective of the original strides, the returned matrix will be transposed, i.e. with strides (1, m) instead of (m, 1) 参数： input (Tensor) – the input 2D square Tensor out (Tensor, 可选) – the optional output Tensor 示例： >>> x = torch.rand(10, 10) >>> x 0.7800 0.2267 0.7855 0.9479 0.5914 0.7119 0.4437 0.9131 0.1289 0.1982 0.0045 0.0425 0.2229 0.4626 0.6210 0.0207 0.6338 0.7067 0.6381 0.8196 0.8350 0.7810 0.8526 0.9364 0.7504 0.2737 0.0694 0.5899 0.8516 0.3883 0.6280 0.6016 0.5357 0.2936 0.7827 0.2772 0.0744 0.2627 0.6326 0.9153 0.7897 0.0226 0.3102 0.0198 0.9415 0.9896 0.3528 0.9397 0.2074 0.6980 0.5235 0.6119 0.6522 0.3399 0.3205 0.5555 0.8454 0.3792 0.4927 0.6086 0.1048 0.0328 0.5734 0.6318 0.9802 0.4458 0.0979 0.3320 0.3701 0.0909 0.2616 0.3485 0.4370 0.5620 0.5291 0.8295 0.7693 0.1807 0.0650 0.8497 0.1655 0.2192 0.6913 0.0093 0.0178 0.3064 0.6715 0.5101 0.2561 0.3396 0.4370 0.4695 0.8333 0.1180 0.4266 0.4161 0.0699 0.4263 0.8865 0.2578 [torch.FloatTensor of size 10x10] >>> x = torch.rand(10, 10) >>> y = torch.inverse(x) >>> z = torch.mm(x, y) >>> z 1.0000 0.0000 0.0000 -0.0000 0.0000 0.0000 0.0000 0.0000 -0.0000 -0.0000 0.0000 1.0000 -0.0000 0.0000 0.0000 0.0000 -0.0000 -0.0000 -0.0000 -0.0000 0.0000 0.0000 1.0000 -0.0000 -0.0000 0.0000 0.0000 0.0000 -0.0000 -0.0000 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 -0.0000 -0.0000 0.0000 0.0000 0.0000 -0.0000 -0.0000 1.0000 0.0000 0.0000 -0.0000 -0.0000 -0.0000 0.0000 0.0000 0.0000 -0.0000 0.0000 1.0000 -0.0000 -0.0000 -0.0000 -0.0000 0.0000 0.0000 0.0000 -0.0000 0.0000 0.0000 1.0000 0.0000 -0.0000 0.0000 0.0000 0.0000 -0.0000 -0.0000 0.0000 0.0000 -0.0000 1.0000 -0.0000 0.0000 -0.0000 0.0000 -0.0000 -0.0000 0.0000 0.0000 -0.0000 -0.0000 1.0000 -0.0000 -0.0000 0.0000 -0.0000 -0.0000 -0.0000 0.0000 -0.0000 -0.0000 0.0000 1.0000 [torch.FloatTensor of size 10x10] >>> torch.max(torch.abs(z - torch.eye(10))) # Max nonzero 5.096662789583206e-07 torch.matmul(tensor1, tensor2, out=None) Matrix product of two tensors. The behavior depends on the dimensionality of the tensors as follows: If both tensors are 1-dimensional, the dot product (scalar) is returned. If both arguments are 2-dimensional, the matrix-matrix product is returned. If the first argument is 1-dimensional and the second argument is 2-dimensional, a 1 is prepended to its dimension for the purpose of the matrix multiply. After the matrix multiply, the prepended dimension is removed. If the first argument is 2-dimensional and the second argument is 1-dimensional, the matrix-vector product is returned. If both arguments are at least 1-dimensional and at least one argument is N-dimensional (where N > 2), then a batched matrix multiply is returned. If the first argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the batched matrix multiply and removed after. If the second argument is 1-dimensional, a 1 is appended to its dimension for the purpose of the batched matrix multiple and removed after. The non-matrix (i.e. batch) dimensions are broadcasted (and thus must be broadcastable). For example, if tensor1 is a j x 1 x n x m Tensor and tensor2 is a k x m x p Tensor, out will be an j x k x n x p Tensor. 注解： The 1-dimensional dot product version of this function does not support an out parameter. 参数： tensor1 (Tensor) – First tensor to be multiplied tensor2 (Tensor) – Second tensor to be multiplied out (Tensor, 可选) – Output tensor torch.mm(mat1, mat2, out=None) → Tensor 执行 mat1 和 mat2 的矩阵乘法. 如果 mat1 是一个 n x m 张量, mat2 是一个 m x p 张量, out 将是一个 n x p 张量. 注解： 这个函数不支持 broadcast](notes/broadcasting.html#broadcasting-semantics). 要使用支持广播矩阵乘法, 参见 [torch.matmul(). 参数： mat1 (Tensor) – First matrix to be multiplied mat2 (Tensor) – Second matrix to be multiplied out (Tensor, 可选) – Output tensor 示例： >>> mat1 = torch.randn(2, 3) >>> mat2 = torch.randn(3, 3) >>> torch.mm(mat1, mat2) 0.0519 -0.3304 1.2232 4.3910 -5.1498 2.7571 [torch.FloatTensor of size 2x3] torch.mv(mat, vec, out=None) → Tensor 执行矩阵 mat 与向量 vec 的乘法操作. 如果 mat 是一个 n x m 张量, vec 是一个大小为 m 的一维张量, out 将是一个大小为 n 的张量. 注解： 这个函数不支持 broadcast. 参数： mat (Tensor) – matrix to be multiplied vec (Tensor) – vector to be multiplied out (Tensor, 可选) – Output tensor 示例： >>> mat = torch.randn(2, 3) >>> vec = torch.randn(3) >>> torch.mv(mat, vec) -2.0939 -2.2950 [torch.FloatTensor of size 2] torch.orgqr() torch.ormqr() torch.potrf(a, out=None) potrf(a, upper, out=None) 计算半正定矩阵 a: 的 Cholesky 分解. 返回结果 u, 若 upper 设为 True 或未提供时, u 是一个上三角矩阵, 使得 成立; 若 upper 设为 False, u 是一个下三角矩阵, 使得 成立. 参数： a (Tensor) – the input 2D Tensor, a symmetric positive semidefinite matrix upper (bool, 可选) – Return upper (default) or lower triangular matrix out (Tensor, 可选) – A Tensor for u 示例： >>> a = torch.randn(3,3) >>> a = torch.mm(a, a.t()) # make symmetric positive definite >>> u = torch.potrf(a) >>> a 2.3563 3.2318 -0.9406 3.2318 4.9557 -2.1618 -0.9406 -2.1618 2.2443 [torch.FloatTensor of size 3x3] >>> u 1.5350 2.1054 -0.6127 0.0000 0.7233 -1.2053 0.0000 0.0000 0.6451 [torch.FloatTensor of size 3x3] >>> torch.mm(u.t(),u) 2.3563 3.2318 -0.9406 3.2318 4.9557 -2.1618 -0.9406 -2.1618 2.2443 [torch.FloatTensor of size 3x3] torch.potri(u, out=None) potri(u, upper, out=None) 给定一个半正定矩阵的 Cholesky 分解因子 u, 计算该半正定矩阵的逆. 返回矩阵 inv, 若 upper 设为 True 或为提供, u 是一个上三角矩阵, 使得 成立; 若 upper 设为 False, u 是一个下三角矩阵, 使得 成立. 参数： u (Tensor) – the input 2D Tensor, a upper or lower triangular Cholesky factor upper (bool, 可选) – Flag if upper (default) or lower triangular matrix out (Tensor, 可选) – A Tensor for inv 示例： >>> a = torch.randn(3,3) >>> a = torch.mm(a, a.t()) # make symmetric positive definite >>> u = torch.potrf(a) >>> a 2.3563 3.2318 -0.9406 3.2318 4.9557 -2.1618 -0.9406 -2.1618 2.2443 [torch.FloatTensor of size 3x3] >>> torch.potri(u) 12.5724 -10.1765 -4.5333 -10.1765 8.5852 4.0047 -4.5333 4.0047 2.4031 [torch.FloatTensor of size 3x3] >>> a.inverse() 12.5723 -10.1765 -4.5333 -10.1765 8.5852 4.0047 -4.5333 4.0047 2.4031 [torch.FloatTensor of size 3x3] torch.potrs(b, u, out=None) potrs(b, u, upper, out=None) Solves a linear system of equations with a positive semidefinite matrix to be inverted given its given a Cholesky factor matrix u: returns matrix c If upper is True or not provided, u is and upper triangular such that . If upper is False, u is and lower triangular such that . 注解： b is always a 2D Tensor, use b.unsqueeze(1) to convert a vector. 参数： b (Tensor) – the right hand side 2D Tensor u (Tensor) – the input 2D Tensor, a upper or lower triangular Cholesky factor upper (bool, 可选) – Return upper (default) or lower triangular matrix out (Tensor, 可选) – A Tensor for c 示例： >>> a = torch.randn(3,3) >>> a = torch.mm(a, a.t()) # make symmetric positive definite >>> u = torch.potrf(a) >>> a 2.3563 3.2318 -0.9406 3.2318 4.9557 -2.1618 -0.9406 -2.1618 2.2443 [torch.FloatTensor of size 3x3] >>> b = torch.randn(3,2) >>> b -0.3119 -1.8224 -0.2798 0.1789 -0.3735 1.7451 [torch.FloatTensor of size 3x2] >>> torch.potrs(b,u) 0.6187 -32.6438 -0.7234 27.0703 -0.6039 13.1717 [torch.FloatTensor of size 3x2] >>> torch.mm(a.inverse(),b) 0.6187 -32.6436 -0.7234 27.0702 -0.6039 13.1717 [torch.FloatTensor of size 3x2] torch.pstrf(a, out=None) pstrf(a, upper, out=None) Computes the pivoted Cholesky decomposition of a positive semidefinite matrix a: returns matrices u and piv. If upper is True or not provided, u is and upper triangular such that , with p the permutation given by piv. If upper is False, u is and lower triangular such that . 参数： a (Tensor) – the input 2D Tensor upper (bool, 可选) – Return upper (default) or lower triangular matrix out (tuple, 可选) – A tuple of u and piv Tensors 示例： >>> a = torch.randn(3,3) >>> a = torch.mm(a, a.t()) # make symmetric positive definite >>> a 5.4417 -2.5280 1.3643 -2.5280 2.9689 -2.1368 1.3643 -2.1368 4.6116 [torch.FloatTensor of size 3x3] >>> u,piv = torch.pstrf(a) >>> u 2.3328 0.5848 -1.0837 0.0000 2.0663 -0.7274 0.0000 0.0000 1.1249 [torch.FloatTensor of size 3x3] >>> piv 0 2 1 [torch.IntTensor of size 3] >>> p = torch.eye(3).index_select(0,piv.long()).index_select(0,piv.long()).t() # make pivot permutation >>> torch.mm(torch.mm(p.t(),torch.mm(u.t(),u)),p) # reconstruct 5.4417 1.3643 -2.5280 1.3643 4.6116 -2.1368 -2.5280 -2.1368 2.9689 [torch.FloatTensor of size 3x3] torch.qr(input, out=None) -> (Tensor, Tensor) 计算矩阵 input 的 QR 分解. 返回矩阵 q 和 r 使得 , 且 q 是一个 正交矩阵, r 是一个上三角矩阵. This returns the thin (reduced) QR factorization. 注解： 如果矩阵 input 中的元素太大, 那么精度可能会丢失. 注解： 尽管该函数总是能给您一个有效的分解, 但在不同平台上结果可能不同 - 取决于该平台上 LAPACK 的实现. 注解： Irrespective of the original strides, the returned matrix q will be transposed, i.e. with strides (1, m) instead of (m, 1). 参数： input (Tensor) – the input 2D Tensor out (tuple, 可选) – A tuple of Q and R Tensors 示例： >>> a = torch.Tensor([[12, -51, 4], [6, 167, -68], [-4, 24, -41]]) >>> q, r = torch.qr(a) >>> q -0.8571 0.3943 0.3314 -0.4286 -0.9029 -0.0343 0.2857 -0.1714 0.9429 [torch.FloatTensor of size 3x3] >>> r -14.0000 -21.0000 14.0000 0.0000 -175.0000 70.0000 0.0000 0.0000 -35.0000 [torch.FloatTensor of size 3x3] >>> torch.mm(q, r).round() 12 -51 4 6 167 -68 -4 24 -41 [torch.FloatTensor of size 3x3] >>> torch.mm(q.t(), q).round() 1 -0 0 -0 1 0 0 0 1 [torch.FloatTensor of size 3x3] torch.svd(input, some=True, out=None) -> (Tensor, Tensor, Tensor) U, S, V = torch.svd(A) 返回大小为 (n x m) 的实矩阵 A 的奇异值分解, 使得 . U 的大小为 n x n S 的大小为n x m V 的大小为 m x m. some 表示将被计算的奇异值的总数. 如果 some=True, 它将计算指定的 some 数量个奇异值, 如果 some=False, 则计算所有奇异值. 注解： Irrespective of the original strides, the returned matrix U will be transposed, i.e. with strides (1, n) instead of (n, 1). 参数： input (Tensor) – the input 2D Tensor some (bool, 可选) – controls the number of singular values to be computed out (tuple, 可选) – the result tuple 示例： >>> a = torch.Tensor([[8.79, 6.11, -9.15, 9.57, -3.49, 9.84], ... [9.93, 6.91, -7.93, 1.64, 4.02, 0.15], ... [9.83, 5.04, 4.86, 8.83, 9.80, -8.99], ... [5.45, -0.27, 4.85, 0.74, 10.00, -6.02], ... [3.16, 7.98, 3.01, 5.80, 4.27, -5.31]]).t() >>> a 8.7900 9.9300 9.8300 5.4500 3.1600 6.1100 6.9100 5.0400 -0.2700 7.9800 -9.1500 -7.9300 4.8600 4.8500 3.0100 9.5700 1.6400 8.8300 0.7400 5.8000 -3.4900 4.0200 9.8000 10.0000 4.2700 9.8400 0.1500 -8.9900 -6.0200 -5.3100 [torch.FloatTensor of size 6x5] >>> u, s, v = torch.svd(a) >>> u -0.5911 0.2632 0.3554 0.3143 0.2299 -0.3976 0.2438 -0.2224 -0.7535 -0.3636 -0.0335 -0.6003 -0.4508 0.2334 -0.3055 -0.4297 0.2362 -0.6859 0.3319 0.1649 -0.4697 -0.3509 0.3874 0.1587 -0.5183 0.2934 0.5763 -0.0209 0.3791 -0.6526 [torch.FloatTensor of size 6x5] >>> s 27.4687 22.6432 8.5584 5.9857 2.0149 [torch.FloatTensor of size 5] >>> v -0.2514 0.8148 -0.2606 0.3967 -0.2180 -0.3968 0.3587 0.7008 -0.4507 0.1402 -0.6922 -0.2489 -0.2208 0.2513 0.5891 -0.3662 -0.3686 0.3859 0.4342 -0.6265 -0.4076 -0.0980 -0.4932 -0.6227 -0.4396 [torch.FloatTensor of size 5x5] >>> torch.dist(a, torch.mm(torch.mm(u, torch.diag(s)), v.t())) 8.934150226306685e-06 torch.symeig(input, eigenvectors=False, upper=True, out=None) -> (Tensor, Tensor) e, V = torch.symeig(input) 返回实对称矩阵 input 的特征值和特征向量. input 和 V 是 m x m 矩阵, e 是一个 m 维的向量. 这个函数计算矩阵 input 的所有特征值 (和向量), 使得 input = V diag(e) V’. 布尔参数 eigenvectors 定义了是否计算特征向量. 如果它为 False, 那么只有特征值会被计算. 如果它为 True, 特征值和特征向量都会被计算. 由于输入矩阵 input 被假定是对称的, 因此默认地只有它的上三角部分会被使用. 如果 upper 是 False, 那么它的下三角部分会被使用. Note: Irrespective of the original strides, the returned matrix V will be transposed, i.e. with strides (1, m) instead of (m, 1). 参数： input (Tensor) – the input symmetric matrix eigenvectors (boolean, 可选) – controls whether eigenvectors have to be computed upper (boolean, 可选) – controls whether to consider upper-triangular or lower-triangular region out (tuple, 可选) – The result tuple of (Tensor, Tensor) Examples: >>> a = torch.Tensor([[ 1.96, 0.00, 0.00, 0.00, 0.00], ... [-6.49, 3.80, 0.00, 0.00, 0.00], ... [-0.47, -6.39, 4.17, 0.00, 0.00], ... [-7.20, 1.50, -1.51, 5.70, 0.00], ... [-0.65, -6.34, 2.67, 1.80, -7.10]]).t() >>> e, v = torch.symeig(a, eigenvectors=True) >>> e -11.0656 -6.2287 0.8640 8.8655 16.0948 [torch.FloatTensor of size 5] >>> v -0.2981 -0.6075 0.4026 -0.3745 0.4896 -0.5078 -0.2880 -0.4066 -0.3572 -0.6053 -0.0816 -0.3843 -0.6600 0.5008 0.3991 -0.0036 -0.4467 0.4553 0.6204 -0.4564 -0.8041 0.4480 0.1725 0.3108 0.1622 [torch.FloatTensor of size 5x5] torch.trtrs() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"tensors.html":{"url":"tensors.html","title":"torch.Tensor","keywords":"","body":"torch.Tensor 译者：@Sylvester、@那伊抹微笑 校对者：@Sariel torch.Tensor 是一种包含单一数据类型元素的多维矩阵. Torch 定义了七种 CPU tensor 类型和八种 GPU tensor 类型: Data type CPU tensor GPU tensor 32-bit floating point torch.FloatTensor torch.cuda.FloatTensor 64-bit floating point torch.DoubleTensor torch.cuda.DoubleTensor 16-bit floating point torch.HalfTensor torch.cuda.HalfTensor 8-bit integer (unsigned) torch.ByteTensor torch.cuda.ByteTensor 8-bit integer (signed) torch.CharTensor torch.cuda.CharTensor 16-bit integer (signed) torch.ShortTensor torch.cuda.ShortTensor 32-bit integer (signed) torch.IntTensor torch.cuda.IntTensor 64-bit integer (signed) torch.LongTensor torch.cuda.LongTensor torch.Tensor 是默认的 tensor 类型(torch.FloatTensor)的简称. 一个 tensor 对象可以从 Python 的 list 或者序列(sequence)构建: >>> torch.FloatTensor([[1, 2, 3], [4, 5, 6]]) 1 2 3 4 5 6 [torch.FloatTensor of size 2x3] 一个空的 tensor 对象可以通过所指定的大小来构建: >>> torch.IntTensor(2, 4).zero_() 0 0 0 0 0 0 0 0 [torch.IntTensor of size 2x4] 可以通过 Python 的索引和切片方式来获取或修改 tensor 对象的内容: >>> x = torch.FloatTensor([[1, 2, 3], [4, 5, 6]]) >>> print(x[1][2]) 6.0 >>> x[0][1] = 8 >>> print(x) 1 8 3 4 5 6 [torch.FloatTensor of size 2x3] 每一个 tensor 对象都有一个相应的 torch.Storage 用来保存数据. tensor 类提供了一个存储的多维的, 有 跨度(strided) 的视图, 并且在视图上定义了数值运算. 注解： 会改变 tensor 对象的函数方法名, 其使用了一个下划线后缀作为标识. 比如, torch.FloatTensor.abs_() 会在原地(in-place)计算绝对值并返回改变后的 tensor. 而 torch.FloatTensor.abs() 会在一个新建的 tensor 中计算结果. class torch.Tensor class torch.Tensor(*sizes) class torch.Tensor(size) class torch.Tensor(sequence) class torch.Tensor(ndarray) class torch.Tensor(tensor) class torch.Tensor(storage) 可以通过提供大小或者数据来创建一个新的 tensor 对象. 如果没有提供参数, 将返回一个空的零维的 tensor. 如果提供了 numpy.ndarray, torch.Tensor, 或者 torch.Storage 作为参数, 其将返回一个与参数共享数据的 tensor 对象. 如果提供一个 Python 序列 (sequence) 作为参数, 将返回从序列的副本中创建的一个新的 tensor 对象. abs() → Tensor 请查看 torch.abs() abs_() → Tensor abs() 的 in-place 运算形式 acos() → Tensor 请查看 torch.acos() acos_() → Tensor acos() 的 in-place 运算形式 add(value) 请查看 torch.add() add_(value) add() 的 in-place 运算形式 addbmm(beta=1, mat, alpha=1, batch1, batch2) → Tensor 请查看 torch.addbmm() addbmm_(beta=1, mat, alpha=1, batch1, batch2) → Tensor addbmm() 的 in-place 运算形式 addcdiv(value=1, tensor1, tensor2) → Tensor 请查看 torch.addcdiv() addcdiv_(value=1, tensor1, tensor2) → Tensor addcdiv() 的 in-place 运算形式 addcmul(value=1, tensor1, tensor2) → Tensor 请查看 torch.addcmul() addcmul_(value=1, tensor1, tensor2) → Tensor addcmul() 的 in-place 运算形式 addmm(beta=1, mat, alpha=1, mat1, mat2) → Tensor 请查看 torch.addmm() addmm_(beta=1, mat, alpha=1, mat1, mat2) → Tensor addmm() 的 in-place 运算形式 addmv(beta=1, tensor, alpha=1, mat, vec) → Tensor 请查看 torch.addmv() addmv_(beta=1, tensor, alpha=1, mat, vec) → Tensor addmv() 的 in-place 运算形式 addr(beta=1, alpha=1, vec1, vec2) → Tensor 请查看 torch.addr() addr_(beta=1, alpha=1, vec1, vec2) → Tensor addr() 的 in-place 运算形式 apply_(callable) → Tensor 将函数 callable 作用于 tensor 的每一个元素, 并将每个元素用 callable 的返回值替换. 注解： 该函数只能在 CPU tensor 中使用, 并且不应该用在有较高性能的要求的代码块中. asin() → Tensor 请查看 torch.asin() asin_() → Tensor asin() 的 in-place 运算形式 atan() → Tensor 请查看 torch.atan() atan2(other) → Tensor 请查看 torch.atan2() atan2_(other) → Tensor atan2() 的 in-place 运算形式 atan_() → Tensor atan() 的 in-place 运算形式 baddbmm(beta=1, alpha=1, batch1, batch2) → Tensor 请查看 torch.baddbmm() baddbmm_(beta=1, alpha=1, batch1, batch2) → Tensor baddbmm() 的 in-place 运算形式 bernoulli() → Tensor 请查看 torch.bernoulli() bernoulli_() → Tensor bernoulli() 的 in-place 运算形式 bmm(batch2) → Tensor 请查看 torch.bmm() byte() 将这个 tensor 转换为 byte 类型 cauchy_(median=0, sigma=1, *, generator=None) → Tensor 用柯西分布得到的数值来填充 tensor 中的元素: ceil() → Tensor 请查看 torch.ceil() ceil_() → Tensor ceil() 的 in-place 运算形式 char() 将这个 tensor 转换为 char 类型 chunk(n_chunks, dim=0) 将 tensor 分解成 tensor 元组. 请查看 torch.chunk(). clamp(min, max) → Tensor 请查看 torch.clamp() clamp_(min, max) → Tensor clamp() 的 in-place 运算形式 clone() → Tensor 返回与原 tensor 具有相同大小和数据类型的 tensor. contiguous() → Tensor 返回一个内存连续的有相同数据的 tensor, 如果原 tensor 内存连续则返回原 tensor. copy_(src, async=False, broadcast=True) → Tensor 将 src 中的元素复制到这个 tensor 中并返回这个 tensor 如果 broadcast 是 True, 源 tensor 一定和这个 tensor broadcastable. 另外, 源 tensor 的元素数量应该和这个 tensor 的元素个数一致. 源 tensor 可以是另一种数据类型, 或者在别的的设备上. 参数： src (Tensor) – 被复制的源 tensor async (bool) – 如果值为 True 并且这个复制操作在 CPU 和 GPU 之间进行, 则拷贝的副本与源信息可能会出现异步(asynchronously). 对于其他类型的复制操作, 这个参数不起作用. broadcast (bool) – 如果值为 True, src 将广播基础的 tensor 的形状. cos() → Tensor 请查看 torch.cos() cos_() → Tensor cos() 的 in-place 运算形式 cosh() → Tensor 请查看 torch.cosh() cosh_() → Tensor cosh() 的 in-place 运算形式 cpu() 如果此 tensor 不在CPU上, 则返回此 tensor 的CPU副本 cross(other, dim=-1) → Tensor 请查看 torch.cross() cuda(device=None, async=False) 返回此对象在 CUDA 内存中的一个副本 . 如果此对象已经在 CUDA 内存中并且在正确的设备上 , 那么不会执行复制操作 , 直接返回原对象 . 参数： device (int) – 目标 GPU 的 id . 默认值是当前设备 . async (bool) – 如果为 True 并且源位于锁定内存中 , 则副本相对于主机是异步的 . 否则此参数不起效果 . cumprod(dim) → Tensor 请查看 torch.cumprod() cumsum(dim) → Tensor 请查看 torch.cumsum() data_ptr() → int 返回 tensor 第一个元素的地址. diag(diagonal=0) → Tensor 请查看 torch.diag() dim() → int 返回 tensor 的维数. dist(other, p=2) → float 请查看 torch.dist() div(value) 请查看 torch.div() div_(value) div() 的 in-place 运算形式 dot(tensor2) → float 请查看 torch.dot() double() 将这个 tensor 转换为 double 类型 eig(eigenvectors=False) -> (Tensor, Tensor) 请查看 torch.eig() element_size() → int 返回单个元素的字节大小. 示例： >>> torch.FloatTensor().element_size() 4 >>> torch.ByteTensor().element_size() 1 eq(other) → Tensor 请查看 torch.eq() eq_(other) → Tensor eq() 的 in-place 运算形式 equal(other) → bool 请查看 torch.equal() erf() → Tensor 请查看 torch.erf() erf_() erfinv() → Tensor 请查看 torch.erfinv() erfinv_() exp() → Tensor 请查看 torch.exp() exp_() → Tensor exp() 的 in-place 运算形式 expand(*sizes) → Tensor 返回 tensor 单个维度扩展到大的一个新的视图. 传递 -1 作为一个维度的大小, 表示这个维度的大小不做改变. Tensor 也可以扩展到一个很大的维数, 新添加的维度将放在前面. (对于新的维度, 大小不能设置为 -1 .) 扩展一个 tensor 不是分配一个新的内存, 而只是在这个存在的 tensor 上, 通过设置 stride 为 0, 创建一个新的某个维度从 1 扩展到很大的视图. 任何大小为 1 的维度, 在不用重新分配内存的情况下, 可以扩展到随意任何一个值. 参数：sizes (torch.Size 或 int...) – 期望扩展的大小 示例： >>> x = torch.Tensor([[1], [2], [3]]) >>> x.size() torch.Size([3, 1]) >>> x.expand(3, 4) 1 1 1 1 2 2 2 2 3 3 3 3 [torch.FloatTensor of size 3x4] >>> x.expand(-1, 4) # -1 means not changing the size of that dimension 1 1 1 1 2 2 2 2 3 3 3 3 [torch.FloatTensor of size 3x4] expand_as(tensor) 将此 tensor 展开为指定 tensor 的大小. 这相当于: self.expand(tensor.size()) exponential_(lambd=1, *, generator=None) → Tensor 将该 tensor 用指数分布得到的元素填充: fill_(value) → Tensor 将该 tensor 用指定的数值填充. float() 将这个 tensor 转换为 float 类型 floor() → Tensor 请查看 torch.floor() floor_() → Tensor floor() 的 in-place 运算形式 fmod(divisor) → Tensor 请查看 torch.fmod() fmod_(divisor) → Tensor fmod() 的 in-place 运算形式 frac() → Tensor 请查看 torch.frac() frac_() → Tensor frac() 的 in-place 运算形式 gather(dim, index) → Tensor 请查看 torch.gather() ge(other) → Tensor 请查看 torch.ge() ge_(other) → Tensor ge() 的 in-place 运算形式 gels(A) → Tensor 请查看 torch.gels() geometric_(p, *, generator=None) → Tensor 将该 tensor 用几何分布得到的元素填充: geqrf() -> (Tensor, Tensor) 请查看 torch.geqrf() ger(vec2) → Tensor 请查看 torch.ger() gesv(A) → Tensor, Tensor 请查看 torch.gesv() gt(other) → Tensor 请查看 torch.gt() gt_(other) → Tensor gt() 的 in-place 运算形式 half() 将这个 tensor 转换为 half-precision float 类型 histc(bins=100, min=0, max=0) → Tensor 请查看 torch.histc() index(m) → Tensor 用一个二进制的掩码或沿着一个给定的维度从 tensor 中选取元素. tensor.index(m) 等同于 tensor[m]. 参数：m (int 或 ByteTensor 或 slice) – 用来选取元素的维度或掩码 index_add_(dim, index, tensor) → Tensor 按参数 index 给出的索引序列, 将参数 tensor 中的元素加到原来的 tensor 中. 参数 tensor 的尺寸必须严格地与原 tensor 匹配, 否则会发生错误. 参数： dim (int) – 索引 index 所指向的维度 index (LongTensor) – 从参数 tensor 中选取数据的索引序列 tensor (Tensor) – 包含需要相加的元素的 tensor 示例： >>> x = torch.Tensor([[1, 1, 1], [1, 1, 1], [1, 1, 1]]) >>> t = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> index = torch.LongTensor([0, 2, 1]) >>> x.index_add_(0, index, t) >>> x 2 3 4 8 9 10 5 6 7 [torch.FloatTensor of size 3x3] index_copy_(dim, index, tensor) → Tensor 按参数 index 给出的索引序列, 将参数 tensor 中的元素复制到原来的 tensor 中. 参数 tensor 的尺寸必须严格地与原 tensor 匹配, 否则会发生错误. 参数： dim (int) – 索引 index 所指向的维度 index (LongTensor) – 从参数 tensor 中选取数据的索引序列 tensor (Tensor) – 包含需要复制的元素的 tensor 示例： >>> x = torch.Tensor(3, 3) >>> t = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> index = torch.LongTensor([0, 2, 1]) >>> x.index_copy_(0, index, t) >>> x 1 2 3 7 8 9 4 5 6 [torch.FloatTensor of size 3x3] index_fill_(dim, index, val) → Tensor 按参数 index 给出的索引序列, 将原 tensor 中的元素用 val 填充. 参数： dim (int) – 索引 index 所指向的维度 index (LongTensor) – 从参数 val 中选取数据的索引序列 val (float) – 用来填充的值 示例： >>> x = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> index = torch.LongTensor([0, 2]) >>> x.index_fill_(1, index, -1) >>> x -1 2 -1 -1 5 -1 -1 8 -1 [torch.FloatTensor of size 3x3] index_select(dim, index) → Tensor 请查看 torch.index_select() int() 将这个 tensor 转换为 int 类型 inverse() → Tensor 请查看 torch.inverse() is_contiguous() → bool 以 C 语言的内存模型为原则, 如果该 tensor 在内如果该 tensor 在内存中连续的, 则返回 True. is_cuda is_pinned() 如果 tensor 驻留在固定内存中, 则返回 true is_set_to(tensor) → bool 如果此对象从 Torch C API 引用的 THTensor 对象与参数 tensor 引用的对象一致, 则返回True. is_signed() kthvalue(k, dim=None, keepdim=False) -> (Tensor, LongTensor) 请查看 torch.kthvalue() le(other) → Tensor 请查看 torch.le() le_(other) → Tensor le() 的 in-place 运算形式 lerp(start, end, weight) 请查看 torch.lerp() lerp_(start, end, weight) lerp() 的 in-place 运算形式 log() → Tensor 请查看 torch.log() log1p() → Tensor 请查看 torch.log1p() log1p_() → Tensor log1p() 的 in-place 运算形式 log_() → Tensor log() 的 in-place 运算形式 log_normal_(mean=1, std=2, *, generator=None) 将该 tensor 用均值为 mean (µ), 标准差为 std (σ) 的对数正态分布得到的元素填充. 要注意 mean 和 stdv 是基本正态分布的均值和标准差, 不是返回的分布: long() 将这个 tensor 转换为 long 类型 lt(other) → Tensor 请查看 torch.lt() lt_(other) → Tensor lt() 的 in-place 运算形式 map_(tensor, callable) 将 callable 作用于本 tensor 和参数 tensor 中的每一个元素, 并将结果存放在本 tensor 中. 本 tensor 和参数 tensor 都必须是 broadcastable. callable 应该有下列标志: def callable(a, b) -&gt; number masked_scatter_(mask, source) 复制 source 的元素到本 tensor 被mask中值为 1 的元素标记的位置中. mask 的形状和本 tensor 的形状必须是可广播的 ( broadcastable ). source 中元素的个数最少为 mask 中值为1的元素的个数. 参数： mask (ByteTensor) – 二进制掩码 source (Tensor) – 复制的源 tensor 注解： mask 作用于 self 自身的 tensor, 而不是参数 source 的 tensor. masked_fill_(mask, value) 将本 tensor 被 mask 中值为 1 的元素标记的位置, 用 value 填充. mask 的形状和本 tensor 的形状必须是可广播的 (broadcastable). Fills elements of this tensor with value where mask is one. 参数： mask (ByteTensor) – 二进制掩码 value (float) – 用来填充的值 masked_select(mask) → Tensor 请查看 torch.masked_select() matmul(other) 两个 tensor 的矩阵乘积. 请查看 torch.matmul(). max(dim=None, keepdim=False) -> float or (Tensor, Tensor) 请查看 torch.max() mean(dim=None, keepdim=False) -> float or (Tensor, Tensor) 请查看 torch.mean() median(dim=None, keepdim=False) -> (Tensor, LongTensor) 请查看 torch.median() min(dim=None, keepdim=False) -> float or (Tensor, Tensor) 请查看 torch.min() mm(mat2) → Tensor 请查看 torch.mm() mode(dim=None, keepdim=False) -> (Tensor, LongTensor) 请查看 torch.mode() mul(value) → Tensor 请查看 torch.mul() mul_(value) mul() 的 in-place 运算形式 multinomial(num_samples, replacement=False, *, generator=None) 请查看 torch.multinomial() mv(vec) → Tensor 请查看 torch.mv() narrow(dimension, start, length) → Tensor 返回一个本 tensor 经过缩小后的 tensor. 维度 dim 缩小范围是 start 到 start + length. 原 tensor 与返回的 tensor 共享相同的底层存储. 参数： dimension (int) – 需要缩小的维度 start (int) – 起始维度 length (int) – 示例： >>> x = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) >>> x.narrow(0, 0, 2) 1 2 3 4 5 6 [torch.FloatTensor of size 2x3] >>> x.narrow(1, 1, 2) 2 3 5 6 8 9 [torch.FloatTensor of size 3x2] ndimension() → int dim() 的另一种表示 ne(other) → Tensor 请查看 torch.ne() ne_(other) → Tensor ne() 的 in-place 运算形式 neg() → Tensor 请查看 torch.neg() neg_() → Tensor neg() 的 in-place 运算形式 nelement() → int numel() 的另一种表示 new(*args, **kwargs) 构造相同数据类型的新 tensor. nonzero() → LongTensor 请查看 torch.nonzero() norm(p=2, dim=None, keepdim=False) → float 请查看 torch.norm() normal_(mean=0, std=1, *, generator=None) 将 tensor 用均值为 mean 和标准差为std的正态分布填充. numel() → int 请查看 torch.numel() numpy() → ndarray 将该 tensor 以 NumPy ndarray 的形式返回. 两者共享相同的底层存储. 原 tensor 的改变会影响到 ndarray, 反之也一样. orgqr(input2) → Tensor 请查看 torch.orgqr() ormqr(input2, input3, left=True, transpose=False) → Tensor 请查看 torch.ormqr() permute(*dims) 排列该 tensor 的尺寸. 参数：*dims (int...) – 按所期望的维数排序 示例： >>> x = torch.randn(2, 3, 5) >>> x.size() torch.Size([2, 3, 5]) >>> x.permute(2, 0, 1).size() torch.Size([5, 2, 3]) pin_memory() 如果 tensor 尚未固定, 则将 tensor 复制到固定内存. potrf(upper=True) → Tensor 请查看 torch.potrf() potri(upper=True) → Tensor 请查看 torch.potri() potrs(input2, upper=True) → Tensor 请查看 torch.potrs() pow(exponent) 请查看 torch.pow() pow_(exponent) pow() 的 in-place 运算形式 prod(dim=None, keepdim=False) → float 请查看 torch.prod() pstrf(upper=True, tol=-1) -> (Tensor, IntTensor) 请查看 torch.pstrf() put_(indices, tensor, accumulate=False) → Tensor 复制 tensor 内的元素到 indices 指定的位置. 为了达到索引的目的, self tensor 被当做一维 (1D) 的 tensor. 如果 accumulate 是 True, tensor 内的元素累加到 self 中. 如果 accumulate 是 False, 在索引包含重复的值时, 行为未定义. 参数： indices (LongTensor) – self 的索引 tensor (Tensor) – 包含需要复制值的 tensor accumulate (bool) – 如果是 True, 元素累加到 self 示例： >>> src = torch.Tensor([[4, 3, 5], ... [6, 7, 8]]) >>> src.put_(torch.LongTensor([1, 3]), torch.Tensor([9, 10])) 4 9 5 10 7 8 [torch.FloatTensor of size 2x3] qr() -> (Tensor, Tensor) 请查看 torch.qr() random_(from=0, to=None, *, generator=None) 将 tensor 用在 [from, to - 1] 上的离散均匀分布进行填充. 如果没有特别说明, 填入的值由本 tensor 的数据类型限定范围. 但是, 对于浮点类型 (floating point types), 如果没有特别说明, 取值范围是0, 2^mantissa, 以确保每个数都是可表示的. 例如, torch.DoubleTensor(1).random_() 将均匀分布在[0, 2^53]. reciprocal() → Tensor 请查看 torch.reciprocal() reciprocal_() → Tensor reciprocal() 的 in-place 运算形式 remainder(divisor) → Tensor 请查看 torch.remainder() remainder_(divisor) → Tensor remainder() 的 in-place 运算形式 renorm(p, dim, maxnorm) → Tensor 请查看 torch.renorm() renorm_(p, dim, maxnorm) → Tensor renorm() 的 in-place 运算形式 repeat(*sizes) 沿着指定的尺寸重复 tensor. 和 expand() 不同, 这个函数复制 tensor 的数据. 参数：*sizes (torch.Size 或 int...) – 沿每个维度重复 tensor 的次数 示例： >>> x = torch.Tensor([1, 2, 3]) >>> x.repeat(4, 2) 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 [torch.FloatTensor of size 4x6] >>> x.repeat(4, 2, 1).size() torch.Size([4, 2, 3]) resize_(*sizes) 将 tensor 的大小调整为指定的大小. 如果元素个数比当前的内存大小大, 就将底层存储大小调整为与新元素数目一致的大小. 如果元素个数比当前内存小, 则底层存储不会被改变. 原来tensor中被保存下来的元素将保持不变, 但新内存将不会被初始化. 参数：*sizes (torch.Size 或 int...) – 期望的大小 示例： >>> x = torch.Tensor([[1, 2], [3, 4], [5, 6]]) >>> x.resize_(2, 2) >>> x 1 2 3 4 [torch.FloatTensor of size 2x2] resize_as_(tensor) 将本 tensor 的大小调整为参数 tensor 的大小. 等效于: self.resize_(tensor.size()) round() → Tensor 请查看 torch.round() round_() → Tensor round() 的 in-place 运算形式 rsqrt() → Tensor 请查看 torch.rsqrt() rsqrt_() → Tensor rsqrt() 的 in-place 运算形式 scatter_(dim, index, src) → Tensor 将 src 中的所有值按照 index 确定的索引顺序写入本 tensor 中. 给定的 dim 声明索引的维度, dim 按照 gather() 中的描述的规则来确定. 注意, 关于 gather, index 的值必须是 0 到 (self.size(dim) -1) 区间, 而且, 属于同一维度的一行的值必须是唯一的. 参数： dim (int) – 索引的轴向 index (LongTensor) – 散射元素的索引指数 src (Tensor 或 float) – 散射的源元素 示例： >>> x = torch.rand(2, 5) >>> x 0.4319 0.6500 0.4080 0.8760 0.2355 0.2609 0.4711 0.8486 0.8573 0.1029 [torch.FloatTensor of size 2x5] >>> torch.zeros(3, 5).scatter_(0, torch.LongTensor([[0, 1, 2, 0, 0], [2, 0, 0, 1, 2]]), x) 0.4319 0.4711 0.8486 0.8760 0.2355 0.0000 0.6500 0.0000 0.8573 0.0000 0.2609 0.0000 0.4080 0.0000 0.1029 [torch.FloatTensor of size 3x5] >>> z = torch.zeros(2, 4).scatter_(1, torch.LongTensor([[2], [3]]), 1.23) >>> z 0.0000 0.0000 1.2300 0.0000 0.0000 0.0000 0.0000 1.2300 [torch.FloatTensor of size 2x4] select(dim, index) → Tensor or number 沿着 dim 给定的维度, 按照 index 切片. 如果这个 tensor 是一维的, 返回一个数字. 否则, 返回一个给定维度已经被移除的 tensor. 参数： dim (int) – 切片的维度 index (int) – 用来选取的索引 注解： select等效于切片. 例如, tensor.select(0, index) 等效于 tensor[index] 和 tensor.select(2, index) 等效于 tensor[:,:,index]. set_(source=None, storage_offset=0, size=None, stride=None) 设置底层存储, 大小, 和步长. 如果 source 是一个 tensor 对象, 本 tensor 和该 tensor 共享底层存储, 并且大小和步长一样. 在其中一个 tensor 中改变元素, 会音响到另一个 tensor. 如果 source 是一个 Storage, 则将设置底层内存, 偏移量, 大小和步长. 参数： source (Tensor 或 Storage) – 用到的 tensor 或 storage storage_offset (int) – storage 的偏移量 size (torch.Size) – 期望的大小. 默认为源 tensor 的大小. stride (tuple) – 期望的步长. 默认为 C 相邻内存的步长. share_memory_() 将底层存储移到共享内存. 如果底层存储已经在共享内存和CUDA tensor 中, 则这是无操作. 共享内存中的 tensor 不能调整大小. short() 将这个 tensor 转换为 short 类型 sigmoid() → Tensor 请查看 torch.sigmoid() sigmoid_() → Tensor sigmoid() 的 in-place 运算形式 sign() → Tensor 请查看 torch.sign() sign_() → Tensor sign() 的 in-place 运算形式 sin() → Tensor 请查看 torch.sin() sin_() → Tensor sin() 的 in-place 运算形式 sinh() → Tensor 请查看 torch.sinh() sinh_() → Tensor sinh() 的 in-place 运算形式 size() → torch.Size 返回 tensor 的大小. 返回的值是 tuple 的子类. 示例： >>> torch.Tensor(3, 4, 5).size() torch.Size([3, 4, 5]) sort(dim=None, descending=False) -> (Tensor, LongTensor) 请查看 torch.sort() split(split_size, dim=0) 将 tensor 分解成 tensor 元组. See torch.split(). sqrt() → Tensor 请查看 torch.sqrt() sqrt_() → Tensor sqrt() 的 in-place 运算形式 squeeze(dim=None) 请查看 torch.squeeze() squeeze_(dim=None) squeeze() 的 in-place 运算形式 std(dim=None, unbiased=True, keepdim=False) → float 请查看 torch.std() storage() → torch.Storage 返回底层存储 storage_offset() → int 按照储存元素个数的偏移返回 tensor 在底层存储中的偏移量(不是按照字节计算). 示例： >>> x = torch.Tensor([1, 2, 3, 4, 5]) >>> x.storage_offset() 0 >>> x[3:].storage_offset() 3 classmethod storage_type() stride(dim) → tuple or int 返回 tesnor 的步长. 步长是指按照 dim 指定的维度, 从一个元素到下一个元素需要跳跃的距离. 当没有指定维度, 会计算所有维度的步长, 并返回一个 tuple. 当给定维度时, 返回这个维度的步长. 参数：dim (int) – 期望的需要计算步长的维度. 示例： >>> x = torch.Tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]) >>> x.stride() (5, 1) >>>x.stride(0) 5 >>> x.stride(-1) 1 sub(value, other) → Tensor 从 tensor 中抽取一个标量或张量. 如果 value 和 other 都是给定的, 则在使用之前 other的每一个元素都会被 value 缩放. 如果 other 是一个tensor, other 的形状必须于基础 tensor 的形状是可广播的 ( broadcastable ). sub_(x) → Tensor sub() 的 in-place 运算形式 sum(dim=None, keepdim=False) → float 请查看 torch.sum() svd(some=True) -> (Tensor, Tensor, Tensor) 请查看 torch.svd() symeig(eigenvectors=False, upper=True) -> (Tensor, Tensor) 请查看 torch.symeig() t() → Tensor 请查看 torch.t() t_() → Tensor t() 的 in-place 运算形式 take(indices) → Tensor 请查看 torch.take() tan() tan_() → Tensor tan() 的 in-place 运算形式 tanh() → Tensor 请查看 torch.tanh() tanh_() → Tensor tanh() 的 in-place 运算形式 tolist() 返回此 tensor 的嵌套列表表示. topk(k, dim=None, largest=True, sorted=True) -> (Tensor, LongTensor) 请查看 torch.topk() trace() → float 请查看 torch.trace() transpose(dim0, dim1) → Tensor 请查看 torch.transpose() transpose_(dim0, dim1) → Tensor transpose() 的 in-place 运算形式 tril(k=0) → Tensor 请查看 torch.tril() tril_(k=0) → Tensor tril() triu(k=0) → Tensor 请查看 torch.triu() triu_(k=0) → Tensor triu() 的 in-place 运算形式 trtrs(A, upper=True, transpose=False, unitriangular=False) -> (Tensor, Tensor) 请查看 torch.trtrs() trunc() → Tensor 请查看 torch.trunc() trunc_() → Tensor trunc() 的 in-place 运算形式 type(new_type=None, async=False) 如果没有指定 new_type 则返回该类型 , 否则将此对象转换为指定类型 . 如果已经是正确的类型 , 则不执行复制并直接返回原对象 . 参数： new_type (type 或 string) – 期望的类型 async (bool) – 如果为 True , 并且源在锁定内存中而目标在GPU中 , 则副本将与主机异步执行 , 反之亦然 . 否则此参数不起效果 . type_as(tensor) 将此张量转换为给定 tensor 的类型. 如果 tensor 已经是正确的类型, 这是一个无用的操作. 这相当于: self.type(tensor.type()) Params: tensor (Tensor): tensor 具有所需的类型 unfold(dim, size, step) → Tensor 返回一个在 dim 维度上包含所有 size 大小切片的 tensor. step 说明两个切片之间的步长. 如果 sizedim 是原tensor在 dim 维度原来的大小, 则返回的 tensor 在 dim 维度的大小是 (sizedim - size) / step + 1 一个额外的切片大小的维度已经添加在返回的 tensor 中. 参数： dim (int) – 需要展开的维度 size (int) – 每一个分片需要展开的大小 step (int) – 相邻分片之间的步长 示例： >>> x = torch.arange(1, 8) >>> x 1 2 3 4 5 6 7 [torch.FloatTensor of size 7] >>> x.unfold(0, 2, 1) 1 2 2 3 3 4 4 5 5 6 6 7 [torch.FloatTensor of size 6x2] >>> x.unfold(0, 2, 2) 1 2 3 4 5 6 [torch.FloatTensor of size 3x2] uniform_(from=0, to=1) → Tensor 将 tensor 用从均匀分布中抽样得到的值填充: unsqueeze(dim) 请查看 torch.unsqueeze() unsqueeze_(dim) unsqueeze() 的 in-place 运算形式 var(dim=None, unbiased=True, keepdim=False) → float 请查看 torch.var() view(*args) → Tensor 返回一个有相同数据但大小不同的新的 tensor. 返回的 tensor 与原 tensor 共享相同的数据, 一定有相同数目的元素, 但大小不同. 一个 tensor 必须是连续的 ( contiguous() ) 才能被查看. 参数：args (torch.Size 或 int...) – 期望的大小 示例： >>> x = torch.randn(4, 4) >>> x.size() torch.Size([4, 4]) >>> y = x.view(16) >>> y.size() torch.Size([16]) >>> z = x.view(-1, 8) # the size -1 is inferred from other dimensions >>> z.size() torch.Size([2, 8]) view_as(tensor) 将该 tensor 作为指定的 tensor 返回查看. 这相当于: self.view(tensor.size()) zero_() 用0填充该 tensor. class torch.ByteTensor 下面这些函数方法只存在于 torch.ByteTensor. all() → bool 如果 tensor 里的所有元素都是非零的, 则返回 True, 否在返回 False. any() → bool 如果 tensor 里的存在元素是非零的, 则返回 True, 否在返回 False. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"sparse.html":{"url":"sparse.html","title":"torch.sparse","keywords":"","body":"torch.sparse 译者：@王帅 校对者：@Timor 警告： 此 API 目前是实验性的 , 可能会在不久的将来发生变化 . Torch 支持 COO(rdinate) 格式的稀疏张量 , 还能高效地存储和处理大多数元素为零的 张量 . 一个稀疏张量可以表示为一对稠密张量 : 一个张量的值和一个二维张量的指数 . 通过提供这两个张量以及稀疏张量的大小 (不能从这些张量推断!) , 可以构造一个稀疏张量 . 假设我们要在位置 (0,2) 处定义条目3 , 位置 (1,0) 的条目4 , 位置 (1,2) 的条目5的 稀疏张量 , 我们可以这样写 : >>> i = torch.LongTensor([[0, 1, 1], [2, 0, 2]]) >>> v = torch.FloatTensor([3, 4, 5]) >>> torch.sparse.FloatTensor(i, v, torch.Size([2,3])).to_dense() 0 0 3 4 0 5 [torch.FloatTensor of size 2x3] 请注意 , LongTensor 的传入参数不是索引元组的列表 . 如果你想用这种方式编写索引 , 你应该在 将它们传递给稀疏构造函数之前进行转换 : >>> i = torch.LongTensor([[0, 2], [1, 0], [1, 2]]) >>> v = torch.FloatTensor([3, 4, 5 ]) >>> torch.sparse.FloatTensor(i.t(), v, torch.Size([2,3])).to_dense() 0 0 3 4 0 5 [torch.FloatTensor of size 2x3] 你还可以构造混合稀疏张量 , 其中只有第一个n维是稀疏的 , 而其余维度是密集的 . >>> i = torch.LongTensor([[2, 4]]) >>> v = torch.FloatTensor([[1, 3], [5, 7]]) >>> torch.sparse.FloatTensor(i, v).to_dense() 0 0 0 0 1 3 0 0 5 7 [torch.FloatTensor of size 5x2] 一个空的稀疏张量可以通过指定它的大小来构造 : >>> torch.sparse.FloatTensor(2, 3) SparseFloatTensor of size 2x3 with indices: [torch.LongTensor with no dimension] and values: [torch.FloatTensor with no dimension] 注解： 我们的稀疏张量格式允许非聚合稀疏张量 , 索引可能对应有重复的坐标 ; 在这 种情况下 , 该索引处的值代表所有重复条目值的总和 . 非聚合张量允许我们更 有效地实现确定的操作符 . 在大多数情况下 , 你不必关心稀疏张量是否聚合 , 因为大多数操作在聚合或 不聚合稀疏张量的情况下都会以相同的方式工作 . 但是 , 你可能需要关心两种情况 . 首先 , 如果你反复执行可以产生重复条目的操作 (例如 , torch.sparse.FloatTensor.add()) , 则应适当聚合稀疏张量以防止它们变得太大. 其次 , 一些操作符将根据是否聚合 (例如 , torch.sparse.FloatTensor._values() 和 torch.sparse.FloatTensor._indices() , 还有 torch.Tensor._sparse_mask()) 来生成不同的值 . 这些运算符前面加下划线表示它们揭示 内部实现细节 , 因此应谨慎使 , 因为与聚合的稀疏张量一起工作的代码可能不适用于未聚合的稀疏张量 ; 一般来说 , 在运用这些运算符之前 , 最安全的就是确保是聚合的 . 例如 , 假设我们想直接通过 torch.sparse.FloatTensor._values() 来实现一个操作 . 随着乘法分布的增加 , 标量的乘法可以轻易实现 ; 然而 , 平方根不能直接实现 , sqrt(a + b) != sqrt(a) +sqrt(b) (如果给定一个非聚合张量 , 这将被计算出来 . ) class torch.sparse.FloatTensor add() add_() clone() dim() div() div_() get_device() hspmm() mm() mul() mul_() resizeAs_() size() spadd() spmm() sspaddmm() sspmm() sub() sub_() t_() toDense() transpose() transpose_() zero_() coalesce() is_coalesced() _indices() _values() _nnz() 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"storage.html":{"url":"storage.html","title":"torch.Storage","keywords":"","body":"torch.Storage 译者：@FanXing 校对者：@Timor 一个 torch.Storage 是一个单一数据类型的连续一维数组 . 每个 torch.Tensor 都有一个对应的相同数据类型的存储 . class torch.FloatStorage byte() 将此存储转换为 byte 类型 char() 将此存储转换为 char 类型 clone() 返回此存储的一个副本 copy_() cpu() 如果当前此存储不在CPU上 , 则返回一个它的CPU副本 . cuda(device=None, async=False) 返回此对象在 CUDA 内存中的一个副本 . 如果此对象已经在 CUDA 内存中并且在正确的设备上 , 那么不会执行复制操作 , 直接返回原对象 . 参数： device (int) – 目标 GPU 的 id . 默认值是当前设备 . async (bool) – 如果为 True 并且源位于锁定内存中 , 则副本相对于主机是异步的 . 否则此参数不起效果 . data_ptr() double() 将此存储转换为 double 类型 element_size() fill_() float() 将此存储转换为 float 类型 from_buffer() from_file(filename, shared=False, size=0) → Storage 如果 shared 为 True , 那么内存将会在所有进程间共享 . 所有的更改都会被写入文件 . 如果 shared 为 False , 那么对于内存的修改 , 则不会影响到文件 . size 是存储中所包含的元素个数 . 如果 shared 为 False 则文件必须包含至少 size * sizeof(Type) 字节 ( Type 是所存储的类型) . 如果 shared 为 True , 文件会在需要的时候被创建 . 参数： filename (str) – 要映射到的文件名 shared (bool) – 是否共享内存 size (int) – 存储中包含元素的个数 half() 将此存储转换为 half 类型 int() 将此存储转换为 int 类型 is_cuda = False is_pinned() is_shared() is_sparse = False long() 将此存储转换为 long 类型 new() pin_memory() 如果此存储当前未被锁定 , 则将它复制到锁定内存中 . resize_() share_memory_() 将存储移动到共享内存中 . 这对于已经存在于共享内存中的存储或者 CUDA 存储无效 , 它们不需要移动就能在进程间共享 . 共享内存中的存储不能调整大小 . 返回值：self short() 将此存储转换为 short 类型 size() tolist() 返回一个包含此存储中的元素的列表 type(new_type=None, async=False) 如果没有指定 new_type 则返回该类型 , 否则将此对象转换为指定类型 . 如果已经是正确的类型 , 则不执行复制并直接返回原对象 . 参数： new_type (type 或 string) – 期望的类型 async (bool) – 如果为 True , 并且源在锁定内存中而目标在GPU中 , 则副本将与主机异步执行 , 反之亦然 . 否则此参数不起效果 . 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"nn.html":{"url":"nn.html","title":"torch.nn","keywords":"","body":"torch.nn 译者：@小王子、@那伊抹微笑、@Yang Shun、@Zhu Yansen、@woaichipinngguo、@buldajs、@吉思雨、@王云峰、@李雨龙、@Yucong Zhu、@林嘉应、@QianFanCe、@dabney777、@Alex、@SiKai Yao、@小乔 @laihongchang @噼里啪啦嘣 @BarrettLi、@KrokYin、@MUSK1881 校对者：@clown9804、@飞龙 Parameters (参数) class torch.nn.Parameter Variable 的一种, 常被用于 module parameter（模块参数）. Parameters 是 Variable](autograd.html#torch.autograd.Variable \"torch.autograd.Variable\") 的子类, 当它和 [Module 一起使用的时候会有一些特殊的属性 - 当它们被赋值给 Module 属性时, 它会自动的被加到 Module 的参数列表中, 并且会出现在 parameters() iterator 迭代器方法中. 将 Varibale 赋值给 Module 属性则不会有这样的影响. 这样做的原因是: 我们有时候会需要缓存一些临时的 state（状态）, 例如: 模型 RNN 中的最后一个隐藏状态. 如果没有 Parameter 这个类的话, 那么这些临时表也会注册为模型变量. Variable 与 Parameter 的另一个不同之处在于, Parameter 不能被 volatile (即: 无法设置 volatile=True) 而且默认 requires_grad=True. Variable 默认 requires_grad=False. 参数： data (Tensor) – parameter tensor. requires_grad (bool, 可选) – 如果参数需要梯度. 更多细节请参阅 反向排除 subgraphs (子图). Containers (容器) Module class torch.nn.Module 所有神经网络的基类. 你的模型应该也是该类的子类. Modules 也可以包含其它 Modules, 允许使用树结构嵌入它们. 你可以将子模块赋值给模型属性 import torch.nn as nn import torch.nn.functional as F class Model(nn.Module): def __init__(self): super(Model, self).__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): x = F.relu(self.conv1(x)) return F.relu(self.conv2(x)) 以这种方式分配的子模块将被注册, 并且在调用 .cuda() 等等方法时也将转换它们的参数. add_module(name, module) 添加一个 child module（子模块）到当前的 module（模块）中. 被添加的 module 还可以通过指定的 name 属性来获取它. 参数： name (string) – 子模块的名称. 可以使用指定的 name 从该模块访问子模块 parameter (Module) – 被添加到模块的子模块. apply(fn) 将 fn 函数递归的应用到每一个子模块 (由 .children() 方法所返回的) 以及 self. 典型的用于包括初始化模型的参数 (也可参阅 torch-nn-init). 参数：fn (Module -> None) – 要被应用到每一个子模块上的函数 返回值：self 返回类型：Module 示例： >>> def init_weights(m): >>> print(m) >>> if type(m) == nn.Linear: >>> m.weight.data.fill_(1.0) >>> print(m.weight) >>> >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2)) >>> net.apply(init_weights) Linear (2 -> 2) Parameter containing: 1 1 1 1 [torch.FloatTensor of size 2x2] Linear (2 -> 2) Parameter containing: 1 1 1 1 [torch.FloatTensor of size 2x2] Sequential ( (0): Linear (2 -> 2) (1): Linear (2 -> 2) ) children() 返回一个最近子模块的 iterator（迭代器）. Yields: Module – 一个子模块 cpu() 将所有的模型参数和缓冲区移动到 CPU. 返回值：self 返回类型：Module cuda(device=None) 将所有的模型参数和缓冲区移动到 GPU. 这将会关联一些参数并且缓存不同的对象. 所以在构建优化器之前应该调用它, 如果模块在优化的情况下会生存在 GPU 上. 参数：device (int, 可选) – 如果指定, 所有参数将被复制到指定的设备上 返回值：self 返回类型：Module double() 将所有的 parameters 和 buffers 的数据类型转换成 double. 返回值：self 返回类型：Module eval() 将模块设置为评估模式. 这种方式只对 Dropout 或 BatchNorm 等模块有效. float() 将所有的 parameters 和 buffers 的数据类型转换成float. 返回值：self 返回类型：Module forward(*input) 定义每次调用时执行的计算. 应该被所有的子类重写. 注解： 尽管需要在此函数中定义正向传递的方式, 但是应该事后尽量调用 Module 实例, 因为前者负责运行已注册的钩子, 而后者静默的忽略它们. half() 将所有的 parameters 和 buffers 的数据类型转换成 half. 返回值：self 返回类型：Module load_state_dict(state_dict, strict=True) 将 state_dict 中的 parameters 和 buffers 复制到此模块和它的子后代中. 如果 strict 为 True, 则 state_dict 的 key 必须和模块的 state_dict() 函数返回的 key 一致. 参数： state_dict (dict) – 一个包含 parameters 和 persistent buffers（持久化缓存的）字典. strict (bool) – 严格的强制 state_dict 属性中的 key 与该模块的函数 state_dict() 返回的 keys 相匹配. modules() 返回一个覆盖神经网络中所有模块的 iterator（迭代器）. Yields: Module – 网络中的一个模块 注解： 重复的模块只返回一次. 在下面的例子中, 1 只会被返回一次. example, l will be returned only once. >>> l = nn.Linear(2, 2) >>> net = nn.Sequential(l, l) >>> for idx, m in enumerate(net.modules()): >>> print(idx, '->', m) 0 -> Sequential ( (0): Linear (2 -> 2) (1): Linear (2 -> 2) ) 1 -> Linear (2 -> 2) named_children() 返回一个 iterator（迭代器）, 而不是最接近的子模块, 产生模块的 name 以及模块本身. Yields: (string, Module) – 包含名称和子模块的 Tuple（元组） 示例： >>> for name, module in model.named_children(): >>> if name in ['conv4', 'conv5']: >>> print(module) named_modules(memo=None, prefix='') 返回一个神经网络中所有模块的 iterator（迭代器）, 产生模块的 name 以及模块本身. Yields: (string, Module) – 名字和模块的 Tuple（元组） 注解： 重复的模块只返回一次. 在下面的例子中, 1 只会被返回一次. >>> l = nn.Linear(2, 2) >>> net = nn.Sequential(l, l) >>> for idx, m in enumerate(net.named_modules()): >>> print(idx, '->', m) 0 -> ('', Sequential ( (0): Linear (2 -> 2) (1): Linear (2 -> 2) )) 1 -> ('0', Linear (2 -> 2)) named_parameters(memo=None, prefix='') 返回模块参数的迭代器, 产生参数的名称以及参数本身 Yields: (string, Parameter) – Tuple 包含名称很参数的 Tuple（元组） 示例： >>> for name, param in self.named_parameters(): >>> if name in ['bias']: >>> print(param.size()) parameters() 返回一个模块参数的迭代器. 这通常传递给优化器. Yields: Parameter – 模型参数 示例： >>> for param in model.parameters(): >>> print(type(param.data), param.size()) (20L,) (20L, 1L, 5L, 5L) register_backward_hook(hook) 在模块上注册一个 backward hook（反向钩子）. 每次计算关于模块输入的梯度时, 都会调用该钩子. 钩子应该有以下结构: hook(module, grad_input, grad_output) -> Tensor or None 如果 module 有多个输入或输出的话, 那么 grad_input 和 grad_output 将会是个 tuple. hook 不应该修改它的参数, 但是它可以选择性地返回一个新的关于输入的梯度, 这个返回的梯度在后续的计算中会替代 grad_input. 返回值：通过调用 handle.remove() 方法可以删除添加钩子的句柄 handle.remove() 返回类型：torch.utils.hooks.RemovableHandle register_buffer(name, tensor) 给模块添加一个持久化的 buffer. 持久化的 buffer 通常被用在这么一种情况: 我们需要保存一个状态, 但是这个状态不能看作成为模型参数. 例如: BatchNorm 的 running_mean 不是一个 parameter, 但是它也是需要保存的状态之一. Buffers 可以使用指定的 name 作为属性访问. 参数： name (string) – buffer 的名称. 可以使用指定的 name 从该模块访问 buffer tensor (Tensor) – 被注册的 buffer. 示例： >>> self.register_buffer('running_mean', torch.zeros(num_features)) register_forward_hook(hook) 在模块上注册一个 forward hook（前向钩子）. 每一次 forward() 函数计算出一个输出后, 该钩子将会被调用. 它应该具有以下结构 hook(module, input, output) -> None 该钩子应该不会修改输入或输出. 返回值：通过调用 handle.remove() 方法可以删除添加钩子的句柄 返回类型：torch.utils.hooks.RemovableHandle register_forward_pre_hook(hook) 在模块上注册一个预前向钩子. 每一次在调用 forward() 函数前都会调用该钩子. 它应该有以下结构: hook(module, input) -> None 该钩子不应该修改输入. 返回值：通过调用 handle.remove() 方法可以删除添加钩子的句柄 handle.remove() 返回类型：torch.utils.hooks.RemovableHandle register_parameter(name, param) 添加一个参数到模块中. 可以使用指定的 name 属性来访问参数. 参数： name (string) – 参数名. 可以使用指定的 name 来从该模块中访问参数 parameter (Parameter) – 要被添加到模块的参数. state_dict(destination=None, prefix='', keep_vars=False) 返回一个字典, 它包含整个模块的状态. 包括参数和持久化的缓冲区 (例如. 运行中的平均值). Keys 是与之对应的参数和缓冲区的 name. 当 keep_vars 为 True 时, 它为每一个参数（而不是一个张量）返回一个 Variable. 参数： destination (dict, 可选) – 如果不是 None, 该返回的字典应该被存储到 destination 中. Default: None prefix (string, 可选) – 向结果字典中的每个参数和缓冲区的 key（名称）添加一个前缀. Default: ‘’ keep_vars (bool, 可选) – 如果为 True, 为每一个参数返回一个 Variable. 如果为 False, 为每一个参数返回一个 Tensor. Default: False 返回值：包含模块整体状态的字典 返回类型：dict 示例： >>> module.state_dict().keys() ['bias', 'weight'] train(mode=True) 设置模块为训练模式. 这只对诸如 Dropout 或 BatchNorm 等模块时才会有影响. 返回值：self 返回类型：Module type(dst_type) 转换所有参数和缓冲区为 dst_type. 参数：dst_type (type 或 string) – 理想的类型 返回值：self 返回类型：Module zero_grad() 将所有模型参数的梯度设置为零. Sequential class torch.nn.Sequential(*args) 一个顺序的容器. 模块将按照它们在构造函数中传递的顺序添加到它. 或者, 也可以传入模块的有序字典. 为了更容易理解, 列举小例来说明 # 使用 Sequential 的例子 model = nn.Sequential( nn.Conv2d(1,20,5), nn.ReLU(), nn.Conv2d(20,64,5), nn.ReLU() ) # 与 OrderedDict 一起使用 Sequential 的例子 model = nn.Sequential(OrderedDict([ ('conv1', nn.Conv2d(1,20,5)), ('relu1', nn.ReLU()), ('conv2', nn.Conv2d(20,64,5)), ('relu2', nn.ReLU()) ])) ModuleList class torch.nn.ModuleList(modules=None) 将子模块放入一个 list 中. ModuleList 可以像普通的 Python list 一样被索引, 但是它包含的模块已经被正确的注册了, 并且所有的 Module 方法都是可见的. 参数：modules (list, 可选) – 要添加的模块列表 示例： class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.linears = nn.ModuleList([nn.Linear(10, 10) for i in range(10)]) def forward(self, x): # ModuleList can act as an iterable, or be indexed using ints for i, l in enumerate(self.linears): x = self.linears[i // 2](x) + l(x) return x append(module) 添加一个指定的模块到 list 尾部. 参数：module (nn.Module) – 要被添加的模块 extend(modules) 在最后添加 Python list 中的模块. 参数：modules (list) – 要被添加的模块列表 ParameterList class torch.nn.ParameterList(parameters=None) 保存 list 中的 parameter. ParameterList 可以像普通的 Python list 那样被索引, 但是它所包含的参数被正确的注册了, 并且所有的 Module 方法都可见的. 参数：modules (list, 可选) – 要被添加的 Parameter 列表 示例： class MyModule(nn.Module): def __init__(self): super(MyModule, self).__init__() self.params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)]) def forward(self, x): # ModuleList 可以充当 iterable（迭代器）, 或者可以使用整数进行索引 for i, p in enumerate(self.params): x = self.params[i // 2].mm(x) + p.mm(x) return x append(parameter) 添加一个指定的参数到 list 尾部. 参数：parameter (nn.Parameter) – parameter to append extend(parameters) 在最后添加 Python list 中的参数. 参数：parameters (list) – list of parameters to append Convolution Layers (卷积层) Conv1d class torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True) 一维卷积层 输入矩阵的维度为 , 输出矩阵维度为 . 其中N为输入数量, C为每个输入样本的通道数量, L为样本中一个通道下的数据的长度. 算法如下: 是互相关运算符, 上式带 项为卷积项. stride 计算相关系数的步长, 可以为 tuple .padding 处理边界时在两侧补0数量dilation 采样间隔数量. 大于1时为非致密采样, 如对(a,b,c,d,e)采样时, 若池化规模为2, dilation 为1时, 使用 (a,b);(b,c)… 进行池化, dilation 为1时, 使用 (a,c);(b,d)… 进行池化. | groups 控制输入和输出之间的连接, group=1, 输出是所有输入的卷积；group=2, 此时相当于 有并排的两个卷基层, 每个卷积层只在对应的输入通道和输出通道之间计算, 并且输出时会将所有 输出通道简单的首尾相接作为结果输出. in_channels 和 out_channels都要可以被 groups 整除. 注解： 数据的最后一列可能会因为 kernal 大小设定不当而被丢弃（大部分发生在 kernal 大小不能被输入 整除的时候, 适当的 padding 可以避免这个问题）. 参数： in_channels (-) – 输入信号的通道数. out_channels (-) – 卷积后输出结果的通道数. kernel_size (-) – 卷积核的形状. stride (-) – 卷积每次移动的步长, 默认为1. padding (-) – 处理边界时填充0的数量, 默认为0(不填充). dilation (-) – 采样间隔数量, 默认为1, 无间隔采样. groups (-) – 输入与输出通道的分组数量. 当不为1时, 默认为1(全连接). bias (-) – 为 True 时, 添加偏置. 形状： 输入 Input: 输出 Output: 其中 变量： weight (Tensor) – 卷积网络层间连接的权重, 是模型需要学习的变量, 形状为 (out_channels, in_channels, kernel_size) bias (Tensor) – 偏置, 是模型需要学习的变量, 形状为 (out_channels) Examples: >>> m = nn.Conv1d(16, 33, 3, stride=2) >>> input = autograd.Variable(torch.randn(20, 16, 50)) >>> output = m(input) Conv2d class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True) 二维卷积层 输入矩阵的维度为 , 输出矩阵维度为 . 其中N为输入数量, C为每个输入样本的通道数量, H, W 分别为样本中一个通道下的数据的形状. 算法如下: 是互相关运算符, 上式带*项为卷积项. stride 计算相关系数的步长, 可以为 tuple .padding 处理边界时在每个维度首尾补0数量.dilation 采样间隔数量. 大于1时为非致密采样.groups 控制输入和输出之间的连接, group=1, 输出是所有输入的卷积； group=2, 此时 相当于有并排的两个卷基层, 每个卷积层只在对应的输入通道和输出通道之间计算, 并且输出时会将所有 输出通道简单的首尾相接作为结果输出. in_channels 和 out_channels都要可以被 groups 整除. kernel_size, stride, padding, dilation 可以为: 单个 int 值 – 宽和高均被设定为此值. 由两个 int 组成的 tuple – 第一个 int 为高, 第二个 int 为宽. 注解： 数据的最后一列可能会因为 kernal 大小设定不当而被丢弃（大部分发生在 kernal 大小不能被输入 整除的时候, 适当的 padding 可以避免这个问题）. 参数： in_channels (-) – 输入信号的通道数. out_channels (-) – 卷积后输出结果的通道数. kernel_size (-) – 卷积核的形状. stride (-) – 卷积每次移动的步长, 默认为1. padding (-) – 处理边界时填充0的数量, 默认为0(不填充). dilation (-) – 采样间隔数量, 默认为1, 无间隔采样. groups (-) – 输入与输出通道的分组数量. 当不为1时, 默认为1(全连接). bias (-) – 为 True 时, 添加偏置. 形状： 输入 Input: 输出 Output: 其中 变量： weight (Tensor) – 卷积网络层间连接的权重, 是模型需要学习的变量, 形状为 (out_channels, in_channels, kernel_size[0], kernel_size[1]) bias (Tensor) – 偏置, 是模型需要学习的变量, 形状为 (out_channels) Examples: >>> # With square kernels and equal stride >>> m = nn.Conv2d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2)) >>> # non-square kernels and unequal stride and with padding and dilation >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1)) >>> input = autograd.Variable(torch.randn(20, 16, 50, 100)) >>> output = m(input) Conv3d class torch.nn.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True) 三维卷基层 输入矩阵的维度为 , 输出矩阵维度为:. 其中N为输入数量, C为每个输入样本的通道数量, D, H, W 分别为样本中一个通道下的数据的形状. 算法如下: 是互相关运算符, 上式带*项为卷积项. stride 计算相关系数的步长, 可以为 tuple .padding 处理边界时在每个维度首尾补0数量.dilation 采样间隔数量. 大于1时为非致密采样.groups 控制输入和输出之间的连接, group=1, 输出是所有输入的卷积； group=2, 此时 相当于有并排的两个卷基层, 每个卷积层只在对应的输入通道和输出通道之间计算, 并且输出时会将所有 输出通道简单的首尾相接作为结果输出. in_channels 和 out_channels都要可以被 groups 整除. kernel_size, stride, padding, dilation 可以为: 单个 int 值 – 宽和高和深度均被设定为此值. 由三个 int 组成的 tuple – 第一个 int 为深度, 第二个 int 为高度, 第三个 int 为宽度. 注解： 数据的最后一列可能会因为 kernal 大小设定不当而被丢弃（大部分发生在 kernal 大小不能被输入 整除的时候, 适当的 padding 可以避免这个问题）. 参数： in_channels (-) – 输入信号的通道数. out_channels (-) – 卷积后输出结果的通道数. kernel_size (-) – 卷积核的形状. stride (-) – 卷积每次移动的步长, 默认为1. padding (-) – 处理边界时填充0的数量, 默认为0(不填充). dilation (-) – 采样间隔数量, 默认为1, 无间隔采样. groups (-) – 输入与输出通道的分组数量. 当不为1时, 默认为1(全连接). bias (-) – 为 True 时, 添加偏置. 形状： 输入 Input: 输出 Output: 其中 变量： weight (Tensor) – 卷积网络层间连接的权重, 是模型需要学习的变量, 形状为 (out_channels, in_channels, kernel_size[0], kernel_size[1], kernel_size[2]) bias (Tensor) – 偏置, 是模型需要学习的变量, 形状为 (out_channels) Examples: >>> # With square kernels and equal stride >>> m = nn.Conv3d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(4, 2, 0)) >>> input = autograd.Variable(torch.randn(20, 16, 10, 50, 100)) >>> output = m(input) ConvTranspose1d class torch.nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1) 一维反卷积层 反卷积层可以理解为输入的数据和卷积核的位置反转的卷积操作. 反卷积有时候也会被翻译成解卷积. stride 计算相关系数的步长.padding 处理边界时在每个维度首尾补0数量.output_padding 输出时候在首尾补0的数量. （卷积时, 形状不同的输入数据 对相同的核函数可以产生形状相同的结果；反卷积时, 同一个输入对相同的核函数可以产生多 个形状不同的输出, 而输出结果只能有一个, 因此必须对输出形状进行约束）. | dilation 采样间隔数量. 大于1时为非致密采样. | groups 控制输入和输出之间的连接, group=1, 输出是所有输入的卷积； group=2, 此时 相当于有并排的两个卷基层, 每个卷积层只在对应的输入通道和输出通道之间计算, 并且输出时会将所有 输出通道简单的首尾相接作为结果输出. in_channels 和 out_channels都要可以被 groups 整除. 注解： 数据的最后一列可能会因为 kernal 大小设定不当而被丢弃（大部分发生在 kernal 大小不能被输入 整除的时候, 适当的 padding 可以避免这个问题）. 参数： in_channels (-) – 输入信号的通道数. out_channels (-) – 卷积后输出结果的通道数. kernel_size (-) – 卷积核的形状. stride (-) – 卷积每次移动的步长, 默认为1. padding (-) – 处理边界时填充0的数量, 默认为0(不填充). output_padding (-) – 输出时候在首尾补值的数量, 默认为0. （卷积时, 形状不同的输入数据 同一个输入对相同的核函数可以产生多 (_对相同的核函数可以产生形状相同的结果；反卷积时_,) – 而输出结果只能有一个, 因此必须对输出形状进行约束） (个形状不同的输出,) – groups (-) – 输入与输出通道的分组数量. 当不为1时, 默认为1(全连接). bias (-) – 为 True 时, 添加偏置. dilation (-) – 采样间隔数量, 默认为1, 无间隔采样. 形状： 输入 Input: 输出 Output: 其中 变量： weight (Tensor) – 卷积网络层间连接的权重, 是模型需要学习的变量, 形状为weight (Tensor): 卷积网络层间连接的权重, 是模型需要学习的变量, 形状为 (in_channels, out_channels, kernel_size[0], kernel_size[1]) bias (Tensor) – 偏置, 是模型需要学习的变量, 形状为 (out_channels) ConvTranspose2d class torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1) 二维反卷积层 反卷积层可以理解为输入的数据和卷积核的位置反转的卷积操作. 反卷积有时候也会被翻译成解卷积. stride 计算相关系数的步长.padding 处理边界时在每个维度首尾补0数量.output_padding 输出时候在每一个维度首尾补0的数量. （卷积时, 形状不同的输入数据 对相同的核函数可以产生形状相同的结果；反卷积时, 同一个输入对相同的核函数可以产生多 个形状不同的输出, 而输出结果只能有一个, 因此必须对输出形状进行约束）. | dilation 采样间隔数量. 大于1时为非致密采样. | groups 控制输入和输出之间的连接, group=1, 输出是所有输入的卷积； group=2, 此时 相当于有并排的两个卷基层, 每个卷积层只在对应的输入通道和输出通道之间计算, 并且输出时会将所有 输出通道简单的首尾相接作为结果输出. in_channels 和 out_channels都应当可以被 groups 整除. kernel_size, stride, padding, output_padding 可以为: 单个 int 值 – 宽和高均被设定为此值. 由两个 int 组成的 tuple – 第一个 int 为高度, 第二个 int 为宽度. 注解： 数据的最后一列可能会因为 kernal 大小设定不当而被丢弃（大部分发生在 kernal 大小不能被输入 整除的时候, 适当的 padding 可以避免这个问题）. 参数： in_channels (-) – 输入信号的通道数. out_channels (-) – 卷积后输出结果的通道数. kernel_size (-) – 卷积核的形状. stride (-) – 卷积每次移动的步长, 默认为1. padding (-) – 处理边界时填充0的数量, 默认为0(不填充). output_padding (-) – 输出时候在首尾补值的数量, 默认为0. （卷积时, 形状不同的输入数据 同一个输入对相同的核函数可以产生多 (_对相同的核函数可以产生形状相同的结果；反卷积时_,) – 而输出结果只能有一个, 因此必须对输出形状进行约束） (个形状不同的输出,) – groups (-) – 输入与输出通道的分组数量. 当不为1时, 默认为1(全连接). bias (-) – 为 True 时, 添加偏置. dilation (-) – 采样间隔数量, 默认为1, 无间隔采样. 形状： 输入 Input: 输出 Output: 其中 变量： weight (Tensor) – 卷积网络层间连接的权重, 是模型需要学习的变量, 形状为weight (Tensor): 卷积网络层间连接的权重, 是模型需要学习的变量, 形状为 (in_channels, out_channels, kernel_size[0], kernel_size[1]) bias (Tensor) – 偏置, 是模型需要学习的变量, 形状为 (out_channels) Examples: >>> # With square kernels and equal stride >>> m = nn.ConvTranspose2d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.ConvTranspose2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2)) >>> input = autograd.Variable(torch.randn(20, 16, 50, 100)) >>> output = m(input) >>> # exact output size can be also specified as an argument >>> input = autograd.Variable(torch.randn(1, 16, 12, 12)) >>> downsample = nn.Conv2d(16, 16, 3, stride=2, padding=1) >>> upsample = nn.ConvTranspose2d(16, 16, 3, stride=2, padding=1) >>> h = downsample(input) >>> h.size() torch.Size([1, 16, 6, 6]) >>> output = upsample(h, output_size=input.size()) >>> output.size() torch.Size([1, 16, 12, 12]) ConvTranspose3d class torch.nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1) 三维反卷积层 反卷积层可以理解为输入的数据和卷积核的位置反转的卷积操作. 反卷积有时候也会被翻译成解卷积. stride 计算相关系数的步长.padding 处理边界时在每个维度首尾补0数量.output_padding 输出时候在每一个维度首尾补0的数量. （卷积时, 形状不同的输入数据 对相同的核函数可以产生形状相同的结果；反卷积时, 同一个输入对相同的核函数可以产生多 个形状不同的输出, 而输出结果只能有一个, 因此必须对输出形状进行约束） | dilation 采样间隔数量. 大于1时为非致密采样. | groups 控制输入和输出之间的连接, group=1, 输出是所有输入的卷积； group=2, 此时 相当于有并排的两个卷基层, 每个卷积层只在对应的输入通道和输出通道之间计算, 并且输出时会将所有 输出通道简单的首尾相接作为结果输出. in_channels 和 out_channels都应当可以被 groups 整除. kernel_size, stride, padding, output_padding 可以为: 单个 int 值 – 深和宽和高均被设定为此值. 由三个 int 组成的 tuple – 第一个 int 为深度, 第二个 int 为高度,第三个 int 为宽度. 注解： 数据的最后一列可能会因为 kernal 大小设定不当而被丢弃（大部分发生在 kernal 大小不能被输入 整除的时候, 适当的 padding 可以避免这个问题）. 参数： in_channels (-) – 输入信号的通道数. out_channels (-) – 卷积后输出结果的通道数. kernel_size (-) – 卷积核的形状. stride (-) – 卷积每次移动的步长, 默认为1. padding (-) – 处理边界时填充0的数量, 默认为0(不填充). output_padding (-) – 输出时候在首尾补值的数量, 默认为0. （卷积时, 形状不同的输入数据 同一个输入对相同的核函数可以产生多 (_对相同的核函数可以产生形状相同的结果；反卷积时_,) – 而输出结果只能有一个, 因此必须对输出形状进行约束） (个形状不同的输出,) – groups (-) – 输入与输出通道的分组数量. 当不为1时, 默认为1(全连接). bias (-) – 为 True 时, 添加偏置. dilation (-) – 采样间隔数量, 默认为1, 无间隔采样. 形状： 输入 Input: 输出 Output: 其中 变量： 是模型需要学习的变量, 形状为weight (卷积网络层间连接的权重,) – 卷积网络层间连接的权重, 是模型需要学习的变量, 形状为 (in_channels, out_channels, kernel_size[0], kernel_size[1], kernel_size[2]) bias (Tensor) – 偏置, 是模型需要学习的变量, 形状为 (out_channels) Examples: >>> # With square kernels and equal stride >>> m = nn.ConvTranspose3d(16, 33, 3, stride=2) >>> # non-square kernels and unequal stride and with padding >>> m = nn.Conv3d(16, 33, (3, 5, 2), stride=(2, 1, 1), padding=(0, 4, 2)) >>> input = autograd.Variable(torch.randn(20, 16, 10, 50, 100)) >>> output = m(input) Pooling Layers (池化层) MaxPool1d class torch.nn.MaxPool1d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False) 对于多个输入通道组成的输入信号,应用一维的最大池化 max pooling 操作 最简单的例子, 如果输入大小为 , 输出大小为 , 该层输出值可以用下式精确计算: 如果 padding 不是0,那么在输入数据的每条边上会隐式填补对应 padding 数量的0值点dilation 用于控制内核点之间的间隔, link 很好地可视化展示了 dilation 的功能 参数： kernel_size – 最大池化操作时的窗口大小 stride – 最大池化操作时窗口移动的步长, 默认值是 kernel_size padding – 输入的每条边隐式补0的数量 dilation – 用于控制窗口中元素的步长的参数 return_indices – 如果等于 True, 在返回 max pooling 结果的同时返回最大值的索引. 这在之后的 Unpooling 时很有用 ceil_mode – 如果等于 True, 在计算输出大小时,将采用向上取整来代替默认的向下取整的方式 形状： 输入： 输出： 遵从如下关系 Examples: >>> # pool of size=3, stride=2 >>> m = nn.MaxPool1d(3, stride=2) >>> input = autograd.Variable(torch.randn(20, 16, 50)) >>> output = m(input) MaxPool2d class torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False) 对于多个输入通道组成的输入信号,应用二维的最大池化 max pooling 操作 最简单的例子, 如果输入大小为 , 输出大小为 , 池化窗口大小 kernel_size 为 该层输出值可以用下式精确计算: 如果 padding 不是0, 那么在输入数据的每条边上会隐式填补对应 padding 数量的0值点dilation 用于控制内核点之间的间隔, link 很好地可视化展示了 dilation 的功能 参数 kernel_size, stride, padding, dilation 可以是以下任意一种数据类型: 单个 int 类型数据 – 此时在 height 和 width 维度上将使用相同的值 包含两个 int 类型数据的 tuple 元组 – 此时第一个 int 数据表示 height 维度上的数值, 第二个 int 数据表示 width 维度上的数值 参数： kernel_size – 最大池化操作时的窗口大小 stride – 最大池化操作时窗口移动的步长, 默认值是 kernel_size padding – 输入的每条边隐式补0的数量 dilation – 用于控制窗口中元素的步长的参数 return_indices – 如果等于 True, 在返回 max pooling 结果的同时返回最大值的索引 这在之后的 Unpooling 时很有用 ceil_mode – 如果等于 True, 在计算输出大小时,将采用向上取整来代替默认的向下取整的方式 形状： 输入： 输出： 遵从如下关系 Examples: >>> # pool of square window of size=3, stride=2 >>> m = nn.MaxPool2d(3, stride=2) >>> # pool of non-square window >>> m = nn.MaxPool2d((3, 2), stride=(2, 1)) >>> input = autograd.Variable(torch.randn(20, 16, 50, 32)) >>> output = m(input) MaxPool3d class torch.nn.MaxPool3d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False) 对于多个输入通道组成的输入信号,应用三维的最大池化 max pooling 操作 最简单的例子, 如果输入大小为 ,输出大小为 池化窗口大小 kernel_size 为 该层输出值可以用下式精确计算: 如果 padding 不是0, 那么在输入数据的每条边上会隐式填补对应 padding 数量的0值点dilation 用于控制内核点之间的间隔, link 很好地可视化展示了 dilation 的功能 参数 kernel_size, stride, padding, dilation 可以是以下任意一种数据类型: 单个 int 类型数据 – 此时在 depth, height 和 width 维度上将使用相同的值 包含三个 int 类型数据的 tuple 元组 – 此时第一个 int 数据表示 depth 维度上的数值, 第二个 int 数据表示 height 维度上的数值,第三个 int 数据表示 width 维度上的数值 参数： kernel_size – 最大池化操作时的窗口大小 stride – 最大池化操作时窗口移动的步长, 默认值是 kernel_size padding – 输入所有三条边上隐式补0的数量 dilation – 用于控制窗口中元素的步长的参数 return_indices – 如果等于 True, 在返回 max pooling 结果的同时返回最大值的索引 这在之后的 Unpooling 时很有用 ceil_mode – 如果等于 True, 在计算输出大小时,将采用向上取整来代替默认的向下取整的方式 形状： 输入： 输出： 遵从如下关系 Examples: >>> # pool of square window of size=3, stride=2 >>> m = nn.MaxPool3d(3, stride=2) >>> # pool of non-square window >>> m = nn.MaxPool3d((3, 2, 2), stride=(2, 1, 2)) >>> input = autograd.Variable(torch.randn(20, 16, 50,44, 31)) >>> output = m(input) MaxUnpool1d class torch.nn.MaxUnpool1d(kernel_size, stride=None, padding=0) MaxPool1d 的逆过程 要注意的是 MaxPool1d 并不是完全可逆的, 因为在max pooling过程中非最大值已经丢失 MaxUnpool1d 以 MaxPool1d 的输出, 包含最大值的索引作为输入 计算max poooling的部分逆过程(对于那些最大值区域), 对于那些非最大值区域将设置为0值 注解： MaxPool1d 可以将多个输入大小映射到相同的输出大小, 因此反演过程可能会模棱两可 为适应这一点, 在调用forward函数时可以将需要的输出大小作为额外的参数 output_size 传入. � 具体用法,请参阅下面的输入和示例 参数： kernel_size (int 或 tuple) – 最大池化操作时的窗口大小 stride (int 或 tuple) – 最大池化操作时窗口移动的步长, 默认值是 kernel_size padding (int 或 tuple) – 输入的每条边填充0值的个数 Inputs: input: 需要转化的输入的 Tensor indices: MaxPool1d 提供的最大值索引 output_size (可选) : torch.Size 类型的数据指定输出的大小 形状： 输入： 输出： 遵从如下关系 或者在调用时指定输出大小 output_size 示例： >>> pool = nn.MaxPool1d(2, stride=2, return_indices=True) >>> unpool = nn.MaxUnpool1d(2, stride=2) >>> input = Variable(torch.Tensor([[[1, 2, 3, 4, 5, 6, 7, 8]]])) >>> output, indices = pool(input) >>> unpool(output, indices) Variable containing: (0 ,.,.) = 0 2 0 4 0 6 0 8 [torch.FloatTensor of size 1x1x8] >>> # Example showcasing the use of output_size >>> input = Variable(torch.Tensor([[[1, 2, 3, 4, 5, 6, 7, 8, 9]]])) >>> output, indices = pool(input) >>> unpool(output, indices, output_size=input.size()) Variable containing: (0 ,.,.) = 0 2 0 4 0 6 0 8 0 [torch.FloatTensor of size 1x1x9] >>> unpool(output, indices) Variable containing: (0 ,.,.) = 0 2 0 4 0 6 0 8 [torch.FloatTensor of size 1x1x8] MaxUnpool2d class torch.nn.MaxUnpool2d(kernel_size, stride=None, padding=0) MaxPool2d 的逆过程 要注意的是 MaxPool2d 并不是完全可逆的, 因为在max pooling过程中非最大值已经丢失 MaxUnpool2d 以 MaxPool2d 的输出, 包含最大值的索引作为输入 计算max poooling的部分逆过程(对于那些最大值区域), 对于那些非最大值区域将设置为0值 注解： MaxPool2d 可以将多个输入大小映射到相同的输出大小, 因此反演过程可能会模棱两可. 为适应这一点, 在调用forward函数时可以将需要的输出大小作为额外的参数 output_size 传入. � 具体用法,请参阅下面的输入和示例 参数： kernel_size (int 或 tuple) – 最大池化操作时的窗口大小 stride (int 或 tuple) – 最大池化操作时窗口移动的步长, 默认值是 kernel_size padding (int 或 tuple) – 输入的每条边填充0值的个数 Inputs: input: 需要转化的输入的 Tensor indices: MaxPool2d 提供的最大值索引 output_size (可选) : torch.Size 类型的数据指定输出的大小 形状： 输入： 输出： 遵从如下关系 或者在调用时指定输出大小 output_size 示例： >>> pool = nn.MaxPool2d(2, stride=2, return_indices=True) >>> unpool = nn.MaxUnpool2d(2, stride=2) >>> input = Variable(torch.Tensor([[[[ 1, 2, 3, 4], ... [ 5, 6, 7, 8], ... [ 9, 10, 11, 12], ... [13, 14, 15, 16]]]])) >>> output, indices = pool(input) >>> unpool(output, indices) Variable containing: (0 ,0 ,.,.) = 0 0 0 0 0 6 0 8 0 0 0 0 0 14 0 16 [torch.FloatTensor of size 1x1x4x4] >>> # specify a different output size than input size >>> unpool(output, indices, output_size=torch.Size([1, 1, 5, 5])) Variable containing: (0 ,0 ,.,.) = 0 0 0 0 0 6 0 8 0 0 0 0 0 14 0 16 0 0 0 0 0 0 0 0 0 [torch.FloatTensor of size 1x1x5x5] MaxUnpool3d class torch.nn.MaxUnpool3d(kernel_size, stride=None, padding=0) MaxPool3d 的逆过程 要注意的是 MaxPool3d 并不是完全可逆的, 因为在max pooling过程中非最大值已经丢失 MaxUnpool3d 以 MaxPool3d 的输出, 包含最大值的索引作为输入 计算max poooling的部分逆过程(对于那些最大值区域), 对于那些非最大值区域将设置为0值 注解： MaxPool3d 可以将多个输入大小映射到相同的输出大小, 因此反演过程可能会模棱两可. 为适应这一点, 在调用forward函数时可以将需要的输出大小作为额外的参数 output_size 传入. � 具体用法,请参阅下面的输入和示例 参数： kernel_size (int 或 tuple) – 最大池化操作时的窗口大小 stride (int 或 tuple) – 最大池化操作时窗口移动的步长, 默认值是 kernel_size padding (int 或 tuple) – 输入的每条边填充0值的个数 Inputs: input: 需要转化的输入的 Tensor indices: MaxPool3d 提供的最大值索引 output_size (可选) : torch.Size 类型的数据指定输出的大小 形状： 输入： 输出： 遵从如下关系 或者在调用时指定输出大小 output_size 示例： >>> # pool of square window of size=3, stride=2 >>> pool = nn.MaxPool3d(3, stride=2, return_indices=True) >>> unpool = nn.MaxUnpool3d(3, stride=2) >>> output, indices = pool(Variable(torch.randn(20, 16, 51, 33, 15))) >>> unpooled_output = unpool(output, indices) >>> unpooled_output.size() torch.Size([20, 16, 51, 33, 15]) AvgPool1d class torch.nn.AvgPool1d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True) 对于多个输入通道组成的输入信号,应用一维的平均池化 average pooling 操作 最简单的例子, 如果输入大小为 , 输出大小为 , 池化窗口大小 kernel_size 为 该层输出值可以用下式精确计算: 如果 padding 不是0, 那么在输入数据的每条边上会隐式填补对应 padding 数量的0值点 参数 kernel_size, stride, padding 可以为单个 int 类型的数据 或者是一个单元素的tuple元组 参数： kernel_size – 平均池化操作时取平均值的窗口的大小 stride – 平均池化操作时窗口移动的步长, 默认值是 kernel_size padding – 输入的每条边隐式补0的数量 ceil_mode – 如果等于 True, 在计算输出大小时,将采用向上取整来代替默认的向下取整的方式 count_include_pad – 如果等于 True, 在计算平均池化的值时,将考虑 padding 填充的0 形状： 输入： 输出： 遵从如下关系 Examples: >>> # pool with window of size=3, stride=2 >>> m = nn.AvgPool1d(3, stride=2) >>> m(Variable(torch.Tensor([[[1,2,3,4,5,6,7]]]))) Variable containing: (0 ,.,.) = 2 4 6 [torch.FloatTensor of size 1x1x3] AvgPool2d class torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True) 对于多个输入通道组成的输入信号,应用二维的平均池化 average pooling 操作 最简单的例子,如果输入大小为 ,输出大小为 , 池化窗口大小 kernel_size 为 该层输出值可以用下式精确计算: 如果 padding 不是0, 那么在输入数据的每条边上会隐式填补对应 padding 数量的0值点 参数 kernel_size, stride, padding 可以是以下任意一种数据类型: 单个 int 类型数据 – 此时在 height 和 width 维度上将使用相同的值 包含两个 int 类型数据的 tuple 元组 – 此时第一个 int 数据表示 height 维度上的数值, 第二个 int 数据表示 width 维度上的数值 参数： kernel_size – 平均池化操作时取平均值的窗口的大小 stride – 平均池化操作时窗口移动的步长, 默认值是 kernel_size padding – 输入的每条边隐式补0的数量 ceil_mode – 如果等于 True, 在计算输出大小时,将采用向上取整来代替默认的向下取整的方式 count_include_pad – 如果等于 True, 在计算平均池化的值时,将考虑 padding 填充的0 形状： 输入： 输出： 遵从如下关系 Examples: >>> # pool of square window of size=3, stride=2 >>> m = nn.AvgPool2d(3, stride=2) >>> # pool of non-square window >>> m = nn.AvgPool2d((3, 2), stride=(2, 1)) >>> input = autograd.Variable(torch.randn(20, 16, 50, 32)) >>> output = m(input) AvgPool3d class torch.nn.AvgPool3d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True) 对于多个输入通道组成的输入信号,应用三维的平均池化 average pooling 操作 最简单的例子, 如果输入大小为 ,输出大小为 池化窗口大小 kernel_size 为 该层输出值可以用下式精确计算: 如果 padding 不是0, 那么在输入数据的每条边上会隐式填补对应 padding 数量的0值点 参数 kernel_size, stride 可以是以下任意一种数据类型: 单个 int 类型数据 – 此时在 depth, height 和 width 维度上将使用相同的值 包含三个 int 类型数据的 tuple 元组 – 此时第一个 int 数据表示 depth 维度上的数值, 第二个 int 数据表示 height 维度上的数值,第三个 int 数据表示 width 维度上的数值 参数： kernel_size – 平均池化操作时取平均值的窗口的大小 stride – 平均池化操作时窗口移动的步长, 默认值是 kernel_size padding – 输入的每条边隐式补0的数量 ceil_mode – 如果等于 True, 在计算输出大小时,将采用向上取整来代替默认的向下取整的方式 count_include_pad – 如果等于 True, 在计算平均池化的值时,将考虑 padding 填充的0 形状： 输入： 输出： 遵从如下关系 Examples: >>> # pool of square window of size=3, stride=2 >>> m = nn.AvgPool3d(3, stride=2) >>> # pool of non-square window >>> m = nn.AvgPool3d((3, 2, 2), stride=(2, 1, 2)) >>> input = autograd.Variable(torch.randn(20, 16, 50,44, 31)) >>> output = m(input) FractionalMaxPool2d class torch.nn.FractionalMaxPool2d(kernel_size, output_size=None, output_ratio=None, return_indices=False, _random_samples=None) 对于多个输入通道组成的输入信号,应用二维的分数最大池化 fractional max pooling 操作 分数最大池化 Fractiona MaxPooling 的具体细节描述,详见Ben Graham论文 Fractional MaxPooling 由目标输出大小确定随机步长,在 kH x kW 区域内进行最大池化的操作 输出特征的数量与输入通道的数量相同 参数： kernel_size – 最大池化操作时窗口的大小. 可以是单个数字 k (等价于 k x k 的正方形窗口) 或者是 一个元组 tuple (kh x kw) output_size – oH x oW 形式的输出图像的尺寸. 可以用 一个 tuple 元组 (oH, oW) 表示 oH x oW 的输出尺寸, 或者是单个的数字 oH 表示 oH x oH 的输出尺寸 output_ratio – 如果想用输入图像的百分比来指定输出图像的大小,可选用该选项. 使用范围在 (0,1) 之间的一个值来指定. return_indices – 如果等于 True,在返回输出结果的同时返回最大值的索引,该索引对 nn.MaxUnpool2d 有用. 默认情况下该值等于 False 示例： >>> # pool of square window of size=3, and target output size 13x12 >>> m = nn.FractionalMaxPool2d(3, output_size=(13, 12)) >>> # pool of square window and target output size being half of input image size >>> m = nn.FractionalMaxPool2d(3, output_ratio=(0.5, 0.5)) >>> input = autograd.Variable(torch.randn(20, 16, 50, 32)) >>> output = m(input) LPPool2d class torch.nn.LPPool2d(norm_type, kernel_size, stride=None, ceil_mode=False) 对于多个输入通道组成的输入信号,应用二维的幂平均池化 power-average pooling 操作 在每个窗口内, 输出的计算方式: 当 p 无穷大时,等价于最大池化 Max Pooling 操作 当 p=1 时, 等价于平均池化 Average Pooling 操作 参数 kernel_size, stride 可以是以下任意一种数据类型: 单个 int 类型数据 – 此时在height和width维度上将使用相同的值 包含两个 int 类型数据的 tuple 元组 – 此时第一个 int 数据表示 height 维度上的数值, 第二个 int 数据表示 width 维度上的数值 参数： kernel_size – 幂平均池化时窗口的大小 stride – 幂平均池化操作时窗口移动的步长, 默认值是 kernel_size ceil_mode – 如果等于 True, 在计算输出大小时,将采用向上取整来代替默认的向下取整的方式 形状： 输入： 输出： 遵从如下关系 Examples: >>> # power-2 pool of square window of size=3, stride=2 >>> m = nn.LPPool2d(2, 3, stride=2) >>> # pool of non-square window of power 1.2 >>> m = nn.LPPool2d(1.2, (3, 2), stride=(2, 1)) >>> input = autograd.Variable(torch.randn(20, 16, 50, 32)) >>> output = m(input) AdaptiveMaxPool1d class torch.nn.AdaptiveMaxPool1d(output_size, return_indices=False) 对于多个输入通道组成的输入信号,应用一维的自适应最大池化 adaptive max pooling 操作 对于任意大小的输入,可以指定输出的尺寸为 H 输出特征的数量与输入通道的数量相同. 参数： output_size – 目标输出的尺寸 H return_indices – 如果等于 True,在返回输出结果的同时返回最大值的索引,该索引对 nn.MaxUnpool1d 有用. 默认情况下该值等于 False 示例： >>> # target output size of 5 >>> m = nn.AdaptiveMaxPool1d(5) >>> input = autograd.Variable(torch.randn(1, 64, 8)) >>> output = m(input) AdaptiveMaxPool2d class torch.nn.AdaptiveMaxPool2d(output_size, return_indices=False) 对于多个输入通道组成的输入信号,应用二维的自适应最大池化 adaptive max pooling 操作 对于任意大小的输入,可以指定输出的尺寸为 H x W 输出特征的数量与输入通道的数量相同. 参数： output_size – H x W 形式的输出图像的尺寸. 可以用 一个 tuple 元组 (H, W) 表示 H x W 的输出尺寸, 或者是单个的数字 H 表示 H x H 的输出尺寸 return_indices – 如果等于 True,在返回输出结果的同时返回最大值的索引,该索引对 nn.MaxUnpool2d 有用. 默认情况下该值等于 False 示例： >>> # target output size of 5x7 >>> m = nn.AdaptiveMaxPool2d((5,7)) >>> input = autograd.Variable(torch.randn(1, 64, 8, 9)) >>> output = m(input) >>> # target output size of 7x7 (square) >>> m = nn.AdaptiveMaxPool2d(7) >>> input = autograd.Variable(torch.randn(1, 64, 10, 9)) >>> output = m(input) AdaptiveMaxPool3d class torch.nn.AdaptiveMaxPool3d(output_size, return_indices=False) 对于多个输入通道组成的输入信号,应用三维的自适应最大池化 adaptive max pooling 操作 对于任意大小的输入,可以指定输出的尺寸为 D x H x W 输出特征的数量与输入通道的数量相同. 参数： output_size – D x H x W 形式的输出图像的尺寸. 可以用 一个 tuple 元组 (D, H, W) 表示 D x H x W 的输出尺寸, 或者是单个的数字 D 表示 D x D x D 的输出尺寸 return_indices – 如果等于 True,在返回输出结果的同时返回最大值的索引,该索引对 nn.MaxUnpool3d 有用. 默认情况下该值等于 False 示例： >>> # target output size of 5x7x9 >>> m = nn.AdaptiveMaxPool3d((5,7,9)) >>> input = autograd.Variable(torch.randn(1, 64, 8, 9, 10)) >>> output = m(input) >>> # target output size of 7x7x7 (cube) >>> m = nn.AdaptiveMaxPool3d(7) >>> input = autograd.Variable(torch.randn(1, 64, 10, 9, 8)) >>> output = m(input) AdaptiveAvgPool1d class torch.nn.AdaptiveAvgPool1d(output_size) 对于多个输入通道组成的输入信号,应用一维的自适应平均池化 adaptive average pooling 操作 对于任意大小的输入,可以指定输出的尺寸为 H 输出特征的数量与输入通道的数量相同. 参数：output_size – 目标输出的尺寸 H 示例： >>> # target output size of 5 >>> m = nn.AdaptiveAvgPool1d(5) >>> input = autograd.Variable(torch.randn(1, 64, 8)) >>> output = m(input) AdaptiveAvgPool2d class torch.nn.AdaptiveAvgPool2d(output_size) 对于多个输入通道组成的输入信号,应用二维的自适应平均池化 adaptive average pooling 操作 对于任意大小的输入,可以指定输出的尺寸为 H x W 输出特征的数量与输入通道的数量相同. 参数：output_size – H x W 形式的输出图像的尺寸. 可以用 一个 tuple 元组 (H, W) 表示 H x W 的输出尺寸, 或者是单个的数字 H 表示 H x H 的输出尺寸 示例： >>> # target output size of 5x7 >>> m = nn.AdaptiveAvgPool2d((5,7)) >>> input = autograd.Variable(torch.randn(1, 64, 8, 9)) >>> output = m(input) >>> # target output size of 7x7 (square) >>> m = nn.AdaptiveAvgPool2d(7) >>> input = autograd.Variable(torch.randn(1, 64, 10, 9)) >>> output = m(input) AdaptiveAvgPool3d class torch.nn.AdaptiveAvgPool3d(output_size) 对于多个输入通道组成的输入信号,应用三维的自适应平均池化 adaptive average pooling 操作 对于任意大小的输入,可以指定输出的尺寸为 D x H x W 输出特征的数量与输入通道的数量相同. 参数：output_size – D x H x W 形式的输出图像的尺寸. 可以用 一个 tuple 元组 (D, H, W) 表示 D x H x W 的输出尺寸, 或者是单个的数字 D 表示 D x D x D 的输出尺寸 示例： >>> # target output size of 5x7x9 >>> m = nn.AdaptiveAvgPool3d((5,7,9)) >>> input = autograd.Variable(torch.randn(1, 64, 8, 9, 10)) >>> output = m(input) >>> # target output size of 7x7x7 (cube) >>> m = nn.AdaptiveAvgPool3d(7) >>> input = autograd.Variable(torch.randn(1, 64, 10, 9, 8)) >>> output = m(input) Padding Layers (填充层) ReflectionPad2d class torch.nn.ReflectionPad2d(padding) 使用输入边界的反射填充输入张量. 参数： padding (int, tuple) – 填充的大小. 如果是int, 则在所有边界填充使用相同的. 则使用 (_如果是4个元组_,) – 形状： 输入： 输出： where 示例： >>> m = nn.ReflectionPad2d(3) >>> input = autograd.Variable(torch.randn(16, 3, 320, 480)) >>> output = m(input) >>> # 使用不同的填充 >>> m = nn.ReflectionPad2d((3, 3, 6, 6)) >>> output = m(input) ReplicationPad2d class torch.nn.ReplicationPad2d(padding) 使用输入边界的复制填充输入张量. 参数：padding (int, tuple) – 填充的大小. 如果是int, 则在所有边界使用相同的填充. 如果是4个元组, 则使用(paddingLeft, paddingRight, paddingTop, paddingBottom) 形状： 输入： 输出： where 示例： >>> m = nn.ReplicationPad2d(3) >>> input = autograd.Variable(torch.randn(16, 3, 320, 480)) >>> output = m(input) >>> # 使用不同的填充 >>> m = nn.ReplicationPad2d((3, 3, 6, 6)) >>> output = m(input) ReplicationPad3d class torch.nn.ReplicationPad3d(padding) 使用输入边界的复制填充输入张量. 参数： padding (int, tuple) – 填充的大小. 如果是int, 则在所有边界使用相同的填充. 则使用 (paddingLeft, paddingRight, (_如果是四个元组_,) – paddingBottom, paddingFront, paddingBack) (paddingTop,) – 形状： 输入： 输出： where 示例： >>> m = nn.ReplicationPad3d(3) >>> input = autograd.Variable(torch.randn(16, 3, 8, 320, 480)) >>> output = m(input) >>> # 使用不同的填充 >>> m = nn.ReplicationPad3d((3, 3, 6, 6, 1, 1)) >>> output = m(input) ZeroPad2d class torch.nn.ZeroPad2d(padding) 用零填充输入张量边界. 参数： padding (int, tuple) – 填充的大小. 如果是int, 则在所有边界使用相同的填充. 形状： 输入： 输出： where 示例： >>> m = nn.ZeroPad2d(3) >>> input = autograd.Variable(torch.randn(16, 3, 320, 480)) >>> output = m(input) >>> # 使用不同的填充 >>> m = nn.ZeroPad2d((3, 3, 6, 6)) >>> output = m(input) ConstantPad2d class torch.nn.ConstantPad2d(padding, value) 用一个常数值填充输入张量边界. 对于 Nd-padding, 使用 nn.functional.pad(). 参数： padding (int, tuple) – 填充的大小. 如果是int, 则在所有边界使用相同的填充. value – 形状： 输入： 输出： where 示例： >>> m = nn.ConstantPad2d(3, 3.5) >>> input = autograd.Variable(torch.randn(16, 3, 320, 480)) >>> output = m(input) >>> # 使用不同的填充 >>> m = nn.ConstantPad2d((3, 3, 6, 6), 3.5) >>> output = m(input) Non-linear Activations (非线性层) ReLU class torch.nn.ReLU(inplace=False) 对输入运用修正线性单元函数 参数：inplace – 选择是否进行覆盖运算 Default: False 形状： 输入： * 代表任意数目附加维度 输出：, 与输入拥有同样的 shape 属性 Examples: >>> m = nn.ReLU() >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) ReLU6 class torch.nn.ReLU6(inplace=False) 对输入的每一个元素运用函数 参数：inplace – 选择是否进行覆盖运算 默认值: False 形状： 输入：, * 代表任意数目附加维度 输出：, 与输入拥有同样的 shape 属性 Examples: >>> m = nn.ReLU6() >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) ELU class torch.nn.ELU(alpha=1.0, inplace=False) 对输入的每一个元素运用函数, 参数： alpha – ELU 定义公式中的 alpha 值. 默认值: 1.0 inplace – 选择是否进行覆盖运算 默认值: False 形状： 输入： * 代表任意数目附加维度 输出：, 与输入拥有同样的 shape 属性 Examples: >>> m = nn.ELU() >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) SELU class torch.nn.SELU(inplace=False) 对输入的每一个元素运用函数, , alpha=1.6732632423543772848170429916717, scale=1.0507009873554804934193349852946. 更多地细节可以参阅论文 Self-Normalizing Neural Networks . 参数：inplace (bool, 可选) – 选择是否进行覆盖运算. 默认值: False 形状： 输入： where * means, any number of additional dimensions 输出：, same shape as the input Examples: >>> m = nn.SELU() >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) PReLU class torch.nn.PReLU(num_parameters=1, init=0.25) 对输入的每一个元素运用函数 这里的 “a” 是自学习的参数. 当不带参数地调用时, nn.PReLU() 在所有输入通道中使用单个参数 “a” . 而如果用 nn.PReLU(nChannels) 调用, “a” 将应用到每个输入. 注解： 当为了表现更佳的模型而学习参数 “a” 时不要使用权重衰减 (weight decay) 参数： num_parameters – 需要学习的 “a” 的个数. 默认等于1 init – “a” 的初始值. 默认等于0.25 形状： 输入： 其中 * 代表任意数目的附加维度 输出：, 和输入的格式 shape 一致 例: >>> m = nn.PReLU() >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) LeakyReLU class torch.nn.LeakyReLU(negative_slope=0.01, inplace=False) 对输入的每一个元素运用, 参数： negative_slope – 控制负斜率的角度, 默认值: 1e-2 inplace – 选择是否进行覆盖运算 默认值: False 形状： 输入： 其中 * 代表任意数目的附加维度 输出：, 和输入的格式shape一致 例: >>> m = nn.LeakyReLU(0.1) >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) Threshold class torch.nn.Threshold(threshold, value, inplace=False) 基于 Tensor 中的每个元素创造阈值函数 Threshold 被定义为 y = x if x > threshold value if x 参数： threshold – 阈值 value – 输入值小于阈值则会被 value 代替 inplace – 选择是否进行覆盖运算. 默认值: False 形状： 输入： 其中 * 代表任意数目的附加维度 输出：, 和输入的格式 shape 一致 例: >>> m = nn.Threshold(0.1, 20) >>> input = Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) Hardtanh class torch.nn.Hardtanh(min_val=-1, max_val=1, inplace=False, min_value=None, max_value=None) 对输入的每一个元素运用 HardTanh HardTanh 被定义为: f(x) = +1, if x > 1 f(x) = -1, if x 线性区域的范围 可以被调整 参数： min_val – 线性区域范围最小值. 默认值: -1 max_val – 线性区域范围最大值. 默认值: 1 inplace – 选择是否进行覆盖运算. 默认值: False 关键字参数 min_value 以及 max_value 已被弃用. 更改为 min_val 和 max_val 形状： 输入： 其中 * 代表任意维度组合 输出：, 与输入有相同的 shape 属性 例 >>> m = nn.Hardtanh(-2, 2) >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) Sigmoid class torch.nn.Sigmoid 对每个元素运用 Sigmoid 函数. Sigmoid 定义如下 形状： 输入： * 表示任意维度组合 输出：, 与输入有相同的 shape 属性 Examples: >>> m = nn.Sigmoid() >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) Tanh class torch.nn.Tanh 对输入的每个元素, 形状： 输入： * 表示任意维度组合 输出：, 与输入有相同的 shape 属性 Examples: >>> m = nn.Tanh() >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) LogSigmoid class torch.nn.LogSigmoid 对输入的每一个元素运用函数 形状： 输入： 其中 * 代表任意数目的附加维度 输出：, 和输入的格式shape一致 例: >>> m = nn.LogSigmoid() >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) Softplus class torch.nn.Softplus(beta=1, threshold=20) 对每个元素运用Softplus函数, Softplus 定义如下 :: Softplus 函数是ReLU函数的平滑逼近. Softplus 函数可以使得输出值限定为正数. 为了保证数值稳定性. 线性函数的转换可以使输出大于某个值. 参数： beta – Softplus 公式中的 beta 值. 默认值: 1 threshold – 阈值. 当输入到该值以上时我们的SoftPlus实现将还原为线性函数. 默认值: 20 形状： 输入： 其中 * 代表任意数目的附加维度 dimensions 输出：, 和输入的格式shape一致 例: >>> m = nn.Softplus() >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) Softshrink class torch.nn.Softshrink(lambd=0.5) 对输入的每一个元素运用 soft shrinkage 函数 SoftShrinkage 运算符定义为: f(x) = x-lambda, if x > lambda > f(x) = x+lambda, if x 参数：lambd – Softshrink 公式中的 lambda 值. 默认值: 0.5 形状： 输入： 其中 * 代表任意数目的附加维度 输出：, 和输入的格式 shape 一致 例: >>> m = nn.Softshrink() >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) Softsign class torch.nn.Softsign 对输入的每一个元素运用函数 形状： 输入： 其中 * 代表任意数目的附加维度 输出：, 和输入的格式 shape 一致 例: >>> m = nn.Softsign() >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) Tanhshrink class torch.nn.Tanhshrink 对输入的每一个元素运用函数, 形状： 输入： 其中 * 代表任意数目的附加维度 输出：, 和输入的格式shape一致 例: >>> m = nn.Tanhshrink() >>> input = autograd.Variable(torch.randn(2)) >>> print(input) >>> print(m(input)) Softmin class torch.nn.Softmin(dim=None) 对n维输入张量运用 Softmin 函数, 将张量的每个元素缩放到 (0,1) 区间且和为 1. 形状： 输入：任意shape 输出：和输入相同 参数：dim (int) – 这是将计算 Softmax 的维度 (所以每个沿着 dim 的切片和为 1). 返回值：返回结果是一个与输入维度相同的张量, 每个元素的取值范围在 [0, 1] 区间. 例: >>> m = nn.Softmin() >>> input = autograd.Variable(torch.randn(2, 3)) >>> print(input) >>> print(m(input)) Softmax class torch.nn.Softmax(dim=None) 对n维输入张量运用 Softmax 函数, 将张量的每个元素缩放到 (0,1) 区间且和为 1. Softmax 函数定义如下 形状： 输入：任意shape 输出：和输入相同 返回值：返回结果是一个与输入维度相同的张量, 每个元素的取值范围在 [0, 1] 区间. 参数：dim (int) – 这是将计算 Softmax 的那个维度 (所以每个沿着 dim 的切片和为 1). 注解： 如果你想对原始 Softmax 数据计算 Log 进行收缩, 并不能使该模块直接使用 NLLLoss 负对数似然损失函数. 取而代之, 应该使用 Logsoftmax (它有更快的运算速度和更好的数值性质). 例: >>> m = nn.Softmax() >>> input = autograd.Variable(torch.randn(2, 3)) >>> print(input) >>> print(m(input)) Softmax2d class torch.nn.Softmax2d 把 SoftMax 应用于每个空间位置的特征. 给定图片的 通道数 Channels x 高 Height x 宽 Width, 它将对图片的每一个位置 使用 Softmax 形状： 输入： 输出： (格式 shape 与输入相同) 返回值：一个维度及格式 shape 都和输入相同的 Tensor, 取值范围在[0, 1] 例: >>> m = nn.Softmax2d() >>> # you softmax over the 2nd dimension >>> input = autograd.Variable(torch.randn(2, 3, 12, 13)) >>> print(input) >>> print(m(input)) LogSoftmax class torch.nn.LogSoftmax(dim=None) 对每个输入的 n 维 Tensor 使用 Log(Softmax(x)). LogSoftmax 公式可简化为 形状： 输入：任意格式 shape 输出：和输入的格式 shape 一致 参数：dim (int) – 这是将计算 Softmax 的那个维度 (所以每个沿着 dim 的切片和为1). 返回值：一个维度及格式 shape 都和输入相同的 Tensor, 取值范围在 [-inf, 0) 例: >>> m = nn.LogSoftmax() >>> input = autograd.Variable(torch.randn(2, 3)) >>> print(input) >>> print(m(input)) Normalization layers (归一化层) BatchNorm1d class torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True) 对 2d 或者 3d 的小批量 (mini-batch) 数据进行批标准化 (Batch Normalization) 操作. 每个小批量数据中,计算各个维度的均值和标准差,并且 gamma 和 beta 是大小为 C 的可学习, 可改变的仿射参数向量( C 为输入大小). 在训练过程中,该层计算均值和方差,并进行平均移动,默认的平均移动动量值为 0.1. 在验证时,训练得到的均值/方差,用于标准化验证数据. BatchNorm 在 ‘C’ 维上处理,即 ‘(N,L)’ 部分运行,被称作 ‘Temporal BatchNorm’ 参数： num_features – 预期输入的特征数,大小为 ‘batch_size x num_features [x width]’ eps – 给分母加上的值,保证数值稳定(分母不能趋近0或取0),默认为 1e-5 momentum – 动态均值和动态方差使用的移动动量值,默认为 0.1 affine – 布尔值,设为 True 时,表示该层添加可学习,可改变的仿射参数,即 gamma 和 beta,默认为 True 形状： 输入： or 输出： or (same shape as input) 示例： >>> # With Learnable Parameters >>> m = nn.BatchNorm1d(100) >>> # Without Learnable Parameters >>> m = nn.BatchNorm1d(100, affine=False) >>> input = autograd.Variable(torch.randn(20, 100)) >>> output = m(input) BatchNorm2d class torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True) 对小批量 (mini-batch) 3d 数据组成的 4d 输入进行标准化 (Batch Normalization) 操作. 每个小批量数据中,计算各个维度的均值和标准差, 并且 gamma 和 beta 是大小为 C 的可学习,可改变的仿射参数向量 (C 为输入大小). 在训练过程中,该层计算均值和方差,并进行平均移动.默认的平均移动动量值为 0.1. 在验证时,训练得到的均值/方差,用于标准化验证数据. BatchNorm 在 ‘C’ 维上处理,即 ‘(N, H, W)’ 部分运行,被称作 ‘Spatial BatchNorm’. 参数： num_features – 预期输入的特征数,大小为 ‘batch_size x num_features x height x width’ eps – 给分母加上的值,保证数值稳定(分母不能趋近0或取0),默认为 1e-5 momentum – 动态均值和动态方差使用的移动动量值,默认为 0.1 affine – 布尔值,设为 True 时,表示该层添加可学习,可改变的仿射参数,即 gamma 和 beta,默认为 True 形状： 输入： 输出： (same shape as input) 示例： >>> # With Learnable Parameters >>> m = nn.BatchNorm2d(100) >>> # Without Learnable Parameters >>> m = nn.BatchNorm2d(100, affine=False) >>> input = autograd.Variable(torch.randn(20, 100, 35, 45)) >>> output = m(input) BatchNorm3d class torch.nn.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, affine=True) 对小批量 (mini-batch) 4d 数据组成的 5d 输入进行标准化 (Batch Normalization) 操作. 每个小批量数据中,计算各个维度的均值和标准差, 并且 gamma 和 beta 是大小为 C 的可学习,可改变的仿射参数向量 (C 为输入大小). 在训练过程中,该层计算均值和方差,并进行平均移动.默认的平均移动动量值为 0.1. 在验证时,训练得到的均值/方差,用于标准化验证数据. BatchNorm 在 ‘C’ 维上处理,即 ‘(N, D, H, W)’ 部分运行,被称作 ‘Volumetric BatchNorm’ 或者 ‘Spatio-temporal BatchNorm’ 参数： num_features – 预期输入的特征数,大小为 ‘batch_size x num_features x depth x height x width’ eps – 给分母加上的值,保证数值稳定(分母不能趋近0或取0),默认为 1e-5 momentum – 动态均值和动态方差使用的移动动量值,默认为 0.1 affine – 布尔值,设为 True 时,表示该层添加可学习,可改变的仿射参数,即 gamma 和 beta,默认为 True 形状： 输入： 输出： (same shape as input) 示例： >>> # With Learnable Parameters >>> m = nn.BatchNorm3d(100) >>> # Without Learnable Parameters >>> m = nn.BatchNorm3d(100, affine=False) >>> input = autograd.Variable(torch.randn(20, 100, 35, 45, 10)) >>> output = m(input) InstanceNorm1d class torch.nn.InstanceNorm1d(num_features, eps=1e-05, momentum=0.1, affine=False) 对 2d 或者 3d 的小批量 (mini-batch) 数据进行实例标准化 (Instance Normalization) 操作. .. math: y = \\frac{x - mean[x]}{ \\sqrt{Var[x]} + \\epsilon} * gamma + beta 对小批量数据中的每一个对象,计算其各个维度的均值和标准差,并且 gamma 和 beta 是大小为 C 的可学习, 可改变的仿射参数向量( C 为输入大小). 在训练过程中,该层计算均值和方差,并进行平均移动,默认的平均移动动量值为 0.1. 在验证时 (.eval()),InstanceNorm 模型默认保持不变,即求得的均值/方差不用于标准化验证数据, 但可以用 .train(False) 方法强制使用存储的均值和方差. 参数： num_features – 预期输入的特征数,大小为 ‘batch_size x num_features x width’ eps – 给分母加上的值,保证数值稳定(分母不能趋近0或取0),默认为 1e-5 momentum – 动态均值和动态方差使用的移动动量值,默认为 0.1 affine – 布尔值,设为 True 时,表示该层添加可学习,可改变的仿射参数,即 gamma 和 beta,默认为 False 形状： 输入： 输出： (same shape as input) 示例： >>> # Without Learnable Parameters >>> m = nn.InstanceNorm1d(100) >>> # With Learnable Parameters >>> m = nn.InstanceNorm1d(100, affine=True) >>> input = autograd.Variable(torch.randn(20, 100, 40)) >>> output = m(input) InstanceNorm2d class torch.nn.InstanceNorm2d(num_features, eps=1e-05, momentum=0.1, affine=False) 对小批量 (mini-batch) 3d 数据组成的 4d 输入进行实例标准化 (Batch Normalization) 操作. .. math: y = \\frac{x - mean[x]}{ \\sqrt{Var[x]} + \\epsilon} * gamma + beta 对小批量数据中的每一个对象,计算其各个维度的均值和标准差,并且 gamma 和 beta 是大小为 C 的可学习, 可改变的仿射参数向量( C 为输入大小). 在训练过程中,该层计算均值和方差,并进行平均移动,默认的平均移动动量值为 0.1. 在验证时 (.eval()),InstanceNorm 模型默认保持不变,即求得的均值/方差不用于标准化验证数据, 但可以用 .train(False) 方法强制使用存储的均值和方差. 参数： num_features – 预期输入的特征数,大小为 ‘batch_size x num_features x height x width’ eps – 给分母加上的值,保证数值稳定(分母不能趋近0或取0),默认为 1e-5 momentum – 动态均值和动态方差使用的移动动量值,默认为 0.1 affine – 布尔值,设为 True 时,表示该层添加可学习,可改变的仿射参数,即 gamma 和 beta,默认为 False 形状： 输入： 输出： (same shape as input) 示例： >>> # Without Learnable Parameters >>> m = nn.InstanceNorm2d(100) >>> # With Learnable Parameters >>> m = nn.InstanceNorm2d(100, affine=True) >>> input = autograd.Variable(torch.randn(20, 100, 35, 45)) >>> output = m(input) InstanceNorm3d class torch.nn.InstanceNorm3d(num_features, eps=1e-05, momentum=0.1, affine=False) 对小批量 (mini-batch) 4d 数据组成的 5d 输入进行实例标准化 (Batch Normalization) 操作. .. math: y = \\frac{x - mean[x]}{ \\sqrt{Var[x]} + \\epsilon} * gamma + beta 对小批量数据中的每一个对象,计算其各个维度的均值和标准差,并且 gamma 和 beta 是大小为 C 的可学习, 可改变的仿射参数向量( C 为输入大小). 在训练过程中,该层计算均值和方差,并进行平均移动,默认的平均移动动量值为 0.1. 在验证时 (.eval()),InstanceNorm 模型默认保持不变,即求得的均值/方差不用于标准化验证数据, 但可以用 .train(False) 方法强制使用存储的均值和方差. 参数： num_features – 预期输入的特征数,大小为 ‘batch_size x num_features x depth x height x width’ eps – 给分母加上的值,保证数值稳定(分母不能趋近0或取0),默认为 1e-5 momentum – 动态均值和动态方差使用的移动动量值,默认为 0.1 affine – 布尔值,设为 True 时,表示该层添加可学习,可改变的仿射参数,即 gamma 和 beta,默认为 False 形状： 输入： 输出： (same shape as input) 示例： >>> # Without Learnable Parameters >>> m = nn.InstanceNorm3d(100) >>> # With Learnable Parameters >>> m = nn.InstanceNorm3d(100, affine=True) >>> input = autograd.Variable(torch.randn(20, 100, 35, 45, 10)) >>> output = m(input) Recurrent layers (循环层) RNN class torch.nn.RNN(*args, **kwargs) 对于输入序列使用一个多层的 Elman RNN, 它的激活函数为 tanh 或者 ReLU . 对输入序列中每个元素, 每层计算公式为: 这里 是当前在时刻 t 的隐状态, 并且 是之前一层在 t 时刻的隐状态, 或者是第一层的输入. 如果 nonlinearity='relu' ,那么将使用 relu 代替 tanh 作为激活函数. 参数： input_size – 输入 x 的特征数量 hidden_size – 隐状态 h 中的特征数量 num_layers – RNN 的层数 nonlinearity – 指定非线性函数使用 [‘tanh’|’relu’]. 默认: ‘tanh’ bias – 如果是 False , 那么 RNN 层就不会使用偏置权重 b_ih 和 b_hh, 默认: True batch_first – 如果 True, 那么输入 Tensor 的 shape 应该是 (batch, seq, feature),并且输出也是一样 dropout – 如果值非零, 那么除了最后一层外, 其它层的输出都会套上一个 dropout 层 bidirectional – 如果 True , 将会变成一个双向 RNN, 默认为 False Inputs: input, h_0 input (seq_len, batch, input_size): 包含输入序列特征的 tensor , input 可以是被填充的变长序列.细节请看 torch.nn.utils.rnn.pack_padded_sequence() . h_0 (num_layers * num_directions, batch, hidden_size): 包含 batch 中每个元素保存着初始隐状态的 tensor Outputs: output, h_n output (seq_len, batch, hidden_size * num_directions): 包含 RNN 最后一层输出特征 (h_k) 的 tensor 对于每个 k ,如果输入是一个 torch.nn.utils.rnn.PackedSequence , 那么输出也是一个可以是被填充的变长序列. h_n (num_layers * num_directions, batch, hidden_size): 包含 k= seq_len 隐状态的 tensor. 变量： weight_ih_l[k] – 第 k 层的 input-hidden 权重,可学习, shape 是 (input_size x hidden_size) weight_hh_l[k] – 第 k 层的 hidden-hidden 权重, 可学习, shape 是 (hidden_size x hidden_size) bias_ih_l[k] – 第 k 层的 input-hidden 偏置, 可学习, shape 是 (hidden_size) bias_hh_l[k] – 第 k 层的 hidden-hidden 偏置, 可学习, shape 是 (hidden_size) Examples: >>> rnn = nn.RNN(10, 20, 2) >>> input = Variable(torch.randn(5, 3, 10)) >>> h0 = Variable(torch.randn(2, 3, 20)) >>> output, hn = rnn(input, h0) LSTM class torch.nn.LSTM(*args, **kwargs) 对于输入序列使用一个多层的 LSTM ( long short-term memory ). 对输入序列的每个元素, LSTM 的每层都会执行以下计算: 这里 是在时刻 t 的隐状态, 是在时刻 t 的细胞状态 (cell state), 是上一层的在时刻 t 的隐状态或者是第一层的 , 而 , , , 分别代表 输入门,遗忘门,细胞和输出门. 参数： input_size – 输入的特征维度 hidden_size – 隐状态的特征维度 num_layers – 层数(和时序展开要区分开) bias – 如果为 False ,那么 LSTM 将不会使用 b_ih 和 b_hh ,默认: True batch_first – 如果为 True , 那么输入和输出 Tensor 的形状为 (batch, seq, feature) dropout – 如果非零的话, 将会在 RNN 的输出上加个 dropout , 最后一层除外 bidirectional – 如果为 True,将会变成一个双向 RNN ,默认为 False Inputs: input, (h_0, c_0) input (seq_len, batch, input_size): 包含输入序列特征的 tensor . 也可以是 packed variable length sequence, 详见 torch.nn.utils.rnn.pack_padded_sequence() . h_0 (num_layers * num_directions, batch, hidden_size): 包含 batch 中每个元素的初始化隐状态的 tensor . c_0 (num_layers * num_directions, batch, hidden_size): 包含 batch 中每个元素的初始化细胞状态的 tensor . Outputs: output, (h_n, c_n) output (seq_len, batch, hidden_size * num_directions): 包含 RNN 最后一层的输出特征 (h_t) 的 tensor , 对于每个 t . 如果输入是 torch.nn.utils.rnn.PackedSequence 那么输出也是一个可以是被填充的变长序列. h_n (num_layers * num_directions, batch, hidden_size): 包含 t=seq_len 隐状态的 tensor. c_n (num_layers * num_directions, batch, hidden_size): 包含 t=seq_len 细胞状态的 tensor. 变量： weight_ih_l[k] – 第 k 层可学习的 input-hidden 权重 (W_ii&#124;W_if&#124;W_ig&#124;W_io), shape 是 (4*hidden_size x input_size) weight_hh_l[k] – 第 k 层可学习的 hidden-hidden 权重 (W_hi&#124;W_hf&#124;W_hg&#124;W_ho), shape 是 (4*hidden_size x hidden_size) bias_ih_l[k] – 第 k 层可学习的 input-hidden 偏置 (b_ii&#124;b_if&#124;b_ig&#124;b_io), shape 是 (4*hidden_size) bias_hh_l[k] – 第 k 层可学习的 hidden-hidden 偏置 (b_hi&#124;b_hf&#124;b_hg&#124;b_ho), shape 是 (4*hidden_size) Examples: >>> rnn = nn.LSTM(10, 20, 2) >>> input = Variable(torch.randn(5, 3, 10)) >>> h0 = Variable(torch.randn(2, 3, 20)) >>> c0 = Variable(torch.randn(2, 3, 20)) >>> output, hn = rnn(input, (h0, c0)) GRU class torch.nn.GRU(*args, **kwargs) 对于输入序列使用一个多层的 GRU (gated recurrent unit). 对输入序列的每个元素, 每层都会执行以下计算: 这里 是在时刻 t 的隐状态, 是前一层在时刻 t 的隐状态或者是第一层的 , 而 , , 分别是重置门,输入门和新门. 参数： input_size – 输入的特征维度 hidden_size – 隐状态的特征维度 num_layers – RNN 的层数 bias – 如果为 False, 那么 RNN 层将不会使用偏置权重 b_ih 和 b_hh 默认: True batch_first – 如果为 True, 那么输入和输出的 tensor 的形状是 (batch, seq, feature) dropout – 如果非零的话,将会在 RNN 的输出上加个 dropout ,最后一层除外 bidirectional – 如果为 True, 将会变成一个双向 RNN . 默认: False Inputs: input, h_0 input (seq_len, batch, input_size): 包含输入序列特征的 tensor . 也可以是 packed variable length sequence, 详见 torch.nn.utils.rnn.pack_padded_sequence() . h_0 (num_layers * num_directions, batch, hidden_size): 包含 batch 中每个元素的初始化隐状态的 tensor Outputs: output, h_n output (seq_len, batch, hidden_size * num_directions): 包含 RNN 最后一层的输出特征 (h_t) 的 tensor , 对于每个 t . 如果输入是 torch.nn.utils.rnn.PackedSequence 那么输出也是一个可以是被填充的变长序列. h_n (num_layers * num_directions, batch, hidden_size): 包含 t=seq_len 隐状态的 tensor. 变量： weight_ih_l[k] – 第 k 层可学习的 input-hidden 权重 (W_ir|W_iz|W_in), shape 为 (3*hidden_size x input_size) weight_hh_l[k] – 第 k 层可学习的 hidden-hidden 权重 (W_hr|W_hz|W_hn), shape 为 (3*hidden_size x hidden_size) bias_ih_l[k] – 第 k 层可学习的 input-hidden 偏置 (b_ir|b_iz|b_in), shape 为 (3*hidden_size) bias_hh_l[k] – 第 k 层可学习的 hidden-hidden 偏置 (b_hr|b_hz|b_hn), shape 为 (3*hidden_size) Examples: >>> rnn = nn.GRU(10, 20, 2) >>> input = Variable(torch.randn(5, 3, 10)) >>> h0 = Variable(torch.randn(2, 3, 20)) >>> output, hn = rnn(input, h0) RNNCell class torch.nn.RNNCell(input_size, hidden_size, bias=True, nonlinearity='tanh') 一个 Elan RNN cell , 激活函数是 tanh 或 ReLU , 用于输入序列. 如果 nonlinearity=’relu’, 那么将会使用 ReLU 来代替 tanh . 参数： input_size – 输入的特征维度 hidden_size – 隐状态的特征维度 bias – 如果为 False, 那么RNN层将不会使用偏置权重 b_ih 和 b_hh. 默认: True nonlinearity – 用于选择非线性激活函数 [‘tanh’|’relu’]. 默认: ‘tanh’ Inputs: input, hidden input (batch, input_size): 包含输入特征的 tensor . hidden (batch, hidden_size): 包含 batch 中每个元素的初始化隐状态的 tensor. Outputs: h’ h’ (batch, hidden_size): 保存着 batch 中每个元素的下一层隐状态的 tensor . 变量： weight_ih – input-hidden 权重, 可学习, shape 为 (input_size x hidden_size) weight_hh – hidden-hidden 权重, 可学习, shape 为 (hidden_size x hidden_size) bias_ih – input-hidden 偏置,可学习, shape 为 (hidden_size) bias_hh – hidden-hidden 偏置,可学习, shape 为 (hidden_size) Examples: >>> rnn = nn.RNNCell(10, 20) >>> input = Variable(torch.randn(6, 3, 10)) >>> hx = Variable(torch.randn(3, 20)) >>> output = [] >>> for i in range(6): ... hx = rnn(input[i], hx) ... output.append(hx) LSTMCell class torch.nn.LSTMCell(input_size, hidden_size, bias=True) LSTM 细胞. 参数： input_size – 输入的特征维度 hidden_size – 隐状态的维度 bias – 如果为 False, 那么RNN层将不会使用偏置权重 b_ih 和 b_hh 默认: True Inputs: input, (h_0, c_0) input (batch, input_size): 包含输入特征的 tensor . h_0 (batch, hidden_size): 包含 batch 中每个元素的初始化隐状态的 tensor. c_0 (batch. hidden_size): 包含 batch 中每个元素的初始化细胞状态的 tensor Outputs: h_1, c_1 h_1 (batch, hidden_size): 保存着 batch 中每个元素的下一层隐状态的 tensor c_1 (batch, hidden_size): 保存着 batch 中每个元素的下一细胞状态的 tensor 变量： weight_ih – input-hidden 权重, 可学习, 形状为 (4*hidden_size x input_size) weight_hh – hidden-hidden 权重, 可学习, 形状为 (4*hidden_size x hidden_size) bias_ih – input-hidden 偏置, 可学习, 形状为 (4*hidden_size) bias_hh – hidden-hidden 偏置, 可学习, 形状为 (4*hidden_size) Examples: >>> rnn = nn.LSTMCell(10, 20) >>> input = Variable(torch.randn(6, 3, 10)) >>> hx = Variable(torch.randn(3, 20)) >>> cx = Variable(torch.randn(3, 20)) >>> output = [] >>> for i in range(6): ... hx, cx = rnn(input[i], (hx, cx)) ... output.append(hx) GRUCell class torch.nn.GRUCell(input_size, hidden_size, bias=True) GRU 细胞 参数： input_size – 输入的特征维度 hidden_size – 隐状态的维度 bias – 如果为 False, 那么RNN层将不会使用偏置权重 b_ih 和 b_hh 默认: True Inputs: input, hidden input (batch, input_size): 包含输入特征的 tensor . hidden (batch, hidden_size): 包含 batch 中每个元素的初始化隐状态的 tensor. Outputs: h’ h’: (batch, hidden_size): 保存着 batch 中每个元素的下一层隐状态的 tensor 变量： weight_ih – input-hidden 权重, 可学习, shape 为, (3*hidden_size x input_size) weight_hh – hidden-hidden 权重, 可学习, shape 为 (3*hidden_size x hidden_size) bias_ih – input-hidden 偏置, 可学习, shape 为 (3*hidden_size) bias_hh – hidden-hidden 偏置, 可学习, shape 为 (3*hidden_size) Examples: >>> rnn = nn.GRUCell(10, 20) >>> input = Variable(torch.randn(6, 3, 10)) >>> hx = Variable(torch.randn(3, 20)) >>> output = [] >>> for i in range(6): ... hx = rnn(input[i], hx) ... output.append(hx) Linear layers (线性层) Linear class torch.nn.Linear(in_features, out_features, bias=True) 对输入数据进行线性变换: 参数： in_features – 每个输入样本的大小 out_features – 每个输出样本的大小 bias – 若设置为 False, 这层不会学习偏置. 默认值: True 形状： 输入： 这里 * 意味着可以添加任意数量的其他维度 输出： 除了最后一个维度外, 其余的都与输入相同 变量： weight – 形状为 (out_features x in_features) 的模块中可学习的权值 bias – 形状为 (out_features) 的模块中可学习的偏置 Examples: >>> m = nn.Linear(20, 30) >>> input = autograd.Variable(torch.randn(128, 20)) >>> output = m(input) >>> print(output.size()) Bilinear class torch.nn.Bilinear(in1_features, in2_features, out_features, bias=True) 对输入数据进行双线性变换: 参数： in1_features – 输入一的每个输入样本的大小 in2_features – 输入二的每个输入样本的大小 out_features – 每个输出样本的大小 bias – 若设置为False, 这层不会学习偏置. 默认值: True 形状： 输入：, 输出： 变量： weight – 形状为 (out_features x in1_features x in2_features) 的模块中可学习的权值 bias – 形状为 (out_features) 的模块中可学习的偏置 Examples: >>> m = nn.Bilinear(20, 30, 40) >>> input1 = autograd.Variable(torch.randn(128, 20)) >>> input2 = autograd.Variable(torch.randn(128, 30)) >>> output = m(input1, input2) >>> print(output.size()) Dropout layers Dropout class torch.nn.Dropout(p=0.5, inplace=False) Dropout 在训练期间, 按照伯努利概率分布, 以概率 p 随机地将输入张量中的部分元素 置为 0, 在每次调用时, 被置为 0 的元素是随机的. Dropout 已被证明是正则化的一个行之有效的技术, 并且在防止神经元之间互适应问题上 也卓有成效.（神经元互适应问题详见论文 Improving neural networks by preventing co-adaptation of feature detectors ） 并且, Dropout 的输出均与 1/(1-p) 的比例系数进行了相乘, 保证了求值时函数是归一化的. Args: p: 元素被置为0的概率, 默认值: 0.5 inplace: 如果为 True, 置0操作将直接发生在传入的元素上.默认值: false Shape: 输入：any.输入数据可以是任何大小 输出：Same.输出数据大小与输入相同 Examples: >>> m = nn.Dropout(p=0.2) >>> input = autograd.Variable(torch.randn(20, 16)) >>> output = m(input) Dropout2d class torch.nn.Dropout2d(p=0.5, inplace=False) Dropout2d 将输入张量的所有通道随机地置为 0.被置为 0 的通道在每次调用时是随机的. 通常输入数据来自 Conv2d 模块. 在论文 Efficient Object Localization Using Convolutional Networks 中有如下 描述: 如果特征映射中的邻接像素是强相关的（在早期的卷积层中很常见）, 那么独立同分布 的 dropout 将不会正则化激活函数, 相反其会导致有效的学习率的下降. 在这样的情况下, 应该使用函数函数 nn.Dropout2d , 它能够提升特征映射之间的独立性. Args: p (float,optional): 元素被置0的概率 inplace（bool, 可选）: 如果被设为’True’, 置0操作将直接作用在输入元素上 Shape: 输入：math:(N, C, H, W) 输出：math:(N, C, H, W) （与输入相同） Examples: &gt;&gt;&gt; m = nn.Dropout2d(p=0.2) &gt;&gt;&gt; input = autograd.Variable(torch.randn(20, 16, 32, 32)) &gt;&gt;&gt; output = m(input) Dropout3d class torch.nn.Dropout3d(p=0.5, inplace=False) Dropout3d 将输入张量的所有通道随机地置为 0.被置为 0 的通道在每次调用时是随机的. 通常输入数据来自 Conv3d 模块. 在论文 Efficient Object Localization Using Convolutional Networks 中有如下 描述: 如果特征映射中的邻接像素是强相关的（在早期的卷积层中很常见）, 那么独立同分布 的 dropout 将不会正则化激活函数, 相反其会导致有效的学习率的下降. 在这样的情况下, 应该使用函数函数 nn.Dropout3d , 它能够促进特征映射之间的独立性. Args: p (float,optional): 元素被置0的概率 inplace（bool, 可选）: 如果被设为 True , 置0操作将直接作用在输入元素上 Shape: 输入：math:(N, C, H, W) 输出：math:(N, C, H, W) （与输入相同） Examples: &gt;&gt;&gt; m = nn.Dropout3d(p=0.2) &gt;&gt;&gt; input = autograd.Variable(torch.randn(20, 16, 4, 32, 32)) &gt;&gt;&gt; output = m(input) AlphaDropout class torch.nn.AlphaDropout(p=0.5) 在输入上应用 Alpha Dropout. Alpha Dropout 是一种维持自正交性质的 Dropout . 对于一个均值为 0 和标准差为 1 的输入 来说, Alpha Dropout 能保持原始数据的均值和标准差.Alpha Dropout 和 SELU 激活函数 携手同行, 后者也保证了输出拥有与输入相同的均值和标准差. Alpha Dropout 在训练期间, 按照伯努利概率分布, 以概率 p 随机地将输入张量中的部分元素 置进行掩盖, 在每次调用中, 被掩盖的元素是随机的, 并且对输出会进行缩放、变换等操作 以保持均值为 0、标准差为 1. 在求值期间, 模块简单的计算一个归一化的函数. 更多信息请参考论文: Self-Normalizing Neural Networks Args: p（float）: 元素被掩盖的概率, 默认值: 0.5 Shape: 输入：any.输入数据可以是任何大小 输出：Same.输出数据大小与输入相同 Examples: &gt;&gt;&gt; m = nn.AlphaDropout(p=0.2) &gt;&gt;&gt; input = autograd.Variable(torch.randn(20, 16)) &gt;&gt;&gt; output = m(input) Sparse layers (稀疏层) Embedding class torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, sparse=False) 一个简单的查找表, 存储了固定字典和大小的 embedding. 这个模块经常用来存储 word embeddings, 并通过索引来检索, 模块的输入是索引构成的列表, 输出是对应的 word embeddings. 参数： num_embeddings (int) – embeddings 字典的大小 embedding_dim (int) – 每个 embedding 向量的大小 padding_idx (int, 可选) – 如果给出, 在索引处, 输出补零 max_norm (float, 可选) – 如果给出, 重新归一化 embeddings, 使其范数小于该值 norm_type (float, 可选) – 为 max_norm 选项计算 p 范数时 P scale_grad_by_freq (boolean, 可选) – 如果给出, 会根据 words 在 mini-batch 中的频率缩放梯度 sparse (boolean, 可选) – 如果为 True, 关于权重矩阵的梯度是一个稀疏张量, 详情请参考稀疏梯度 Variables: weight (Tensor) – shape 为 (num_embeddings, embedding_dim) 的模块的可学习权重 形状： 输入：LongTensor (N, W), N = mini-batch, W = 每个 mini-batch 中用来提取的索引数 输出：(N, W, embedding_dim) 注解： 请注意, 只支持有限数量的优化器. 稀疏梯度: 当前是 (cuda 和 cpu) 版本的 optim.SGD, 和 (cpu) 版本的 optim.Adagrad. Examples: >>> # an Embedding module containing 10 tensors of size 3 >>> embedding = nn.Embedding(10, 3) >>> # a batch of 2 samples of 4 indices each >>> input = Variable(torch.LongTensor([[1,2,4,5],[4,3,2,9]])) >>> embedding(input) Variable containing: (0 ,.,.) = -1.0822 1.2522 0.2434 0.8393 -0.6062 -0.3348 0.6597 0.0350 0.0837 0.5521 0.9447 0.0498 (1 ,.,.) = 0.6597 0.0350 0.0837 -0.1527 0.0877 0.4260 0.8393 -0.6062 -0.3348 -0.8738 -0.9054 0.4281 [torch.FloatTensor of size 2x4x3] >>> # example with padding_idx >>> embedding = nn.Embedding(10, 3, padding_idx=0) >>> input = Variable(torch.LongTensor([[0,2,0,5]])) >>> embedding(input) Variable containing: (0 ,.,.) = 0.0000 0.0000 0.0000 0.3452 0.4937 -0.9361 0.0000 0.0000 0.0000 0.0706 -2.1962 -0.6276 [torch.FloatTensor of size 1x4x3] EmbeddingBag class torch.nn.EmbeddingBag(num_embeddings, embedding_dim, max_norm=None, norm_type=2, scale_grad_by_freq=False, mode='mean') 计算一 个’bags’ 里的 embedding s的均值或和, 不用实例化中间的 embeddings 对于固定长度的 bags nn.EmbeddingBag 和 mode=sum 相当于 nn.Embedding 与之后的 torch.sum(dim=1) 其与 mode=mean 相当于 nn.Embedding 与之后的 torch.mean(dim=1) 然而, 比起一连串这样的操作, nn.EmbeddingBag 在时间和内存上更加高效. 参数： num_embeddings (int) – embeddings 字典的大小 embedding_dim (int) – 每个 embedding 向量的大小 max_norm (float, 可选) – 如果给出, 重新归一化 embeddings, 使其范数小于该值 norm_type (float, 可选) – 为 max_norm 选项计算 p 范数时的 P scale_grad_by_freq (boolean, 可选) – 如果给出, 会根据 words 在 mini-batch 中的频率缩放梯度 mode (string, 可选) – ‘sum’ | ‘mean’. 指定减少 bag 的方式. 默认: ‘mean’ Variables: weight (Tensor) – shape 为 (num_embeddings, embedding_dim) 的模块的可学习权重 Inputs: input, offsets input (N or BxN): LongTensor, 包括要提取的 embeddings 的索引, 当 input 是形状为 N 的 1D 张量时, 一个给出的 offsets 张量中包括: mini-batch 中每个新序列的起始位置 offsets (B or None): LongTensor, 包括一个 mini-batch 的可变长度序列中的每个新样本的起始位置 如果 input 是 2D (BxN) 的, offset 就不用再给出; 如果 input 是一个 mini-batch 的固定长度的序列, 每个序列的长度为 N 形状： 输入：LongTensor N, N = 要提取的 embeddings 的数量, 或者是 LongTensor BxN, B = mini-batch 中序列的数量, N = 每个序列中 embeddings 的数量 Offsets: LongTensor B, B = bags 的数量, 值为每个 bag 中 input 的 offset, i.e. 是长度的累加. Offsets 不会给出, 如果 Input是 2D 的BxN 张量, 输入被认为是固定长度的序列 输出：(B, embedding_dim) Examples: >>> # an Embedding module containing 10 tensors of size 3 >>> embedding_sum = nn.EmbeddingBag(10, 3, mode='sum') >>> # a batch of 2 samples of 4 indices each >>> input = Variable(torch.LongTensor([1,2,4,5,4,3,2,9])) >>> offsets = Variable(torch.LongTensor([0,4])) >>> embedding_sum(input, offsets) Variable containing: -0.7296 -4.6926 0.3295 -0.5186 -0.5631 -0.2792 [torch.FloatTensor of size 2x3] Distance functions (距离函数) CosineSimilarity class torch.nn.CosineSimilarity(dim=1, eps=1e-08) 返回沿着 dim 方向计算的 x1 与 x2 之间的余弦相似度. 参数： dim (int, 可选) – 计算余弦相似度的维度. Default: 1 eps (float, 可选) – 小的值以避免被零除. Default: 1e-8 形状： Input1: , 其中的 D 表示 dim 的位置 Input2: , 与 Input1 一样的 shape 输出： Examples: >>> input1 = autograd.Variable(torch.randn(100, 128)) >>> input2 = autograd.Variable(torch.randn(100, 128)) >>> cos = nn.CosineSimilarity(dim=1, eps=1e-6) >>> output = cos(input1, input2) >>> print(output) PairwiseDistance class torch.nn.PairwiseDistance(p=2, eps=1e-06) 计算向量 v1, v2 之间的 batchwise pairwise distance(分批成对距离): 参数： p (_real_) – norm degree(规范程度). Default: 2 eps (float, 可选) – 小的值以避免被零除. Default: 1e-6 形状： Input1: , 其中的 D = vector dimension(向量维度) Input2: , 与 Input1 的 shape 一样 输出： Examples: >>> pdist = nn.PairwiseDistance(p=2) >>> input1 = autograd.Variable(torch.randn(100, 128)) >>> input2 = autograd.Variable(torch.randn(100, 128)) >>> output = pdist(input1, input2) Loss functions (损失函数) L1Loss class torch.nn.L1Loss(size_average=True, reduce=True) 创建一个衡量输入 x 与目标 y 之间差的绝对值的平均值的标准, 该 函数会逐元素地求出 x 和 y 之间差的绝对值, 最后返回绝对值的平均值. x 和 y 可以是任意维度的数组, 但需要有相同数量的n个元素. 求和操作会对n个元素求和, 最后除以 n . 在构造函数的参数中传入 size_average=False, 最后求出来的绝对值将不会除以 n. 参数： size_average (bool, 可选) – 默认情况下, loss 会在每个 mini-batch（小批量） 上取平均值. 如果字段 size_average 被设置为 False, loss 将会在每个 mini-batch（小批量） 上累加, 而不会取平均值. 当 reduce 的值为 False 时该字段会被忽略. 默认值: True reduce (bool, 可选) – 默认情况下, loss 会在每个 mini-batch（小批量）上求平均值或者 求和. 当 reduce 是 False 时, 损失函数会对每个 batch 元素都返回一个 loss 并忽 略 size_average 字段. 默认值: True 形状： 输入: , * 表示任意数量的额外维度 目标: , 和输入的shape相同 输出: 标量. 如果 reduce 是 False , 则输出为 , shape与输出相同 Examples: >>> loss = nn.L1Loss() >>> input = autograd.Variable(torch.randn(3, 5), requires_grad=True) >>> target = autograd.Variable(torch.randn(3, 5)) >>> output = loss(input, target) >>> output.backward() MSELoss class torch.nn.MSELoss(size_average=True, reduce=True) 输入 x 和 目标 y 之间的均方差 x 和 y 可以是任意维度的数组, 但需要有相同数量的n个元素. 求和操作会对n个元素求和, 最后除以 n. 在构造函数的参数中传入 size_average=False , 最后求出来的绝对值将不会除以 n. 要得到每个 batch 中每个元素的 loss, 设置 reduce 为 False. 返回的 loss 将不会 取平均值, 也不会被 size_average 影响. 参数： size_average (bool, 可选) – 默认情况下, loss 会在每个 mini-batch（小批量） 上取平均值. 如果字段 size_average 被设置为 False , loss 会在每 个 mini-batch（小批量）上求和. 只有当 reduce 的值为 True 才会生效. 默认值: True reduce (bool, 可选) – 默认情况下, loss 会根据 size_average 的值在每 个 mini-batch（小批量）上求平均值或者求和. 当 reduce 是 False 时, 损失函数会对每 个 batch 元素都返回一个 loss 并忽略 size_average字段. 默认值: True 形状： 输入: , 其中 * 表示任意数量的额外维度. 目标: , shape 跟输入相同 Examples: >>> loss = nn.MSELoss() >>> input = autograd.Variable(torch.randn(3, 5), requires_grad=True) >>> target = autograd.Variable(torch.randn(3, 5)) >>> output = loss(input, target) >>> output.backward() CrossEntropyLoss class torch.nn.CrossEntropyLoss(weight=None, size_average=True, ignore_index=-100, reduce=True) 该类把 LogSoftMax 和 NLLLoss 结合到了一个类中 当训练有 C 个类别的分类问题时很有效. 可选参数 weight 必须是一个1维 Tensor, 权重将被分配给各个类别. 对于不平衡的训练集非常有效. input 含有每个类别的分数 input 必须是一个2维的形如 (minibatch, C) 的 Tensor. target 是一个类别索引 (0 to C-1), 对应于 minibatch 中的每个元素 loss 可以描述为: loss(x, class) = -log(exp(x[class]) / (\\sum_j exp(x[j]))) = -x[class] + log(\\sum_j exp(x[j])) 当 weight 参数存在时: loss(x, class) = weight[class] * (-x[class] + log(\\sum_j exp(x[j]))) loss 在每个 mini-batch（小批量）上取平均值. 参数： weight (Tensor, 可选) – 自定义的每个类别的权重. 必须是一个长度为 C 的 Tensor size_average (bool, 可选) – 默认情况下, loss 会在每个 mini-batch（小批量） 上取平均值. 如果字段 size_average 被设置为 False, loss 将会在每个 mini-batch（小批量） 上累加, 而不会取平均值. 当 reduce 的值为 False 时该字段会被忽略. ignore_index (int, 可选) – 设置一个目标值, 该目标值会被忽略, 从而不会影响到 输入的梯度. 当 size_average 字段为 True 时, loss 将会在没有被忽略的元素上 取平均. reduce (bool, 可选) – 默认情况下, loss 会根据 size_average 的值在每 个 mini-batch（小批量）上求平均值或者求和. 当 reduce 是 False 时, 损失函数会对 每个 batch 元素都返回一个 loss 并忽略 size_average 字段. 默认值: True 形状： 输入: , 其中 C 是类别的数量 目标: , 其中的每个元素都满足 0 &lt;= targets[i] &lt;= C-1 输出: 标量. 如果 reduce 是 False, 则输出为 . Examples: >>> loss = nn.CrossEntropyLoss() >>> input = autograd.Variable(torch.randn(3, 5), requires_grad=True) >>> target = autograd.Variable(torch.LongTensor(3).random_(5)) >>> output = loss(input, target) >>> output.backward() NLLLoss class torch.nn.NLLLoss(weight=None, size_average=True, ignore_index=-100, reduce=True) 负对数似然损失. 用于训练 C 个类别的分类问题. 可选参数 weight 是 一个1维的 Tensor, 用来设置每个类别的权重. 当训练集不平衡时该参数十分有用. 由前向传播得到的输入应该含有每个类别的对数概率: 输入必须是形如 (minibatch, C) 的 2维 Tensor. 在一个神经网络的最后一层添加 LogSoftmax 层可以得到对数概率. 如果你不希望在神经网络中 加入额外的一层, 也可以使用 CrossEntropyLoss 函数. 该损失函数需要的目标值是一个类别索引 (0 到 C-1, 其中 C 是类别数量) 该 loss 可以描述为: loss(x, class) = -x[class] 或者当 weight 参数存在时可以描述为: loss(x, class) = -weight[class] * x[class] 又或者当 ignore_index 参数存在时可以描述为: loss(x, class) = class != ignoreIndex ? -weight[class] * x[class] : 0 参数： weight (Tensor, 可选) – 自定义的每个类别的权重. 必须是一个长度为 C 的 Tensor size_average (bool, 可选) – 默认情况下, loss 会在每个 mini-batch（小批量） 上取平均值. 如果字段 size_average 被设置为 False, loss 将会在每个 mini-batch（小批量） 上累加, 而不会取平均值. 当 reduce 的值为 False 时该字段会被忽略. 默认值: True ignore_index (int, 可选) – 设置一个目标值, 该目标值会被忽略, 从而不会影响到 输入的梯度. 当 size_average 为 True 时, loss 将会在没有被忽略的元素上 取平均值. reduce (bool, 可选) – 默认情况下, loss 会在每个 mini-batch（小批量）上求平均值或者 求和. 当 reduce 是 False 时, 损失函数会对每个 batch 元素都返回一个 loss 并忽 略 size_average 字段. 默认值: True 形状： 输入: , 其中 C 是类别的数量 目标: , 其中的每个元素都满足 0 &lt;= targets[i] &lt;= C-1 输出: 标量. 如果 reduce 是 False, 则输出为 . Examples: >>> m = nn.LogSoftmax() >>> loss = nn.NLLLoss() >>> # input is of size N x C = 3 x 5 >>> input = autograd.Variable(torch.randn(3, 5), requires_grad=True) >>> # each element in target has to have 0 >> target = autograd.Variable(torch.LongTensor([1, 0, 4])) >>> output = loss(m(input), target) >>> output.backward() PoissonNLLLoss class torch.nn.PoissonNLLLoss(log_input=True, full=False, size_average=True, eps=1e-08) 目标值为泊松分布的负对数似然损失. 该损失可以描述为: target ~ Pois(input) loss(input, target) = input - target * log(input) + log(target!) 最后一项可以被省略或者用 Stirling 公式来近似. 该近似用于大于1的目标值. 当目标值 小于或等于1时, 则将0加到 loss 中. 参数： log_input (bool, 可选) – 如果设置为 True , loss 将会按照公 式 exp(input) - target * input 来计算, 如果设置为 False , loss 将会按照 input - target * log(input+eps) 计算. full (bool, 可选) – 是否计算全部的 loss, i. e. 加上 Stirling 近似项 target * log(target) - target + 0.5 * log(2 * pi * target). size_average (bool, 可选) – 默认情况下, loss 会在每个 mini-batch（小批量） 上取平均值. 如果字段 size_average 被设置为 False, loss 将会在每个 mini-batch（小批量） 上累加, 而不会取平均值. eps (float, 可选) – 当 log_input==False 时, 取一个很小的值用来避免计算 log(0). 默认值: 1e-8 Examples: >>> loss = nn.PoissonNLLLoss() >>> log_input = autograd.Variable(torch.randn(5, 2), requires_grad=True) >>> target = autograd.Variable(torch.randn(5, 2)) >>> output = loss(log_input, target) >>> output.backward() NLLLoss2d class torch.nn.NLLLoss2d(weight=None, size_average=True, ignore_index=-100, reduce=True) 对于图片输入的负对数似然损失. 它计算每个像素的负对数似然损失. 参数： weight (Tensor, 可选) – 自定义的每个类别的权重. 必须是一个长度为 C 的 Tensor size_average – 默认情况下, loss 会在每个 mini-batch（小批量） 上取平均值. 如果字段 size_average 被设置为 False, loss 将会在每个 mini-batch（小批量） 上累加, 而不会取平均值. 当 reduce 的值为 False 时该字段会被忽略. 默认值: True reduce (bool, 可选) – 默认情况下, loss 会在每个 mini-batch（小批量）上求平均值或者 求和. 当 reduce 是 False 时, 损失函数会对每个 batch 元素都返回一个 loss 并忽 略 size_average 字段. 默认值: True 形状： 输入： where C = number of classes Target: where each value is 0 &lt;= targets[i] &lt;= C-1 输出：scalar. If reduce is False, then instead. Examples: >>> m = nn.Conv2d(16, 32, (3, 3)).float() >>> loss = nn.NLLLoss2d() >>> # input is of size N x C x height x width >>> input = autograd.Variable(torch.randn(3, 16, 10, 10)) >>> # each element in target has to have 0 >> target = autograd.Variable(torch.LongTensor(3, 8, 8).random_(0, 4)) >>> output = loss(m(input), target) >>> output.backward() KLDivLoss class torch.nn.KLDivLoss(size_average=True, reduce=True) Kullback-Leibler divergence 损失 KL 散度可用于衡量不同的连续分布之间的距离, 在连续的输出分布的空间上(离散采样)上进行直接回归时 很有效. 跟 NLLLoss 一样, input 需要含有 对数概率 , 不同于 ClassNLLLoss, input 可 以不是2维的 Tensor, 因为该函数会逐元素地求值. 该方法需要一个shape跟 input Tensor 一样的 target Tensor. 损失可以描述为: 默认情况下, loss 会在每个 mini-batch（小批量）上和 维度 上取平均值. 如果字段 size_average 设置为 False, 则 loss 不会取平均值. 参数： size_average (bool, 可选) – 默认情况下, loss 会在每个 mini-batch（小批量）上 和 维度 上取平均值. 如果设置为 False, 则 loss 会累加, 而不是取平均值. reduce (bool, 可选) – 默认情况下, loss 会根据 size_average 在每 个 mini-batch（小批量）上求平均值或者求和. 当 reduce 是 False 时, 损失函数会对每 个 batch 元素都返回一个 loss 并忽略 size_average 字段. 默认值: True 形状： 输入: , 其中 * 表示任意数量的额外维度. 目标: , shape 跟输入相同 输出: 标量. 如果 reduce 是 True, 则输出为 , shape 跟输入相同. BCELoss class torch.nn.BCELoss(weight=None, size_average=True) 计算目标和输出之间的二进制交叉熵: 当定义了 weight 参数时: 这可用于测量重构的误差, 例如自动编码机. 注意目标的值 t[i] 的范围为0到1之间. 参数： weight (Tensor, 可选) – 自定义的每个 batch 元素的 loss 的权重. 必须是一个长度为 “nbatch” 的 的 Tensor size_average (bool, 可选) – 默认情况下, loss 会在每个 mini-batch（小批量） 上取平均值. 如果字段 size_average 被设置为 False , loss 会在每 个 mini-batch（小批量）上累加, 而不是取平均值. 默认值: True 形状： 输入: , 其中 * 表示任意数量的额外维度. 目标: , shape 跟输入相同 Examples: >>> m = nn.Sigmoid() >>> loss = nn.BCELoss() >>> input = autograd.Variable(torch.randn(3), requires_grad=True) >>> target = autograd.Variable(torch.FloatTensor(3).random_(2)) >>> output = loss(m(input), target) >>> output.backward() BCEWithLogitsLoss class torch.nn.BCEWithLogitsLoss(weight=None, size_average=True) 该损失函数把 Sigmoid 层集成到了 BCELoss 类中. 该版比用一个简单的 Sigmoid 层和 BCELoss 在数值上更稳定, 因为把这两个操作合并为一个层之后, 可以利用 log-sum-exp 的 技巧来实现数值稳定. 目标和输出之间的二值交叉熵(不含sigmoid函数)是: 当定义了 weight 参数之后可描述为: 这可用于测量重构的误差, 例如自动编码机. 注意目标的值 t[i] 的范围为0到1之间. 参数： weight (Tensor, 可选) – 自定义的每个 batch 元素的 loss 的权重. 必须是一个长度 为 “nbatch” 的 Tensor size_average (bool, 可选) – 默认情况下, loss 会在每个 mini-batch（小批量） 上取平均值. 如果字段 size_average 被设置为 False , loss 会在每 个 mini-batch（小批量）上累加, 而不是取平均值. 默认值: True 形状： 输入: , 其中 * 表示任意数量的额外维度. 目标: , shape 跟输入相同 Examples: >>> loss = nn.BCEWithLogitsLoss() >>> input = autograd.Variable(torch.randn(3), requires_grad=True) >>> target = autograd.Variable(torch.FloatTensor(3).random_(2)) >>> output = loss(input, target) >>> output.backward() MarginRankingLoss class torch.nn.MarginRankingLoss(margin=0, size_average=True) 创建一个衡量 mini-batch(小批量) 中的2个1维 Tensor 的输入 x1 和 x2, 和1个1维 Tensor 的目标 y(y 的取值是 1 或者 -1) 之间损失的标准. 如果 y == 1 则认为第一个输入值应该排列在第二个输入值之上(即值更大), y == -1 时则相反. 对于 mini-batch(小批量) 中每个实例的损失函数如下: loss(x, y) = max(0, -y * (x1 - x2) + margin) 如果内部变量 size_average = True, 则损失函数计算批次中所有实例的损失值的平均值; 如果 size_average = False, 则损失函数计算批次中所有实例的损失至的合计. size_average 默认值为 True. HingeEmbeddingLoss class torch.nn.HingeEmbeddingLoss(margin=1.0, size_average=True) 衡量输入 Tensor(张量) x 和 目标 Tensor(张量) y (取值为 1 和 -1) 之间的损失值. 此方法通常用来衡量两个输入值是否相似, 例如使用L1成对距离作为 x, 并且通常用来进行非线性嵌入学习或者 半监督学习: { x_i, if y_i == 1 loss(x, y) = 1/n { { max(0, margin - x_i), if y_i == -1 x 和 y 分别可以是具有 n 个元素的任意形状. 合计操作对所有元素进行计算. 如果 size_average=False, 则计算时不会除以 n 取平均值. margin 的默认值是 1, 或者可以通过构造函数来设置. MultiLabelMarginLoss class torch.nn.MultiLabelMarginLoss(size_average=True) 创建一个标准, 用以优化多元分类问题的合页损失函数 (基于空白的损失), 计算损失值时 需要2个参数分别为输入, x (一个2维小批量 Tensor) 和输出 y (一个2维 Tensor, 其值为 x 的索引值). 对于mini-batch(小批量) 中的每个样本按如下公式计算损失: loss(x, y) = sum_ij(max(0, 1 - (x[y[j]] - x[i]))) / x.size(0) 其中 i 的取值范围是 0 到 x.size(0), j 的取值范围是 0 到 y.size(0), y[j] &gt;= 0, 并且对于所有 i 和 j 有 i != y[j]. y 和 x 必须有相同的元素数量. 此标准仅考虑 y[j] 中最先出现的非零值. 如此可以允许每个样本可以有数量不同的目标类别. SmoothL1Loss class torch.nn.SmoothL1Loss(size_average=True, reduce=True) 创建一个标准, 当某个元素的错误值的绝对值小于1时使用平方项计算, 其他情况则使用L1范式计算. 此方法创建的标准对于异常值不如 MSELoss敏感, 但是同时在某些情况下可以防止梯度爆炸 (比如 参见论文 “Fast R-CNN” 作者 Ross Girshick). 也被称为 Huber 损失函数: { 0.5 * (x_i - y_i)^2, if |x_i - y_i| x 和 y 可以是任意形状只要都具备总计 n 个元素 合计仍然针对所有元素进行计算, 并且最后除以 n. 如果把内部变量 size_average 设置为 False, 则不会被除以 n. 参数： size_average (bool, 可选) – 损失值默认会按照所有元素取平均值. 但是, 如果 size_average 被 设置为 False, 则损失值为所有元素的合计. 如果 reduce 参数设为 False, 则忽略此参数的值. 默认: True reduce (bool, 可选) – 损失值默认会按照所有元素取平均值或者取合计值. 当 reduce 设置为 False 时, 损失函数对于每个元素都返回损失值并且忽略 size_average 参数. 默认: True 形状： 输入: * 代表任意个其他维度 目标: , 同输入 输出: 标量. 如果 reduce 设为 False 则为 , 同输入 SoftMarginLoss class torch.nn.SoftMarginLoss(size_average=True) 创建一个标准, 用以优化两分类的 logistic loss. 输入为 x (一个2维 mini-batch Tensor)和 目标 y (一个包含 1 或者 -1 的 Tensor). loss(x, y) = sum_i (log(1 + exp(-y[i]*x[i]))) / x.nelement() 可以通过设置 self.size_average 为 False 来禁用按照元素数量取平均的正则化操作. MultiLabelSoftMarginLoss class torch.nn.MultiLabelSoftMarginLoss(weight=None, size_average=True) 创建一个标准, 基于输入 x 和目标 y的 max-entropy(最大熵), 优化多标签 one-versus-all 损失. 输入 x 为一个2维 mini-batch Tensor, 目标 y 为2进制2维 Tensor. 对每个 mini-batch 中的样本, 对应的 loss 为: loss(x, y) = - sum_i (y[i] * log( 1 / (1 + exp(-x[i])) ) + ( (1-y[i]) * log(exp(-x[i]) / (1 + exp(-x[i])) ) ) 其中 i == 0 至 x.nElement()-1, y[i] in {0,1}. y 和 x 必须具有相同的维度. CosineEmbeddingLoss class torch.nn.CosineEmbeddingLoss(margin=0, size_average=True) 新建一个标准, 用以衡量输入 Tensor x1, x2 和取值为 1 或者 -1 的标签 Tensor y之间的 损失值. 此标准用 cosine 距离来衡量2个输入参数之间是否相似, 并且一般用来学习非线性 embedding 或者半监督 学习. margin 应该取 -1 到 1 之间的值, 建议取值范围是 0 到 0.5. 如果没有设置 margin 参数, 则默认值取 0. 每个样本的损失函数如下: { 1 - cos(x1, x2), if y == 1 loss(x, y) = { { max(0, cos(x1, x2) - margin), if y == -1 如果内部变量 size_average 设置为 True, 则损失函数以 batch 中所有的样本数取平均值; 如果 size_average 设置为 False, 则损失函数对 batch 中所有的样本求和. 默认情况下, size_average = True. MultiMarginLoss class torch.nn.MultiMarginLoss(p=1, margin=1, weight=None, size_average=True) 创建一个标准, 用以优化多元分类问题的合页损失函数 (基于空白的损失), 计算损失值时 需要2个参数分别为输入, x (一个2维小批量 Tensor) 和输出 y (一个1维 Tensor, 其值为 x 的索引值, 0 y x.size(1)): 对于每个 mini-batch(小批量) 样本: loss(x, y) = sum_i(max(0, (margin - x[y] + x[i]))^p) / x.size(0) 其中 i == 0 至 x.size(0) 并且 i != y. 可选择的, 如果您不想所有的类拥有同样的权重的话, 您可以通过在构造函数中传入 weight 参数来 解决这个问题, weight 是一个1维 Tensor. 传入 weight 后, 损失函数变为: loss(x, y) = sum_i(max(0, w[y] * (margin - x[y] - x[i]))^p) / x.size(0) 默认情况下, 求出的损失值会对每个 minibatch 样本的结果取平均. 可以通过设置 size_average 为 False 来用合计操作取代取平均操作. TripletMarginLoss class torch.nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-06, swap=False) 创建一个标准, 用以衡量三元组合的损失值, 计算损失值时需要3个输入张量 x1, x2, x3 和 一个大于零的 margin 值. 此标准可以用来衡量输入样本间的相对相似性. 一个三元输入组合由 a, p 和 n: anchor, positive 样本 和 negative 样本组成. 所有输入变量的形式必须为 . 距离交换的详细说明请参考论文 Learning shallow convolutional feature descriptors with triplet losses by V. Balntas, E. Riba et al. 其中 . 参数： anchor – anchor 输入 tensor positive – positive 输入 tensor negative – negative 输入 tensor p – 正则化率. Default: 2 形状： 输入： 其中 D = vector dimension 输出： >>> triplet_loss = nn.TripletMarginLoss(margin=1.0, p=2) >>> input1 = autograd.Variable(torch.randn(100, 128)) >>> input2 = autograd.Variable(torch.randn(100, 128)) >>> input3 = autograd.Variable(torch.randn(100, 128)) >>> output = triplet_loss(input1, input2, input3) >>> output.backward() Vision layers (视觉层) PixelShuffle class torch.nn.PixelShuffle(upscale_factor) 对张量中形如 的元素, 重新排列成 . 当使用 stride = 的高效子像素卷积很有用. 参考如下论文获得更多信息: Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network Shi et. al (2016) . 参数：upscale_factor (int) – 增加空间分辨率的因子 形状： 输入: 输出: Examples: >>> ps = nn.PixelShuffle(3) >>> input = autograd.Variable(torch.Tensor(1, 9, 4, 4)) >>> output = ps(input) >>> print(output.size()) torch.Size([1, 1, 12, 12]) Upsample class torch.nn.Upsample(size=None, scale_factor=None, mode='nearest') 对给定的多通道一维时序数据, 二维空间数据, 或三维容积数据进行上采样. 输入数据的格式为 minibatch x channels x [depth] x [height] x width. 因此, 对于2-D空间数据的输入, 期望得到一个4-D张量；对于3-D立体数据输入, 期望得到一个5-D张量. 对3D, 4D, 5D的输入张量进行最近邻、线性、双线性和三线性采样, 可用于该上采样方法. 可以提供 scale_factor 或目标输出的 size 来计算输出的大小. （不能同时都给, 因为这样做是含糊不清的. ） 参数： size (tuple, 可选) – 整型数的元组 ([D_out], [H_out], W_out) 输出大小 scale_factor (int / tuple[int...], 可选) – 图像高度/宽度/深度的乘数 mode (string, 可选) – 上采样算法: nearest | linear | bilinear | trilinear. 默认为: nearest 形状： 输入: , 或 输出: , 或 其中: 或 size[-3] 或 size[-2] 或 size[-1] 示例: >>> inp Variable containing: (0 ,0 ,.,.) = 1 2 3 4 [torch.FloatTensor of size 1x1x2x2] >>> m = nn.Upsample(scale_factor=2, mode='bilinear') >>> m(inp) Variable containing: (0 ,0 ,.,.) = 1.0000 1.3333 1.6667 2.0000 1.6667 2.0000 2.3333 2.6667 2.3333 2.6667 3.0000 3.3333 3.0000 3.3333 3.6667 4.0000 [torch.FloatTensor of size 1x1x4x4] >>> inp Variable containing: (0 ,0 ,.,.) = 1 2 3 4 [torch.FloatTensor of size 1x1x2x2] >>> m = nn.Upsample(scale_factor=2, mode='nearest') >>> m(inp) Variable containing: (0 ,0 ,.,.) = 1 1 2 2 1 1 2 2 3 3 4 4 3 3 4 4 [torch.FloatTensor of size 1x1x4x4] UpsamplingNearest2d class torch.nn.UpsamplingNearest2d(size=None, scale_factor=None) 对多个输入通道组成的输入信号进行2维最近邻上采样. 为了指定采样范围, 提供了 size 或 scale_factor 作为构造参数. 当给定 size, 输出图像的大小为 (h, w). 参数： size (tuple, 可选) – 输出图片大小的整型元组(H_out, W_out) scale_factor (int, 可选) – 图像的 长和宽的乘子. 形状： 输入： 输出： 其中 示例: >>> inp Variable containing: (0 ,0 ,.,.) = 1 2 3 4 [torch.FloatTensor of size 1x1x2x2] >>> m = nn.UpsamplingNearest2d(scale_factor=2) >>> m(inp) Variable containing: (0 ,0 ,.,.) = 1 1 2 2 1 1 2 2 3 3 4 4 3 3 4 4 [torch.FloatTensor of size 1x1x4x4] UpsamplingBilinear2d class torch.nn.UpsamplingBilinear2d(size=None, scale_factor=None) 对多个输入通道组成的输入信号进行2维双线性上采样. 为了指定采样范围, 提供了 size 或 scale_factor 作为构造参数. 当给定 size, 输出图像的大小为 (h, w). 参数： size (tuple, 可选) – 输出图片大小的整型元组(H_out, W_out) scale_factor (int, 可选) – 图像的 长和宽的乘子. 形状： 输入： 输出： 其中 示例： >>> inp Variable containing: (0 ,0 ,.,.) = 1 2 3 4 [torch.FloatTensor of size 1x1x2x2] >>> m = nn.UpsamplingBilinear2d(scale_factor=2) >>> m(inp) Variable containing: (0 ,0 ,.,.) = 1.0000 1.3333 1.6667 2.0000 1.6667 2.0000 2.3333 2.6667 2.3333 2.6667 3.0000 3.3333 3.0000 3.3333 3.6667 4.0000 [torch.FloatTensor of size 1x1x4x4] DataParallel layers (multi-GPU, distributed) (数据并行层, 多 GPU 的, 分布式的) DataParallel class torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0) 在模块级别实现数据并行性. 此容器通过在批次维度中分块, 将输入分割到指定设备上, 从而并行化给定模块的应用程 序.在正向传递中, 模块被复制到每个设备上, 每个副本处理一部分输入.在向后传递期间, 来自每个副本的梯度变化被汇总到原始模块中. batch size 应该大于 GPUs 的数量.同时也应该是 GPU 数量的整数倍, 以 便每个块大小相同（以便每个 GPU 处理相同数量的样本）. 引用 :使用 nn.DataParallel 替代 multiprocessing 允许将任意位置和关键字输入传入 DataParallel EXCEPT Tensors. 所有的变量将被分 散在指定的维度（默认为0）.原始类型将被广播, 但所有其他类型将是一个浅层副本, 如 果写入模型的正向传递, 可能会被损坏. Args : module: 并行的模型 device_ids: CUDA devices（CUDA 驱动） (default: all devices) output_device: 输出设备位置 (default: device_ids[0]) 示例 :: >>> net = torch.nn.DataParallel(model, device_ids=[0, 1, 2]) >>> output = net(input_var) DistributedDataParallel class torch.nn.parallel.DistributedDataParallel(module, device_ids=None, output_device=None, dim=0) 在模块级别实现分布式数据并行. 此容器通过在批次维度中分块, 将输入分割到指定设备上, 从而并行化给定模块的应用程序. 该模块被复制到每台机器和每个设备上, 每个这样的副本处理一部分输入.在向后传递期间, 来自每个节点的梯度被平均. batch size 应该大于 GPUs 的数量.同时也应该是 GPU 数量的整数倍, 以便每个块大小 相同（以便每个 GPU 处理相同数量的样本）. 引用 :Basics](distributed.html#distributed-basics) 和 使用 nn.DataParallel 替代 multiprocessing. 对输入的约束和 [torch.nn.DataParallel 中一样. 创建这个类需要分布式包已经在 process group 模式下被初始化 (引用 torch.distributed.init_process_group()). 警告： 这个模块只能和gloo后端一起工作. 警告： 构造器, 转发方法和输出（或者这个模块的输出功能）的区分是分布式同步点.考虑到不同的 进程可能会执行不同的代码. 警告： 该模块假设所有参数在创建时都在模型中注册.之后不应该添加或删除参数.同样适用于缓冲区. 警告： 这个模块假定所有的缓冲区和梯度都是密集的. 警告： 这个模块不能用于 : func: torch.autograd.grad （即只有在参数的 .grad 属性中 累积梯度才能使用）. 注解： 参数永远不会在进程之间广播.模块在梯度上执行全部优化步骤, 并假定它们将以相同的方式在 所有进程中进行优化.缓冲区（e.g. BatchNorm stats）在等级0的过程中从模块广播到系统 中的每个迭代中的所有其他副本. Args : module: 需要并行的模型 device_ids: CUDA devices (default: all devices) output_device: device location of output (default: device_ids[0]) 示例 :: >>> torch.distributed.init_process_group(world_size=4, init_method='...') >>> net = torch.nn.DistributedDataParallel(model) Utilities (工具包) clip_grad_norm torch.nn.utils.clip_grad_norm(parameters, max_norm, norm_type=2) 接收一个包含 Variable 的可迭代对象, 对 Variable 的梯度按范数进行裁剪. 范数是对所有梯度进行计算的, 等价于把所有输入变量的梯度连接成一个向量, 然后对这个向量按范数进行裁剪. 梯度将会被原地修改. 参数： parameters (Iterable[Variable]) – 一个可迭代对象, 其包含将要进行梯度正规化的 Variable max_norm (float 或 int) – 梯度的最大范数 norm_type (float 或 int) – p 范数(指定 p ). 用 'inf' 表示无穷范数 返回值：梯度的范数 (视为单个向量的). weight_norm torch.nn.utils.weight_norm(module, name='weight', dim=0) 将权重归一化应用于给定模块中的指定参数. . 权重归一化是将权重张量的大小和方向分离的再参数化. 该函数会用两个参数代替 name (e.g. “weight”)所指定的参数. 在新的参数中, 一个指定参数的大小 (e.g. “weight_g”), 一个指定参数的方向. 权重归一化是通过一个钩子实现的, 该钩子会在 ~Module.forward 的每次调用之前根据大小和方向(两个新参数)重新计算权重张量. 默认情况下, dim=0, 范数会在每一个输出的 channel/plane 上分别计算. 若要对整个权重张量计算范数, 使用 dim=None. 参见 https://arxiv.org/abs/1602.07868 参数： module (nn.Module) – 给定的 module name (str, 可选) – 权重参数的 name dim (int, 可选) – 进行范数计算的维度 返回值：添加了权重归一化钩子的原 module 示例： >>> m = weight_norm(nn.Linear(20, 40), name='weight') Linear (20 -> 40) >>> m.weight_g.size() torch.Size([40, 1]) >>> m.weight_v.size() torch.Size([40, 20]) remove_weight_norm torch.nn.utils.remove_weight_norm(module, name='weight') 从模块中移除权重归一化/再参数化. 参数： module (nn.Module) – 给定的 module name (str, 可选) – 权重参数的 name 示例： >>> m = weight_norm(nn.Linear(20, 40)) >>> remove_weight_norm(m) PackedSequence torch.nn.utils.rnn.PackedSequence(_cls, data, batch_sizes) 保存一个打包序列的 data 和 batch_sizes. 所有的 RNN 模块都接收这种被包裹后的序列作为它们的输入. 注解： 永远不要手动创建这个类的实例. 它们应当被 pack_padded_sequence() 这样的函数实例化. 变量： data (Variable) – 包含打包后序列的 Variable batch_sizes (list[int]) – 包含每个序列步的 batch size 的列表 pack_padded_sequence torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False) 将填充过的变长序列打包(压紧). 输入的形状可以是 TxBx* . T是最长序列长度(等于 lengths[0]), B是批量大小, *代表任意维度(可以是 0). 如果 batch_first=True , 那么相应的输入大小就是 BxTx* . Variable 中保存的序列, 应该按序列长度的长短排序, 长的在前, 短的在后. 即 input[:,0] 代表的是最长的序列, input[:, B-1] 保存的是最短的序列. 注解： 只要是维度大于等于2的 input 都可以作为这个函数的参数. 你可以用它来打包 labels, 然后用 RNN 的输出和打包后的 labels 来计算 loss. 通过 PackedSequence 对象的 .data 属性可以获取 Variable. 参数： input (Variable) – 变长序列被填充后的 batch lengths (list[int]) – Variable 中每个序列的长度. batch_first (bool, 可选) – 如果是 True, input 的形状应该是 BxTx*. 返回值：一个 PackedSequence 对象. pad_packed_sequence torch.nn.utils.rnn.pad_packed_sequence(sequence, batch_first=False, padding_value=0.0) 填充打包过的变长序列. 这是 pack_padded_sequence() 的逆操作. 返回的 Varaible 的值的 size 是 TxBx*, T 是最长序列的长度, B 是 batch_size, 如果 batch_first=True, 那么返回值是 BxTx*. Batch中的元素将会以它们长度的逆序排列. 参数： sequence (PackedSequence) – 将要被填充的 batch batch_first (bool, 可选) – 如果为 True , 返回的数据的格式为 BxTx*. padding_value (float, 可选) – 用来填充元素的值 返回值：一个 tuple, 包含被填充后的序列, 和 batch 中序列的长度列表. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"optim.html":{"url":"optim.html","title":"torch.optim","keywords":"","body":"torch.optim 译者：@于增源 校对者：@青梅往事 torch.optim is a package implementing various optimization algorithms. Most commonly used methods are already supported, and the interface is general enough, so that more sophisticated ones can be also easily integrated in the future. 如何使用 optimizer (优化器) 为了使用 torch.optim 你需要创建一个 optimizer 对象, 这个对象能够保持当前的状态以及依靠梯度计算 来完成参数更新. 构建 要构建一个 Optimizer 你需要一个可迭代的参数 (全部都应该是 Variable) 进行优化. 然后, 你能够设置优化器的参数选项, 例如学习率, 权重衰减等. 注解： 如果你需要通过 .cuda() 将模型移动到 GPU 上, 请在构建优化器之前来移动. 模型的参数在进行 .cuda() 之后将变成不同的对象,该对象与之前调用的参数不同. 通常来说, 在对优化器进行构建和调用的时候, 你应该要确保优化参数位于相同的 地点. 例子 optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9) optimizer = optim.Adam([var1, var2], lr = 0.0001) 为每个参数单独设置选项 Optimizer 也支持为每个参数单独设置选项. 若要这么做, 不要直接使用 ~torch.autograd.Variable 的迭代, 而是使用 dict 的迭代. 每一个 dict 都分别定义了一组参数, 并且应该要包含 params 键,这个键对应列表的参数. 其他的键应该与 optimizer 所接受的其他参数的关键字相匹配, 并且会被用于对这组参数的优化. 注解： 你仍然能够传递选项作为关键字参数.在未重写这些选项的组中, 它们会被用作默认值. 这非常适用于当你只想改动一个参数组的选项, 但其他参数组的选项不变的情况. 例如, 当我们想指定每一层的学习率时, 这是非常有用的: optim.SGD([ {'params': model.base.parameters()}, {'params': model.classifier.parameters(), 'lr': 1e-3} ], lr=1e-2, momentum=0.9) 这意味着 model.base 的参数将会使用 1e-2 的学习率,model.classifier 的参数将会使用 1e-3 的学习率, 并且 0.9 的 momentum 将应用于所有参数. 进行单步优化 所有的优化器都实现了 step() 方法, 且更新到所有的参数. 它可以通过以下两种方式来使用: optimizer.step() 这是大多数 optimizer 所支持的简化版本. 一旦使用 backward() 之类的函数计算出来梯度之后我们就可以调用这个函数了. 例子 for input, target in dataset: optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() optimizer.step() optimizer.step(closure) 一些优化算法例如 Conjugate Gradient 和 LBFGS 需要重复多次计算函数, 因此你需要传入一个闭包去允许它们重新计算你的模型. 这个闭包应当清空梯度, 计算损失, 然后返回. 例子 for input, target in dataset: def closure(): optimizer.zero_grad() output = model(input) loss = loss_fn(output, target) loss.backward() return loss optimizer.step(closure) 算法 class torch.optim.Optimizer(params, defaults) 优化器的基类. 参数： params (iterable): Variable 或 dict 的迭代, 指定了应该优化哪些参数. defaults (dict): 包含了优化选项默认值的字典(一个参数组没有指定的参数选项将会使用默认值). add_param_group(param_group) 增加一组参数到 Optimizer 的 param_groups 里面. 当微调一个预训练好的网络作为冻结层时是有用的, 它能够使用可训练的和可增加的参数到 Optimizer 作为一个训练预处理. 参数：param_group (dict) – 指定这一组中具有特殊优化选项的那些 Variables 能够被优化. load_state_dict(state_dict) 加载优化器状态. 参数：state_dict (dict) – 优化器状态. 是调用 state_dict() 时所返回的对象. state_dict() 以 dict 的形式返回优化器的状态. 它包含两部分内容: state - 一个包含当前优化状态的字典（dict）, 字典里的内容因优化器的不同而变换. param_groups - 一个包含所有参数组的字典（dict）. step(closure) 进行单次优化(参数更新). 参数：closure (callable) – 一个重新评价模型并返回 loss 的闭包大多数优化器可选择. zero_grad() Clears the gradients of all optimized Variable s. class torch.optim.Adadelta(params, lr=1.0, rho=0.9, eps=1e-06, weight_decay=0) 实施 Adadelta 算法. 它在 ADADELTA: 一种可调节学习率的方法 中提出 Args: params (iterable): 通过参数迭代去优化或者字典的形式定义参数组. rho (float, 可选): 用来计算平均平方梯度的系数(默认值: 0.9) eps (float, 可选): 增加分母来确保数值稳定性(默认值: 1e-6) lr (float, 可选): 在将 delta 应用于参数之前对其进行系数的缩放(默认值: 1.0) * weight_decay (float, 可选): 权重衰减 (L2正则化) (默认值: 0) step(closure=None) 实行单步优化. 参数：closure (callable, 可选) – 重新评估模型并返回误差损失的闭包. class torch.optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0) 实现 Adagrad 算法. 它在 Adaptive Subgradient Methods for Online Learning and Stochastic Optimization 中被提出. Args: params (iterable): 迭代的优化参数或者以字典的形式定义参数组 lr (float, 可选): 学习率 (默认值: 1e-2) lr_decay (float, 可选): 学习率衰减 (默认值: 0) weight_decay (float, 可选): 权重衰减 (L2正则化) (默认值: 0) step(closure=None) 进行单步优化. 参数：closure (callable, 可选) – 一个重新评价模型并返回误差的闭包. class torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0) 实现 Adam 算法. 它在 Adam: A Method for Stochastic Optimization 中被提出. Args: params (iterable): 迭代的优化参数或者以字典的形式定义参数组. lr (float, 可选): 学习率 (默认值: 1e-3) betas (Tuple[float, float], 可选): 用来计算梯度和平方梯度的系数 (默认值: (0.9, 0.999)) eps (float, 可选): 增加分母来确保数值稳定性 (默认值: 1e-8) * weight_decay (float, 可选): 权重衰减 (L2 正则化) (默认值: 0) step(closure=None) 进行单步优化. 参数：closure (callable, 可选) – 一个重新评价模型并返回误差的闭包. class torch.optim.SparseAdam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08) 实现上一版本 Adam 算法来适用于 sparse tensors. 在这个变化下,只将显示出来的梯度进行更新存储并且只将这部分梯度应用到参数中. Args: params (iterable): 待优化的迭代参数或者是定义了参数组的 dict lr (float, 可选): 学习率 (default: 1e-3) betas (Tuple[float, float], 可选): 用来计算梯度和平方梯度的系数 (默认值: (0.9, 0.999)) eps (float, 可选): 增加分母来确保数值稳定性 (默认值: 1e-8) step(closure=None) 进行单步优化. 参数：closure (callable, 可选) – 一个重新评价模型并返回 loss 的闭包, 对于大多数参数来说是可选的. class torch.optim.Adamax(params, lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0) 实现 Adamax 算法 ( Adam 的一种基于无穷范数的变种). 它在 Adam: A Method for Stochastic Optimization 中被提出. Args: params (iterable): 迭代的优化参数或者以字典的形式定义参数组. lr (float, 可选): 学习率 (默认值: 2e-3) betas (Tuple[float, float], 可选): 用来计算梯度和平方梯度的系数 eps (float, 可选): 增加分母来确保数值稳定性 (默认值: 1e-8) * weight_decay (float, 可选): 权重衰减 (L2 正则化) (默认值: 0) step(closure=None) 进行单步优化. 参数：closure (callable, 可选) – 一个重新评价模型并返回误差的闭包. class torch.optim.ASGD(params, lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0) 实现平均随机梯度下降算法. 它在 Acceleration of stochastic approximation by averaging 中被提出 Args: params (iterable): 迭代的优化参数或者以字典的形式定义参数组 lr (float, 可选): 学习率 (默认值: 1e-2) lambd (float, 可选): 衰减期 (默认值: 1e-4) alpha (float, 可选): eta 更新的权重 (默认值: 0.75) t0 (float, 可选): 指明在哪一次开始平均化 (默认值: 1e6) weight_decay (float, 可选): 权重衰减 (L2 正则化) (默认值: 0) step(closure=None) 进行单步优化. 参数：closure (callable, 可选) – 一个重新评价模型并返回误差的闭包. class torch.optim.LBFGS(params, lr=1, max_iter=20, max_eval=None, tolerance_grad=1e-05, tolerance_change=1e-09, history_size=100, line_search_fn=None) 实现 L-BFGS 算法. 警告： 这个 optimizer 不支持为每个参数单独设置选项以及不支持参数组（只能有一个）. 警告： 目前所有的参数不得不都在同一设备上. 这在将来会得到改进. 注解： 这是一个内存高度密集的 optimizer (它要求额外的 param_bytes * (history_size + 1) 个字节). 如果它不适应内存, 尝试减小历史规格, 或者使用不同的算法. Args: lr (float): 学习率 (默认值: 1) max_iter (int): 每一步优化的最大迭代次数 (默认值: 20) max_eval (int): 每一步优化的最大函数评估次数 (默认值: max_iter 1.25). tolerance_grad (float): 一阶最优的终止容忍度 (默认值: 1e-5). tolerance_change (float): 在函数值/参数变化量上的终止容忍度 (默认值: 1e-9). * history_size (int): 更新历史尺寸 (默认值: 100). step(closure) 进行单步优化. 参数：closure (callable) – 一个重新评价模型并返回 loss 的闭包, 对于大多数参数来说是可选的. class torch.optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False) 实现 RMSprop 算法. 由 G. Hinton 在此提出 course. 中心版本首次出现在 Generating Sequences With Recurrent Neural Networks. 算法: params (iterable): 待优化的迭代参数或者是定义了参数组的 dict lr (float, 可选): 学习率 (默认值: 1e-2) momentum (float, 可选): 动量因子 (默认值: 0) alpha (float, 可选): 平滑常量 (default: 0.99) eps (float, 可选): 为了增加数值计算的稳定性而加到分母里的项 (默认值: 1e-8) centered (bool, 可选) : 如果为 True, 计算 RMSProp 的中值, 并且用它的方差预测值对梯度进行归一化 * weight_decay (float, 可选): weight decay (L2 penalty) (default: 0) step(closure=None) Performs a single optimization step. 参数：closure (callable, 可选) – A closure that reevaluates the model and returns the loss. class torch.optim.Rprop(params, lr=0.01, etas=(0.5, 1.2), step_sizes=(1e-06, 50)) 实现弹性反向传播算法. Args: params (iterable): 待优化的迭代参数或者是定义了参数组的 dict lr (float, 可选): 学习率 (默认值: 1e-2) * etas (Tuple[float, float], 可选): 一对 (etaminus, etaplis), t它们分别是乘法 的增加和减小的因子 (默认值: (0.5, 1.2)) step_sizes (Tuple[float, float], 可选): 允许的一对最小和最大的步长 (默认值: (1e-6, 50)) step(closure=None) 进行单步优化. 参数：closure (callable, 可选) – 一个重新评价模型并返回 loss 的闭包, 对于大多数参数来说是可选的. class torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False) 实现随机梯度下降算法（ momentum 可选）. Nesterov 动量基于 On the importance of initialization and momentum in deep learning 中的公式. Args: params (iterable): 待优化的迭代参数或者是定义了参数组的 dict lr (float): 学习率 momentum (float, 可选): 动量因子 (默认值: 0) weight_decay (float, 可选): 权重衰减 (L2 正则化) (默认值: 0) dampening (float, 可选): 动量的抑制因子 (默认值: 0) nesterov (bool, 可选): 使用 Nesterov 动量 (默认值: False) 示例： >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) >>> optimizer.zero_grad() >>> loss_fn(model(input), target).backward() >>> optimizer.step() 注解： 带有动量 /Nesterov 的 SGD 的实现稍微不同于 Sutskever 等人以及其他框架中的实现. 考虑动量的具体情况, 更新可以写成 其中 p, g, v 和 分别是参数、梯度、速度和动量. 这跟 Sutskever 等人以及其他框架的实现是相反的, 它们采用这样的更新. Nesterov 的版本也相应的被修改了. step(closure=None) 进行单步优化. 参数：closure (callable, 可选) – 一个重新评价模型并返回 loss 的闭包, 对于大多数参数来说是可选的. 如何调整学习率 mod: torch.optim.lr_scheduler 基于循环的次数提供了一些方法来调节学习率. class: torch.optim.lr_scheduler.ReduceLROnPlateau 基于验证测量结果来设置不同的学习率. --- --- class torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-1) 将每个参数组的学习速率设置为给定函数的初始LR. 当 last_epoch=-1, 设置出事的 lr 作为 lr. Args: optimizer (Optimizer): 封装好的优化器. lr_lambda (function or list): 计算给定整数参数历元的乘法因子的函数, 或者一系列的此类函数, 每组的一个都在 optimizer.param_groups 中. * last_epoch (int): 最后一个 epoch 的索引. 默认值: -1. 示例： >>> # Assuming optimizer has two groups. >>> lambda1 = lambda epoch: epoch // 30 >>> lambda2 = lambda epoch: 0.95 ** epoch >>> scheduler = LambdaLR(optimizer, lr_lambda=[lambda1, lambda2]) >>> for epoch in range(100): >>> scheduler.step() >>> train(...) >>> validate(...) class torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1) 通过 gamma 在每一个 epoch 里面的 step_size 设置每个参数组的初始学习率衰减变量. 当 last_epoch=-1, 设置初始 lr 为 lr. Args: optimizer (Optimizer): 封装好的优化器. step_size (int): 学习率衰减周期. gamma (float): 学习率衰减的乘法因子. 默认值: 0.1. last_epoch (int): 最后一个 epoch 的索引. 默认值: -1. 示例： >>> # Assuming optimizer uses lr = 0.5 for all groups >>> # lr = 0.05 if epoch >> # lr = 0.005 if 30 >> # lr = 0.0005 if 60 >> # ... >>> scheduler = StepLR(optimizer, step_size=30, gamma=0.1) >>> for epoch in range(100): >>> scheduler.step() >>> train(...) >>> validate(...) class torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1, last_epoch=-1) 一旦 epoch 的数量达到了一个临界点通过 gamma 在每一个 epoch 里面的 step_size 设置每个参数 组的初始学习率衰减变量.当 last_epoch=-1, 设置初始 lr 作为 lr. Args: optimizer (Optimizer): 封装好的优化器. milestones (list): epoch 索引列表. 必须为递增的. * gamma (float): 学习率衰减的乘法因子. 默认值: 0.1. last_epoch (int): 最后一个 epoch 的索引. 默认值: -1. 示例： >>> # Assuming optimizer uses lr = 0.5 for all groups >>> # lr = 0.05 if epoch >> # lr = 0.005 if 30 >> # lr = 0.0005 if epoch >= 80 >>> scheduler = MultiStepLR(optimizer, milestones=[30,80], gamma=0.1) >>> for epoch in range(100): >>> scheduler.step() >>> train(...) >>> validate(...) class torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma, last_epoch=-1) 通过 gamma 在每一个 epoch 里面的 step_size 设置每个参数组的初始学习率衰减变量 . 当 last_epoch=-1, 设置初始 lr 作为 lr. :param optimizer: 封装好的优化器. :type optimizer: Optimizer :param gamma: 学习率衰减的乘法因子. :type gamma: float :param last_epoch: 最后一个 epoch 的索引. 默认值: -1. :type last_epoch: int class torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=False, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08) 当一个指标已经停止提升时减少学习率.模型通常受益于通过一次2-10的学习停止因素减少学习率 这个调度程序读取一个指标质量 以及看到 ‘patience’ 的数量在一个 epoch 里面如果没有提升, 这时学习率已经减小. Args: * optimizer (Optimizer): 封装好的优化器. mode (str): min, max 其中一个. 在 min 模块下,当质量监测已经 停止下降时 lr 将被减少; 在 max 模块下 当质量监测已经停止上升时 lr 将 被减少. 默认值: ‘min’. factor (float): 哪个学习率将会被减少的影响因子 . new_lr = lr * factor. 默认值: 0.1. patience (int): epoch 中没有改善的次数, 学习率将会降低. . 默认值: 10. verbose (bool): 若为 True, 每次更新打印信息到控制台输出. 默认值: False. threshold (float): 测量新的最佳阈值, 只关注有重大意义的改变. 默认值: 1e-4. threshold_mode (str): rel, abs 中的一个. 在 rel 模式下, dynamic_threshold = best ( 1 + threshold ) 在 ‘max’ 模式下或者在 min 模式下 best ( 1 - threshold ) . 在 abs 模式下, dynamic_threshold = best + threshold 在 max 模式下或者在 min 模式下 best - threshold . 默认值: ‘rel’. cooldown (int): lr 已经减少之后去等待最佳的正常操作之前的 epoch 数目. 默认值: 0. min_lr (float or list): 一个列表的标量.所有参数组或每个组的学习率下限. 默认值: 0. eps (float): lr 最小的衰减值适应于. 如果新 lr 和旧 lr 之间的差异小于 eps,更新可以忽略. 默认值: 1e-8. 示例： >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9) >>> scheduler = ReduceLROnPlateau(optimizer, 'min') >>> for epoch in range(10): >>> train(...) >>> val_loss = validate(...) >>> # Note that step should be called after validate() >>> scheduler.step(val_loss) 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"autograd.html":{"url":"autograd.html","title":"Automatic differentiation package - torch.autograd","keywords":"","body":"Automatic differentiation package - torch.autograd 译者：@ZhenLei Xu 校对者：@青梅往事 torch.autograd 提供了类和函数用来对任意标量函数进行求导.只需要对已有的代码进行微小的改变-只需要将所有的 tensors 包含在 Variable 对象中即可. torch.autograd.backward(variables, grad_variables=None, retain_graph=None, create_graph=None, retain_variables=None) 给定图某一个的节点变量variables,计算对该变量求导的梯度和. 计算图可以通过链式法则求导.如果任何 variables 都是非标量(比如 他们的 data 属性中有多个元素)并且需要求导, 那么此函数需要指定 grad_variables. 它的长度应该和variables的长度匹配,里面保存了相关 variable 的梯度 (对于不需要 gradient tensor 的 variable, 应制定为 None). 此函数累积叶子节点 variables 计算的梯度 - 调用此函数之前应先将叶子节点 variables 梯度置零. 参数: variables (Variable 列表): 被求微分的叶子节点. grad_variables ((Tensor, Variable 或 None) 列表):对应 variable 的梯度. 任何张量将自动转换为变量除非create_graph 是 True. 没有值可以被指定为标量变量或者不需要被求导. 如果没有值被所有的grad_variables接受, 那么该参数是可以被省略的. retain_graph (bool, 可选): 如果是 False, 该图计算过的梯度被释放掉.注意的是,几乎所有情况都设置为True并不是必须的并且能够高效的计算.将该 create_graph 参数值设置为默认即可. create_graph (bool, 可选): 如果是 True, 将会建立一个梯度图, 用来求解高阶导数.默认为 False, 除非 grad_variables 拥有不止一个 易变的 Variable. torch.autograd.grad(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=None, only_inputs=True, allow_unused=False) 计算并返回给定值的梯度的和. grad_outputs 是一个列表同时长度与 output 一样, 存放了预先计算 input 的梯度的和. 如果 output 不需要被求导, 那么梯度将为 None). 当不需要派生图时,可以将梯度作为张量,或者作为变量,在这种情况下,图将被创建. 如果参数 only_inputs 为 True, 该方法将会返回给定输入的梯度值列表.如果为 False, 那么遗留下来的所有叶子节点的梯度都会被计算, 被且会被列加到 .grad 参数中. 参数: outputs (变量序列): 梯度函数的返回值. inputs (变量序列): 需要计算的梯度的输入 (并且不会被累加到 .grad 参数中). grad_outputs (张量或变量序列): 每一个输出的梯度. 所有的张量都会变成变量并且是可变的除非参数 create_graph 为 True. 没有值可以被指定为标量变量或者不需要变化的值. 如果所有 grad_variabls 都可以接受 None 值,那么这个参数是可选的. retain_graph (bool, 可选): 如果是 False, 用于计算 grad 的图将被释放. 几乎所有情况都设置为True 并不是必须的并且能够高效地运行. 默认与 create_graph 参数一样. create_graph (bool, 可选): 如果是 True, 梯度图将会被建立,用来求解高阶导数. 默认为 False , 除非参数 grad_variables 包含不只一个变量. only_inputs (bool, 可选): 如果是 True, 叶子节点的导数将会在图中, 但是不会出现在参数 inputs 也不会被计算以及累加. 默认为 True. allow_unused (bool, 可选): 如果是 False, 指定计算输出时未使用的输入（因此它们的 grad 始终为零）是错误的. 默认为 False. Variable (变量) API compatibility Variable API 几乎与常规 Tensor API 相同(一些会覆盖梯度计算输入的内置方法除外). 在大多数情况下, 变量量可以安全地替换张量并且代码将保持正常工作. 因为这个, 我们没有记录变量上的所有操作, 你应该参阅 torch.Tensor 文档来查看变量上的所有操作. In-place operations on Variables 在 autograd 支持就地操作是一件困难的事情, 在大多数情况下我们不鼓励使用. Autograd 积极的缓冲区释放和重用使得它非常高效, 而且很少有就地操作实际上大量地降低了内存使用量的情况. 除非你正在大量的的内存压力下运行, 否则你可能永远不需要使用它们. In-place correctness checks 所有的 Variable 跟踪适用于它们的就地操作, 并且如果实现检测到一个变量是否被其中一个函数后台保存, 但是之后它被就地修改了, 会在开始求导时会报出异常. 这确保了如果你在就地使用函数并没有看到任何错误, 你可以肯定的是计算变量是正确的. class torch.autograd.Variable 封装一个张量用来各种操作. 变量是张量对象周围的轻包装,能够拥有导数等数据, 这个引用允许回溯整个操作链创建数据. 如果变量已经由用户创建, 它的 grad_fn 为 None 我们称之为叶子节点. 由于 autograd 只支持标量值函数微分, grad 大小始终与数据大小匹配. 此外,导数通常只分配 叶变量,否则将始终为零. 参数: data: 包裹任何类型的张量. grad: 变量保持类型和位置匹配的变量 .data. 这个属性是懒惰的分配,不能被重新分配. requires_grad: 指示变量是否已被使用的布尔值由包含任何变量的子图创建,需要它. 有关更多详细信息,请参阅 excluded-subgraphs.只能在叶变量上进行更改. volatile: 布尔值表示应该使用变量推理模式,即不保存历史. 查看 反向排除 subgraphs (子图) 更多细节. 只能在叶变量上进行更改. is_leaf: 指示是否为叶子节点,即是否由用户创建的节点. grad_fn: 导数函数跟踪. 参数: data (任何 tensor 类): 用来包装的张量. requires_grad (bool): 指示是否要被求导. 仅限关键字. volatile (bool): 指示是否可变. 仅限关键字. backward(gradient=None, retain_graph=None, create_graph=None, retain_variables=None) 给定图叶子节点计算导数. 该图使用链式规则进行计算. 如果变量是非标量（即其数据具有多个元素）并且需要 改变,该功能另外需要指定“梯度”.它应该是一个包含匹配类型和位置的张量 微分函数的梯度w.r.t. self . 这个功能在叶子上累积梯度 - 你可能需要调用之前将它们置零. 参数: gradient (Tensor, Variable or None): 计算变量的梯度. 如果是张量,则会自动转换到一个变量,这是挥发性的,除非 create_graph 为真.没有值可以被指定为标量变量或那些 不要求毕业. 如果一个None值是可以接受的这个参数是可选的. retain_graph (bool, 可选): 如果 “False” ,则用于计算的图形导数将被释放. 请注意,在几乎所有情况下设置这个选项为 True 是不需要的,通常可以解决在一个更有效的方式. 默认值为create_graph. create_graph (bool, 可选): 如果“真”,派生图将会被构造,允许计算更高阶的导数. 默认为 False,除非 gradient 是一个volatile变量. detach() 将一个Variable从创建它的图中分离,并把它设置成 leaf variable. 返回变量使用与原始数据张量相同的数据张量,其中任何一个的就地修改都将被看到,并可能触发 错误在正确性检查. detach_() 将一个 Variable 从创建它的图中分离,并把它设置成 leaf variable. register_hook(hook) 注册一个backward钩子. 每次gradients被计算的时候,这个 hook 都被调用 .hook 应该拥有以下签名: hook(grad) -> Variable or None hook不应该修改它的输入,但是它可以选择性的返回一个替代当前梯度的新梯度. 这个函数返回一个 句柄 (handle).它有一个方法 handle.remove(),可以用这个方法将 hook 从 module 移除. 示例： >>> v = Variable(torch.Tensor([0, 0, 0]), requires_grad=True) >>> h = v.register_hook(lambda grad: grad * 2) # double the gradient >>> v.backward(torch.Tensor([1, 1, 1])) >>> v.grad.data 2 2 2 [torch.FloatTensor of size 3] >>> h.remove() # removes the hook retain_grad() 为非叶变量启用 .grad 属性. Function (函数) class torch.autograd.Function 记录操作历史记录并定义区分操作的方法. 每个执行在 Varaibles 上的 operation 都会创建一个 Function 对象,这个 Function 对象执行计算工作,同时记录下来.这个历史以有向无环图的形式保存下来, 有向图的节点为 functions ,有向图的边代表数据依赖关系 (input 通常情况下,用户能和 Functions 交互的唯一方法就是创建 Function 的子类,定义新的 operation. 这是扩展 torch.autograd 的推荐方法. 每个 Function 只被使用一次(在forward过程中). 参数: requires_grad: 布尔类型依赖于方法 backward() 会不会还会被使用. 比如: >>> class Exp(Function): >>> >>> @staticmethod >>> def forward(ctx, i): >>> result = i.exp() >>> ctx.save_for_backward(result) >>> return result >>> >>> @staticmethod >>> def backward(ctx, grad_output): >>> result, = ctx.saved_variables >>> return grad_output * result static backward(ctx, *grad_outputs)[source] 定义反向传播操作 这个方法将会被继承他的所有子类覆盖. 第一个参数为上下文参数, 接下来可以输入任何张量或变量 (张量或其他类型), 并且有多个返回值, 并且为函数 forward() 的输入. 每个参数都是给定输出的导数, 并且每一个输出都是输入的导数. 上下文可以用来检索转发过程中保存的变量. static forward(ctx, *args, **kwargs) 进行操作. 这个方法将会被继承他的所有子类覆盖. 第一个参数为上下文参数,接下来可以输入任何张量或变量 (张量或其他类型). 上下文可以用来存储可以在回传期间检索的变量. Profiler(分析器) Autograd 包含一个分析器, 可以让你检查你的模型在CPU 和 GPU 上不同运算的成本. 目前实现有两种模式 - 只使用 CPU 的 profile. 和基于 nvprof (注册 CPU 和 GPU 活动) 的方式使用 emit_nvtx. class torch.autograd.profiler.profile(enabled=True) 结果的评价指标. 参数：enabled (bool, 可选) – 如果设置为 False ,则没有评价指标. Default: True. 示例： >>> x = Variable(torch.randn(1, 1), requires_grad=True) >>> with torch.autograd.profiler.profile() as prof: ... y = x ** 2 ... y.backward() >>> # NOTE: some columns were removed for brevity ... print(prof) ------------------------------------- --------------- --------------- Name CPU time CUDA time ------------------------------------- --------------- --------------- PowConstant 142.036us 0.000us N5torch8autograd9GraphRootE 63.524us 0.000us PowConstantBackward 184.228us 0.000us MulConstant 50.288us 0.000us PowConstant 28.439us 0.000us Mul 20.154us 0.000us N5torch8autograd14AccumulateGradE 13.790us 0.000us N5torch8autograd5CloneE 4.088us 0.000us export_chrome_trace(path) 将EventList导出为Chrome跟踪工具文件. 断点能够通过 chrome://tracing URL来读取. 参数：path (str) – 制定断点写的路径. key_averages() 平均所有的功能指标通过他们的键. 返回值：包含 FunctionEventAvg 对象的 EventList. table(sort_by=None) 打印操作表 参数：sort_by (str, 可选) – 用来对参数进行排序. 默认情况下,它们以与登记相同的顺序打印. 有效的键: cpu_time, cuda_time, cpu_time_total, cuda_time_total, count. 返回值：包含表的字符串. total_average() 所有事件的平均指标. 返回值：一个 FunctionEventAvg 对象. class torch.autograd.profiler.emit_nvtx(enabled=True) 使每个autograd操作都发出一个NVTX范围的上下文管理器. 如下使用是正确的: nvprof --profile-from-start off -o trace_name.prof -- 不幸的是,没有办法强制nvprof刷新收集到的数据到磁盘,因此对于 CUDA 分析,必须使用此上下文管理器进行注释 nvprof 跟踪并等待进程在检查之前退出. 然后,可以使用NVIDIA Visual Profiler（nvvp）来显示时间轴,或者 torch.autograd.profiler.load_nvprof() 可以加载检查结果. 参数：enabled (bool, 可选) – 如果设置为 False ,则没有评价指标. 默认: True. 示例： >>> with torch.cuda.profiler.profile(): ... model(x) # Warmup CUDA memory allocator and profiler ... with torch.autograd.profiler.emit_nvtx(): ... model(x) torch.autograd.profiler.load_nvprof(path) 打开 nvprof trace 文件. 参数：path (str) – nvprof trace 文件路径. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributions.html":{"url":"distributions.html","title":"Probability distributions - torch.distributions","keywords":"","body":"Probability distributions - torch.distributions 译者：@叶舒泉 校对者：@smilesboy、@Charles Xu 该 distributions 统计分布包中含有可自定义参数的概率分布和采样函数. 当概率密度函数对其参数可微时, 可以使用 log_prob() 方法来实施梯度方法 Policy Gradient. 它的一个基本方法是REINFORCE规则: 这其中 是参数, 是学习率, 是奖惩, 是在策略 中从 状态下采取 行动的概率. 在实践中, 我们要从神经网络的输出中采样选出一个行动, 在某个环境中应用该行动, 然后 使用 log_prob 函数来构造一个等价的损失函数. 请注意, 这里我们使用了负号, 因为优化器使用 是是梯度下降法, 然而上面的REINFORCE规则是假设了梯度上升情形. 如下所示是在多项式分布下 实现REINFORCE的代码: probs = policy_network(state) # NOTE: 等同于多项式分布 m = Categorical(probs) action = m.sample() next_state, reward = env.step(action) loss = -m.log_prob(action) * reward loss.backward() Distribution (概率分布) class torch.distributions.Distribution Distribution是概率分布的抽象基类. log_prob(value) 返回在value处的概率密度函数的对数. 参数：value (Tensor 或 Variable) – （基类的参数,没有实际用处） sample() 生成一个样本, 如果分布参数有多个, 就生成一批样本. sample_n(n) 生成n个样本, 如果分布参数有多个, 就生成n批样本. Bernoulli (伯努利分布) class torch.distributions.Bernoulli(probs) 创建以 probs 为参数的伯努利分布. 样本是二进制的 (0或1). 他们以p的概率取值为1, 以 (1 - p) 的概率取值为0. 例: >>> m = Bernoulli(torch.Tensor([0.3])) >>> m.sample() # 30% chance 1; 70% chance 0 0.0 [torch.FloatTensor of size 1] 参数：probs (Tensor 或 Variable) – 采样到 1 的概率 Categorical (类别分布) class torch.distributions.Categorical(probs) 创建以 probs 为参数的类别分布. 它和 multinomial() 采样的分布是一样的. 样本是来自 “0 … K-1” 的整数,其中 “K” 是probs.size(-1). 如果 probs 是长度为 K 的一维列表,则每个元素是对该索引处的类进行抽样的相对概率. 如果 probs 是二维的,它被视为一批概率向量. 另见: torch.multinomial() 例: >>> m = Categorical(torch.Tensor([ 0.25, 0.25, 0.25, 0.25 ])) >>> m.sample() # equal probability of 0, 1, 2, 3 3 [torch.LongTensor of size 1] 参数：probs (Tensor 或 Variable) – 事件概率 Normal (正态分布) class torch.distributions.Normal(mean, std) 创建以 mean 和 std 为参数的正态分布（也称为高斯分布）. 例: >>> m = Normal(torch.Tensor([0.0]), torch.Tensor([1.0])) >>> m.sample() # normally distributed with mean=0 and stddev=1 0.1046 [torch.FloatTensor of size 1] 参数： mean (float 或 Tensor 或 Variable) – 分布的均值 std (float 或 Tensor 或 Variable) – 分布的标准差 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"multiprocessing.html":{"url":"multiprocessing.html","title":"Multiprocessing package - torch.multiprocessing","keywords":"","body":"Multiprocessing package - torch.multiprocessing 译者：@夜神月 校对者：@smilesboy torch.multiprocessing 是本地 multiprocessing 多进程处理模块的一个 wrapper（包装器）. 它通过注册自定义的 reducers（缩减器）, 使用共享内存来提供不同进程中相同数据的共享视图. 一旦 tensor/storage（张量/存储）移动到共享内存 (请参阅 share_memory_()), 就可以将其发送到其他进程而不做任何复制. 该 API 与原始模块 100% 兼容 - 只需将 import multiprocessing 更改为 import torch.multiprocessing 就 可以将所有张量通过队列发送, 或通过其它机制共享, 移动到共享内存. 由于 API 的相似性, 我们没有记录大部分这个包的内容, 我们参考引用原始模块中非常优秀的文档. 警告： 如果主进程突然退出 (例如, 由于传入的信号) , Python 的多进程有时无法清理其子进程. 这是一个已知的警告, 所以如果你在中断解释器之后发现任何资源泄漏, 这可能意味着这只是发生在你身上. 管理策略 torch.multiprocessing.get_all_sharing_strategies() 返回当前系统支持的一组共享策略. torch.multiprocessing.get_sharing_strategy() 返回用于共享 CPU 张量的当前策略. torch.multiprocessing.set_sharing_strategy(new_strategy) 为共享的 CPU 张量来设置策略. 参数：new_strategy (str) – 所选策略的名称. 必须是函数 get_all_sharing_strategies() 所返回的值之一. 共享 CUDA 张量 在进程之间共享 CUDA 张量仅在 Python 3 中支持, 使用 spawn 或 forkserver 启动方法. Python 2 中的 multiprocessing 只能使用 fork 创建子进程, 而中 CUDA 运行时是不支持的. 警告： CUDA API 要求输出到其他进程的分配保持有效, 只要它们被它们使用. 您应该注意, 并确保您共享的 CUDA 张量不会超出范围, 在有必要的情况下. 这不应该是共享模型参数的问题, 而是应该小心地传递其他类型的数据. 请注意, 此限制不适用于共享 CPU 内存. 共享策略 本节简要介绍不同分享策略的工作原理. 请注意, 它仅适用于 CPU 张量 - CUDA 张量将始终使用 CUDA API, 因为这是它们可以共享的唯一方式. File descriptor - file_descriptor 注解： 这是默认的策略 (除了不支持的 macOS 和 OS X之外) This is the default strategy (except for macOS and OS X where it’s not supported). 这个策略将使用文件描述符作为共享内存句柄. 无论何时将存储移动到共享内存, 从 shm_open 获取的文件描述符都将与该对象一起缓存, 并且当将要将其发送到其他进程时, 文件描述符将被传送 (例如, 通过 UNIX sockets) 到其中. 接收器还将缓存文件描述符并对其进行 mmap, 以获得存储数据的共享视图. 请注意, 如果共享张量很大, 这个策略会在大部分时间保持大量的文件描述符. 如果您的系统对打开的文件描述符的数量有限制, 并且不能提高它们, 则应该使用 file_system 策略. File system - file_system 该策略将使用给 shm_open 的文件名来标识共享内存区. 这样做的好处是不需要缓存从中获取的文件描述符, 但同时也容易发生共享内存泄漏. 该文件创建后不能被删除, 因为其他进程需要访问它来打开它们各自的视图. 如果该进程崩溃, 并且不调用存储析构函数, 则这些文件将保留在系统中. 这种情况非常严重, 因为它们会一直使用内存, 直到系统重新启动, 或者被手动释放. 为了解决共享内存文件泄漏的问题, torch.multiprocessing 模块会产生一个名为 torch_shm_manager 的守护进程, 它将把自己从当前进程组中分离出来, 并跟踪所有的共享内存分配. 一旦连接到它的所有进程退出, 它将等待一会儿, 以确保不会有新的连接. 并将迭代组中已分配的所有共享内存文件. 如果发现其中任何一个仍然存在, 它们将被释放. 我们已经测试了这个方法, 并证明它对各种失败都是有效的. 不过, 如果你的系统有足够高的限制, file_descriptor 是一个所支持的策略, 虽然我们不建议切换到这个策略上. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"distributed.html":{"url":"distributed.html","title":"Distributed communication package - torch.distributed","keywords":"","body":"Distributed communication package - torch.distributed 译者：@Mu Wu9527 校对者：@smilesboy torch.distributed 提供类似 MPI 的前向运算机制, 支持在多台机的网络中交换数据. 支持不同的后段和初始化方法. 目前torch.distributed支持三个后端, 每个都有不同的功能. 下表显示哪些功能可用于 CPU/CUDA 张量. 只有在设备上编译安装PyTorch, 才能在MPI的设备上支持cuda. Backend tcp gloo mpi Device CPU GPU CPU GPU CPU GPU --- --- --- --- --- --- --- send ✓ ✘ ✘ ✘ ✓ ? recv ✓ ✘ ✘ ✘ ✓ ? broadcast ✓ ✘ ✓ ✓ ✓ ? all_reduce ✓ ✘ ✓ ✓ ✓ ? reduce ✓ ✘ ✘ ✘ ✓ ? all_gather ✓ ✘ ✘ ✘ ✓ ? gather ✓ ✘ ✘ ✘ ✓ ? scatter ✓ ✘ ✘ ✘ ✓ ? barrier ✓ ✘ ✓ ✓ ✓ ? Basics torch.distributed 为在一台或多台机器上运行的多个计算节点提供多进程并行的通信模块和PyTorch的支持. 类 torch.nn.parallel.DistributedDataParallel() 建立在这个功能之上, 以提供任何PyTorch模型分布式训练的装饰器. 这个类和 Multiprocessing package - torch.multiprocessing 和 torch.nn.DataParallel() 并不相同, PyTorch集群分布式计算支持多台机器, 使用时用户必须在主要训练的脚本中, 明确地将每个进程复制到每台机器中. 在单机多节点计算的情况下, 使用 torch.distributed 和 torch.nn.parallel.DistributedDataParallel() 作为 训练的装饰器, 相比于 torch.nn.DataParallel() 之类的数据并行计算, 任然具有优势: 在每次迭代中, 每个进程维护自己的优化器, 执行完整的优化步骤. 虽然这看起来可能是多余的, 但是因为梯度已经被收集在 一起, 并且计算了梯度的平均值, 因此对于每个进程梯度是相同的, 这可以减少在节点之间传递张量, 再计算参数的时间. 每个进程都包含一个独立的Python解释器, 消除了Python解释器的额外开销, 以及由于驱动多线程, 模型副本和GPU造成 “GIL-thrashing” . 对于需要消耗大量Python解释器运行时间 (包括具有循环图层或许多小组件的模型) 的模型来说是非常重要的. Initialization 在调用其他模型之前, 这个包需要使用 torch.distributed.init_process_group() 函数进行初始化. 在初始化单元中, 所有进程都会参与. torch.distributed.init_process_group(backend, init_method='env://', **kwargs) 初始化方法. 参数： backend (str) – 使用后端的名字. 输入的有效值包括: tcp , mpi and gloo . init_method (str, 可选) – 指定如何初始化的URL. world_size (int, 可选) – 参与工作的进程数量. rank (int, 可选) – 当前进程的排名. group_name (str, 可选) – 集群的名字. 请参阅init方法的描述. 为了支持 backend == mpi , PyTorch 需要在支持 MPI 的系统上用进行源码编译安装 torch.distributed.get_rank() 返回当前进程的排名. 排名是独一无二的 Rank（排名）是分配给分布式集群中每个进程的唯一标识符. 它们总是连续的整数, 范围从0到 world_size . torch.distributed.get_world_size() 返回在分布式集群中的进程数目. 目前支持三种初始化的方法: TCP initialization 提供两种TCP的初始化的方法, 两种方法都需要各台机器的网络地址和集群机器数目 world_size . 第一种方法需要指定属于0级进程的地址, 并且初始化时所有进程的等级都由手动指定. 第二种方法是, 地址必须是有效的IP多播地址, 在这种情况下, 可以自动分配等级. 多路通信的初始化也支持 group_name 参数, 它允许你为多个作业使用相同的地址, 只要它们使用不同的小组名即可. import torch.distributed as dist # Use address of one of the machines dist.init_process_group(init_method='tcp://10.1.1.20:23456', rank=args.rank, world_size=4) # or a multicast address - rank will be assigned automatically if unspecified dist.init_process_group(init_method='tcp://[ff15:1e18:5d4c:4cf0:d02d:b659:53ba:b0a7]:23456', world_size=4) Shared file-system initialization 另一个初始化方法使用一个文件系统, 这个文件系统在一个组中的所有机器上共享和可见, 以及一个所需的 world_size 参数. URL应该以 file:// 开头, 并包含一个可以和共享文件系统所有现有目录中的路径相区别的路径, 作为URL. 这个初始化方法也 支持 group_name 参数, 它允许你为多个作业使用相同的共享文件路径, 只要它们使用不同的小组名. 警告： 这种方法假设文件系统支持使用 fcntl 进行锁定 -大多数本地系统和NFS都支持它. import torch.distributed as dist # Rank will be assigned automatically if unspecified dist.init_process_group(init_method='file:///mnt/nfs/sharedfile', world_size=4, group_name=args.group) Environment variable initialization 此方法将从环境变量中读取配置, 从而可以完全自定义如何获取信息. 要设置的变量是: MASTER_PORT - 需要; 必须是0级机器上的自由端口 MASTER_ADDR - 需要 (除了等级0) ; 等级0节点的地址 WORLD_SIZE - 需要; 可以在这里设置, 或者在调用init函数 RANK - 需要; 可以在这里设置, 或者在调用init函数 等级为0的机器将用于设置所有连接. 这是默认的方法, 这意味着 init_method 不必被特别指定(或者可以是 env:// ) Groups 默认的集群 (collectives) 操作默认的小组 (group), 要求所有的进程进入分布式函数中调用. 一些工作负载可以从可以从更细粒度的通信中受益 这是分布式集群发挥作用的地方. new_group() 函数可以用来创建新的组, 并且包含所有进程的任意子集. 它返回一个不透明的组句柄, 它可以作为集群的 group 参数 (集群 collectives 是一般的编程模式中的交换信息的分布式函数) . torch.distributed.new_group(ranks=None) 创建一个新的分布式小组 此函数要求主组中的所有进程（即作为分布式作业一部分的所有进程）都会输入此函数, 即使它们不是该小组的成员. 此外, 应该在所有的进程中以相同的顺序创建新的小组. 参数：ranks (list[int]) – 小组内成员的 Rank 的列表. 返回值：分配组的句柄, 以便在集群中调用. Point-to-point communication torch.distributed.send(tensor, dst) 同步发送张量. 参数： tensor (Tensor) – 发送的张量. dst (int) – 指定发送的目的地的 Rank. torch.distributed.recv(tensor, src=None) 同步接收张量. 参数： tensor (Tensor) – 用收到的数据填充张量. src (int, 可选) – 发送端的Rank, 如果没有指定, 将会接收任何发送的数据. 返回值：发送端的Rank. isend() 和 irecv() 使用时返回分布式请求对象. 通常, 这个对象的类型是未指定的, 因为它们不能使用手动创建, 但是它们支持两种方法指定: is_completed() - 如果操作完成返回True wait() - 如果操作完成会阻塞所有的进程. is_completed() 如果结果返回, 保证函数返回True. 当使用MPI作为后端, isend() 和 irecv() 支持 “不超车” 式的工作方式, 这种方式可以保证消息的顺序. 更多的细节可以看 http://mpi-forum.org/docs/mpi-2.2/mpi22-report/node54.htm#Node54 torch.distributed.isend(tensor, dst) 异步发送张量数据. 参数： tensor (Tensor) – 发送的张量的数据. dst (int) – 指定发送到的 Rank. 返回值：分布式请求对象. torch.distributed.irecv(tensor, src) 异步接收张量. 参数： tensor (Tensor) – 用收到的数据填充张量. src (int) – 指定发送张量的 Rank. 返回值：一个分布式请求对象. Collective functions torch.distributed.broadcast(tensor, src, group=) 向某个小组内的张量广播的方法. tensor 在该小组处理数据的所有过程中元素的数目必须相同. 参数： tensor (Tensor) – 如果发送端 src 是当前进程的 Rank, 则发送数据, 否则使用张量保存接收的数据. src (int) – 发送端的 Rank. group (optional) – 集群内的小组的名字. torch.distributed.all_reduce(tensor, op=, group=) 处理所有机器上的处理的张量数据, 计算最终的结果. 在所有进程中调用 tensor 将按位相同. 参数： tensor (Tensor) – 集群的输入和输出. op (optional) – “torch.distributed.reduce_op” 枚举值之一. 指定用于元素减少的操作. group (optional) – 集群的内的小组的名字. torch.distributed.reduce(tensor, dst, op=, group=) 减少所有机器上的张量数据. 只有级别为 dst 的进程才会收到最终结果. 参数： tensor (Tensor) – 集群的输入和输出数据. 分别在每台机器上本地处理. op (optional) – “torch.distributed.reduce_op” 枚举值之一. 指定用于元素减少的操作. group (optional) – 集群的内的小组的名字. torch.distributed.all_gather(tensor_list, tensor, group=) 在整个集群中收集list表格中的张量. 参数： tensor_list (list_[Tensor]_) – 输出列表. 它应该包含正确大小的张量以用于集体的输出. tensor (Tensor) – 张量从当前进程中进行广播. group (optional) – 集群的内的小组的名字. torch.distributed.gather(tensor, **kwargs) 收集一个张量列表从一个单一进程中. 参数： tensor (Tensor) – 输入的数据. dst (int) – 目的地的 Rank. 包括除了正在接收数据的进程的所有进程. gather_list (list_[Tensor]_) – 用于接收数据的适当大小的张量列表. 只在接收过程中需要. group (optional) – 集群的内的小组的名字. torch.distributed.scatter(tensor, **kwargs) 将张量列表散布到小组中的所有进程. 每个进程只会收到一个张量, 并将其数据存储在 tensor 的参数中. 参数： tensor (Tensor) – 输出的张量. src (int) – 发送端的 Rank. 包括除了正在接收数据的进程的所有进程. scatter_list (list_[Tensor]_) – 张量分散的列表. 仅在发送数据的过程中需要. group (optional) – 集群的内的小组的名字. torch.distributed.barrier(group=) 同步所有进程. 这个集群阻塞进程, 直到全部的小组的计算结果都输入进这个函数中. 参数：group (optional) – 集群的内的小组的名字. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"legacy.html":{"url":"legacy.html","title":"Legacy package - torch.legacy","keywords":"","body":"Legacy package - torch.legacy 译者：@那伊抹微笑 校对者：@smilesboy 包含从 Lua torch 移植的代码的包. 为了能够与现有的模型一起工作, 并简化当前 Lua torch 用户的过渡, 我们特意创建了这个包. 您可以在 torch.legacy.nn 中找到 nn 代码, 并在 torch.legacy.optim 中进行 optim 优化. 该 API 应该完适配 Lua torch. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"cuda.html":{"url":"cuda.html","title":"torch.cuda","keywords":"","body":"torch.cuda 译者：@谈笑风生 校对者：@smilesboy 这个包增加了对 CUDA tensor (张量) 类型的支持,利用 GPUs 计算实现了与 CPU tensors 相同的类型. 这个是 lazily initialized (懒加载,延迟加载), 所以你可以一直导入它,并且可以用 is_available() 来判断 你的系统是否支持 CUDA. CUDA 语义 有更多关于使用 CUDA 的细节. torch.cuda.current_blas_handle() 返回指向当前 cuBLAS 句柄的 cublasHandle_t 指针 torch.cuda.current_device() 返回当前选择的设备的索引. torch.cuda.current_stream() 返回当前选择的 Stream . class torch.cuda.device(idx) 更改选定设备的上下文管理器. 参数：idx (int) – 选择设备编号. 如果参数无效,则是无效操作. torch.cuda.device_count() 返回可用的 GPU 数量. torch.cuda.device_ctx_manager device的别名。 class torch.cuda.device_of(obj) 将当前设备更改为给定对象的上下文管理器. 可以使用张量和存储作为参数,如果给定的对象不是在 GPU 上分配的,这是一个无效操作. 参数：obj (Tensor 或 Storage) – 在选定设备上分配的对象. torch.cuda.empty_cache() 释放当前由缓存持有的所有未占用缓存内存分配器,以便可以在其他GPU应用程序中使用并在 nvidia-smi 中可见. torch.cuda.get_device_capability(device) 获取设备的 CUDA 算力. 参数：device (int) – 返回设备名, 参数无效时, 方法失效. 返回值：设备的主次要 CUDA 算力. 返回类型：tuple(int, int) torch.cuda.get_device_name(device) 获取设备名. 参数：device (int) – 返回设备名. 参数无效时,则是无效操作. torch.cuda.is_available() 返回一个 bool 值表示 CUDA 目前是否可用. torch.cuda.set_device(device) 设置当前设备. 不鼓励使用这个函数 device . 在大多数情况下,最好使用 CUDA_VISIBLE_DEVICES 环境变量. 参数：device (int) – 选择设备. 参数无效时,则是无效操作. torch.cuda.stream(*args, **kwds) 选择给定流的上下文管理器. 在选定的流上, 所有的CUDA内核在其上下文内排队. 参数：stream (Stream) – 选择流. 如果是 None , 管理器无效. torch.cuda.synchronize() 等待当前设备上所有流中的所有内核完成. Random Number Generator torch.cuda.get_rng_state(device=-1) 将当前 GPU 的随机数生成器状态作为 ByteTensor 返回. 参数：device (int, 可选) – 设备的 RNG 状态. Default: -1 (i.e., 使用当前设备). 警告： 函数需要提前初始化 CUDA . torch.cuda.set_rng_state(new_state, device=-1) 设置当前 GPU 的随机数发生器状态. 参数：new_state (torch.ByteTensor) – 所需的状态 torch.cuda.manual_seed(seed) 设置用于当前 GPU 生成随机数的种子. 如果 CUDA 不可用,调用这个函数是安全的;在这种情况下,它将被忽略. 参数：seed (int 或 long) – 所需的种子. 警告： 如果您正在使用多 GPU 模型,则此功能不足以获得确定性. seef作用于所有 GPUs , 使用 manual_seed_all() . torch.cuda.manual_seed_all(seed) 设置在所有 GPU 上生成随机数的种子. 如果 CUDA 不可用, 调用此函数是安全的; 这种情况下,会被忽略. 参数：seed (int 或 long) – 所需的种子. torch.cuda.seed() 将用于生成随机数的种子设置为当前 GPU 的随机数. 如果 CUDA 不可用,则调用此函数是安全的. 在那种情况下,会被忽略. 警告： 如果您正在使用多 GPU 模型, 则此功能不足以获得确定性. seef作用于所有 GPUs , 使用 seed_all(). torch.cuda.seed_all() 在所有 GPU 上将用于生成随机数的种子设置为随机数. 如果 CUDA 不可用,则调用此函数是安全的. 在那种情况下,会被忽略. torch.cuda.initial_seed() 返回当前 GPU 的当前随机种子. 警告： 函数提前初始化 CUDA . Communication collectives torch.cuda.comm.broadcast(tensor, devices) 将张量广播给多个 GPU . 参数： tensor (Tensor) – 需要广播的张量. devices (Iterable) – 在一个可迭代设备中广播. 请注意, 它应该像 (src, dst1, dst2, …), 其中的第一个元素是来至其广播的源设备. 返回值：一个元组, 包含 tensor 副本,放置在与设备的索引相对应的 设备 上. torch.cuda.comm.reduce_add(inputs, destination=None) 从多个 GPU 中收集张量. 所有的输入应该有匹配的 shapes (形状). 参数： inputs (Iterable[Tensor]) – 添加一个可迭代的张量. destination (int, 可选) – 放置输出的设备 (默认: 当前设备). 返回值：包含所有输入的元素和的张量, 存放在 destination(目标) 设备. torch.cuda.comm.scatter(tensor, devices, chunk_sizes=None, dim=0, streams=None) 分散张量到多个 GPU. 参数： tensor (Tensor) – 需要分散的张量. devices (Iterable[int]) – 整数的迭代,指定张量应分散在哪些设备之间. chunk_sizes (Iterable[int], 可选) – 要放在每个设备上的块的大小. 应该匹配 设备 长度和 tensor.size(dim) 的和. 如果未指定,张量将被划分成相等的块. dim (int, 可选) – 分块张量沿着的维度 返回值：一个元组包含 tensor 块, 传递给 devices . torch.cuda.comm.gather(tensors, dim=0, destination=None) 从多个 GPU 收集张量. 张量尺寸在不同于 dim 的维度上都应该匹配. 参数： tensors (Iterable[Tensor]) – 张量集合的迭代器. dim (int) – 张量被连接的维度. destination (int, 可选) – 输出设备 (-1 代表 CPU, 默认: 当前设备) 返回值：一个位于 目标 设备上的张量, 将 tensors 沿着 dim 连接起来的结果. Streams and events class torch.cuda.Stream CUDA 流的包装. 参数： device (int, 可选) – 分配流的设备. priority (int, 可选) – 流的优先级. 较低的数字代表较高的优先级. query() 检查事件是否已被记录. 返回值：一个 BOOL 值, 指示事件是否已被记录. record_event(event=None) 记录一个事件. 参数：event (Event, 可选) – 要记录的事件.如果没有给出,将分配一个新的. 返回值：记录的事件. synchronize() 等待流中的所有内核完成. wait_event(event) 将所有未来的工作提交到流等待事件. 参数：event (Event) – 等待的事件. wait_stream(stream) 与另一个流同步. 提交到此流的所有未来工作将等待直到所有核心在调用完成时提交给给定的流. 参数：stream (Stream) – 同步流. class torch.cuda.Event(enable_timing=False, blocking=False, interprocess=False, _handle=None) CUDA 事件包装器. 参数： enable_timing (bool) – 指示事件是否应测量时间 (默认: False) blocking (bool) – 如果 True, wait() 将阻塞 (默认: False ) interprocess (bool) – 如果 True, 事件可以在进程之间共享 (默认: False) elapsed_time(end_event) 返回记录事件之前所经过的时间. ipc_handle() 返回此事件的 IPC 句柄. query() 检查事件是否已记录. 返回值：一个 BOOL 值, 指示事件是否已被记录. record(stream=None) 记录给定流中的事件. synchronize() 与事件同步. wait(stream=None) 使给定流等待事件发生. Memory management torch.cuda.empty_cache() 释放当前由缓存持有的所有未占用缓存内存分配器,以便可以在其他GPU应用程序中使用并在 nvidia-smi 中可见. NVIDIA Tools Extension (NVTX) torch.cuda.nvtx.mark(msg) 描述在某个时刻发生的瞬间事件. 参数：msg (string) – 事件(用 ASCII 编码表示). torch.cuda.nvtx.range_push(msg) 设置一个固定范围的堆栈,返回的堆栈范围深度从0开始. 参数：msg (string) – 范围(用 ASCII 编码设置) torch.cuda.nvtx.range_pop() 弹出一个固定范围的堆栈,返回的堆栈范围深度从0结束. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"ffi.html":{"url":"ffi.html","title":"torch.utils.ffi","keywords":"","body":"torch.utils.ffi 译者：@之茗 校对者：@aleczhang torch.utils.ffi.create_extension(name, headers, sources, verbose=True, with_cuda=False, package=False, relative_to='.', **kwargs) 创建并配置一个 cffi.FFI 对象, 用于构建 PyTorch 的扩展. 参数： name (str) – 包名. 可以是嵌套模块, 例如. .ext.my_lib. headers (str 或 List[str]) – 只包含导出函数的头文件列表. sources (List[str]) – 用于编译的sources列表. verbose (bool, 可选) – 如果设置为 False, 则不会打印输出 (默认值: True). with_cuda (bool, 可选) – 设置为 True 以使用 CUDA 头文件进行编译 (默认值: False) package (bool, 可选) – 设置为 True 以在包模式下构建 (对于要作为 pip 程序包安装的模块) (默认值: False). relative_to (str, 可选) – 构建文件的路径. 当 package 为 True 时需要. 最好使用 __file__ 作为参数. kwargs – 传递给 ffi 以声明扩展的附件参数. 参考 Extension API reference 查阅更详细内容. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"data.html":{"url":"data.html","title":"torch.utils.data","keywords":"","body":"torch.utils.data 译者：@之茗 校对者：@aleczhang class torch.utils.data.Dataset 表示 Dataset 的抽象类. 所有其它数据集都应继承该类. 所有子类都应该重写 __len__, 提供数据集大小的方法, 和 __getitem__, 支持从 0 到 len(self) 整数索引的方法. class torch.utils.data.TensorDataset(data_tensor, target_tensor) 包装数据和目标张量的数据集. 通过沿着第一个维度索引两个张量来恢复每个样本. 参数： data_tensor (Tensor) – 包含样本数据. target_tensor (Tensor) – 包含样本目标 (标签). class torch.utils.data.ConcatDataset(datasets) 用以连结多个数据集的数据集. 目的: 对于组装不同的现有数据集非常有帮助, 可能是 大规模的数据集, 因为串联操作是以即时方式完成的. 参数：datasets (iterable) – 需要连结的数据集列表 class torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=, pin_memory=False, drop_last=False) 数据加载器. 组合数据集和采样器,并在数据集上提供单进程或多进程迭代器. 参数： dataset (Dataset) – 从该数据集中加载数据. batch_size (int, 可选) – 每个 batch 加载多少个样本 (默认值: 1). shuffle (bool, 可选) – 设置为 True 时, 会在每个 epoch 重新打乱数据 (默认值: False). sampler (Sampler, 可选) – 定义从数据集中提取样本的策略. 如果指定, shuffle 值必须为 False. batch_sampler (Sampler, 可选) – 与 sampler 相似, 但一次返回一批指标. 与 batch_size, shuffle, sampler, and drop_last 互斥. num_workers (int, 可选) – 用多少个子进程加载数据. 0表示数据将在主进程中加载 (默认值: 0) collate_fn (callable, 可选) – 合并样本列表以形成一个 mini-batch. pin_memory (bool, 可选) – 如果为 True, 数据加载器会将张量复制到 CUDA 固定内存中, 然后再返回它们. drop_last (bool, 可选) – 设定为 True 以丢掉最后一个不完整的 batch, 如果数据集大小不能被 batch size整除. 设定为 False 并且数据集的大小不能被 batch size整除, 则最后一个 batch 将会更小. (default: False) class torch.utils.data.sampler.Sampler(data_source) 所有采样器的基类. 每一个 Sampler 的子类都必须提供一个 iter 方法, 提供一种 迭代数据集元素的索引的方法, 以及一个 len 方法, 用来返回 迭代器的长度. class torch.utils.data.sampler.SequentialSampler(data_source) 总是以相同的顺序, 依次对元素进行采样. 参数：data_source (Dataset) – 采样的数据集 class torch.utils.data.sampler.RandomSampler(data_source) 采用无放回采样法, 随机对样本元素采样. 参数：data_source (Dataset) – 采样的数据集 class torch.utils.data.sampler.SubsetRandomSampler(indices) 采用无放回采样法, 样本元素从指定的索引列表中随机抽取. 参数：indices (list) – 索引的列表 class torch.utils.data.sampler.WeightedRandomSampler(weights, num_samples, replacement=True) 使用给定的概率 (权重) 对 [0,..,len(weights)-1] 范围的元素进行采样. 参数： weights (list) – 权重列表, 没必要加起来等于 1 num_samples (int) – 抽样数量 replacement (bool) – 设定为 True, 使用有放回采样法. 设定为 False, 采用无放回采样法, 这意味着对于一行来说,当一个 样本索引被取到后, 对于改行, 这个样本索引不能再次被取到. class torch.utils.data.distributed.DistributedSampler(dataset, num_replicas=None, rank=None) 将数据加载限制为数据集子集的采样器. 当与 torch.nn.parallel.DistributedDataParallel 组合使用时, 特别有用. 在这种情况下, 每个进程都可以将分布式采样器实例作为Data Loader采样器, 并且加载一个原始数据集的子集并独占该数据子集. 注解： 数据集被假定为不变的大小. 参数： dataset – 采样的数据集. num_replicas (optional) – 参与分布式训练的进程数量. rank (optional) – 在 num_replicas 中, 当前进程的等级. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"model_zoo.html":{"url":"model_zoo.html","title":"torch.utils.model_zoo","keywords":"","body":"torch.utils.model_zoo 译者：@之茗 校对者：@aleczhang torch.utils.model_zoo.load_url(url, model_dir=None, map_location=None) 从给定的 URL 处加载 Torch 序列化对象. 如果该对象已经存在于 model_dir 中, 则将被反序列化并返回. URL 的文件名部分应该遵循命名约定 filename-&lt;sha256&gt;.ext 其中 &lt;sha256&gt; 是文件内容的 SHA256 哈希的前八位或更多位数. 哈希用于确保唯一的名称并验证文件的内容. model_dir 的默认值为 $TORCH_HOME/models 其中 $TORCH_HOME 默认值为 ~/.torch. 可以使用 $TORCH_MODEL_ZOO 环境变量来覆盖默认目录. 参数： url (string) – 需要下载对象的 URL model_dir (string, 可选) – 保存对象的目录 map_location (optional) – 一个函数或者一个字典,指定如何重新映射存储位置 (详情查阅 torch.load) 示例： >>> state_dict = torch.utils.model_zoo.load_url('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth') 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"onnx.html":{"url":"onnx.html","title":"torch.onnx","keywords":"","body":"torch.onnx 译者：@Haofan Wang 校对者：@aleczhang torch.onnx 模块可以将模型导出成 ONNX IR 形式.被导出的模型可以通过 ONNX 库被重新导入, 然后转化为可以在其它的深度学习框架上运行的模型. 示例:从Pytorch到Caffe2的端对端AlexNet模型 这里是一个简单的脚本程序,它将一个在 torchvision 中已经定义的预训练 AlexNet 模型导出到 ONNX 格式. 它会运行一次,然后把模型保存至 alexnet.proto: from torch.autograd import Variable import torch.onnx import torchvision dummy_input = Variable(torch.randn(10, 3, 224, 224)).cuda() model = torchvision.models.alexnet(pretrained=True).cuda() torch.onnx.export(model, dummy_input, \"alexnet.proto\", verbose=True) 得到的 alexnet.proto 是一个 protobuf 二值文件, 它包含所导出模型 ( 这里是 AlexNet )中网络架构和网络参数. 关键参数 verbose=True 会使导出过程中打印出该网络的可读表示: # All parameters are encoded explicitly as inputs. By convention, # learned parameters (ala nn.Module.state_dict) are first, and the # actual inputs are last. graph(%1 : Float(64, 3, 11, 11) %2 : Float(64) # The definition sites of all variables are annotated with type # information, specifying the type and size of tensors. # For example, %3 is a 192 x 64 x 5 x 5 tensor of floats. %3 : Float(192, 64, 5, 5) %4 : Float(192) # ---- omitted for brevity ---- %15 : Float(1000, 4096) %16 : Float(1000) %17 : Float(10, 3, 224, 224)) { # the actual input! # Every statement consists of some output tensors (and their types), # the operator to be run (with its attributes, e.g., kernels, strides, # etc.), its input tensors (%17, %1) %19 : UNKNOWN_TYPE = Conv[kernels=[11, 11], strides=[4, 4], pads=[2, 2, 2, 2], dilations=[1, 1], group=1](%17, %1), uses = [[%20.i0]]; # UNKNOWN_TYPE: sometimes type information is not known. We hope to eliminate # all such cases in a later release. %20 : Float(10, 64, 55, 55) = Add[broadcast=1, axis=1](%19, %2), uses = [%21.i0]; %21 : Float(10, 64, 55, 55) = Relu(%20), uses = [%22.i0]; %22 : Float(10, 64, 27, 27) = MaxPool[kernels=[3, 3], pads=[0, 0, 0, 0], dilations=[1, 1], strides=[2, 2]](%21), uses = [%23.i0]; # ... # Finally, a network returns some tensors return (%58); } 你可以使用 onnx 库验证 protobuf, 并且用 conda 安装 onnx conda install -c conda-forge onnx 然后运行: import onnx # Load the ONNX model model = onnx.load(\"alexnet.proto\") # Check that the IR is well formed onnx.checker.check_model(model) # Print a human readable representation of the graph onnx.helper.printable_graph(model.graph) 为了能够使用 caffe2 运行脚本, 你需要三样东西: 你需要安装 Caffe2. 如果你之前没有安装,请参照 安装指南. 你需要安装 onnx-caffe2,一个纯 Python 的库,它为 ONNX 提供了 Caffe2 的 后端.你可以使用 pip 安装 onnx-caffe2: pip install onnx-caffe2 一旦这些安装完成,你就可以使用 Caffe2 的后端: # ...continuing from above import onnx_caffe2.backend as backend import numpy as np rep = backend.prepare(model, device=\"CUDA:0\") # or \"CPU\" # For the Caffe2 backend: # rep.predict_net is the Caffe2 protobuf for the network # rep.workspace is the Caffe2 workspace for the network # (see the class onnx_caffe2.backend.Workspace) outputs = rep.run(np.random.randn(10, 3, 224, 224).astype(np.float32)) # To run networks with more than one input, pass a tuple # rather than a single numpy ndarray. print(outputs[0]) 之后,我们还会提供其它深度学习框架的后端支持. 局限 ONNX 导出器是一个基于轨迹的导出器,这意味着它执行时需要运行一次模型,然后导出实际参与运算的运算符. 这也意味着, 如果你的模型是动态的,例如,改变一些依赖于输入数据的操作,这时的导出结果是不准确的.同样,一 个轨迹可能只对一个具体的输入尺寸有效 (这是为什么我们在轨迹中需要有明确的输入的原因之一.) 我们建议检查 模型的轨迹,确保被追踪的运算符是合理的. Pytorch 和 Caffe2 中的一些运算符经常有着数值上的差异.根据模型的结构,这些差异可能是微小的,但它们会在 表现上产生很大的差别 (尤其是对于未训练的模型.) 之后,为了帮助你在准确度要求很高的情况中,能够轻松地避免这 些差异带来的影响,我们计划让 Caffe2 能够直接调用 Torch 的运算符. 支持的运算符 以下是已经被支持的运算符: add (nonzero alpha not supported) sub (nonzero alpha not supported) mul div cat mm addmm neg tanh sigmoid mean t expand (only when used before a broadcasting ONNX operator; e.g., add) transpose view split squeeze prelu (single weight shared among input channels not supported) threshold (non-zero threshold/non-zero value not supported) leaky_relu glu softmax avg_pool2d (ceil_mode not supported) log_softmax unfold (experimental support with ATen-Caffe2 integration) elu Conv BatchNorm MaxPool1d (ceil_mode not supported) MaxPool2d (ceil_mode not supported) MaxPool3d (ceil_mode not supported) Embedding (no optional arguments supported) RNN ConstantPadNd Dropout FeatureDropout (training mode not supported) Index (constant integer and tuple indices supported) Negate 上面的运算符足够导出下面的模型: AlexNet DCGAN DenseNet Inception (注意:该模型对操作符十分敏感) ResNet SuperResolution VGG word_language_model 用于指定运算符定义的接口是高度实验性的,并且还没有记录.喜欢探索的用户应该注意,这些API可能会在之后被修改. Functions torch.onnx.export(model, args, f, export_params=True, verbose=False, training=False) 将一个模型导出成 ONNX 格式.这个导出器为了得到模型运行的轨迹,会运行一次你的模型.同时,它不支持动态模型（如 RNN.） 也可参考: onnx-export 参数: model (torch.nn.Module): 将被导出模型. args (tuple of arguments): 模型的输入, model(*args) 必须是对模型的有效调用.任何非变量参数将被硬编码到导出的模型中.任何变量参数都将按照它们在参数中出现的顺序,成为输出模型的输入.如果 args 是一个变量,相当于用该变量的一个元组来调用它.（注意:目前还不支持将关键参数传递给模型,如果需要,请联系我们.） f: 一个类文件对象（必须实现返回文件描述的fileno）或一个包含文件名的字符串. 一个二进制 Protobuf 将被写入这个文件. export_params (bool, default True): 如果指定,所有参数将被导出.如果要导出未经训练的模型,请将其设置为 False.在这种情况下,导出的模型将首先将其所有参数作为参数,顺序由 model.state_dict().values() 指定. verbose (bool, default False): 如果指定,会打印出正在导出轨迹的调式描述. training (bool, default False): 在训练模式下输出模型.目前, ONNX 只是作为导出模型的接口,所以你通常不需要将其设为 True. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"torchvision_reference.html":{"url":"torchvision_reference.html","title":"torchvision 参考","keywords":"","body":"torchvision 参考 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"torchvision.html":{"url":"torchvision.html","title":"torchvision","keywords":"","body":"torchvision 译者：@那伊抹微笑、@dawenzi123、@LeeGeong、@liandongze 校对者：@咸鱼 模块 torchvision 库包含了计算机视觉中一些常用的数据集, 模型架构以及图像变换方法. Package Reference torchvision.datasets MNIST Fashion-MNIST COCO LSUN ImageFolder Imagenet-12 CIFAR STL10 SVHN PhotoTour torchvision.models Alexnet VGG ResNet SqueezeNet DenseNet Inception v3 torchvision.transforms PIL Image 上的变换 torch.*Tensor 上的变换 转换类型的变换 通用的变换 torchvision.utils torchvision.get_image_backend() 获取用于加载图像的包的名称 torchvision.set_image_backend(backend) 指定用于加载图像的包. 参数：backend (string) – 图像处理后端的名称. {‘PIL’, ‘accimage’} 之一. accimage 使用 Intel IPP library（高性能图像加载和增强程序模拟的程序）.通常比PIL库要快, 但是不支持许多操作. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"datasets.html":{"url":"datasets.html","title":"torchvision.datasets","keywords":"","body":"torchvision.datasets 译者：@那伊抹微笑、@dawenzi123、@LeeGeong、@liandongze 校对者：@咸鱼 所有的数据集都是 torch.utils.data.Dataset 类的子类, 也就是说, 他们内部都实现了 __getitem__ 和 __len__ 这两个方法. 同时, 他们也都可以传递给类 torch.utils.data.Dataset, 它可以使用 torch.multiprocessing 工作器来并行的加载多个样本. 示例： imagenet_data = torchvision.datasets.ImageFolder('path/to/imagenet_root/') data_loader = torch.utils.data.DataLoader(imagenet_data, batch_size=4, shuffle=True, num_workers=args.nThreads) 可用的数据集如下所示: Datasets MNIST Fashion-MNIST COCO Captions Detection LSUN ImageFolder Imagenet-12 CIFAR STL10 SVHN PhotoTour 所有数据集都有几乎相似的 API, 它们有两个普通的参数: transform 和 target_transform 可分别的对输入和目标数据集进行变换. - transform: 输入原始图片, 返回转换后的图片. - target_transform: 输入为 target, 返回转换后的 target. MNIST class torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False) MNIST Dataset. 参数： root (string) – processed/training.pt 和 processed/test.pt 存在的主目录. train (bool, 可选) – 如果 True, 数据来自训练集 training.pt , 如果 False, 数据来自测试集 test.pt . download (bool, 可选) – 如果 true, 就从网上下载数据集并且放到 root 目录下. 如果数据集已经下载, 那么不会再次下载. transform (callable, 可选) – 一个 transform 函数, 它输入 PIL image 并且返回 转换后的版本. E.g, transforms.RandomCrop target_transform (callable, 可选) – 一个 transform 函数, 输入 target 并且 转换它. Fashion-MNIST class torchvision.datasets.FashionMNIST(root, train=True, transform=None, target_transform=None, download=False) Fashion-MNIST Dataset. 参数： root (string) – processed/training.pt 和 processed/test.pt 存在的主目录. train (bool, 可选) – 如果 True, 数据来自训练集 training.pt , 如果 False, 数据来自测试集 test.pt . download (bool, 可选) – 如果 true, 就从网上下载数据集并且放到 root 目录下. 如果数据集已经下载, 那么不会再次下载. transform (callable, 可选) – 一个 transform 函数, 它输入 PIL image 并且返回 转换后的版本. E.g, transforms.RandomCrop target_transform (callable, 可选) – 一个 transform 函数, 输入 target 并且 转换它. COCO 注解： 需要安装 COCO API Captions class torchvision.datasets.CocoCaptions(root, annFile, transform=None, target_transform=None) MS Coco Captions Dataset. 参数： root (string) – 数据集下载存放的主目录. annFile (string) – json 注释文件存放的路径 transform (callable, 可选) – 一个 transform 函数, 它输入 PIL image 并且返回 转换后的版本. E.g, transforms.ToTensor target_transform (callable, 可选) – 一个 transform 函数, 输入 target 并且 转换它. 示例： import torchvision.datasets as dset import torchvision.transforms as transforms cap = dset.CocoCaptions(root = 'dir where images are', annFile = 'json annotation file', transform=transforms.ToTensor()) print('Number of samples: ', len(cap)) img, target = cap[3] # load 4th sample print(\"Image Size: \", img.size()) print(target) Output: Number of samples: 82783 Image Size: (3L, 427L, 640L) [u'A plane emitting smoke stream flying over a mountain.', u'A plane darts across a bright blue sky behind a mountain covered in snow', u'A plane leaves a contrail above the snowy mountain top.', u'A mountain that has a plane flying overheard in the distance.', u'A mountain view with a plume of smoke in the background'] __getitem__(index) 参数：index (int) – Index 返回值：Tuple (image, target). 目标是一个图像标注的列表. 返回类型：tuple Detection class torchvision.datasets.CocoDetection(root, annFile, transform=None, target_transform=None) MS Coco Detection Dataset. 参数： root (string) – 数据集下载存放的主目录. annFile (string) – json 注释文件存放的路径 transform (callable, 可选) – 一个 transform 函数, 它输入 PIL image 并且返回 转换后的版本. E.g, transforms.ToTensor target_transform (callable, 可选) – 一个 transform 函数, 输入 target 并且 转换它. __getitem__(index) 参数：index (int) – Index 返回值：Tuple (image, target). 目标是由 coco.loadAnns 返回的对象. 返回类型：tuple LSUN class torchvision.datasets.LSUN(db_path, classes='train', transform=None, target_transform=None) LSUN dataset. 参数： db_path (string) – 数据集文件存放的主目录. classes (string 或 list) – {‘train’, ‘val’, ‘test’} 中的一个, 或者是一个要载入种类的列表. e,g. [‘bedroom_train’, ‘church_train’]. transform (callable, 可选) – 一个 transform 函数, 它输入 PIL image 并且返回 转换后的版本. E.g, transforms.RandomCrop target_transform (callable, 可选) – 一个 transform 函数, 输入 target 并且 转换它. __getitem__(index) 参数：index (int) – Index 返回值：Tuple (image, target) 目标是目标类别的索引. 返回类型：tuple ImageFolder class torchvision.datasets.ImageFolder(root, transform=None, target_transform=None, loader=) 一个通用的数据加载器, 数据集中的数据以以下方式组织: root/dog/xxx.png root/dog/xxy.png root/dog/xxz.png root/cat/123.png root/cat/nsdf3.png root/cat/asd932_.png 参数： root (string) – 主目录. transform (callable, 可选) – 一个 transform 函数, 它输入 PIL image 并且返回 转换后的版本. E.g, transforms.RandomCrop target_transform (callable, 可选) – 一个 transform 函数, 输入 target 并且 转换它. loader – 一个从给定路径载入图像的函数. __getitem__(index) 参数：index (int) – Index 返回值：(image, target) 目标是目标类别的class_index. 返回类型：tuple Imagenet-12 这可以通过一个 ImageFolder 数据集轻易实现. 该数据预处理过程如 这里描述的 所示 这里是一个预处理示例. CIFAR class torchvision.datasets.CIFAR10(root, train=True, transform=None, target_transform=None, download=False) CIFAR10 Dataset. 参数： root (string) – cifar-10-batches-py 存在的主目录. train (bool, 可选) – 如果 True, 数据来自训练集, 如果 False, 数据来自测试集. transform (callable, 可选) – 一个 transform 函数, 它输入 PIL image 并且返回 转换后的版本. E.g, transforms.RandomCrop target_transform (callable, 可选) – 一个 transform 函数, 输入 target 并且 转换它. download (bool, 可选) – 如果 true, 就从网上下载数据集并且放到 root 目录下. 如果数据集已经下载, 那么不会再次下载. __getitem__(index) 参数：index (int) – Index 返回值：(image, target) 目标是目标分类的索引. 返回类型：tuple class torchvision.datasets.CIFAR100(root, train=True, transform=None, target_transform=None, download=False) CIFAR100 Dataset. CIFAR10 Dataset 的一个子类. STL10 class torchvision.datasets.STL10(root, split='train', transform=None, target_transform=None, download=False) STL10 Dataset. 参数： root (string) – stl10_binary数据集存放的主目录. split (string) – {‘train’, ‘test’, ‘unlabeled’, ‘train+unlabeled’} 中的一个. 它是根据数据集选择的. transform (callable, 可选) – 一个 transform 函数, 它输入 PIL image 并且返回 转换后的版本. E.g, transforms.RandomCrop target_transform (callable, 可选) – 一个 transform 函数, 输入 target 并且 转换它. download (bool, 可选) – 如果 true, 就从网上下载数据集并且放到 root 目录下. 如果数据集已经下载, 那么不会再次下载. __getitem__(index) 参数：index (int) – Index 返回值：(image, target) 目标是目标类的索引. 返回类型：tuple SVHN class torchvision.datasets.SVHN(root, split='train', transform=None, target_transform=None, download=False) SVHN Dataset. Note: 原始的 SVHN 数据集把标签 10 分给了数字 0. 然而在这个数据集, 我们把标签 0 分给了数字 0 以便 和 PyTorch 的损失函数不产生冲突, 它期待的类标签的范围是 [0, C-1]. 参数： root (string) – SVHN数据集存放的主目录. split (string) – {‘train’, ‘test’, ‘extra’} 中的一个. 它是根据数据集选择的. ‘extra’ 是一个额外的训练集. transform (callable, 可选) – 一个 transform 函数, 它输入 PIL image 并且返回 转换后的版本. E.g, transforms.RandomCrop target_transform (callable, 可选) – 一个 transform 函数, 输入 target 并且 转换它. download (bool, 可选) – 如果 true, 就从网上下载数据集并且放到 root 目录下. 如果数据集已经下载, 那么不会再次下载. __getitem__(index) 参数：index (int) – Index 返回值：(image, target) 目标是目标类的索引. 返回类型：tuple PhotoTour class torchvision.datasets.PhotoTour(root, name, train=True, transform=None, download=False) Learning Local Image Descriptors Data Dataset. 参数： root (string) – 图像存放的主目录. name (string) – 载入的数据集的名字. transform (callable, 可选) – 一个 transform 函数, 它输入 PIL image 并且返回 转换后的版本. download (bool, 可选) – 如果 true, 就从网上下载数据集并且放到 root 目录下. 如果数据集已经下载, 那么不会再次下载. __getitem__(index) 参数：index (int) – Index 返回值：(data1, data2, matches) 返回类型：tuple 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"models.html":{"url":"models.html","title":"torchvision.models","keywords":"","body":"torchvision.models 译者：@那伊抹微笑、@dawenzi123、@LeeGeong、@liandongze 校对者：@咸鱼 torchvision.models 模块的子模块中包含以下模型结构: AlexNet VGG ResNet SqueezeNet DenseNet Inception v3 你可以使用随机初始化的权重来创建这些模型: import torchvision.models as models resnet18 = models.resnet18() alexnet = models.alexnet() vgg16 = models.vgg16() squeezenet = models.squeezenet1_0() densenet = models.densenet161() inception = models.inception_v3() 我们提供使用PyTorch torch.utils.model_zoo 预训练 (pre-train)的模型, 可以通过参数 pretrained=True 来构造这些预训练模型. import torchvision.models as models resnet18 = models.resnet18(pretrained=True) alexnet = models.alexnet(pretrained=True) squeezenet = models.squeezenet1_0(pretrained=True) vgg16 = models.vgg16(pretrained=True) densenet = models.densenet161(pretrained=True) inception = models.inception_v3(pretrained=True) 所有预训练 (pre-train) 模型要求输入图像使用相同的标准化处理, 例如: mini-batches 中 RGB 三通道图像的 shape (3 x H x W), H 和 W 需要至少为 224, 图像必须被加载在 [0, 1] 的范围内 然后使用 mean = [0.485, 0.456, 0.406] 和 std = [0.229, 0.224, 0.225] 进行标准化处理. 你可以使用以下转换进行预标准化预处理: normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) 一个使用这种标准化处理的 imagenet 样例 here ImageNet 1-crop error rates (224x224) Network Top-1 error Top-5 error AlexNet 43.45 20.91 VGG-11 30.98 11.37 VGG-13 30.07 10.75 VGG-16 28.41 9.62 VGG-19 27.62 9.12 VGG-11 with batch normalization 29.62 10.19 VGG-13 with batch normalization 28.45 9.63 VGG-16 with batch normalization 26.63 8.50 VGG-19 with batch normalization 25.76 8.15 ResNet-18 30.24 10.92 ResNet-34 26.70 8.58 ResNet-50 23.85 7.13 ResNet-101 22.63 6.44 ResNet-152 21.69 5.94 SqueezeNet 1.0 41.90 19.58 SqueezeNet 1.1 41.81 19.38 Densenet-121 25.35 7.83 Densenet-169 24.00 7.00 Densenet-201 22.80 6.43 Densenet-161 22.35 6.20 Inception v3 22.55 6.44 Alexnet torchvision.models.alexnet(pretrained=False, **kwargs) AlexNet 模型结构论文地址 “One weird trick…” . 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. VGG torchvision.models.vgg11(pretrained=False, **kwargs) VGG 11层模型 (configuration “A”) 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.vgg11_bn(pretrained=False, **kwargs) 带有批标准化（batch normalization) 的VGG 11层模型 (configuration “A”) 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.vgg13(pretrained=False, **kwargs) VGG 13层模型 (configuration “B”) 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.vgg13_bn(pretrained=False, **kwargs) 带有批标准化（batch normalization) 的 VGG 13层模型 (configuration “B”) 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.vgg16(pretrained=False, **kwargs) VGG 16层模型 (configuration “D”) 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.vgg16_bn(pretrained=False, **kwargs) 带有批标准化（batch normalization) 的 VGG 16层模型 (configuration “D”) 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.vgg19(pretrained=False, **kwargs) VGG 19层模型 (configuration “E”) 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.vgg19_bn(pretrained=False, **kwargs) 带有批标准化（batch normalization) 的 VGG 19层模型 (configuration ‘E’) 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. ResNet torchvision.models.resnet18(pretrained=False, **kwargs) 构造一个 ResNet-18 模型. 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.resnet34(pretrained=False, **kwargs) 构造一个 ResNet-34 模型. 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.resnet50(pretrained=False, **kwargs) 构造一个 ResNet-50 模型. 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.resnet101(pretrained=False, **kwargs) 构造一个 ResNet-101 模型. 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.resnet152(pretrained=False, **kwargs) 构造一个 ResNet-152 模型. 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. SqueezeNet torchvision.models.squeezenet1_0(pretrained=False, **kwargs) SqueezeNet 模型结构源于论文: “SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.squeezenet1_1(pretrained=False, **kwargs) SqueezeNet 1.1 模型源于论文: official SqueezeNet repo. SqueezeNet 1.1 比 SqueezeNet 1.0 减少了 2.4倍的运算量, 并在不损伤准确率的基础上减少了少许参数. 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. DenseNet torchvision.models.densenet121(pretrained=False, **kwargs) Densenet-121 模型源自于: “Densely Connected Convolutional Networks” 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.densenet169(pretrained=False, **kwargs) Densenet-169 模型源自于: “Densely Connected Convolutional Networks” 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.densenet161(pretrained=False, **kwargs) Densenet-161 模型源自于: “Densely Connected Convolutional Networks” 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. torchvision.models.densenet201(pretrained=False, **kwargs) Densenet-201 模型源自于: “Densely Connected Convolutional Networks” 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. Inception v3 torchvision.models.inception_v3(pretrained=False, **kwargs) Inception v3 模型结构源自于 “Rethinking the Inception Architecture for Computer Vision”. 参数：pretrained (bool) – True, 返回一个在 ImageNet 上预训练的模型. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"transforms.html":{"url":"transforms.html","title":"torchvision.transforms","keywords":"","body":"torchvision.transforms 译者：@那伊抹微笑、@dawenzi123、@LeeGeong、@liandongze 校对者：@咸鱼 Transforms (变换) 是常见的 image transforms (图像变换) .他们可以使用 Compose 类以链在一起来进行操作. class torchvision.transforms.Compose(transforms) 将多个变换组合到一起. 参数：transforms (Transform 对象列表) – 要组合的变换列表. 示例： >>> transforms.Compose([ >>> transforms.CenterCrop(10), >>> transforms.ToTensor(), >>> ]) PIL Image 上的变换 class torchvision.transforms.Resize(size, interpolation=2) 调整输入的 PIL Image 尺寸为给定的 size（尺寸）. 参数： size (sequence 或 int) – 期望输出的尺寸. 如果 size（尺寸）是一个像 (h, w) 这样的序列, 则 output size（输出尺寸）将于此匹配. 如果 size（尺寸）是一个 int 类型的数字, 图像较小的边缘将被匹配到该数字. 例如, 如果 height > width, 那么图像将会被重新缩放到 (size * height / width, size). 即按照size/width的比值缩放 interpolation (int, 可选) – 期望的插值. 默认是 PIL.Image.BILINEAR class torchvision.transforms.Scale(*args, **kwargs) Note: 为了支持 Resize, 该变换已经过时了. class torchvision.transforms.CenterCrop(size) 在中心裁剪指定的 PIL Image. 参数：size (sequence 或 int) – 期望裁剪的输出尺寸. 如果 size（尺寸）是 int 类型的整数, 而不是像 (h, w) 这样类型的序列, 裁剪出来的图像是 (size, size) 这样的正方形的. class torchvision.transforms.RandomCrop(size, padding=0) 在一个随机位置裁剪指定的 PIL Image. 参数： size (sequence 或 int) – 期望输出的裁剪尺寸. 如果 size（尺寸）是 int 类型的整数, 而不是像 (h, w) 这样类型的序列, 裁剪出来的图像是 (size, size) 这样的正方形的. padding (int 或 sequence, 可选) – 图像的每个边框上的可选填充. 缺省值是 0, 即没有填充. 如果提供长度为 4 的序列, 则分别用于填充左侧, 顶部, 右侧, 底部边界. class torchvision.transforms.RandomHorizontalFlip 以概率0.5随机水平翻转图像 class torchvision.transforms.RandomVerticalFlip 以概率0.5随机垂直翻转图像. class torchvision.transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2) 将给定的 PIL 图像裁剪为随机大小和纵横比例. 原始高宽比的随机大小（默认: 0.08 到 1.0）和随机宽高比（默认: 3/4 到 4/3）的裁剪. 该裁剪最终会被调整为指定的尺寸. 该操作普遍用于训练 Inception networks. 参数： size – 每条边的期望的输出尺寸 scale – 原始剪裁尺寸大小的范围 ratio – 原始裁剪纵横比的范围 interpolation – Default: PIL.Image.BILINEAR class torchvision.transforms.RandomSizedCrop(*args, **kwargs) Note: 为了支持 RandomResizedCrop, 该变换已经被弃用. class torchvision.transforms.Grayscale(num_output_channels=1) 将图像转换为灰度图像. 参数：num_output_channels (int) – (1 or 3) 输出图像所期望的通道数量 返回值：灰度版本的输入. - 如果 num_output_channels == 1 : 返回的图像是 1 通道 - 如果 num_output_channels == 3 : 返回的图像是 3 通道, 并且 r == g == b 返回类型：PIL Image class torchvision.transforms.RandomGrayscale(p=0.1) 随机将图像转换为灰度图像, 概率为 p (default 0.1). 参数：p (float) – 图像应该被转换成灰度的概率. 返回值：灰度版本的输入图像的概率为 p, 不变的概率为（1-p） - 如果输入图像为1个通道: 则灰度版本是 1 通道 - 如果输入图像为3个通道: 则灰度版本是 3 通道, 并且 r == g == b 返回类型：PIL Image class torchvision.transforms.FiveCrop(size) 将给定的 PIL Image 裁剪成四个角落和中心裁剪 注解： 该变换返回一个图像元组, 并且数据集返回的输入和目标的数量可能不匹配. 请参阅下面的例子来处理这个问题. 参数：size (sequence 或 int) – 期望输出的裁剪尺寸. 如果 size 是 int 类型的整数, 而不是像 (h, w) 这样类型的序列, 裁剪出来的图像是 (size, size) 这样的正方形的.. 示例： >>> transform = Compose([ >>> FiveCrop(size), # 一个 PIL Images 的列表 >>> Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops])) # 返回一个4D Tensor >>> ]) >>> #在你的测试循环可以如下操作: >>> input, target = batch # 输入是5DTensor,输出是2D >>> bs, ncrops, c, h, w = input.size() >>> result = model(input.view(-1, c, h, w)) # fuse batch size and ncrops >>> result_avg = result.view(bs, ncrops, -1).mean(1) # avg over crops class torchvision.transforms.TenCrop(size, vertical_flip=False) 将给定的 PIL Image 裁剪成四个角, 中心裁剪, 并加上这些的翻转版本（默认使用水平翻转） 注解： 该变换返回一个图像元组, 并且数据集返回的输入和目标的数量可能不匹配. 请参阅下面的例子来处理这个问题. 参数： size (sequence 或 int) – 期望输出的裁剪尺寸. 如果 size（尺寸）是 int 类型的整数, 而不是像 (h, w) 这样类型的序列, 裁剪出来的图像是 (size, size) 这样的正方形的. vertical_flip (bool) – 使用垂直翻转而不是水平的方式 示例： >>> transform = Compose([ >>> TenCrop(size), # this is a list of PIL Images >>> Lambda(lambda crops: torch.stack([ToTensor()(crop) for crop in crops])) # returns a 4D tensor >>> ]) >>> #In your test loop you can do the following: >>> input, target = batch # input is a 5d tensor, target is 2d >>> bs, ncrops, c, h, w = input.size() >>> result = model(input.view(-1, c, h, w)) # fuse batch size and ncrops >>> result_avg = result.view(bs, ncrops, -1).mean(1) # avg over crops class torchvision.transforms.Pad(padding, fill=0) 用指定的 “pad” 值填充指定的 PIL image. 参数： padding (int 或 tuple) – 填充每个边框. 如果提供了一个 int 型的整数, 则用于填充所有边界. 如果提供长度为 2 的元组, 则这是分别在 左/右 和 上/下 的填充. 如果提供长度为 4 的元组, 则这是分别用于 左, 上, 右 和 下 部边界的填充. fill – 像素填充. 默认值为 0. 如果长度为 3 的元组, 分别用于填充 R, G, B 通道. class torchvision.transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0) 随机更改图像的亮度, 对比度和饱和度. 参数： brightness (float) – 亮度改变的范围. brightness_factor 从 [max(0, 1 - brightness), 1 + brightness]的范围中一致选择. contrast (float) – 对比度改变的范围. contrast_factor 从 [max(0, 1 - contrast), 1 + contrast]的范围中一致选择. saturation (float) – 饱和度改变的范围. saturation_factor 从[max(0, 1 - saturation), 1 + saturation]的范围中一致选择. hue (float) – 色调改变的范围. hue_factor 从 [-hue, hue]的范围中一致选择. 应该 >=0 且 torch.*Tensor 上的变换 class torchvision.transforms.Normalize(mean, std) 用均值和标准偏差对张量图像进行归一化. 给定均值: (M1,...,Mn) 和标准差: (S1,..,Sn) 用于 n 个通道, 该变换将标准化输入 torch.*Tensor 的每一个通道. 例如: input[channel] = (input[channel] - mean[channel]) / std[channel] 参数： mean (sequence) – 每一个通道的均值序列. std (sequence) – 每一个通道的标准差序列. __call__(tensor) 参数：tensor (Tensor) – 需要被归一化的大小为 (C, H, W)Tensor image. 返回值：归一化后的 Tensor image. 返回类型：Tensor 转换类型的变换 class torchvision.transforms.ToTensor 转换一个 PIL Image 或 numpy.ndarray 为 tensor（张量）. 将范围 [0, 255] 中的 PIL Image 或 numpy.ndarray (H x W x C) 转换形状为 (C x H x W) , 值范围为 [0.0, 1.0] 的 torch.FloatTensor. __call__(pic) 参数：pic (PIL Image 或 numpy.ndarray) – 将要被转换为 tensor 的 Image. 返回值：转换后的 image. 返回类型：Tensor class torchvision.transforms.ToPILImage(mode=None) 转换一个 tensor 或 ndarray 为 PIL Image. 转换一个形状为(C x H x W) 的 torch.*Tensor 或一个形状为(H x W x C )的numpy ndarray 至一个 PIL Image ,同时保留值范围. 参数：mode (PIL.Image 模式) – 输入数据的色域和像素深度 (可选). 如果 mode 为 None (默认) ,这里对输入数据有一些假设: 1. 如果输入有3个通道, mode 假设为 RGB. 2. 如果输入有4个通道, mode 假设为 RGBA. 3. 如果输入有1个通道, mode 根据数据类型确定 (i,e, int, float, short). __call__(pic) 参数：pic (Tensor 或 numpy.ndarray) – 要转换为PIL Image的图像. 返回值：转换为PIL Image的图像. 返回类型：PIL Image 通用的变换 class torchvision.transforms.Lambda(lambd) 应用一个用户定义的 Lambda 作为变换. 参数：lambd (function) – Lambda/function 以用于 transform. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"utils.html":{"url":"utils.html","title":"torchvision.utils","keywords":"","body":"torchvision.utils 译者：@那伊抹微笑、@dawenzi123、@LeeGeong、@liandongze 校对者：@咸鱼 torchvision.utils.make_grid(tensor, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0) 制作一个图形网格. 参数： tensor (Tensor 或 list) – 给定 4D mini-batch Tensor 形状为 (B x C x H x W) 或者一个同样形状的 list of images. nrow (int, 可选) – 网格每一行显示的image数量. 最后网格的形状是 (B / nrow, nrow). 默认是 8. padding (int, 可选) – 填充的数量. 默认为 2. normalize (bool, 可选) – 如果值为True,通过减去最小像素值并除以最大的像素值的方法, 把图像的范围变为 (0, 1),此过程为归一化处理. range (tuple, 可选) – tuple (min, max) 这里 min 和 max 都是数字, 这些数字是用来规范 image的. 默认情况下, min 和 max 是从 tensor 里计算出来的. scale_each (bool, 可选) – 如果值为True, 每个image独立规范化, 而不是根据所有image的像素最大最小值来归一化. pad_value (float, 可选) – 填充像素的值. 示例： 请参阅 这里 的手册 torchvision.utils.save_image(tensor, filename, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0) 将一个给定的 Tensor 保存为 image（图像）文件. 参数： tensor (Tensor 或 list) – 被保存的图片. 如果给定的是 mini-batch tensor, 通过调用 make_grid 将 tensor 保存为网格图像. **kwargs – 其它参数文档在 make_grid 中. 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}