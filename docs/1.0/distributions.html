
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Probability distributions - torch.distributions · Pytorch 中文文档</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="ApacheCN">
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-insert-logo/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-pageview-count/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-emphasize/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-alerts/style.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-auto-scroll-table/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-page-toc-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-tbfed-pagefooter/footer.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-advanced-emoji/emoji-website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="jit.html" />
    
    
    <link rel="prev" href="distributed.html" />
    

    <style>
    @media only screen and (max-width: 640px) {
        .book-header .hidden-mobile {
            display: none;
        }
    }
    </style>
    <script>
        window["gitbook-plugin-github-buttons"] = {"buttons":[{"user":"apachecn","repo":"pytorch-doc-zh","type":"star","count":true,"size":"small"}]};
    </script>

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    中文教程
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="tut_getting_started.html">
            
                <a href="tut_getting_started.html">
            
                    
                    起步
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.1" data-path="deep_learning_60min_blitz.html">
            
                <a href="deep_learning_60min_blitz.html">
            
                    
                    PyTorch 深度学习: 60 分钟极速入门
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.1.1" data-path="blitz_tensor_tutorial.html">
            
                <a href="blitz_tensor_tutorial.html">
            
                    
                    什么是 PyTorch？
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.1.2" data-path="blitz_autograd_tutorial.html">
            
                <a href="blitz_autograd_tutorial.html">
            
                    
                    Autograd：自动求导
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.1.3" data-path="blitz_neural_networks_tutorial.html">
            
                <a href="blitz_neural_networks_tutorial.html">
            
                    
                    神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.1.4" data-path="blitz_cifar10_tutorial.html">
            
                <a href="blitz_cifar10_tutorial.html">
            
                    
                    训练分类器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.1.5" data-path="blitz_data_parallel_tutorial.html">
            
                <a href="blitz_data_parallel_tutorial.html">
            
                    
                    可选：数据并行处理
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.1.2" data-path="data_loading_tutorial.html">
            
                <a href="data_loading_tutorial.html">
            
                    
                    数据加载和处理教程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3" data-path="pytorch_with_examples.html">
            
                <a href="pytorch_with_examples.html">
            
                    
                    用例子学习 PyTorch
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.4" data-path="transfer_learning_tutorial.html">
            
                <a href="transfer_learning_tutorial.html">
            
                    
                    迁移学习教程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.5" data-path="deploy_seq2seq_hybrid_frontend_tutorial.html">
            
                <a href="deploy_seq2seq_hybrid_frontend_tutorial.html">
            
                    
                    混合前端的 seq2seq 模型部署
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.6" data-path="saving_loading_models.html">
            
                <a href="saving_loading_models.html">
            
                    
                    Saving and Loading Models
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.7" data-path="nn_tutorial.html">
            
                <a href="nn_tutorial.html">
            
                    
                    What is torch.nn really?
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="tut_image.html">
            
                <a href="tut_image.html">
            
                    
                    图像
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.2.1" data-path="finetuning_torchvision_models_tutorial.html">
            
                <a href="finetuning_torchvision_models_tutorial.html">
            
                    
                    Torchvision 模型微调
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.2" data-path="spatial_transformer_tutorial.html">
            
                <a href="spatial_transformer_tutorial.html">
            
                    
                    空间变换器网络教程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.3" data-path="neural_style_tutorial.html">
            
                <a href="neural_style_tutorial.html">
            
                    
                    使用 PyTorch 进行图像风格转换
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.4" data-path="fgsm_tutorial.html">
            
                <a href="fgsm_tutorial.html">
            
                    
                    对抗性示例生成
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.5" data-path="super_resolution_with_caffe2.html">
            
                <a href="super_resolution_with_caffe2.html">
            
                    
                    使用 ONNX 将模型从 PyTorch 传输到 Caffe2 和移动端
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="tut_text.html">
            
                <a href="tut_text.html">
            
                    
                    文本
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.3.1" data-path="chatbot_tutorial.html">
            
                <a href="chatbot_tutorial.html">
            
                    
                    聊天机器人教程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.2" data-path="char_rnn_generation_tutorial.html">
            
                <a href="char_rnn_generation_tutorial.html">
            
                    
                    使用字符级别特征的 RNN 网络生成姓氏
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.3" data-path="char_rnn_classification_tutorial.html">
            
                <a href="char_rnn_classification_tutorial.html">
            
                    
                    使用字符级别特征的 RNN 网络进行姓氏分类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.4" data-path="deep_learning_nlp_tutorial.html">
            
                <a href="deep_learning_nlp_tutorial.html">
            
                    
                    Deep Learning for NLP with Pytorch
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.3.4.1" data-path="nlp_pytorch_tutorial.html">
            
                <a href="nlp_pytorch_tutorial.html">
            
                    
                    PyTorch 介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.4.2" data-path="nlp_deep_learning_tutorial.html">
            
                <a href="nlp_deep_learning_tutorial.html">
            
                    
                    使用 PyTorch 进行深度学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.4.3" data-path="nlp_word_embeddings_tutorial.html">
            
                <a href="nlp_word_embeddings_tutorial.html">
            
                    
                    Word Embeddings: Encoding Lexical Semantics
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.4.4" data-path="nlp_sequence_models_tutorial.html">
            
                <a href="nlp_sequence_models_tutorial.html">
            
                    
                    序列模型和 LSTM 网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.4.5" data-path="nlp_advanced_tutorial.html">
            
                <a href="nlp_advanced_tutorial.html">
            
                    
                    Advanced: Making Dynamic Decisions and the Bi-LSTM CRF
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.3.5" data-path="seq2seq_translation_tutorial.html">
            
                <a href="seq2seq_translation_tutorial.html">
            
                    
                    基于注意力机制的 seq2seq 神经网络翻译
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="tut_generative.html">
            
                <a href="tut_generative.html">
            
                    
                    生成
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.4.1" data-path="dcgan_faces_tutorial.html">
            
                <a href="dcgan_faces_tutorial.html">
            
                    
                    DCGAN Tutorial
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="tut_reinforcement_learning.html">
            
                <a href="tut_reinforcement_learning.html">
            
                    
                    强化学习
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.5.1" data-path="reinforcement_q_learning.html">
            
                <a href="reinforcement_q_learning.html">
            
                    
                    Reinforcement Learning (DQN) Tutorial
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="tut_extending_pytorch.html">
            
                <a href="tut_extending_pytorch.html">
            
                    
                    扩展 PyTorch
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.6.1" data-path="numpy_extensions_tutorial.html">
            
                <a href="numpy_extensions_tutorial.html">
            
                    
                    用 numpy 和 scipy 创建扩展
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6.2" data-path="cpp_extension.html">
            
                <a href="cpp_extension.html">
            
                    
                    Custom C++   and CUDA Extensions
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6.3" data-path="torch_script_custom_ops.html">
            
                <a href="torch_script_custom_ops.html">
            
                    
                    Extending TorchScript with Custom C++   Operators
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.7" data-path="tut_production_usage.html">
            
                <a href="tut_production_usage.html">
            
                    
                    生产性使用
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.7.1" data-path="dist_tuto.html">
            
                <a href="dist_tuto.html">
            
                    
                    Writing Distributed Applications with PyTorch
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7.2" data-path="aws_distributed_training_tutorial.html">
            
                <a href="aws_distributed_training_tutorial.html">
            
                    
                    使用 Amazon AWS 进行分布式训练
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7.3" data-path="ONNXLive.html">
            
                <a href="ONNXLive.html">
            
                    
                    ONNX 现场演示教程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7.4" data-path="cpp_export.html">
            
                <a href="cpp_export.html">
            
                    
                    在 C++ 中加载 PYTORCH 模型
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.8" data-path="tut_other_language.html">
            
                <a href="tut_other_language.html">
            
                    
                    其它语言中的 PyTorch
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.8.1" data-path="cpp_frontend.html">
            
                <a href="cpp_frontend.html">
            
                    
                    使用 PyTorch C++ 前端
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    中文文档
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="docs_notes.html">
            
                <a href="docs_notes.html">
            
                    
                    注解
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1.1" data-path="notes_autograd.html">
            
                <a href="notes_autograd.html">
            
                    
                    自动求导机制
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.2" data-path="notes_broadcasting.html">
            
                <a href="notes_broadcasting.html">
            
                    
                    广播语义
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.3" data-path="notes_cuda.html">
            
                <a href="notes_cuda.html">
            
                    
                    CUDA 语义
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.4" data-path="notes_extending.html">
            
                <a href="notes_extending.html">
            
                    
                    Extending PyTorch
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.5" data-path="notes_faq.html">
            
                <a href="notes_faq.html">
            
                    
                    Frequently Asked Questions
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.6" data-path="notes_multiprocessing.html">
            
                <a href="notes_multiprocessing.html">
            
                    
                    Multiprocessing best practices
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.7" data-path="notes_randomness.html">
            
                <a href="notes_randomness.html">
            
                    
                    Reproducibility
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.8" data-path="notes_serialization.html">
            
                <a href="notes_serialization.html">
            
                    
                    Serialization semantics
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.9" data-path="notes_windows.html">
            
                <a href="notes_windows.html">
            
                    
                    Windows FAQ
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="docs_package_ref.html">
            
                <a href="docs_package_ref.html">
            
                    
                    包参考
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.2.1" data-path="torch.html">
            
                <a href="torch.html">
            
                    
                    torch
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.2.1.1" data-path="torch_tensors.html">
            
                <a href="torch_tensors.html">
            
                    
                    Tensors
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.1.2" data-path="torch_random_sampling.html">
            
                <a href="torch_random_sampling.html">
            
                    
                    Random sampling
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.1.3" data-path="torch_serialization_parallelism_utilities.html">
            
                <a href="torch_serialization_parallelism_utilities.html">
            
                    
                    Serialization, Parallelism, Utilities
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.1.4" data-path="torch_math_operations.html">
            
                <a href="torch_math_operations.html">
            
                    
                    Math operations
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.2.1.4.1" data-path="torch_math_operations_pointwise_ops.html">
            
                <a href="torch_math_operations_pointwise_ops.html">
            
                    
                    Pointwise Ops
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.1.4.2" data-path="torch_math_operations_reduction_ops.html">
            
                <a href="torch_math_operations_reduction_ops.html">
            
                    
                    Reduction Ops
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.1.4.3" data-path="torch_math_operations_comparison_ops.html">
            
                <a href="torch_math_operations_comparison_ops.html">
            
                    
                    Comparison Ops
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.1.4.4" data-path="torch_math_operations_spectral_ops.html">
            
                <a href="torch_math_operations_spectral_ops.html">
            
                    
                    Spectral Ops
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.1.4.5" data-path="torch_math_operations_other_ops.html">
            
                <a href="torch_math_operations_other_ops.html">
            
                    
                    Other Operations
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.1.4.6" data-path="torch_math_operations_blas_lapack_ops.html">
            
                <a href="torch_math_operations_blas_lapack_ops.html">
            
                    
                    BLAS and LAPACK Operations
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.2.2" data-path="tensors.html">
            
                <a href="tensors.html">
            
                    
                    torch.Tensor
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.3" data-path="tensor_attributes.html">
            
                <a href="tensor_attributes.html">
            
                    
                    Tensor Attributes
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.4" data-path="type_info.html">
            
                <a href="type_info.html">
            
                    
                    数据类型信息
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.5" data-path="sparse.html">
            
                <a href="sparse.html">
            
                    
                    torch.sparse
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.6" data-path="cuda.html">
            
                <a href="cuda.html">
            
                    
                    torch.cuda
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.7" data-path="storage.html">
            
                <a href="storage.html">
            
                    
                    torch.Storage
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.8" data-path="nn.html">
            
                <a href="nn.html">
            
                    
                    torch.nn
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.9" data-path="nn_functional.html">
            
                <a href="nn_functional.html">
            
                    
                    torch.nn.functional
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.10" data-path="nn_init.html">
            
                <a href="nn_init.html">
            
                    
                    torch.nn.init
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.11" data-path="optim.html">
            
                <a href="optim.html">
            
                    
                    torch.optim
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.12" data-path="autograd.html">
            
                <a href="autograd.html">
            
                    
                    Automatic differentiation package - torch.autograd
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.13" data-path="distributed.html">
            
                <a href="distributed.html">
            
                    
                    Distributed communication package - torch.distributed
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.2.14" data-path="distributions.html">
            
                <a href="distributions.html">
            
                    
                    Probability distributions - torch.distributions
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.15" data-path="jit.html">
            
                <a href="jit.html">
            
                    
                    Torch Script
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.16" data-path="multiprocessing.html">
            
                <a href="multiprocessing.html">
            
                    
                    多进程包 - torch.multiprocessing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.17" data-path="bottleneck.html">
            
                <a href="bottleneck.html">
            
                    
                    torch.utils.bottleneck
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.18" data-path="checkpoint.html">
            
                <a href="checkpoint.html">
            
                    
                    torch.utils.checkpoint
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.19" data-path="docs_cpp_extension.html">
            
                <a href="docs_cpp_extension.html">
            
                    
                    torch.utils.cpp_extension
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.20" data-path="data.html">
            
                <a href="data.html">
            
                    
                    torch.utils.data
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.21" data-path="dlpack.html">
            
                <a href="dlpack.html">
            
                    
                    torch.utils.dlpack
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.22" data-path="hub.html">
            
                <a href="hub.html">
            
                    
                    torch.hub
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.23" data-path="model_zoo.html">
            
                <a href="model_zoo.html">
            
                    
                    torch.utils.model_zoo
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.24" data-path="onnx.html">
            
                <a href="onnx.html">
            
                    
                    torch.onnx
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.25" data-path="distributed_deprecated.html">
            
                <a href="distributed_deprecated.html">
            
                    
                    Distributed communication package (deprecated) - torch.distributed.deprecated
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="docs_torchvision_ref.html">
            
                <a href="docs_torchvision_ref.html">
            
                    
                    torchvision 参考
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.3.1" data-path="torchvision_datasets.html">
            
                <a href="torchvision_datasets.html">
            
                    
                    torchvision.datasets
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.2" data-path="torchvision_models.html">
            
                <a href="torchvision_models.html">
            
                    
                    torchvision.models
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.3" data-path="torchvision_transforms.html">
            
                <a href="torchvision_transforms.html">
            
                    
                    torchvision.transforms
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.4" data-path="torchvision_utils.html">
            
                <a href="torchvision_utils.html">
            
                    
                    torchvision.utils
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >Probability distributions - torch.distributions</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="&#x6982;&#x7387;&#x5206;&#x5E03;---torchdistributions">&#x6982;&#x7387;&#x5206;&#x5E03; - torch.distributions</h1>
<blockquote>
<p>&#x8BD1;&#x8005;&#xFF1A;<a href="https://github.com/hijkzzz" target="_blank">hijkzzz</a></p>
</blockquote>
<p><code>distributions</code> &#x5305;&#x542B;&#x53EF;&#x53C2;&#x6570;&#x5316;&#x7684;&#x6982;&#x7387;&#x5206;&#x5E03;&#x548C;&#x91C7;&#x6837;&#x51FD;&#x6570;. &#x8FD9;&#x5141;&#x8BB8;&#x6784;&#x9020;&#x7528;&#x4E8E;&#x4F18;&#x5316;&#x7684;&#x968F;&#x673A;&#x8BA1;&#x7B97;&#x56FE;&#x548C;&#x968F;&#x673A;&#x68AF;&#x5EA6;&#x4F30;&#x8BA1;&#x5668;.  &#x8FD9;&#x4E2A;&#x5305;&#x4E00;&#x822C;&#x9075;&#x5FAA; <a href="https://arxiv.org/abs/1711.10604" target="_blank">TensorFlow Distributions</a> &#x5305;&#x7684;&#x8BBE;&#x8BA1;.</p>
<p>&#x901A;&#x5E38;, &#x4E0D;&#x53EF;&#x80FD;&#x76F4;&#x63A5;&#x901A;&#x8FC7;&#x968F;&#x673A;&#x6837;&#x672C;&#x53CD;&#x5411;&#x4F20;&#x64AD;.  &#x4F46;&#x662F;, &#x6709;&#x4E24;&#x79CD;&#x4E3B;&#x8981;&#x65B9;&#x6CD5;&#x53EF;&#x521B;&#x5EFA;&#x53EF;&#x4EE5;&#x53CD;&#x5411;&#x4F20;&#x64AD;&#x7684;&#x4EE3;&#x7406;&#x51FD;&#x6570;.  &#x5373;&#x5F97;&#x5206;&#x51FD;&#x6570;&#x4F30;&#x8BA1;&#x5668;/&#x4F3C;&#x7136;&#x6BD4;&#x4F30;&#x8BA1;&#x5668;/REINFORCE&#x548C;pathwise derivative&#x4F30;&#x8BA1;&#x5668;.  REINFORCE&#x901A;&#x5E38;&#x88AB;&#x89C6;&#x4E3A;&#x5F3A;&#x5316;&#x5B66;&#x4E60;&#x4E2D;&#x7B56;&#x7565;&#x68AF;&#x5EA6;&#x65B9;&#x6CD5;&#x7684;&#x57FA;&#x7840;, &#x5E76;&#x4E14;pathwise derivative&#x4F30;&#x8BA1;&#x5668;&#x5E38;&#x89C1;&#x4E8E;&#x53D8;&#x5206;&#x81EA;&#x52A8;&#x7F16;&#x7801;&#x5668;&#x4E2D;&#x7684;&#x91CD;&#x65B0;&#x53C2;&#x6570;&#x5316;&#x6280;&#x5DE7;. &#x5F97;&#x5206;&#x51FD;&#x6570;&#x4EC5;&#x9700;&#x8981;&#x6837;&#x672C;&#x7684;&#x503C; <img src="img/cb804637f7fdaaf91569cfe4f047b418.jpg" alt="">, pathwise derivative &#x9700;&#x8981;&#x5BFC;&#x6570; <img src="img/385dbaaac9dd8aad33acc31ac64d2f27.jpg" alt="">. &#x63A5;&#x4E0B;&#x6765;&#x7684;&#x90E8;&#x5206;&#x5C06;&#x5728;&#x4E00;&#x4E2A;&#x5F3A;&#x5316;&#x5B66;&#x4E60;&#x793A;&#x4F8B;&#x4E2D;&#x8BA8;&#x8BBA;&#x8FD9;&#x4E24;&#x4E2A;&#x95EE;&#x9898;.  &#x6709;&#x5173;&#x8BE6;&#x7EC6;&#x4FE1;&#x606F;, &#x8BF7;&#x53C2;&#x9605; <a href="https://arxiv.org/abs/1506.05254" target="_blank">Gradient Estimation Using Stochastic Computation Graphs</a> .</p>
<h2 id="&#x5F97;&#x5206;&#x51FD;&#x6570;">&#x5F97;&#x5206;&#x51FD;&#x6570;</h2>
<p>&#x5F53;&#x6982;&#x7387;&#x5BC6;&#x5EA6;&#x51FD;&#x6570;&#x76F8;&#x5BF9;&#x4E8E;&#x5176;&#x53C2;&#x6570;&#x53EF;&#x5FAE;&#x5206;&#x65F6;, &#x6211;&#x4EEC;&#x53EA;&#x9700;&#x8981;<code>sample()</code>&#x548C;<code>log_prob()</code>&#x6765;&#x5B9E;&#x73B0;REINFORCE:</p>
<p><img src="img/b50e881c13615b1d9aa00ad0c9cdfa99.jpg" alt=""></p>
<p><img src="img/51b8359f970d2bfe2ad4cdc3ac1aed3c.jpg" alt=""> &#x662F;&#x53C2;&#x6570;, <img src="img/82005cc2e0087e2a52c7e43df4a19a00.jpg" alt=""> &#x662F;&#x5B66;&#x4E60;&#x901F;&#x7387;, <img src="img/f9f040e861365a0560b2552b4e4e17da.jpg" alt=""> &#x662F;&#x5956;&#x52B1; &#x5E76;&#x4E14; <img src="img/2e84bb32ea0808870a16b888aeaf8d0d.jpg" alt=""> &#x662F;&#x5728;&#x72B6;&#x6001; <img src="img/0492c0bfd615cb5e61c847ece512ff51.jpg" alt=""> &#x4EE5;&#x53CA;&#x7ED9;&#x5B9A;&#x7B56;&#x7565; <img src="img/5f3ddae3395c04f9346a3ac1d327ae2a.jpg" alt="">&#x6267;&#x884C;&#x52A8;&#x4F5C; <img src="img/070b1af5eca3a5c5d72884b536090f17.jpg" alt=""> &#x7684;&#x6982;&#x7387;.</p>
<p>&#x5728;&#x5B9E;&#x8DF5;&#x4E2D;, &#x6211;&#x4EEC;&#x5C06;&#x4ECE;&#x7F51;&#x7EDC;&#x8F93;&#x51FA;&#x4E2D;&#x91C7;&#x6837;&#x4E00;&#x4E2A;&#x52A8;&#x4F5C;, &#x5C06;&#x8FD9;&#x4E2A;&#x52A8;&#x4F5C;&#x5E94;&#x7528;&#x4E8E;&#x4E00;&#x4E2A;&#x73AF;&#x5883;&#x4E2D;, &#x7136;&#x540E;&#x4F7F;&#x7528;<code>log_prob</code>&#x6784;&#x9020;&#x4E00;&#x4E2A;&#x7B49;&#x6548;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;. &#x8BF7;&#x6CE8;&#x610F;, &#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x8D1F;&#x6570;&#x662F;&#x56E0;&#x4E3A;&#x4F18;&#x5316;&#x5668;&#x4F7F;&#x7528;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;, &#x800C;&#x4E0A;&#x9762;&#x7684;&#x89C4;&#x5219;&#x5047;&#x8BBE;&#x68AF;&#x5EA6;&#x4E0A;&#x5347;. &#x6709;&#x4E86;&#x786E;&#x5B9A;&#x7684;&#x7B56;&#x7565;, REINFORCE&#x7684;&#x5B9E;&#x73B0;&#x4EE3;&#x7801;&#x5982;&#x4E0B;:</p>
<pre><code class="lang-py">probs = policy_network(state)
<span class="hljs-comment"># Note that this is equivalent to what used to be called multinomial</span>
m = Categorical(probs)
action = m.sample()
next_state, reward = env.step(action)
loss = -m.log_prob(action) * reward
loss.backward()
</code></pre>
<h2 id="pathwise-derivative">Pathwise derivative</h2>
<p>&#x5B9E;&#x73B0;&#x8FD9;&#x4E9B;&#x968F;&#x673A;/&#x7B56;&#x7565;&#x68AF;&#x5EA6;&#x7684;&#x53E6;&#x4E00;&#x79CD;&#x65B9;&#x6CD5;&#x662F;&#x4F7F;&#x7528;&#x6765;&#x81EA;<code>rsample()</code>&#x65B9;&#x6CD5;&#x7684;&#x91CD;&#x65B0;&#x53C2;&#x6570;&#x5316;&#x6280;&#x5DE7;, &#x5176;&#x4E2D;&#x53C2;&#x6570;&#x5316;&#x968F;&#x673A;&#x53D8;&#x91CF;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x65E0;&#x53C2;&#x6570;&#x968F;&#x673A;&#x53D8;&#x91CF;&#x7684;&#x53C2;&#x6570;&#x786E;&#x5B9A;&#x6027;&#x51FD;&#x6570;&#x6784;&#x9020;.  &#x56E0;&#x6B64;, &#x91CD;&#x65B0;&#x53C2;&#x6570;&#x5316;&#x7684;&#x6837;&#x672C;&#x53D8;&#x5F97;&#x53EF;&#x5FAE;&#x5206;.  &#x5B9E;&#x73B0;Pathwise derivative&#x7684;&#x4EE3;&#x7801;&#x5982;&#x4E0B;:</p>
<pre><code class="lang-py">params = policy_network(state)
m = Normal(*params)
<span class="hljs-comment"># Any distribution with .has_rsample == True could work based on the application</span>
action = m.rsample()
next_state, reward = env.step(action)  <span class="hljs-comment"># Assuming that reward is differentiable</span>
loss = -reward
loss.backward()
</code></pre>
<h2 id="&#x5206;&#x5E03;">&#x5206;&#x5E03;</h2>
<pre><code class="lang-py">class torch.distributions.distribution.Distribution(batch_shape=torch.Size([]), event_shape=torch.Size([]), validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)" target="_blank"><code>object</code></a></p>
<p>Distribution&#x662F;&#x6982;&#x7387;&#x5206;&#x5E03;&#x7684;&#x62BD;&#x8C61;&#x57FA;&#x7C7B;.</p>
<pre><code class="lang-py">arg_constraints
</code></pre>
<p>&#x4ECE;&#x53C2;&#x6570;&#x540D;&#x79F0;&#x8FD4;&#x56DE;&#x5B57;&#x5178;&#x5230; <a href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code>Constraint</code></a> &#x5BF9;&#x8C61;&#xFF08;&#x5E94;&#x8BE5;&#x6EE1;&#x8DB3;&#x8FD9;&#x4E2A;&#x5206;&#x5E03;&#x7684;&#x6BCF;&#x4E2A;&#x53C2;&#x6570;&#xFF09;.&#x4E0D;&#x662F;&#x5F20;&#x91CF;&#x7684;arg&#x4E0D;&#x9700;&#x8981;&#x51FA;&#x73B0;&#x5728;&#x8FD9;&#x4E2A;&#x5B57;&#x5178;&#x4E2D;.</p>
<pre><code class="lang-py">batch_shape
</code></pre>
<p>&#x8FD4;&#x56DE;&#x6279;&#x91CF;&#x53C2;&#x6570;&#x7684;&#x5F62;&#x72B6;.</p>
<pre><code class="lang-py">cdf(value)
</code></pre>
<p>&#x8FD4;&#x56DE;<code>value</code>&#x5904;&#x7684;&#x7D2F;&#x79EF;&#x5BC6;&#x5EA6;/&#x8D28;&#x91CF;&#x51FD;&#x6570;&#x4F30;&#x8BA1;.</p>
<p>| &#x53C2;&#x6570;: | <strong>value</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; |</p>
<pre><code class="lang-py">entropy()
</code></pre>
<p>&#x8FD4;&#x56DE;&#x5206;&#x5E03;&#x7684;&#x71B5;, &#x6279;&#x91CF;&#x7684;&#x5F62;&#x72B6;&#x4E3A; batch_shape.</p>
<p>| &#x8FD4;&#x56DE;&#x503C;: | Tensor &#x5F62;&#x72B6;&#x4E3A; batch_shape. |</p>
<pre><code class="lang-py">enumerate_support(expand=<span class="hljs-keyword">True</span>)
</code></pre>
<p>&#x8FD4;&#x56DE;&#x5305;&#x542B;&#x79BB;&#x6563;&#x5206;&#x5E03;&#x652F;&#x6301;&#x7684;&#x6240;&#x6709;&#x503C;&#x7684;&#x5F20;&#x91CF;. &#x7ED3;&#x679C;&#x5C06;&#x5728;&#x7EF4;&#x5EA6;0&#x4E0A;&#x679A;&#x4E3E;, &#x6240;&#x4EE5;&#x7ED3;&#x679C;&#x7684;&#x5F62;&#x72B6;&#x5C06;&#x662F; <code>(cardinality,) + batch_shape + event_shape</code> (&#x5BF9;&#x4E8E;&#x5355;&#x53D8;&#x91CF;&#x5206;&#x5E03; <code>event_shape = ()</code>).</p>
<p>&#x6CE8;&#x610F;, &#x8FD9;&#x5728;lock-step&#x4E2D;&#x679A;&#x4E3E;&#x4E86;&#x6240;&#x6709;&#x6279;&#x5904;&#x7406;&#x5F20;&#x91CF;<code>[[0, 0], [1, 1], &#x2026;]</code>. &#x5F53; <code>expand=False</code>, &#x679A;&#x4E3E;&#x6CBF;&#x7740;&#x7EF4;&#x5EA6; 0&#x8FDB;&#x884C;, &#x4F46;&#x662F;&#x5269;&#x4E0B;&#x7684;&#x6279;&#x5904;&#x7406;&#x7EF4;&#x5EA6;&#x662F;&#x5355;&#x7EF4;&#x5EA6;, <code>[[0], [1], ..</code>.</p>
<p>&#x904D;&#x5386;&#x6574;&#x4E2A;&#x7B1B;&#x5361;&#x5C14;&#x79EF;&#x7684;&#x4F7F;&#x7528; <code>itertools.product(m.enumerate_support())</code>.</p>
<p>| &#x53C2;&#x6570;: | <strong>expand</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)" target="_blank"><em>bool</em></a>) &#x2013; &#x662F;&#x5426;&#x6269;&#x5C55;&#x5BF9;&#x6279;&#x5904;&#x7406;dim&#x7684;&#x652F;&#x6301;&#x4EE5;&#x5339;&#x914D;&#x5206;&#x5E03;&#x7684; <code>batch_shape</code>. |</p>
<p>| &#x8FD4;&#x56DE;&#x503C;: | &#x5F20;&#x91CF;&#x5728;&#x7EF4;&#x4E0A;0&#x8FED;&#x4EE3;. |</p>
<pre><code class="lang-py">event_shape
</code></pre>
<p>&#x8FD4;&#x56DE;&#x5355;&#x4E2A;&#x6837;&#x672C;&#x7684;&#x5F62;&#x72B6; (&#x975E;&#x6279;&#x91CF;).</p>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<p>&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x5206;&#x5E03;&#x5B9E;&#x4F8B;(&#x6216;&#x586B;&#x5145;&#x6D3E;&#x751F;&#x7C7B;&#x63D0;&#x4F9B;&#x7684;&#x73B0;&#x6709;&#x5B9E;&#x4F8B;), &#x5176;&#x6279;&#x5904;&#x7406;&#x7EF4;&#x5EA6;&#x6269;&#x5C55;&#x4E3A; <code>batch_shape</code>.  &#x8FD9;&#x4E2A;&#x65B9;&#x6CD5;&#x8C03;&#x7528; <a href="tensors.html#torch.Tensor.expand" title="torch.Tensor.expand"><code>expand</code></a> &#x5728;&#x5206;&#x5E03;&#x7684;&#x53C2;&#x6570;&#x4E0A;. &#x56E0;&#x6B64;, &#x8FD9;&#x4E0D;&#x4F1A;&#x4E3A;&#x6269;&#x5C55;&#x7684;&#x5206;&#x5E03;&#x5B9E;&#x4F8B;&#x5206;&#x914D;&#x65B0;&#x7684;&#x5185;&#x5B58;.  &#x6B64;&#x5916;, &#x7B2C;&#x4E00;&#x6B21;&#x521B;&#x5EFA;&#x5B9E;&#x4F8B;&#x65F6;, &#x8FD9;&#x4E0D;&#x4F1A;&#x5728;&#x4E2D;&#x91CD;&#x590D;&#x4EFB;&#x4F55;&#x53C2;&#x6570;&#x68C0;&#x67E5;&#x6216;&#x53C2;&#x6570;&#x5E7F;&#x64AD;&#x5728; <code>__init__.py</code>.</p>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>batch_shape</strong> (<em>torch.Size</em>) &#x2013; &#x6240;&#x9700;&#x7684;&#x6269;&#x5C55;&#x5C3A;&#x5BF8;.</li>
<li><strong>_instance</strong> &#x2013; &#x7531;&#x9700;&#x8981;&#x91CD;&#x5199;<code>.expand</code>&#x7684;&#x5B50;&#x7C7B;&#x63D0;&#x4F9B;&#x7684;&#x65B0;&#x5B9E;&#x4F8B;.</li>
</ul>
<p>| &#x8FD4;&#x56DE;&#x503C;: | &#x6279;&#x5904;&#x7406;&#x7EF4;&#x5EA6;&#x6269;&#x5C55;&#x4E3A;<code>batch_size</code>&#x7684;&#x65B0;&#x5206;&#x5E03;&#x5B9E;&#x4F8B;. |</p>
<pre><code class="lang-py">icdf(value)
</code></pre>
<p> &#x8FD4;&#x56DE;&#x6309;<code>value</code>&#x8BA1;&#x7B97;&#x7684;&#x53CD;&#x5411;&#x7D2F;&#x79EF;&#x5BC6;&#x5EA6;/&#x8D28;&#x91CF;&#x51FD;&#x6570;.</p>
<p>| &#x53C2;&#x6570;: | <strong>value</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; |</p>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<p>&#x8FD4;&#x56DE;&#x6309;<code>value</code>&#x8BA1;&#x7B97;&#x7684;&#x6982;&#x7387;&#x5BC6;&#x5EA6;/&#x8D28;&#x91CF;&#x51FD;&#x6570;&#x7684;&#x5BF9;&#x6570;.</p>
<p>| &#x53C2;&#x6570;: | <strong>value</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; |</p>
<pre><code class="lang-py">mean
</code></pre>
<p>&#x8FD4;&#x56DE;&#x5206;&#x5E03;&#x7684;&#x5E73;&#x5747;&#x503C;.</p>
<pre><code class="lang-py">perplexity()
</code></pre>
<p>&#x8FD4;&#x56DE;&#x5206;&#x5E03;&#x7684;&#x56F0;&#x60D1;&#x5EA6;, &#x6279;&#x91CF;&#x7684;&#x5173;&#x4E8E; batch_shape.</p>
<p>| &#x8FD4;&#x56DE;&#x503C;: | &#x5F62;&#x72B6;&#x4E3A; batch_shape &#x7684;&#x5F20;&#x91CF;. |</p>
<pre><code class="lang-py">rsample(sample_shape=torch.Size([]))
</code></pre>
<p>&#x5982;&#x679C;&#x5206;&#x5E03;&#x7684;&#x53C2;&#x6570;&#x662F;&#x6279;&#x91CF;&#x7684;, &#x5219;&#x751F;&#x6210;sample_shape&#x5F62;&#x72B6;&#x7684;&#x91CD;&#x65B0;&#x53C2;&#x6570;&#x5316;&#x6837;&#x672C;&#x6216;sample_shape&#x5F62;&#x72B6;&#x7684;&#x6279;&#x91CF;&#x91CD;&#x65B0;&#x53C2;&#x6570;&#x5316;&#x6837;&#x672C;.</p>
<pre><code class="lang-py">sample(sample_shape=torch.Size([]))
</code></pre>
<p>&#x5982;&#x679C;&#x5206;&#x5E03;&#x7684;&#x53C2;&#x6570;&#x662F;&#x6279;&#x91CF;&#x7684;, &#x5219;&#x751F;&#x6210;sample_shape&#x5F62;&#x72B6;&#x7684;&#x6837;&#x672C;&#x6216;sample_shape&#x5F62;&#x72B6;&#x7684;&#x6279;&#x91CF;&#x6837;&#x672C;.</p>
<pre><code class="lang-py">sample_n(n)
</code></pre>
<p>&#x5982;&#x679C;&#x5206;&#x5E03;&#x53C2;&#x6570;&#x662F;&#x5206;&#x6279;&#x7684;, &#x5219;&#x751F;&#x6210;n&#x4E2A;&#x6837;&#x672C;&#x6216;n&#x6279;&#x6837;&#x672C;.</p>
<pre><code class="lang-py">stddev
</code></pre>
<p>&#x8FD4;&#x56DE;&#x5206;&#x5E03;&#x7684;&#x6807;&#x51C6;&#x5DEE;.</p>
<pre><code class="lang-py">support
</code></pre>
<p>&#x8FD4;&#x56DE;<a href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code>Constraint</code></a> &#x5BF9;&#x8C61;&#x8868;&#x793A;&#x8BE5;&#x5206;&#x5E03;&#x7684;&#x652F;&#x6301;.</p>
<pre><code class="lang-py">variance
</code></pre>
<p>&#x8FD4;&#x56DE;&#x5206;&#x5E03;&#x7684;&#x65B9;&#x5DEE;.</p>
<h2 id="exponentialfamily">ExponentialFamily</h2>
<pre><code class="lang-py">class torch.distributions.exp_family.ExponentialFamily(batch_shape=torch.Size([]), event_shape=torch.Size([]), validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x6307;&#x6570;&#x65CF;&#x662F;&#x6307;&#x6570;&#x65CF;&#x6982;&#x7387;&#x5206;&#x5E03;&#x7684;&#x62BD;&#x8C61;&#x57FA;&#x7C7B;, &#x5176;&#x6982;&#x7387;&#x8D28;&#x91CF;/&#x5BC6;&#x5EA6;&#x51FD;&#x6570;&#x7684;&#x5F62;&#x5F0F;&#x5B9A;&#x4E49;&#x5982;&#x4E0B;</p>
<p><img src="img/0c8313886f5c82dfae90e21b65152815.jpg" alt=""></p>
<p><img src="img/51b8359f970d2bfe2ad4cdc3ac1aed3c.jpg" alt=""> &#x8868;&#x793A;&#x81EA;&#x7136;&#x53C2;&#x6570;, <img src="img/e705d3772de12f4df3b0cd75af5110a1.jpg" alt=""> &#x8868;&#x793A;&#x5145;&#x5206;&#x7EDF;&#x8BA1;&#x91CF;, <img src="img/f876c4d8353c747436006e70fb6c4f5d.jpg" alt=""> &#x662F;&#x7ED9;&#x5B9A;&#x65CF;&#x7684;&#x5BF9;&#x6570;&#x5F52;&#x4E00;&#x5316;&#x51FD;&#x6570;  <img src="img/d3b6af2f20ffbc8480c6ee97c42958b2.jpg" alt=""> &#x662F;carrier measure.</p>
<p>&#x6CE8;&#x610F;</p>
<p>&#x8BE5;&#x7C7B;&#x662F;<code>Distribution</code>&#x7C7B;&#x4E0E;&#x6307;&#x6570;&#x65CF;&#x5206;&#x5E03;&#x4E4B;&#x95F4;&#x7684;&#x4E2D;&#x4ECB;, &#x4E3B;&#x8981;&#x7528;&#x4E8E;&#x68C0;&#x9A8C;<code>.entropy()</code>&#x548C;&#x89E3;&#x6790;KL&#x6563;&#x5EA6;&#x65B9;&#x6CD5;&#x7684;&#x6B63;&#x786E;&#x6027;. &#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x8FD9;&#x4E2A;&#x7C7B;&#x6765;&#x8BA1;&#x7B97;&#x71B5;&#x548C;KL&#x6563;&#x5EA6;&#x4F7F;&#x7528;AD&#x6846;&#x67B6;&#x548C;Bregman&#x6563;&#x5EA6; (&#x51FA;&#x81EA;: Frank Nielsen and Richard Nock, Entropies and Cross-entropies of Exponential Families).</p>
<pre><code class="lang-py">entropy()
</code></pre>
<p>&#x5229;&#x7528;&#x5BF9;&#x6570;&#x5F52;&#x4E00;&#x5316;&#x5668;&#x7684;Bregman&#x6563;&#x5EA6;&#x8BA1;&#x7B97;&#x71B5;&#x7684;&#x65B9;&#x6CD5;.</p>
<h2 id="bernoulli">Bernoulli</h2>
<pre><code class="lang-py">class torch.distributions.bernoulli.Bernoulli(probs=None, logits=None, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code>torch.distributions.exp_family.ExponentialFamily</code></a></p>
<p>&#x521B;&#x5EFA;&#x53C2;&#x6570;&#x5316;&#x7684;&#x4F2F;&#x52AA;&#x5229;&#x5206;&#x5E03;, &#x6839;&#x636E; <a href="#torch.distributions.bernoulli.Bernoulli.probs" title="torch.distributions.bernoulli.Bernoulli.probs"><code>probs</code></a> &#x6216;&#x8005; <a href="#torch.distributions.bernoulli.Bernoulli.logits" title="torch.distributions.bernoulli.Bernoulli.logits"><code>logits</code></a> (&#x4F46;&#x4E0D;&#x662F;&#x540C;&#x65F6;&#x90FD;&#x6709;).</p>
<p>&#x6837;&#x672C;&#x662F;&#x4E8C;&#x503C;&#x7684; (0 &#x6216;&#x8005; 1). &#x53D6;&#x503C; <code>1</code> &#x4F34;&#x968F;&#x6982;&#x7387; <code>p</code> , &#x6216;&#x8005; <code>0</code> &#x4F34;&#x968F;&#x6982;&#x7387; <code>1 - p</code>.</p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Bernoulli(torch.tensor([<span class="hljs-number">0.3</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># 30% chance 1; 70% chance 0</span>
tensor([ <span class="hljs-number">0.</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>probs</strong> (<em>Number__,</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; the probabilty of sampling <code>1</code></li>
<li><strong>logits</strong> (<em>Number__,</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; the log-odds of sampling <code>1</code></li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;logits&apos;</span>: Real(), <span class="hljs-string">&apos;probs&apos;</span>: Interval(lower_bound=<span class="hljs-number">0.0</span>, upper_bound=<span class="hljs-number">1.0</span>)}
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">enumerate_support(expand=<span class="hljs-keyword">True</span>)
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_enumerate_support = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">logits
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">param_shape
</code></pre>
<pre><code class="lang-py">probs
</code></pre>
<pre><code class="lang-py">sample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">support = Boolean()
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="beta">Beta</h2>
<pre><code class="lang-py">class torch.distributions.beta.Beta(concentration1, concentration0, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code>torch.distributions.exp_family.ExponentialFamily</code></a></p>
<p>Beta &#x5206;&#x5E03;, &#x53C2;&#x6570;&#x4E3A; <a href="#torch.distributions.beta.Beta.concentration1" title="torch.distributions.beta.Beta.concentration1"><code>concentration1</code></a> &#x548C; <a href="#torch.distributions.beta.Beta.concentration0" title="torch.distributions.beta.Beta.concentration0"><code>concentration0</code></a>.</p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Beta(torch.tensor([<span class="hljs-number">0.5</span>]), torch.tensor([<span class="hljs-number">0.5</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># Beta distributed with concentration concentration1 and concentration0</span>
tensor([ <span class="hljs-number">0.1046</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>concentration1</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5206;&#x5E03;&#x7684;&#x7B2C;&#x4E00;&#x4E2A;&#x6D53;&#x5EA6;&#x53C2;&#x6570;&#xFF08;&#x901A;&#x5E38;&#x79F0;&#x4E3A;alpha&#xFF09;</li>
<li><strong>concentration0</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5206;&#x5E03;&#x7684;&#x7B2C;&#x4E8C;&#x4E2A;&#x6D53;&#x5EA6;&#x53C2;&#x6570;(&#x901A;&#x5E38;&#x79F0;&#x4E3A;beta)</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;concentration0&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>), <span class="hljs-string">&apos;concentration1&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">concentration0
</code></pre>
<pre><code class="lang-py">concentration1
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">rsample(sample_shape=())
</code></pre>
<pre><code class="lang-py">support = Interval(lower_bound=<span class="hljs-number">0.0</span>, upper_bound=<span class="hljs-number">1.0</span>)
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="binomial">Binomial</h2>
<pre><code class="lang-py">class torch.distributions.binomial.Binomial(total_count=1, probs=None, logits=None, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;Binomial &#x5206;&#x5E03;, &#x53C2;&#x6570;&#x4E3A; <code>total_count</code> &#x548C; <a href="#torch.distributions.binomial.Binomial.probs" title="torch.distributions.binomial.Binomial.probs"><code>probs</code></a> &#x6216;&#x8005; <a href="#torch.distributions.binomial.Binomial.logits" title="torch.distributions.binomial.Binomial.logits"><code>logits</code></a> (&#x4F46;&#x4E0D;&#x662F;&#x540C;&#x65F6;&#x90FD;&#x6709;&#x4F7F;&#x7528;). <code>total_count</code> &#x5FC5;&#x987B;&#x548C; [<code>probs</code>] &#x4E4B;&#x95F4;&#x53EF;&#x5E7F;&#x64AD;(#torch.distributions.binomial.Binomial.probs &quot;torch.distributions.binomial.Binomial.probs&quot;)/<a href="#torch.distributions.binomial.Binomial.logits" title="torch.distributions.binomial.Binomial.logits"><code>logits</code></a>.</p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Binomial(<span class="hljs-number">100</span>, torch.tensor([<span class="hljs-number">0</span> , <span class="hljs-number">.2</span>, <span class="hljs-number">.8</span>, <span class="hljs-number">1</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>x = m.sample()
tensor([   <span class="hljs-number">0.</span>,   <span class="hljs-number">22.</span>,   <span class="hljs-number">71.</span>,  <span class="hljs-number">100.</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>m = Binomial(torch.tensor([[<span class="hljs-number">5.</span>], [<span class="hljs-number">10.</span>]]), torch.tensor([<span class="hljs-number">0.5</span>, <span class="hljs-number">0.8</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>x = m.sample()
tensor([[ <span class="hljs-number">4.</span>,  <span class="hljs-number">5.</span>],
 [ <span class="hljs-number">7.</span>,  <span class="hljs-number">6.</span>]])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>total_count</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)" target="_blank"><em>int</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x4F2F;&#x52AA;&#x5229;&#x8BD5;&#x9A8C;&#x6B21;&#x6570;</li>
<li><strong>probs</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x4E8B;&#x4EF6;&#x6982;&#x7387;</li>
<li><strong>logits</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x4E8B;&#x4EF6; log-odds</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;logits&apos;</span>: Real(), <span class="hljs-string">&apos;probs&apos;</span>: Interval(lower_bound=<span class="hljs-number">0.0</span>, upper_bound=<span class="hljs-number">1.0</span>), <span class="hljs-string">&apos;total_count&apos;</span>: IntegerGreaterThan(lower_bound=<span class="hljs-number">0</span>)}
</code></pre>
<pre><code class="lang-py">enumerate_support(expand=<span class="hljs-keyword">True</span>)
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_enumerate_support = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">logits
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">param_shape
</code></pre>
<pre><code class="lang-py">probs
</code></pre>
<pre><code class="lang-py">sample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">support
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="categorical">Categorical</h2>
<pre><code class="lang-py">class torch.distributions.categorical.Categorical(probs=None, logits=None, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A; categorical &#x5206;&#x5E03;, &#x53C2;&#x6570;&#x4E3A; <a href="#torch.distributions.categorical.Categorical.probs" title="torch.distributions.categorical.Categorical.probs"><code>probs</code></a> &#x6216;&#x8005; <a href="#torch.distributions.categorical.Categorical.logits" title="torch.distributions.categorical.Categorical.logits"><code>logits</code></a> (&#x4F46;&#x4E0D;&#x662F;&#x540C;&#x65F6;&#x90FD;&#x6709;).</p>
<p>&#x6CE8;&#x610F;</p>
<p>&#x5B83;&#x7B49;&#x4EF7;&#x4E8E;&#x4ECE; <a href="torch.html#torch.multinomial" title="torch.multinomial"><code>torch.multinomial()</code></a> &#x7684;&#x91C7;&#x6837;.</p>
<p>&#x6837;&#x672C;&#x662F;&#x6574;&#x6570;&#x6765;&#x81EA;<img src="img/7c6904e60a8ff7044a079e10eaee1f57.jpg" alt=""> <code>K</code> &#x662F; <code>probs.size(-1)</code>.</p>
<p>&#x5982;&#x679C; <a href="#torch.distributions.categorical.Categorical.probs" title="torch.distributions.categorical.Categorical.probs"><code>probs</code></a> &#x662F; 1D &#x7684;, &#x957F;&#x5EA6;&#x4E3A;<code>K</code>, &#x6BCF;&#x4E2A;&#x5143;&#x7D20;&#x662F;&#x5728;&#x8BE5;&#x7D22;&#x5F15;&#x5904;&#x5BF9;&#x7C7B;&#x8FDB;&#x884C;&#x62BD;&#x6837;&#x7684;&#x76F8;&#x5BF9;&#x6982;&#x7387;.</p>
<p>&#x5982;&#x679C; <a href="#torch.distributions.categorical.Categorical.probs" title="torch.distributions.categorical.Categorical.probs"><code>probs</code></a> &#x662F; 2D &#x7684;, &#x5B83;&#x88AB;&#x89C6;&#x4E3A;&#x4E00;&#x7EC4;&#x76F8;&#x5BF9;&#x6982;&#x7387;&#x5411;&#x91CF;.</p>
<p>&#x6CE8;&#x610F;</p>
<p><a href="#torch.distributions.categorical.Categorical.probs" title="torch.distributions.categorical.Categorical.probs"><code>probs</code></a>  &#x5FC5;&#x987B;&#x662F;&#x975E;&#x8D1F;&#x7684;&#x3001;&#x6709;&#x9650;&#x7684;&#x5E76;&#x4E14;&#x5177;&#x6709;&#x975E;&#x96F6;&#x548C;, &#x5E76;&#x4E14;&#x5B83;&#x5C06;&#x88AB;&#x5F52;&#x4E00;&#x5316;&#x4E3A;&#x548C;&#x4E3A;1.</p>
<p>&#x8BF7;&#x53C2;&#x9605;: <a href="torch.html#torch.multinomial" title="torch.multinomial"><code>torch.multinomial()</code></a></p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Categorical(torch.tensor([ <span class="hljs-number">0.25</span>, <span class="hljs-number">0.25</span>, <span class="hljs-number">0.25</span>, <span class="hljs-number">0.25</span> ]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># equal probability of 0, 1, 2, 3</span>
tensor(<span class="hljs-number">3</span>)
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>probs</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; event probabilities</li>
<li><strong>logits</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; event log probabilities</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;logits&apos;</span>: Real(), <span class="hljs-string">&apos;probs&apos;</span>: Simplex()}
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">enumerate_support(expand=<span class="hljs-keyword">True</span>)
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_enumerate_support = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">logits
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">param_shape
</code></pre>
<pre><code class="lang-py">probs
</code></pre>
<pre><code class="lang-py">sample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">support
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="cauchy">Cauchy</h2>
<pre><code class="lang-py">class torch.distributions.cauchy.Cauchy(loc, scale, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x6837;&#x672C;&#x6765;&#x81EA;&#x67EF;&#x897F;(&#x6D1B;&#x4F26;&#x5179;)&#x5206;&#x5E03;. &#x5747;&#x503C;&#x4E3A;0&#x7684;&#x72EC;&#x7ACB;&#x6B63;&#x6001;&#x5206;&#x5E03;&#x968F;&#x673A;&#x53D8;&#x91CF;&#x4E4B;&#x6BD4;&#x670D;&#x4ECE;&#x67EF;&#x897F;&#x5206;&#x5E03;. </p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Cauchy(torch.tensor([<span class="hljs-number">0.0</span>]), torch.tensor([<span class="hljs-number">1.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># sample from a Cauchy distribution with loc=0 and scale=1</span>
tensor([ <span class="hljs-number">2.3214</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>loc</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5206;&#x5E03;&#x7684;&#x6A21;&#x6001;&#x6216;&#x4E2D;&#x503C;.</li>
<li><strong>scale</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; half width at half maximum.</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;loc&apos;</span>: Real(), <span class="hljs-string">&apos;scale&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">cdf(value)
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">icdf(value)
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">rsample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">support = Real()
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="chi2">Chi2</h2>
<pre><code class="lang-py">class torch.distributions.chi2.Chi2(df, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.gamma.Gamma" title="torch.distributions.gamma.Gamma"><code>torch.distributions.gamma.Gamma</code></a></p>
<p> &#x521B;&#x5EFA;&#x7531;&#x5F62;&#x72B6;&#x53C2;&#x6570;<a href="#torch.distributions.chi2.Chi2.df" title="torch.distributions.chi2.Chi2.df"><code>df</code></a>&#x53C2;&#x6570;&#x5316;&#x7684;Chi2&#x5206;&#x5E03;.  &#x8FD9;&#x5B8C;&#x5168;&#x7B49;&#x540C;&#x4E8E; <code>Gamma(alpha=0.5*df, beta=0.5)</code></p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Chi2(torch.tensor([<span class="hljs-number">1.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># Chi2 distributed with shape df=1</span>
tensor([ <span class="hljs-number">0.1046</span>])
</code></pre>
<p>| &#x53C2;&#x6570;: | <strong>df</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5206;&#x5E03;&#x7684;&#x5F62;&#x72B6;&#x53C2;&#x6570; |</p>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;df&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">df
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<h2 id="dirichlet">Dirichlet</h2>
<pre><code class="lang-py">class torch.distributions.dirichlet.Dirichlet(concentration, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code>torch.distributions.exp_family.ExponentialFamily</code></a></p>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A; Dirichlet &#x5206;&#x5E03;, &#x53C2;&#x6570;&#x4E3A;<code>concentration</code>.</p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Dirichlet(torch.tensor([<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># Dirichlet distributed with concentrarion concentration</span>
tensor([ <span class="hljs-number">0.1046</span>,  <span class="hljs-number">0.8954</span>])
</code></pre>
<p>| &#x53C2;&#x6570;: | <strong>concentration</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013;  &#x5206;&#x5E03;&#x7684;&#x6D53;&#x5EA6;&#x53C2;&#x6570;&#xFF08;&#x901A;&#x5E38;&#x79F0;&#x4E3A;alpha&#xFF09; |</p>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;concentration&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">rsample(sample_shape=())
</code></pre>
<pre><code class="lang-py">support = Simplex()
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="exponential">Exponential</h2>
<pre><code class="lang-py">class torch.distributions.exponential.Exponential(rate, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code>torch.distributions.exp_family.ExponentialFamily</code></a></p>
<p>&#x521B;&#x5EFA;&#x7531;<code>rate</code>&#x53C2;&#x6570;&#x5316;&#x7684;&#x6307;&#x6570;&#x5206;&#x5E03;.</p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Exponential(torch.tensor([<span class="hljs-number">1.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># Exponential distributed with rate=1</span>
tensor([ <span class="hljs-number">0.1046</span>])
</code></pre>
<p>| &#x53C2;&#x6570;: | <strong>rate</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; rate = 1 / &#x5206;&#x5E03;&#x7684;scale  |</p>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;rate&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">cdf(value)
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">icdf(value)
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">rsample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">stddev
</code></pre>
<pre><code class="lang-py">support = GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="fishersnedecor">FisherSnedecor</h2>
<pre><code class="lang-py">class torch.distributions.fishersnedecor.FisherSnedecor(df1, df2, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x521B;&#x5EFA;&#x7531;<code>df1</code>&#x548C;<code>df2</code>&#x53C2;&#x6570;&#x5316;&#x7684;Fisher-Snedecor&#x5206;&#x5E03;</p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = FisherSnedecor(torch.tensor([<span class="hljs-number">1.0</span>]), torch.tensor([<span class="hljs-number">2.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># Fisher-Snedecor-distributed with df1=1 and df2=2</span>
tensor([ <span class="hljs-number">0.2453</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>df1</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013;  &#x81EA;&#x7531;&#x5EA6;&#x53C2;&#x6570;1</li>
<li><strong>df2</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x81EA;&#x7531;&#x5EA6;&#x53C2;&#x6570;2</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;df1&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>), <span class="hljs-string">&apos;df2&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">rsample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">support = GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="gamma">Gamma</h2>
<pre><code class="lang-py">class torch.distributions.gamma.Gamma(concentration, rate, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code>torch.distributions.exp_family.ExponentialFamily</code></a></p>
<p>&#x521B;&#x5EFA;&#x7531;<code>concentration</code>&#x548C;<code>rate</code>&#x53C2;&#x6570;&#x5316;&#x7684;&#x4F3D;&#x9A6C;&#x5206;&#x5E03;. .</p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Gamma(torch.tensor([<span class="hljs-number">1.0</span>]), torch.tensor([<span class="hljs-number">1.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># Gamma distributed with concentration=1 and rate=1</span>
tensor([ <span class="hljs-number">0.1046</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>concentration</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5206;&#x5E03;&#x7684;&#x5F62;&#x72B6;&#x53C2;&#x6570;&#xFF08;&#x901A;&#x5E38;&#x79F0;&#x4E3A;alpha&#xFF09;</li>
<li><strong>rate</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; rate = 1 /  &#x5206;&#x5E03;scale (&#x901A;&#x5E38;&#x79F0;&#x4E3A;beta )</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;concentration&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>), <span class="hljs-string">&apos;rate&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">rsample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">support = GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="geometric">Geometric</h2>
<pre><code class="lang-py">class torch.distributions.geometric.Geometric(probs=None, logits=None, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x521B;&#x5EFA;&#x7531;<code>probs</code>&#x53C2;&#x6570;&#x5316;&#x7684;&#x51E0;&#x4F55;&#x5206;&#x5E03;, &#x5176;&#x4E2D;<code>probs</code>&#x662F;&#x4F2F;&#x52AA;&#x5229;&#x8BD5;&#x9A8C;&#x6210;&#x529F;&#x7684;&#x6982;&#x7387;. &#x5B83;&#x8868;&#x793A;&#x6982;&#x7387;&#x5728; <img src="img/10396db36bab7b7242cfe94f04374444.jpg" alt=""> &#x6B21;&#x4F2F;&#x52AA;&#x5229;&#x8BD5;&#x9A8C;&#x4E2D;,  &#x524D; <img src="img/a1c2f8d5b1226e67bdb44b12a6ddf18b.jpg" alt=""> &#x8BD5;&#x9A8C;&#x5931;&#x8D25;, &#x7136;&#x540E;&#x6210;&#x529F;.</p>
<p>&#x6837;&#x672C;&#x662F;&#x975E;&#x8D1F;&#x6574;&#x6570; [0, <img src="img/06485c2c6e992cf346fdfe033a86a10d.jpg" alt="">).</p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Geometric(torch.tensor([<span class="hljs-number">0.3</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># underlying Bernoulli has 30% chance 1; 70% chance 0</span>
tensor([ <span class="hljs-number">2.</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>probs</strong> (<em>Number__,</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013;  &#x62BD;&#x6837;<code>1</code>&#x7684;&#x6982;&#x7387; . &#x5FC5;&#x987B;&#x662F;&#x5728;&#x8303;&#x56F4; (0, 1]</li>
<li><strong>logits</strong> (<em>Number__,</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x62BD;&#x6837; <code>1</code>&#x7684;log-odds.</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;logits&apos;</span>: Real(), <span class="hljs-string">&apos;probs&apos;</span>: Interval(lower_bound=<span class="hljs-number">0.0</span>, upper_bound=<span class="hljs-number">1.0</span>)}
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">logits
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">probs
</code></pre>
<pre><code class="lang-py">sample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">support = IntegerGreaterThan(lower_bound=<span class="hljs-number">0</span>)
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="gumbel">Gumbel</h2>
<pre><code class="lang-py">class torch.distributions.gumbel.Gumbel(loc, scale, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code>torch.distributions.transformed_distribution.TransformedDistribution</code></a></p>
<p>&#x6765;&#x81EA;Gumbel&#x5206;&#x5E03;&#x7684;&#x6837;&#x672C;.</p>
<p>Examples:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Gumbel(torch.tensor([<span class="hljs-number">1.0</span>]), torch.tensor([<span class="hljs-number">2.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># sample from Gumbel distribution with loc=1, scale=2</span>
tensor([ <span class="hljs-number">1.0124</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>loc</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013;  &#x5206;&#x5E03;&#x7684;&#x4F4D;&#x7F6E;&#x53C2;&#x6570;</li>
<li><strong>scale</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013;  &#x5206;&#x5E03;&#x7684;scale &#x53C2;&#x6570;</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;loc&apos;</span>: Real(), <span class="hljs-string">&apos;scale&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">stddev
</code></pre>
<pre><code class="lang-py">support = Real()
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="halfcauchy">HalfCauchy</h2>
<pre><code class="lang-py">class torch.distributions.half_cauchy.HalfCauchy(scale, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code>torch.distributions.transformed_distribution.TransformedDistribution</code></a></p>
<p>&#x521B;&#x5EFA;<code>scale</code>&#x53C2;&#x6570;&#x5316;&#x7684;&#x534A;&#x6B63;&#x6001;&#x5206;&#x5E03;:</p>
<pre><code class="lang-py">X ~ Cauchy(<span class="hljs-number">0</span>, scale)
Y = |X| ~ HalfCauchy(scale)
</code></pre>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = HalfCauchy(torch.tensor([<span class="hljs-number">1.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># half-cauchy distributed with scale=1</span>
tensor([ <span class="hljs-number">2.3214</span>])
</code></pre>
<p>| &#x53C2;&#x6570;: | <strong>scale</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5B8C;&#x5168;&#x67EF;&#x897F;&#x5206;&#x5E03;&#x7684;scale |</p>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;scale&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">cdf(value)
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">icdf(prob)
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">scale
</code></pre>
<pre><code class="lang-py">support = GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="halfnormal">HalfNormal</h2>
<pre><code class="lang-py">class torch.distributions.half_normal.HalfNormal(scale, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code>torch.distributions.transformed_distribution.TransformedDistribution</code></a></p>
<p>&#x521B;&#x5EFA;&#x6309;<code>scale</code>&#x53C2;&#x6570;&#x5316;&#x7684;&#x534A;&#x6B63;&#x6001;&#x5206;&#x5E03;:</p>
<pre><code class="lang-py">X ~ Normal(<span class="hljs-number">0</span>, scale)
Y = |X| ~ HalfNormal(scale)
</code></pre>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = HalfNormal(torch.tensor([<span class="hljs-number">1.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># half-normal distributed with scale=1</span>
tensor([ <span class="hljs-number">0.1046</span>])
</code></pre>
<p>| &#x53C2;&#x6570;: | <strong>scale</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5B8C;&#x5168;&#x6B63;&#x6001;&#x5206;&#x5E03;&#x7684;scale |</p>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;scale&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">cdf(value)
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">icdf(prob)
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">scale
</code></pre>
<pre><code class="lang-py">support = GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="independent">Independent</h2>
<pre><code class="lang-py">class torch.distributions.independent.Independent(base_distribution, reinterpreted_batch_ndims, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x91CD;&#x65B0;&#x89E3;&#x91CA;&#x4E00;&#x4E9B;&#x5206;&#x5E03;&#x7684;&#x6279;&#x91CF; dims &#x4F5C;&#x4E3A; event dims.</p>
<p> &#x8FD9;&#x4E3B;&#x8981;&#x7528;&#x4E8E;&#x6539;&#x53D8;<a href="#torch.distributions.independent.Independent.log_prob" title="torch.distributions.independent.Independent.log_prob"><code>log_prob()</code></a>&#x7ED3;&#x679C;&#x7684;&#x5F62;&#x72B6;.&#x4F8B;&#x5982;, &#x8981;&#x521B;&#x5EFA;&#x4E0E;&#x591A;&#x5143;&#x6B63;&#x6001;&#x5206;&#x5E03;&#x5F62;&#x72B6;&#x76F8;&#x540C;&#x7684;&#x5BF9;&#x89D2;&#x6B63;&#x6001;&#x5206;&#x5E03;(&#x56E0;&#x6B64;&#x5B83;&#x4EEC;&#x662F;&#x53EF;&#x4E92;&#x6362;&#x7684;), &#x60A8;&#x53EF;&#x4EE5;&#x8FD9;&#x6837;&#x505A;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>loc = torch.zeros(<span class="hljs-number">3</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>scale = torch.ones(<span class="hljs-number">3</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>mvn = MultivariateNormal(loc, scale_tril=torch.diag(scale))
<span class="hljs-meta">&gt;&gt;&gt; </span>[mvn.batch_shape, mvn.event_shape]
[torch.Size(()), torch.Size((<span class="hljs-number">3</span>,))]
<span class="hljs-meta">&gt;&gt;&gt; </span>normal = Normal(loc, scale)
<span class="hljs-meta">&gt;&gt;&gt; </span>[normal.batch_shape, normal.event_shape]
[torch.Size((<span class="hljs-number">3</span>,)), torch.Size(())]
<span class="hljs-meta">&gt;&gt;&gt; </span>diagn = Independent(normal, <span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>[diagn.batch_shape, diagn.event_shape]
[torch.Size(()), torch.Size((<span class="hljs-number">3</span>,))]
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>base_distribution</strong> (<a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><em>torch.distributions.distribution.Distribution</em></a>) &#x2013; &#x57FA;&#x7840;&#x5206;&#x5E03;</li>
<li><strong>reinterpreted_batch_ndims</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)" target="_blank"><em>int</em></a>) &#x2013;&#x8981;&#x91CD;&#x89E3;&#x91CA;&#x7684;&#x6279;&#x91CF;dims&#x7684;&#x6570;&#x91CF;</li>
</ul>
<pre><code class="lang-py">arg_constraints = {}
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">enumerate_support(expand=<span class="hljs-keyword">True</span>)
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_enumerate_support
</code></pre>
<pre><code class="lang-py">has_rsample
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">rsample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">sample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">support
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="laplace">Laplace</h2>
<pre><code class="lang-py">class torch.distributions.laplace.Laplace(loc, scale, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x521B;&#x5EFA;&#x53C2;&#x6570;&#x5316;&#x7684;&#x62C9;&#x666E;&#x62C9;&#x65AF;&#x5206;&#x5E03;, &#x53C2;&#x6570;&#x662F; <code>loc</code> &#x548C; :attr:&#x2019;scale&#x2019;.</p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Laplace(torch.tensor([<span class="hljs-number">0.0</span>]), torch.tensor([<span class="hljs-number">1.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># Laplace distributed with loc=0, scale=1</span>
tensor([ <span class="hljs-number">0.1046</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>loc</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5206;&#x5E03;&#x5747;&#x503C;</li>
<li><strong>scale</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5206;&#x5E03;scale</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;loc&apos;</span>: Real(), <span class="hljs-string">&apos;scale&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">cdf(value)
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">icdf(value)
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">rsample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">stddev
</code></pre>
<pre><code class="lang-py">support = Real()
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="lognormal">LogNormal</h2>
<pre><code class="lang-py">class torch.distributions.log_normal.LogNormal(loc, scale, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code>torch.distributions.transformed_distribution.TransformedDistribution</code></a></p>
<p> &#x521B;&#x5EFA;&#x53C2;&#x6570;&#x5316;&#x7684;&#x5BF9;&#x6570;&#x6B63;&#x6001;&#x5206;&#x5E03;, &#x53C2;&#x6570;&#x4E3A; <a href="#torch.distributions.log_normal.LogNormal.loc" title="torch.distributions.log_normal.LogNormal.loc"><code>loc</code></a> &#x548C; <a href="#torch.distributions.log_normal.LogNormal.scale" title="torch.distributions.log_normal.LogNormal.scale"><code>scale</code></a>:</p>
<pre><code class="lang-py">X ~ Normal(loc, scale)
Y = exp(X) ~ LogNormal(loc, scale)
</code></pre>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = LogNormal(torch.tensor([<span class="hljs-number">0.0</span>]), torch.tensor([<span class="hljs-number">1.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># log-normal distributed with mean=0 and stddev=1</span>
tensor([ <span class="hljs-number">0.1046</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>loc</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013;  &#x5206;&#x5E03;&#x5BF9;&#x6570;&#x5E73;&#x5747;&#x503C;</li>
<li><strong>scale</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013;  &#x5206;&#x5E03;&#x5BF9;&#x6570;&#x7684;&#x6807;&#x51C6;&#x5DEE;</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;loc&apos;</span>: Real(), <span class="hljs-string">&apos;scale&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">loc
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">scale
</code></pre>
<pre><code class="lang-py">support = GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="lowrankmultivariatenormal">LowRankMultivariateNormal</h2>
<pre><code class="lang-py">class torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal(loc, cov_factor, cov_diag, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x4F7F;&#x7528;&#x7531;<code>cov_factor</code>&#x548C;<code>cov_diag</code>&#x53C2;&#x6570;&#x5316;&#x7684;&#x4F4E;&#x79E9;&#x5F62;&#x5F0F;&#x7684;&#x534F;&#x65B9;&#x5DEE;&#x77E9;&#x9635;&#x521B;&#x5EFA;&#x591A;&#x5143;&#x6B63;&#x6001;&#x5206;&#x5E03;:</p>
<pre><code class="lang-py">covariance_matrix = cov_factor @ cov_factor.T + cov_diag
</code></pre>
<p>Example</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = LowRankMultivariateNormal(torch.zeros(<span class="hljs-number">2</span>), torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]), torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># normally distributed with mean=`[0,0]`, cov_factor=`[1,0]`, cov_diag=`[1,1]`</span>
tensor([<span class="hljs-number">-0.2102</span>, <span class="hljs-number">-0.5429</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>loc</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5206;&#x5E03;&#x7684;&#x5747;&#x503C;, &#x5F62;&#x72B6;&#x4E3A; <code>batch_shape + event_shape</code></li>
<li><strong>cov_factor</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x534F;&#x65B9;&#x5DEE;&#x77E9;&#x9635;&#x4F4E;&#x79E9;&#x5F62;&#x5F0F;&#x7684;&#x56E0;&#x5B50;&#x90E8;&#x5206;, &#x5F62;&#x72B6;&#x4E3A; <code>batch_shape + event_shape + (rank,)</code></li>
<li><strong>cov_diag</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x534F;&#x65B9;&#x5DEE;&#x77E9;&#x9635;&#x7684;&#x4F4E;&#x79E9;&#x5F62;&#x5F0F;&#x7684;&#x5BF9;&#x89D2;&#x90E8;&#x5206;, &#x5F62;&#x72B6;&#x4E3A; <code>batch_shape + event_shape</code></li>
</ul>
<p>&#x6CE8;&#x610F;</p>
<p>&#x907F;&#x514D;&#x4E86;&#x534F;&#x65B9;&#x5DEE;&#x77E9;&#x9635;&#x7684;&#x884C;&#x5217;&#x5F0F;&#x548C;&#x9006;&#x7684;&#x8BA1;&#x7B97;, &#x5F53; <code>cov_factor.shape[1] &lt;&lt; cov_factor.shape[0]</code> &#x7531;&#x4E8E; <a href="https://en.wikipedia.org/wiki/Woodbury_matrix_identity" target="_blank">Woodbury matrix identity</a> &#x548C; <a href="https://en.wikipedia.org/wiki/Matrix_determinant_lemma" target="_blank">matrix determinant lemma</a>.  &#x7531;&#x4E8E;&#x8FD9;&#x4E9B;&#x516C;&#x5F0F;, &#x6211;&#x4EEC;&#x53EA;&#x9700;&#x8981;&#x8BA1;&#x7B97;&#x5C0F;&#x5C3A;&#x5BF8;&#x201C;capacitance&#x201D;&#x77E9;&#x9635;&#x7684;&#x884C;&#x5217;&#x5F0F;&#x548C;&#x9006;:</p>
<pre><code class="lang-py">capacitance = I + cov_factor.T @ inv(cov_diag) @ cov_factor
</code></pre>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;cov_diag&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>), <span class="hljs-string">&apos;cov_factor&apos;</span>: Real(), <span class="hljs-string">&apos;loc&apos;</span>: Real()}
</code></pre>
<pre><code class="lang-py">covariance_matrix
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">precision_matrix
</code></pre>
<pre><code class="lang-py">rsample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">scale_tril
</code></pre>
<pre><code class="lang-py">support = Real()
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="multinomial">Multinomial</h2>
<pre><code class="lang-py">class torch.distributions.multinomial.Multinomial(total_count=1, probs=None, logits=None, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x521B;&#x5EFA;&#x7531;<code>total_count</code>&#x548C;<code>probs</code>&#x6216;<code>logits</code>&#xFF08;&#x4F46;&#x4E0D;&#x662F;&#x4E24;&#x8005;&#xFF09;&#x53C2;&#x6570;&#x5316;&#x7684;&#x591A;&#x9879;&#x5F0F;&#x5206;&#x5E03;.  <code>probs</code>&#x7684;&#x6700;&#x5185;&#x5C42;&#x7EF4;&#x5EA6;&#x662F;&#x5BF9;&#x7C7B;&#x522B;&#x7684;&#x7D22;&#x5F15;.  &#x6240;&#x6709;&#x5176;&#x4ED6;&#x7EF4;&#x5EA6;&#x7D22;&#x5F15;&#x6279;&#x6B21;. </p>
<p>&#x6CE8;&#x610F; <code>total_count</code> &#x4E0D;&#x9700;&#x8981;&#x6307;&#x5B9A;, &#x5F53;&#x53EA;&#x6709; <a href="#torch.distributions.multinomial.Multinomial.log_prob" title="torch.distributions.multinomial.Multinomial.log_prob"><code>log_prob()</code></a> &#x88AB;&#x8C03;&#x7528;</p>
<p>&#x6CE8;&#x610F;</p>
<p><a href="#torch.distributions.multinomial.Multinomial.probs" title="torch.distributions.multinomial.Multinomial.probs"><code>probs</code></a> &#x5FC5;&#x987B;&#x662F;&#x975E;&#x8D1F;&#x7684;&#x3001;&#x6709;&#x9650;&#x7684;&#x5E76;&#x4E14;&#x5177;&#x6709;&#x975E;&#x96F6;&#x548C;, &#x5E76;&#x4E14;&#x5B83;&#x5C06;&#x88AB;&#x5F52;&#x4E00;&#x5316;&#x4E3A;&#x548C;&#x4E3A;1.</p>
<ul>
<li><a href="#torch.distributions.multinomial.Multinomial.sample" title="torch.distributions.multinomial.Multinomial.sample"><code>sample()</code></a> &#x6240;&#x6709;&#x53C2;&#x6570;&#x548C;&#x6837;&#x672C;&#x90FD;&#x9700;&#x8981;&#x4E00;&#x4E2A;&#x5171;&#x4EAB;&#x7684;<code>total_count</code>.</li>
<li><a href="#torch.distributions.multinomial.Multinomial.log_prob" title="torch.distributions.multinomial.Multinomial.log_prob"><code>log_prob()</code></a>  &#x5141;&#x8BB8;&#x6BCF;&#x4E2A;&#x53C2;&#x6570;&#x548C;&#x6837;&#x672C;&#x4F7F;&#x7528;&#x4E0D;&#x540C;&#x7684;<code>total_count</code>.</li>
</ul>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Multinomial(<span class="hljs-number">100</span>, torch.tensor([ <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>x = m.sample()  <span class="hljs-comment"># equal probability of 0, 1, 2, 3</span>
tensor([ <span class="hljs-number">21.</span>,  <span class="hljs-number">24.</span>,  <span class="hljs-number">30.</span>,  <span class="hljs-number">25.</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>Multinomial(probs=torch.tensor([<span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>])).log_prob(x)
tensor([<span class="hljs-number">-4.1338</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>total_count</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)" target="_blank"><em>int</em></a>) &#x2013; &#x8BD5;&#x9A8C;&#x6B21;&#x6570;</li>
<li><strong>probs</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x4E8B;&#x4EF6;&#x6982;&#x7387;</li>
<li><strong>logits</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x4E8B;&#x4EF6;&#x5BF9;&#x6570;&#x6982;&#x7387;</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;logits&apos;</span>: Real(), <span class="hljs-string">&apos;probs&apos;</span>: Simplex()}
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">logits
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">param_shape
</code></pre>
<pre><code class="lang-py">probs
</code></pre>
<pre><code class="lang-py">sample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">support
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="multivariatenormal">MultivariateNormal</h2>
<pre><code class="lang-py">class torch.distributions.multivariate_normal.MultivariateNormal(loc, covariance_matrix=None, precision_matrix=None, scale_tril=None, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x521B;&#x5EFA;&#x7531;&#x5747;&#x503C;&#x5411;&#x91CF;&#x548C;&#x534F;&#x65B9;&#x5DEE;&#x77E9;&#x9635;&#x53C2;&#x6570;&#x5316;&#x7684;&#x591A;&#x5143;&#x6B63;&#x6001;(&#x4E5F;&#x79F0;&#x4E3A;&#x9AD8;&#x65AF;)&#x5206;&#x5E03;.</p>
<p>&#x591A;&#x5143;&#x6B63;&#x6001;&#x5206;&#x5E03;&#x53EF;&#x4EE5;&#x7528;&#x6B63;&#x5B9A;&#x534F;&#x65B9;&#x5DEE;&#x77E9;&#x9635;<img src="img/ea86c11eaef9af2b4d699b88c2474ffd.jpg" alt="">&#x6765;&#x53C2;&#x6570;&#x5316;&#x6216;&#x8005;&#x4E00;&#x4E2A;&#x6B63;&#x5B9A;&#x7684;&#x7CBE;&#x5EA6;&#x77E9;&#x9635; <img src="img/1949bfcc1decf198a2ff50b6e25f4cf6.jpg" alt="">  &#x6216;&#x8005;&#x662F;&#x4E00;&#x4E2A;&#x6B63;&#x5BF9;&#x89D2;&#x9879;&#x7684;&#x4E0B;&#x4E09;&#x89D2;&#x77E9;&#x9635; <img src="img/f4996f1b5056dd364eab16f975b808ff.jpg" alt="">, &#x4F8B;&#x5982; <img src="img/6749b6afc75abfc8e0652ac8e5c0b8d8.jpg" alt="">. &#x8FD9;&#x4E2A;&#x4E09;&#x89D2;&#x77E9;&#x9635;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x534F;&#x65B9;&#x5DEE;&#x7684;Cholesky&#x5206;&#x89E3;&#x5F97;&#x5230;.</p>
<p>&#x4F8B;&#x5B50;</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = MultivariateNormal(torch.zeros(<span class="hljs-number">2</span>), torch.eye(<span class="hljs-number">2</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># normally distributed with mean=`[0,0]` and covariance_matrix=`I`</span>
tensor([<span class="hljs-number">-0.2102</span>, <span class="hljs-number">-0.5429</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>loc</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5206;&#x5E03;&#x7684;&#x5747;&#x503C;</li>
<li><strong>covariance_matrix</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x6B63;&#x5B9A;&#x534F;&#x65B9;&#x5DEE;&#x77E9;&#x9635;</li>
<li><strong>precision_matrix</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x6B63;&#x5B9A;&#x7CBE;&#x5EA6;&#x77E9;&#x9635;</li>
<li><strong>scale_tril</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5177;&#x6709;&#x6B63;&#x503C;&#x5BF9;&#x89D2;&#x7EBF;&#x7684;&#x4E0B;&#x4E09;&#x89D2;&#x534F;&#x65B9;&#x5DEE;&#x56E0;&#x5B50;</li>
</ul>
<p>&#x6CE8;&#x610F;</p>
<p>&#x4EC5;&#x4EC5;&#x4E00;&#x4E2A; <a href="#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix" title="torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix"><code>covariance_matrix</code></a> &#x6216;&#x8005; <a href="#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix" title="torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix"><code>precision_matrix</code></a> &#x6216;&#x8005; <a href="#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril" title="torch.distributions.multivariate_normal.MultivariateNormal.scale_tril"><code>scale_tril</code></a> &#x53EF;&#x88AB;&#x6307;&#x5B9A;.</p>
<p>&#x4F7F;&#x7528; <a href="#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril" title="torch.distributions.multivariate_normal.MultivariateNormal.scale_tril"><code>scale_tril</code></a>  &#x4F1A;&#x66F4;&#x6709;&#x6548;&#x7387;: &#x5185;&#x90E8;&#x7684;&#x6240;&#x6709;&#x8BA1;&#x7B97;&#x90FD;&#x57FA;&#x4E8E; <a href="#torch.distributions.multivariate_normal.MultivariateNormal.scale_tril" title="torch.distributions.multivariate_normal.MultivariateNormal.scale_tril"><code>scale_tril</code></a>. &#x5982;&#x679C; <a href="#torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix" title="torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix"><code>covariance_matrix</code></a> &#x6216;&#x8005; <a href="#torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix" title="torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix"><code>precision_matrix</code></a> &#x5DF2;&#x7ECF;&#x88AB;&#x4F20;&#x5165;, &#x5B83;&#x4EC5;&#x7528;&#x4E8E;&#x4F7F;&#x7528;Cholesky&#x5206;&#x89E3;&#x8BA1;&#x7B97;&#x76F8;&#x5E94;&#x7684;&#x4E0B;&#x4E09;&#x89D2;&#x77E9;&#x9635;.</p>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;covariance_matrix&apos;</span>: PositiveDefinite(), <span class="hljs-string">&apos;loc&apos;</span>: RealVector(), <span class="hljs-string">&apos;precision_matrix&apos;</span>: PositiveDefinite(), <span class="hljs-string">&apos;scale_tril&apos;</span>: LowerCholesky()}
</code></pre>
<pre><code class="lang-py">covariance_matrix
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">precision_matrix
</code></pre>
<pre><code class="lang-py">rsample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">scale_tril
</code></pre>
<pre><code class="lang-py">support = Real()
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="negativebinomial">NegativeBinomial</h2>
<pre><code class="lang-py">class torch.distributions.negative_binomial.NegativeBinomial(total_count, probs=None, logits=None, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x8D1F;&#x4E8C;&#x9879;&#x5206;&#x5E03;, &#x5373;&#x5728;&#x8FBE;&#x5230;<code>total_count</code>&#x5931;&#x8D25;&#x4E4B;&#x524D;&#x6240;&#x9700;&#x7684;&#x72EC;&#x7ACB;&#x76F8;&#x540C;&#x4F2F;&#x52AA;&#x5229;&#x8BD5;&#x9A8C;&#x7684;&#x6570;&#x91CF;&#x7684;&#x5206;&#x5E03;. &#x6BCF;&#x6B21;&#x4F2F;&#x52AA;&#x5229;&#x8BD5;&#x9A8C;&#x6210;&#x529F;&#x7684;&#x6982;&#x7387;&#x90FD;&#x662F;<code>probs</code>. </p>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>total_count</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013;  &#x975E;&#x8D1F;&#x6570;&#x4F2F;&#x52AA;&#x5229;&#x8BD5;&#x9A8C;&#x505C;&#x6B62;&#x7684;&#x6B21;&#x6570;, &#x867D;&#x7136;&#x5206;&#x5E03;&#x4ECD;&#x7136;&#x5BF9;&#x5B9E;&#x6570;&#x6709;&#x6548;</li>
<li><strong>probs</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x4E8B;&#x4EF6;&#x6982;&#x7387;, &#x533A;&#x95F4;&#x4E3A; [0, 1)</li>
<li><strong>logits</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x4E8B;&#x4EF6;&#x5BF9;&#x6570;&#x51E0;&#x7387; - &#x6210;&#x529F;&#x6982;&#x7387;&#x7684;&#x51E0;&#x7387;</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;logits&apos;</span>: Real(), <span class="hljs-string">&apos;probs&apos;</span>: HalfOpenInterval(lower_bound=<span class="hljs-number">0.0</span>, upper_bound=<span class="hljs-number">1.0</span>), <span class="hljs-string">&apos;total_count&apos;</span>: GreaterThanEq(lower_bound=<span class="hljs-number">0</span>)}
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">logits
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">param_shape
</code></pre>
<pre><code class="lang-py">probs
</code></pre>
<pre><code class="lang-py">sample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">support = IntegerGreaterThan(lower_bound=<span class="hljs-number">0</span>)
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="normal">Normal</h2>
<pre><code class="lang-py">class torch.distributions.normal.Normal(loc, scale, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code>torch.distributions.exp_family.ExponentialFamily</code></a></p>
<p>&#x521B;&#x5EFA;&#x7531;<code>loc</code>&#x548C;<code>scale</code>&#x53C2;&#x6570;&#x5316;&#x7684;&#x6B63;&#x6001;&#xFF08;&#x4E5F;&#x79F0;&#x4E3A;&#x9AD8;&#x65AF;&#xFF09;&#x5206;&#x5E03;</p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Normal(torch.tensor([<span class="hljs-number">0.0</span>]), torch.tensor([<span class="hljs-number">1.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># normally distributed with loc=0 and scale=1</span>
tensor([ <span class="hljs-number">0.1046</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>loc</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5747;&#x503C; (&#x4E5F;&#x88AB;&#x79F0;&#x4E3A; mu)</li>
<li><strong>scale</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x6807;&#x51C6;&#x5DEE;(&#x4E5F;&#x88AB;&#x79F0;&#x4E3A;) sigma)</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;loc&apos;</span>: Real(), <span class="hljs-string">&apos;scale&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">cdf(value)
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">icdf(value)
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">rsample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">sample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">stddev
</code></pre>
<pre><code class="lang-py">support = Real()
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="onehotcategorical">OneHotCategorical</h2>
<pre><code class="lang-py">class torch.distributions.one_hot_categorical.OneHotCategorical(probs=None, logits=None, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x7531;<code>probs</code>&#x6216;l<code>ogits</code>&#x53C2;&#x6570;&#x5316;&#x7684;One Hot Categorical &#x5206;&#x5E03;</p>
<p>&#x6837;&#x672C;&#x662F;&#x5927;&#x5C0F;&#x4E3A; <code>probs.size(-1)</code>&#x70ED;&#x7F16;&#x7801;&#x5411;&#x91CF;.</p>
<p>&#x6CE8;&#x610F;</p>
<p><code>probs</code>&#x5FC5;&#x987B;&#x662F;&#x975E;&#x8D1F;&#x7684;, &#x6709;&#x9650;&#x7684;&#x5E76;&#x4E14;&#x5177;&#x6709;&#x975E;&#x96F6;&#x548C;, &#x5E76;&#x4E14;&#x5B83;&#x5C06;&#x88AB;&#x5F52;&#x4E00;&#x5316;&#x4E3A;&#x603B;&#x548C;&#x4E3A;1. </p>
<p>&#x8BF7;&#x53C2;&#x89C1;: <code>torch.distributions.Categorical()</code> &#x5BF9;&#x4E8E;&#x6307;&#x5B9A; <a href="#torch.distributions.one_hot_categorical.OneHotCategorical.probs" title="torch.distributions.one_hot_categorical.OneHotCategorical.probs"><code>probs</code></a> &#x548C; <a href="#torch.distributions.one_hot_categorical.OneHotCategorical.logits" title="torch.distributions.one_hot_categorical.OneHotCategorical.logits"><code>logits</code></a>.</p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = OneHotCategorical(torch.tensor([ <span class="hljs-number">0.25</span>, <span class="hljs-number">0.25</span>, <span class="hljs-number">0.25</span>, <span class="hljs-number">0.25</span> ]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># equal probability of 0, 1, 2, 3</span>
tensor([ <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">0.</span>,  <span class="hljs-number">1.</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>probs</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; event probabilities</li>
<li><strong>logits</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; event log probabilities</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;logits&apos;</span>: Real(), <span class="hljs-string">&apos;probs&apos;</span>: Simplex()}
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">enumerate_support(expand=<span class="hljs-keyword">True</span>)
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_enumerate_support = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">logits
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">param_shape
</code></pre>
<pre><code class="lang-py">probs
</code></pre>
<pre><code class="lang-py">sample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">support = Simplex()
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="pareto">Pareto</h2>
<pre><code class="lang-py">class torch.distributions.pareto.Pareto(scale, alpha, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code>torch.distributions.transformed_distribution.TransformedDistribution</code></a></p>
<p>&#x6765;&#x81EA;Pareto Type 1&#x5206;&#x5E03;&#x7684;&#x6837;&#x672C;.</p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Pareto(torch.tensor([<span class="hljs-number">1.0</span>]), torch.tensor([<span class="hljs-number">1.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># sample from a Pareto distribution with scale=1 and alpha=1</span>
tensor([ <span class="hljs-number">1.5623</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>scale</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5206;&#x5E03;&#x7684;Scale</li>
<li><strong>alpha</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5206;&#x5E03;&#x7684;Shape</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;alpha&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>), <span class="hljs-string">&apos;scale&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">support
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="poisson">Poisson</h2>
<pre><code class="lang-py">class torch.distributions.poisson.Poisson(rate, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.exp_family.ExponentialFamily" title="torch.distributions.exp_family.ExponentialFamily"><code>torch.distributions.exp_family.ExponentialFamily</code></a></p>
<p>&#x521B;&#x5EFA;&#x6309;<code>rate</code>&#x53C2;&#x6570;&#x5316;&#x7684;&#x6CCA;&#x677E;&#x5206;&#x5E03;</p>
<p>&#x6837;&#x672C;&#x662F;&#x975E;&#x8D1F;&#x6574;&#x6570;, pmf&#x662F;</p>
<p><img src="img/32c47de57300c954795486fea3201bdc.jpg" alt=""></p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Poisson(torch.tensor([<span class="hljs-number">4</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()
tensor([ <span class="hljs-number">3.</span>])
</code></pre>
<p>| &#x53C2;&#x6570;: | <strong>rate</strong> (<em>Number__,</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; rate &#x53C2;&#x6570; |</p>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;rate&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">sample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">support = IntegerGreaterThan(lower_bound=<span class="hljs-number">0</span>)
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="relaxedbernoulli">RelaxedBernoulli</h2>
<pre><code class="lang-py">class torch.distributions.relaxed_bernoulli.RelaxedBernoulli(temperature, probs=None, logits=None, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code>torch.distributions.transformed_distribution.TransformedDistribution</code></a></p>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;RelaxedBernoulli&#x5206;&#x5E03;, &#x901A;&#x8FC7;<a href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature" title="torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature"><code>temperature</code></a>&#x53C2;&#x6570;&#x5316;, &#x4EE5;&#x53CA;<code>probs</code>&#x6216;<code>logits</code>&#xFF08;&#x4F46;&#x4E0D;&#x662F;&#x4E24;&#x8005;&#xFF09;.  &#x8FD9;&#x662F;&#x4F2F;&#x52AA;&#x5229;&#x5206;&#x5E03;&#x7684;&#x677E;&#x5F1B;&#x7248;&#x672C;, &#x56E0;&#x6B64;&#x503C;&#x5728;&#xFF08;0,1&#xFF09;&#x4E2D;, &#x5E76;&#x4E14;&#x5177;&#x6709;&#x53EF;&#x91CD;&#x53C2;&#x6570;&#x5316;&#x7684;&#x6837;&#x672C;. </p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = RelaxedBernoulli(torch.tensor([<span class="hljs-number">2.2</span>]),
 torch.tensor([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.99</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()
tensor([ <span class="hljs-number">0.2951</span>,  <span class="hljs-number">0.3442</span>,  <span class="hljs-number">0.8918</span>,  <span class="hljs-number">0.9021</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>temperature</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x677E;&#x5F1B; temperature</li>
<li><strong>probs</strong> (<em>Number__,</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013;&#x91C7;&#x6837; <code>1</code> &#x7684;&#x6982;&#x7387;</li>
<li><strong>logits</strong> (<em>Number__,</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x91C7;&#x6837; <code>1</code> &#x7684;&#x5BF9;&#x6570;&#x6982;&#x7387;</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;logits&apos;</span>: Real(), <span class="hljs-string">&apos;probs&apos;</span>: Interval(lower_bound=<span class="hljs-number">0.0</span>, upper_bound=<span class="hljs-number">1.0</span>)}
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">logits
</code></pre>
<pre><code class="lang-py">probs
</code></pre>
<pre><code class="lang-py">support = Interval(lower_bound=<span class="hljs-number">0.0</span>, upper_bound=<span class="hljs-number">1.0</span>)
</code></pre>
<pre><code class="lang-py">temperature
</code></pre>
<h2 id="relaxedonehotcategorical">RelaxedOneHotCategorical</h2>
<pre><code class="lang-py">class torch.distributions.relaxed_categorical.RelaxedOneHotCategorical(temperature, probs=None, logits=None, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code>torch.distributions.transformed_distribution.TransformedDistribution</code></a></p>
<p>&#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x7531;&#x6E29;&#x5EA6;&#x53C2;&#x6570;&#x5316;&#x7684;<code>RelaxedOneHotCategorical</code>&#x5206;&#x5E03;, &#x4EE5;&#x53CA;<code>probs</code>&#x6216;<code>logits</code>.  &#x8FD9;&#x662F;<code>OneHotCategorical</code>&#x5206;&#x5E03;&#x7684;&#x677E;&#x5F1B;&#x7248;&#x672C;, &#x56E0;&#x6B64;&#x5B83;&#x7684;&#x6837;&#x672C;&#x662F;&#x5355;&#x4E00;&#x7684;, &#x5E76;&#x4E14;&#x53EF;&#x4EE5;&#x91CD;&#x53C2;&#x6570;&#x5316;. </p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = RelaxedOneHotCategorical(torch.tensor([<span class="hljs-number">2.2</span>]),
 torch.tensor([<span class="hljs-number">0.1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.3</span>, <span class="hljs-number">0.4</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()
tensor([ <span class="hljs-number">0.1294</span>,  <span class="hljs-number">0.2324</span>,  <span class="hljs-number">0.3859</span>,  <span class="hljs-number">0.2523</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>temperature</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x677E;&#x5F1B; temperature</li>
<li><strong>probs</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x4E8B;&#x4EF6;&#x6982;&#x7387;</li>
<li><strong>logits</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013;&#x5BF9;&#x6570;&#x4E8B;&#x4EF6;&#x6982;&#x7387;.</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;logits&apos;</span>: Real(), <span class="hljs-string">&apos;probs&apos;</span>: Simplex()}
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">logits
</code></pre>
<pre><code class="lang-py">probs
</code></pre>
<pre><code class="lang-py">support = Simplex()
</code></pre>
<pre><code class="lang-py">temperature
</code></pre>
<h2 id="studentt">StudentT</h2>
<pre><code class="lang-py">class torch.distributions.studentT.StudentT(df, loc=0.0, scale=1.0, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x6839;&#x636E;&#x81EA;&#x7531;&#x5EA6;<code>df</code>, &#x5E73;&#x5747;<code>loc</code>&#x548C;<code>scale</code>&#x521B;&#x5EFA;&#x5B66;&#x751F;t&#x5206;&#x5E03;. </p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = StudentT(torch.tensor([<span class="hljs-number">2.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># Student&apos;s t-distributed with degrees of freedom=2</span>
tensor([ <span class="hljs-number">0.1046</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>df</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x81EA;&#x7531;&#x5EA6;</li>
<li><strong>loc</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5747;&#x503C;</li>
<li><strong>scale</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5206;&#x5E03;&#x7684;scale</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;df&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>), <span class="hljs-string">&apos;loc&apos;</span>: Real(), <span class="hljs-string">&apos;scale&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">rsample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">support = Real()
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="transformeddistribution">TransformedDistribution</h2>
<pre><code class="lang-py">class torch.distributions.transformed_distribution.TransformedDistribution(base_distribution, transforms, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>Distribution&#x7C7B;&#x7684;&#x6269;&#x5C55;, &#x5B83;&#x5C06;&#x4E00;&#x7CFB;&#x5217;&#x53D8;&#x6362;&#x5E94;&#x7528;&#x4E8E;&#x57FA;&#x672C;&#x5206;&#x5E03;. &#x5047;&#x8BBE;f&#x662F;&#x6240;&#x5E94;&#x7528;&#x53D8;&#x6362;&#x7684;&#x7EC4;&#x6210;:</p>
<pre><code class="lang-py">X ~ BaseDistribution
Y = f(X) ~ TransformedDistribution(BaseDistribution, f)
log p(Y) = log p(X) + log |det (dX/dY)|
</code></pre>
<p>&#x6CE8;&#x610F; <code>.event_shape</code> of a <a href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code>TransformedDistribution</code></a> &#x662F;&#x5176;&#x57FA;&#x672C;&#x5206;&#x5E03;&#x53CA;&#x5176;&#x53D8;&#x6362;&#x7684;&#x6700;&#x5927;&#x5F62;&#x72B6;, &#x56E0;&#x4E3A;&#x53D8;&#x6362;&#x53EF;&#x4EE5;&#x5F15;&#x5165;&#x4E8B;&#x4EF6;&#x4E4B;&#x95F4;&#x7684;&#x76F8;&#x5173;&#x6027;.</p>
<p>&#x4E00;&#x4E2A;&#x4F7F;&#x7528;&#x4F8B;&#x5B50; <a href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code>TransformedDistribution</code></a>:</p>
<pre><code class="lang-py"><span class="hljs-comment"># Building a Logistic Distribution</span>
<span class="hljs-comment"># X ~ Uniform(0, 1)</span>
<span class="hljs-comment"># f = a + b * logit(X)</span>
<span class="hljs-comment"># Y ~ f(X) ~ Logistic(a, b)</span>
base_distribution = Uniform(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)
transforms = [SigmoidTransform().inv, AffineTransform(loc=a, scale=b)]
logistic = TransformedDistribution(base_distribution, transforms)
</code></pre>
<p>&#x6709;&#x5173;&#x66F4;&#x591A;&#x793A;&#x4F8B;, &#x8BF7;&#x67E5;&#x770B;&#x6709;&#x5173;&#x5B9E;&#x73B0; <a href="#torch.distributions.gumbel.Gumbel" title="torch.distributions.gumbel.Gumbel"><code>Gumbel</code></a>, <a href="#torch.distributions.half_cauchy.HalfCauchy" title="torch.distributions.half_cauchy.HalfCauchy"><code>HalfCauchy</code></a>, <a href="#torch.distributions.half_normal.HalfNormal" title="torch.distributions.half_normal.HalfNormal"><code>HalfNormal</code></a>, <a href="#torch.distributions.log_normal.LogNormal" title="torch.distributions.log_normal.LogNormal"><code>LogNormal</code></a>, <a href="#torch.distributions.pareto.Pareto" title="torch.distributions.pareto.Pareto"><code>Pareto</code></a>, <a href="#torch.distributions.weibull.Weibull" title="torch.distributions.weibull.Weibull"><code>Weibull</code></a>, <a href="#torch.distributions.relaxed_bernoulli.RelaxedBernoulli" title="torch.distributions.relaxed_bernoulli.RelaxedBernoulli"><code>RelaxedBernoulli</code></a> &#x548C; <a href="#torch.distributions.relaxed_categorical.RelaxedOneHotCategorical" title="torch.distributions.relaxed_categorical.RelaxedOneHotCategorical"><code>RelaxedOneHotCategorical</code></a></p>
<pre><code class="lang-py">arg_constraints = {}
</code></pre>
<pre><code class="lang-py">cdf(value)
</code></pre>
<p>&#x901A;&#x8FC7;&#x9006;&#x53D8;&#x6362;&#x548C;&#x8BA1;&#x7B97;&#x57FA;&#x5206;&#x5E03;&#x7684;&#x5206;&#x6570;&#x6765;&#x8BA1;&#x7B97;&#x7D2F;&#x79EF;&#x5206;&#x5E03;&#x51FD;&#x6570;.</p>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample
</code></pre>
<pre><code class="lang-py">icdf(value)
</code></pre>
<p>&#x4F7F;&#x7528;transform(s)&#x8BA1;&#x7B97;&#x9006;&#x7D2F;&#x79EF;&#x5206;&#x5E03;&#x51FD;&#x6570;, &#x5E76;&#x8BA1;&#x7B97;&#x57FA;&#x5206;&#x5E03;&#x7684;&#x5206;&#x6570;.</p>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<p>&#x901A;&#x8FC7;&#x53CD;&#x8F6C;&#x53D8;&#x6362;&#x5E76;&#x4F7F;&#x7528;&#x57FA;&#x672C;&#x5206;&#x5E03;&#x7684;&#x5206;&#x6570;&#x548C;&#x65E5;&#x5FD7;abs det jacobian&#x8BA1;&#x7B97;&#x5206;&#x6570;&#x6765;&#x5BF9;&#x6837;&#x672C;&#x8FDB;&#x884C;&#x8BC4;&#x5206;</p>
<pre><code class="lang-py">rsample(sample_shape=torch.Size([]))
</code></pre>
<p>&#x5982;&#x679C;&#x5206;&#x5E03;&#x53C2;&#x6570;&#x662F;&#x6279;&#x5904;&#x7406;&#x7684;, &#x5219;&#x751F;&#x6210;sample_shape&#x5F62;&#x72B6;&#x7684;&#x91CD;&#x65B0;&#x53C2;&#x6570;&#x5316;&#x6837;&#x672C;&#x6216;sample_shape&#x5F62;&#x72B6;&#x7684;&#x91CD;&#x65B0;&#x53C2;&#x6570;&#x5316;&#x6837;&#x672C;&#x6279;&#x6B21;.  &#x9996;&#x5148;&#x4ECE;&#x57FA;&#x672C;&#x5206;&#x5E03;&#x4E2D;&#x91C7;&#x6837;, &#x5E76;&#x5BF9;&#x5217;&#x8868;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x53D8;&#x6362;&#x5E94;&#x7528;<code>transform()</code></p>
<pre><code class="lang-py">sample(sample_shape=torch.Size([]))
</code></pre>
<p>&#x5982;&#x679C;&#x5206;&#x5E03;&#x53C2;&#x6570;&#x662F;&#x6279;&#x5904;&#x7406;&#x7684;, &#x5219;&#x751F;&#x6210;sample_shape&#x5F62;&#x6837;&#x672C;&#x6216;sample_shape&#x5F62;&#x6837;&#x672C;&#x6279;&#x5904;&#x7406;.  &#x9996;&#x5148;&#x4ECE;&#x57FA;&#x672C;&#x5206;&#x5E03;&#x4E2D;&#x91C7;&#x6837;, &#x5E76;&#x5BF9;&#x5217;&#x8868;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x53D8;&#x6362;&#x5E94;&#x7528;<code>transform()</code>. </p>
<pre><code class="lang-py">support
</code></pre>
<h2 id="uniform">Uniform</h2>
<pre><code class="lang-py">class torch.distributions.uniform.Uniform(low, high, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><code>torch.distributions.distribution.Distribution</code></a></p>
<p>&#x4ECE;&#x534A;&#x5F00;&#x533A;&#x95F4;<code>[low, high)</code>&#x751F;&#x6210;&#x5747;&#x5300;&#x5206;&#x5E03;&#x7684;&#x968F;&#x673A;&#x6837;&#x672C;</p>
<p>&#x4F8B;&#x5B50;:</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Uniform(torch.tensor([<span class="hljs-number">0.0</span>]), torch.tensor([<span class="hljs-number">5.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># uniformly distributed in the range [0.0, 5.0)</span>
tensor([ <span class="hljs-number">2.3418</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>low</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013;  &#x4E0B;&#x9650;&#xFF08;&#x542B;&#xFF09;.</li>
<li><strong>high</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x4E0A;&#x9650;(&#x6392;&#x9664;).</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;high&apos;</span>: Dependent(), <span class="hljs-string">&apos;low&apos;</span>: Dependent()}
</code></pre>
<pre><code class="lang-py">cdf(value)
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">has_rsample = <span class="hljs-keyword">True</span>
</code></pre>
<pre><code class="lang-py">icdf(value)
</code></pre>
<pre><code class="lang-py">log_prob(value)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">rsample(sample_shape=torch.Size([]))
</code></pre>
<pre><code class="lang-py">stddev
</code></pre>
<pre><code class="lang-py">support
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="weibull">Weibull</h2>
<pre><code class="lang-py">class torch.distributions.weibull.Weibull(scale, concentration, validate_args=None)
</code></pre>
<p>&#x57FA;&#x7C7B;: <a href="#torch.distributions.transformed_distribution.TransformedDistribution" title="torch.distributions.transformed_distribution.TransformedDistribution"><code>torch.distributions.transformed_distribution.TransformedDistribution</code></a></p>
<p>&#x6765;&#x81EA;&#x53CC;&#x53C2;&#x6570;Weibull&#x5206;&#x5E03;&#x7684;&#x6837;&#x672C;.</p>
<p>Example</p>
<pre><code class="lang-py"><span class="hljs-meta">&gt;&gt;&gt; </span>m = Weibull(torch.tensor([<span class="hljs-number">1.0</span>]), torch.tensor([<span class="hljs-number">1.0</span>]))
<span class="hljs-meta">&gt;&gt;&gt; </span>m.sample()  <span class="hljs-comment"># sample from a Weibull distribution with scale=1, concentration=1</span>
tensor([ <span class="hljs-number">0.4784</span>])
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>scale</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; Scale (lambda).</li>
<li><strong>concentration</strong> (<a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; Concentration (k/shape).</li>
</ul>
<pre><code class="lang-py">arg_constraints = {<span class="hljs-string">&apos;concentration&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>), <span class="hljs-string">&apos;scale&apos;</span>: GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)}
</code></pre>
<pre><code class="lang-py">entropy()
</code></pre>
<pre><code class="lang-py">expand(batch_shape, _instance=<span class="hljs-keyword">None</span>)
</code></pre>
<pre><code class="lang-py">mean
</code></pre>
<pre><code class="lang-py">support = GreaterThan(lower_bound=<span class="hljs-number">0.0</span>)
</code></pre>
<pre><code class="lang-py">variance
</code></pre>
<h2 id="kl-divergence"><code>KL Divergence</code></h2>
<pre><code class="lang-py">torch.distributions.kl.kl_divergence(p, q)
</code></pre>
<p>&#x8BA1;&#x7B97;Kullback-Leibler&#x6563;&#x5EA6; <img src="img/739a8e4cd0597805c3e4daf35c0fc7c6.jpg" alt=""> &#x5BF9;&#x4E8E;&#x4E24;&#x4E2A;&#x5206;&#x5E03;.</p>
<p><img src="img/ff8dcec3abe559720f8b0b464d2471b2.jpg" alt=""></p>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>p</strong> (<a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><em>Distribution</em></a>) &#x2013; <code>Distribution</code> &#x5BF9;&#x8C61;.</li>
<li><strong>q</strong> (<a href="#torch.distributions.distribution.Distribution" title="torch.distributions.distribution.Distribution"><em>Distribution</em></a>) &#x2013; <code>Distribution</code> &#x5BF9;&#x8C61;.</li>
</ul>
<p>| &#x8FD4;&#x56DE;&#x503C;: | &#x6279;&#x91CF;&#x7684; KL &#x6563;&#x5EA6;, &#x5F62;&#x72B6;&#x4E3A; <code>batch_shape</code>. |</p>
<p>| &#x8FD4;&#x56DE;&#x7C7B;&#x578B;&#xFF1A; | <a href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a> |</p>
<p>| &#x5F02;&#x5E38;: | <a href="https://docs.python.org/3/library/exceptions.html#NotImplementedError" title="(in Python v3.7)" target="_blank"><code>NotImplementedError</code></a> &#x2013; &#x5982;&#x679C;&#x5206;&#x5E03;&#x7C7B;&#x578B;&#x5C1A;&#x672A;&#x901A;&#x8FC7;&#x6CE8;&#x518C; <a href="#torch.distributions.kl.register_kl" title="torch.distributions.kl.register_kl"><code>register_kl()</code></a>. |</p>
<pre><code class="lang-py">torch.distributions.kl.register_kl(type_p, type_q)
</code></pre>
<p>&#x88C5;&#x9970;&#x5668;&#x6CE8;&#x518C;<a href="#torch.distributions.kl.kl_divergence" title="torch.distributions.kl.kl_divergence"><code>kl_divergence()</code></a>&#x7684;&#x6210;&#x5BF9;&#x51FD;&#x6570;</p>
<pre><code class="lang-py"><span class="hljs-meta">@register_kl(Normal, Normal)</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">kl_normal_normal</span><span class="hljs-params">(p, q)</span>:</span>
    <span class="hljs-comment"># insert implementation here</span>
</code></pre>
<p>Lookup&#x8FD4;&#x56DE;&#x7531;&#x5B50;&#x7C7B;&#x6392;&#x5E8F;&#x7684;&#x6700;&#x5177;&#x4F53;(type,type)&#x5339;&#x914D;.  &#x5982;&#x679C;&#x5339;&#x914D;&#x4E0D;&#x660E;&#x786E;, &#x5219;&#x4F1A;&#x5F15;&#x53D1;<code>RuntimeWarning</code>.  &#x4F8B;&#x5982;, &#x89E3;&#x51B3;&#x6A21;&#x68F1;&#x4E24;&#x53EF;&#x7684;&#x60C5;&#x51B5;</p>
<pre><code class="lang-py"><span class="hljs-meta">@register_kl(BaseP, DerivedQ)</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">kl_version1</span><span class="hljs-params">(p, q)</span>:</span> ...
<span class="hljs-meta">@register_kl(DerivedP, BaseQ)</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">kl_version2</span><span class="hljs-params">(p, q)</span>:</span> ...
</code></pre>
<p>&#x4F60;&#x5E94;&#x8BE5;&#x6CE8;&#x518C;&#x7B2C;&#x4E09;&#x4E2A;&#x6700;&#x5177;&#x4F53;&#x7684;&#x5B9E;&#x73B0;, &#x4F8B;&#x5982;:</p>
<pre><code class="lang-py">register_kl(DerivedP, DerivedQ)(kl_version1)  <span class="hljs-comment"># Break the tie.</span>
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>type_p</strong> (<a href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.7)" target="_blank"><em>type</em></a>) &#x2013; &#x5B50;&#x7C7B; <code>Distribution</code>.</li>
<li><strong>type_q</strong> (<a href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.7)" target="_blank"><em>type</em></a>) &#x2013; &#x5B50;&#x7C7B; <code>Distribution</code>.</li>
</ul>
<h2 id="transforms"><code>Transforms</code></h2>
<pre><code class="lang-py">class torch.distributions.transforms.Transform(cache_size=0)
</code></pre>
<p>&#x6709;&#x53EF;&#x8BA1;&#x7B97;&#x7684;log det jacobians&#x8FDB;&#x884C;&#x53EF;&#x9006;&#x53D8;&#x6362;&#x7684;&#x62BD;&#x8C61;&#x7C7B;.  &#x5B83;&#x4EEC;&#x4E3B;&#x8981;&#x7528;&#x4E8E; <code>torch.distributions.TransformedDistribution</code>.</p>
<p>&#x7F13;&#x5B58;&#x5BF9;&#x4E8E;&#x5176;&#x53CD;&#x8F6C;&#x6602;&#x8D35;&#x6216;&#x6570;&#x503C;&#x4E0D;&#x7A33;&#x5B9A;&#x7684;&#x53D8;&#x6362;&#x5F88;&#x6709;&#x7528;.  &#x8BF7;&#x6CE8;&#x610F;, &#x5FC5;&#x987B;&#x6CE8;&#x610F;&#x8BB0;&#x5FC6;&#x503C;, &#x56E0;&#x4E3A;&#x53EF;&#x4EE5;&#x98A0;&#x5012;&#x81EA;&#x52A8;&#x8BB0;&#x5F55;&#x56FE;.  &#x4F8B;&#x5982;, &#x4EE5;&#x4E0B;&#x64CD;&#x4F5C;&#x6709;&#x6216;&#x6CA1;&#x6709;&#x7F13;&#x5B58;:</p>
<pre><code class="lang-py">y = t(x)
t.log_abs_det_jacobian(x, y).backward()  <span class="hljs-comment"># x will receive gradients.</span>
</code></pre>
<p>&#x4F46;&#x662F;, &#x7531;&#x4E8E;&#x4F9D;&#x8D56;&#x6027;&#x53CD;&#x8F6C;, &#x7F13;&#x5B58;&#x65F6;&#x4F1A;&#x51FA;&#x73B0;&#x4EE5;&#x4E0B;&#x9519;&#x8BEF;:</p>
<pre><code class="lang-py">y = t(x)
z = t.inv(y)
grad(z.sum(), [y])  <span class="hljs-comment"># error because z is x</span>
</code></pre>
<p> &#x6D3E;&#x751F;&#x7C7B;&#x5E94;&#x8BE5;&#x5B9E;&#x73B0;<code>_call()</code>&#x6216;<code>_inverse()</code>&#x4E2D;&#x7684;&#x4E00;&#x4E2A;&#x6216;&#x4E24;&#x4E2A;.  &#x8BBE;&#x7F6E;<code>bijective=True</code>&#x7684;&#x6D3E;&#x751F;&#x7C7B;&#x4E5F;&#x5E94;&#x8BE5;&#x5B9E;&#x73B0;<code>log_abs_det_jacobian()</code></p>
<p>| &#x53C2;&#x6570;: | <strong>cache_size</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)" target="_blank"><em>int</em></a>) &#x2013; &#x7F13;&#x5B58;&#x5927;&#x5C0F;.  &#x5982;&#x679C;&#x4E3A;&#x96F6;, &#x5219;&#x4E0D;&#x8FDB;&#x884C;&#x7F13;&#x5B58;.  &#x5982;&#x679C;&#x662F;, &#x5219;&#x7F13;&#x5B58;&#x6700;&#x65B0;&#x7684;&#x5355;&#x4E2A;&#x503C;.  &#x4EC5;&#x652F;&#x6301;0&#x548C;1 |</p>
<p>| Variables: | </p>
<ul>
<li><strong>domain</strong> (<a href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code>Constraint</code></a>) &#x2013;  &#x8868;&#x793A;&#x8BE5;&#x53D8;&#x6362;&#x6709;&#x6548;&#x8F93;&#x5165;&#x7684;&#x7EA6;&#x675F;.</li>
<li><strong>codomain</strong> (<a href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code>Constraint</code></a>) &#x2013; &#x8868;&#x793A;&#x6B64;&#x8F6C;&#x6362;&#x7684;&#x6709;&#x6548;&#x8F93;&#x51FA;&#x7684;&#x7EA6;&#x675F;, &#x8FD9;&#x4E9B;&#x8F93;&#x51FA;&#x662F;&#x9006;&#x53D8;&#x6362;&#x7684;&#x8F93;&#x5165;.</li>
<li><strong>bijective</strong> (<a href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)" target="_blank"><em>bool</em></a>) &#x2013;  &#x8FD9;&#x4E2A;&#x53D8;&#x6362;&#x662F;&#x5426;&#x662F;&#x53CC;&#x5C04;&#x7684;. &#x53D8;&#x6362; <code>t</code> &#x662F;&#x53CC;&#x5C04;&#x7684; &#x5982;&#x679C; <code>t.inv(t(x)) == x</code> &#x5E76;&#x4E14; <code>t(t.inv(y)) == y</code> &#x5BF9;&#x4E8E;&#x6BCF;&#x4E00;&#x4E2A; <code>x</code> &#x548C; <code>y</code>. &#x4E0D;&#x662F;&#x53CC;&#x5C04;&#x7684;&#x53D8;&#x5F62;&#x5E94;&#x8BE5;&#x81F3;&#x5C11;&#x4FDD;&#x6301;&#x8F83;&#x5F31;&#x7684;&#x4F2A;&#x9006;&#x5C5E;&#x6027; <code>t(t.inv(t(x)) == t(x)</code> and <code>t.inv(t(t.inv(y))) == t.inv(y)</code>.</li>
<li><strong>sign</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)" target="_blank"><em>int</em></a> <em>or</em> <a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) &#x2013; &#x5BF9;&#x4E8E;&#x53CC;&#x5C04;&#x5355;&#x53D8;&#x91CF;&#x53D8;&#x6362;, &#x5B83;&#x5E94;&#x8BE5;&#x662F;+1&#x6216;-1, &#x8FD9;&#x53D6;&#x51B3;&#x4E8E;&#x53D8;&#x6362;&#x662F;&#x5355;&#x8C03;&#x9012;&#x589E;&#x8FD8;&#x662F;&#x9012;&#x51CF;.</li>
<li><strong>event_dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)" target="_blank"><em>int</em></a>) &#x2013; &#x53D8;&#x6362;event_shape&#x4E2D;&#x76F8;&#x5173;&#x7684;&#x7EF4;&#x6570;.  &#x8FD9;&#x5BF9;&#x4E8E;&#x9010;&#x70B9;&#x53D8;&#x6362;&#x5E94;&#x8BE5;&#x662F;0, &#x5BF9;&#x4E8E;&#x5728;&#x77E2;&#x91CF;&#x4E0A;&#x5171;&#x540C;&#x4F5C;&#x7528;&#x7684;&#x53D8;&#x6362;&#x662F;1, &#x5BF9;&#x4E8E;&#x5728;&#x77E9;&#x9635;&#x4E0A;&#x5171;&#x540C;&#x4F5C;&#x7528;&#x7684;&#x53D8;&#x6362;&#x662F;2, &#x7B49;&#x7B49;.</li>
</ul>
<pre><code class="lang-py">inv
</code></pre>
<p>&#x8FD4;&#x56DE;&#x9006;<a href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code>Transform</code></a>. &#x6EE1;&#x8DB3; <code>t.inv.inv is t</code>.</p>
<pre><code class="lang-py">sign
</code></pre>
<p>&#x5982;&#x679C;&#x9002;&#x7528;, &#x8FD4;&#x56DE;&#x96C5;&#x53EF;&#x6BD4;&#x884C;&#x5217;&#x5F0F;&#x7684;&#x7B26;&#x53F7;.  &#x4E00;&#x822C;&#x6765;&#x8BF4;, &#x8FD9;&#x53EA;&#x9002;&#x7528;&#x4E8E;&#x53CC;&#x5C04;&#x53D8;&#x6362;.</p>
<pre><code class="lang-py">log_abs_det_jacobian(x, y)
</code></pre>
<p>&#x8BA1;&#x7B97; log det jacobian <code>log |dy/dx|</code> &#x7ED9;&#x5B9A;&#x8F93;&#x5165;&#x548C;&#x8F93;&#x51FA;.</p>
<pre><code class="lang-py">class torch.distributions.transforms.ComposeTransform(parts)
</code></pre>
<p>&#x5728;&#x4E00;&#x4E2A;&#x94FE;&#x4E2D;&#x7EC4;&#x5408;&#x591A;&#x4E2A;&#x8F6C;&#x6362;. &#x6B63;&#x5728;&#x7EC4;&#x5408;&#x7684;&#x8F6C;&#x6362;&#x8D1F;&#x8D23;&#x7F13;&#x5B58;.</p>
<p>| &#x53C2;&#x6570;: | <strong>parts</strong> (list of <a href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code>Transform</code></a>) &#x2013; &#x5217;&#x8868; transforms. |</p>
<pre><code class="lang-py">class torch.distributions.transforms.ExpTransform(cache_size=0)
</code></pre>
<p>&#x8F6C;&#x6362;&#x901A;&#x8FC7;&#x6620;&#x5C04; <img src="img/ec8d939394f24908d017d86153e312ea.jpg" alt="">.</p>
<pre><code class="lang-py">class torch.distributions.transforms.PowerTransform(exponent, cache_size=0)
</code></pre>
<p>&#x8F6C;&#x6362;&#x901A;&#x8FC7;&#x6620;&#x5C04; <img src="img/2062af7179e0c19c3599816de6768cee.jpg" alt="">.</p>
<pre><code class="lang-py">class torch.distributions.transforms.SigmoidTransform(cache_size=0)
</code></pre>
<p>&#x8F6C;&#x6362;&#x901A;&#x8FC7;&#x6620;&#x5C04; <img src="img/749abef3418941161a1c6ff80d9eae76.jpg" alt=""> and <img src="img/6feb73eb74f2267e5caa87d9693362cb.jpg" alt="">.</p>
<pre><code class="lang-py">class torch.distributions.transforms.AbsTransform(cache_size=0)
</code></pre>
<p>&#x8F6C;&#x6362;&#x901A;&#x8FC7;&#x6620;&#x5C04; <img src="img/dca0dc2e17c81b7ec261e70549de5507.jpg" alt="">.</p>
<pre><code class="lang-py">class torch.distributions.transforms.AffineTransform(loc, scale, event_dim=0, cache_size=0)
</code></pre>
<p>&#x901A;&#x8FC7;&#x9010;&#x70B9;&#x4EFF;&#x5C04;&#x6620;&#x5C04;<img src="img/e1df459e7ff26d682fc956b62868f7c4.jpg" alt="">&#x8FDB;&#x884C;&#x8F6C;&#x6362; .</p>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>loc</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a> <em>or</em> <a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a>) &#x2013; Location.</li>
<li><strong>scale</strong> (<a href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a> <em>or</em> <a href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)" target="_blank"><em>float</em></a>) &#x2013; Scale.</li>
<li><strong>event_dim</strong> (<a href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)" target="_blank"><em>int</em></a>) &#x2013; &#x53EF;&#x9009;&#x7684; <code>event_shape</code> &#x5927;&#x5C0F;. T&#x5BF9;&#x4E8E;&#x5355;&#x53D8;&#x91CF;&#x968F;&#x673A;&#x53D8;&#x91CF;, &#x8BE5;&#x503C;&#x5E94;&#x4E3A;&#x96F6;, &#x5BF9;&#x4E8E;&#x77E2;&#x91CF;&#x5206;&#x5E03;, 1&#x5E94;&#x4E3A;&#x96F6;, &#x5BF9;&#x4E8E;&#x77E9;&#x9635;&#x7684;&#x5206;&#x5E03;, &#x5E94;&#x4E3A;2.</li>
</ul>
<pre><code class="lang-py">class torch.distributions.transforms.SoftmaxTransform(cache_size=0)
</code></pre>
<p>&#x4ECE;&#x65E0;&#x7EA6;&#x675F;&#x7A7A;&#x95F4;&#x5230;&#x5355;&#x7EAF;&#x5F62;&#x7684;&#x8F6C;&#x6362;, &#x901A;&#x8FC7; <img src="img/ec8d939394f24908d017d86153e312ea.jpg" alt=""> &#x7136;&#x540E;&#x5F52;&#x4E00;&#x5316;.</p>
<p>&#x8FD9;&#x4E0D;&#x662F;&#x53CC;&#x5C04;&#x7684;, &#x4E0D;&#x80FD;&#x7528;&#x4E8E;HMC.  &#x7136;&#x800C;, &#x8FD9;&#x4E3B;&#x8981;&#x662F;&#x534F;&#x8C03;&#x7684;&#xFF08;&#x9664;&#x4E86;&#x6700;&#x7EC8;&#x7684;&#x5F52;&#x4E00;&#x5316;&#xFF09;, &#x56E0;&#x6B64;&#x9002;&#x5408;&#x4E8E;&#x5750;&#x6807;&#x65B9;&#x5F0F;&#x7684;&#x4F18;&#x5316;&#x7B97;&#x6CD5;. </p>
<pre><code class="lang-py">class torch.distributions.transforms.StickBreakingTransform(cache_size=0)
</code></pre>
<p>&#x5C06;&#x65E0;&#x7EA6;&#x675F;&#x7A7A;&#x95F4;&#x901A;&#x8FC7; stick-breaking &#x8FC7;&#x7A0B;&#x8F6C;&#x5316;&#x4E3A;&#x4E00;&#x4E2A;&#x989D;&#x5916;&#x7EF4;&#x5EA6;&#x7684;&#x5355;&#x7EAF;&#x5F62;. </p>
<p>&#x8FD9;&#x79CD;&#x53D8;&#x6362;&#x662F;<code>Dirichlet</code>&#x5206;&#x5E03;&#x7684;&#x7834;&#x68D2;&#x6784;&#x9020;&#x4E2D;&#x7684;&#x8FED;&#x4EE3;sigmoid&#x53D8;&#x6362;:&#x7B2C;&#x4E00;&#x4E2A;&#x903B;&#x8F91;&#x901A;&#x8FC7;sigmoid&#x53D8;&#x6362;&#x6210;&#x7B2C;&#x4E00;&#x4E2A;&#x6982;&#x7387;&#x548C;&#x6240;&#x6709;&#x5176;&#x4ED6;&#x6982;&#x7387;, &#x7136;&#x540E;&#x8FD9;&#x4E2A;&#x8FC7;&#x7A0B;&#x91CD;&#x590D;&#x51FA;&#x73B0;. </p>
<p>&#x8FD9;&#x662F;&#x53CC;&#x5C04;&#x7684;, &#x9002;&#x5408;&#x5728;HMC&#x4E2D;&#x4F7F;&#x7528;; &#x7136;&#x800C;, &#x5B83;&#x5C06;&#x5750;&#x6807;&#x6DF7;&#x5408;&#x5728;&#x4E00;&#x8D77;, &#x4E0D;&#x592A;&#x9002;&#x5408;&#x4F18;&#x5316;.</p>
<pre><code class="lang-py">class torch.distributions.transforms.LowerCholeskyTransform(cache_size=0)
</code></pre>
<p>&#x5C06;&#x65E0;&#x7EA6;&#x675F;&#x77E9;&#x9635;&#x8F6C;&#x6362;&#x4E3A;&#x5177;&#x6709;&#x975E;&#x8D1F;&#x5BF9;&#x89D2;&#x9879;&#x7684;&#x4E0B;&#x4E09;&#x89D2;&#x77E9;&#x9635;.</p>
<p>&#x8FD9;&#x5BF9;&#x4E8E;&#x6839;&#x636E;Cholesky&#x5206;&#x89E3;&#x6765;&#x53C2;&#x6570;&#x5316;&#x6B63;&#x5B9A;&#x77E9;&#x9635;&#x662F;&#x6709;&#x7528;&#x7684;.</p>
<h2 id="constraints"><code>Constraints</code></h2>
<p>The following constraints are implemented:</p>
<ul>
<li><code>constraints.boolean</code></li>
<li><code>constraints.dependent</code></li>
<li><code>constraints.greater_than(lower_bound)</code></li>
<li><code>constraints.integer_interval(lower_bound, upper_bound)</code></li>
<li><code>constraints.interval(lower_bound, upper_bound)</code></li>
<li><code>constraints.lower_cholesky</code></li>
<li><code>constraints.lower_triangular</code></li>
<li><code>constraints.nonnegative_integer</code></li>
<li><code>constraints.positive</code></li>
<li><code>constraints.positive_definite</code></li>
<li><code>constraints.positive_integer</code></li>
<li><code>constraints.real</code></li>
<li><code>constraints.real_vector</code></li>
<li><code>constraints.simplex</code></li>
<li><code>constraints.unit_interval</code></li>
</ul>
<pre><code class="lang-py">class torch.distributions.constraints.Constraint
</code></pre>
<p>constraints &#x7684;&#x62BD;&#x8C61;&#x57FA;&#x7C7B;.</p>
<p>constraint&#x5BF9;&#x8C61;&#x8868;&#x793A;&#x53D8;&#x91CF;&#x6709;&#x6548;&#x7684;&#x533A;&#x57DF;, &#x4F8B;&#x5982;,  &#x5176;&#x4E2D;&#x53EF;&#x4EE5;&#x4F18;&#x5316;&#x53D8;&#x91CF;</p>
<pre><code class="lang-py">check(value)
</code></pre>
<p>&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x5B57;&#x8282;&#x5F20;&#x91CF; <code>sample_shape + batch_shape</code> &#x6307;&#x793A;&#x503C;&#x4E2D;&#x7684;&#x6BCF;&#x4E2A;&#x4E8B;&#x4EF6;&#x662F;&#x5426;&#x6EE1;&#x8DB3;&#x6B64;&#x7EA6;&#x675F;.</p>
<pre><code class="lang-py">torch.distributions.constraints.dependent_property
</code></pre>
<p>alias of <code>torch.distributions.constraints._DependentProperty</code></p>
<pre><code class="lang-py">torch.distributions.constraints.integer_interval
</code></pre>
<p>alias of <code>torch.distributions.constraints._IntegerInterval</code></p>
<pre><code class="lang-py">torch.distributions.constraints.greater_than
</code></pre>
<p>alias of <code>torch.distributions.constraints._GreaterThan</code></p>
<pre><code class="lang-py">torch.distributions.constraints.greater_than_eq
</code></pre>
<p>alias of <code>torch.distributions.constraints._GreaterThanEq</code></p>
<pre><code class="lang-py">torch.distributions.constraints.less_than
</code></pre>
<p>alias of <code>torch.distributions.constraints._LessThan</code></p>
<pre><code class="lang-py">torch.distributions.constraints.interval
</code></pre>
<p>alias of <code>torch.distributions.constraints._Interval</code></p>
<pre><code class="lang-py">torch.distributions.constraints.half_open_interval
</code></pre>
<p>alias of <code>torch.distributions.constraints._HalfOpenInterval</code></p>
<h2 id="constraint-registry"><code>Constraint Registry</code></h2>
<p>PyTorch &#x63D0;&#x4F9B;&#x4E24;&#x4E2A;&#x5168;&#x5C40; <a href="#torch.distributions.constraint_registry.ConstraintRegistry" title="torch.distributions.constraint_registry.ConstraintRegistry"><code>ConstraintRegistry</code></a> &#x5BF9;&#x8C61; , &#x94FE;&#x63A5; <a href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code>Constraint</code></a> &#x5BF9;&#x8C61;&#x5230; <a href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code>Transform</code></a> &#x5BF9;&#x8C61;. &#x8FD9;&#x4E9B;&#x5BF9;&#x8C61;&#x65E2;&#x6709;&#x8F93;&#x5165;&#x7EA6;&#x675F;, &#x4E5F;&#x6709;&#x8FD4;&#x56DE;&#x53D8;&#x6362;, &#x4F46;&#x662F;&#x5B83;&#x4EEC;&#x5BF9;&#x53CC;&#x5C04;&#x6027;&#x6709;&#x4E0D;&#x540C;&#x7684;&#x4FDD;&#x8BC1;.</p>
<ol>
<li><code>biject_to(constraint)</code>  &#x67E5;&#x627E;&#x4E00;&#x4E2A;&#x53CC;&#x5C04;&#x7684; <a href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code>Transform</code></a> &#x4ECE; <code>constraints.real</code> &#x5230;&#x7ED9;&#x5B9A;&#x7684; <code>constraint</code>.  &#x8FD4;&#x56DE;&#x7684;&#x8F6C;&#x6362;&#x4FDD;&#x8BC1;&#x5177;&#x6709; <code>.bijective = True</code> &#x5E76;&#x4E14;&#x5E94;&#x8BE5;&#x5B9E;&#x73B0;&#x4E86; <code>.log_abs_det_jacobian()</code>.</li>
<li><code>transform_to(constraint)</code> &#x67E5;&#x627E;&#x4E00;&#x4E2A;&#x4E0D;&#x4E00;&#x5B9A;&#x662F;&#x53CC;&#x5C04;&#x7684; <a href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code>Transform</code></a> &#x4ECE; <code>constraints.real</code> &#x5230;&#x7ED9;&#x5B9A;&#x7684; <code>constraint</code>. &#x8FD4;&#x56DE;&#x7684;&#x8F6C;&#x6362;&#x4E0D;&#x4FDD;&#x8BC1;&#x5B9E;&#x73B0; <code>.log_abs_det_jacobian()</code>.</li>
</ol>
<p><code>transform_to()</code>&#x6CE8;&#x518C;&#x8868;&#x5BF9;&#x4E8E;&#x5BF9;&#x6982;&#x7387;&#x5206;&#x5E03;&#x7684;&#x7EA6;&#x675F;&#x53C2;&#x6570;&#x6267;&#x884C;&#x65E0;&#x7EA6;&#x675F;&#x4F18;&#x5316;&#x975E;&#x5E38;&#x6709;&#x7528;, &#x8FD9;&#x4E9B;&#x53C2;&#x6570;&#x7531;&#x6BCF;&#x4E2A;&#x5206;&#x5E03;&#x7684;<code>.arg_constraints</code>&#x6307;&#x793A;.  &#x8FD9;&#x4E9B;&#x53D8;&#x6362;&#x901A;&#x5E38;&#x4F1A;&#x8FC7;&#x5EA6;&#x53C2;&#x6570;&#x5316;&#x7A7A;&#x95F4;&#x4EE5;&#x907F;&#x514D;&#x65CB;&#x8F6C;; &#x56E0;&#x6B64;, &#x5B83;&#x4EEC;&#x66F4;&#x9002;&#x5408;&#x50CF;Adam&#x90A3;&#x6837;&#x7684;&#x5750;&#x6807;&#x4F18;&#x5316;&#x7B97;&#x6CD5;</p>
<pre><code class="lang-py">loc = torch.zeros(<span class="hljs-number">100</span>, requires_grad=<span class="hljs-keyword">True</span>)
unconstrained = torch.zeros(<span class="hljs-number">100</span>, requires_grad=<span class="hljs-keyword">True</span>)
scale = transform_to(Normal.arg_constraints[<span class="hljs-string">&apos;scale&apos;</span>])(unconstrained)
loss = -Normal(loc, scale).log_prob(data).sum()
</code></pre>
<p><code>biject_to()</code> &#x6CE8;&#x518C;&#x8868;&#x5BF9;&#x4E8E;Hamiltonian Monte Carlo&#x975E;&#x5E38;&#x6709;&#x7528;, &#x5176;&#x4E2D;&#x6765;&#x81EA;&#x5177;&#x6709;&#x7EA6;&#x675F;. <code>.support</code>&#x7684;&#x6982;&#x7387;&#x5206;&#x5E03;&#x7684;&#x6837;&#x672C;&#x5728;&#x65E0;&#x7EA6;&#x675F;&#x7A7A;&#x95F4;&#x4E2D;&#x4F20;&#x64AD;, &#x5E76;&#x4E14;&#x7B97;&#x6CD5;&#x901A;&#x5E38;&#x662F;&#x65CB;&#x8F6C;&#x4E0D;&#x53D8;&#x7684;</p>
<pre><code class="lang-py">dist = Exponential(rate)
unconstrained = torch.zeros(<span class="hljs-number">100</span>, requires_grad=<span class="hljs-keyword">True</span>)
sample = biject_to(dist.support)(unconstrained)
potential_energy = -dist.log_prob(sample).sum()
</code></pre>
<p>&#x6CE8;&#x610F;</p>
<p>&#x4E00;&#x4E2A; <code>transform_to</code> &#x548C; <code>biject_to</code> &#x4E0D;&#x540C;&#x7684;&#x4F8B;&#x5B50;&#x662F; <code>constraints.simplex</code>: <code>transform_to(constraints.simplex)</code> &#x8FD4;&#x56DE;&#x4E00;&#x4E2A; <a href="#torch.distributions.transforms.SoftmaxTransform" title="torch.distributions.transforms.SoftmaxTransform"><code>SoftmaxTransform</code></a> &#x7B80;&#x5355;&#x5730;&#x5BF9;&#x5176;&#x8F93;&#x5165;&#x8FDB;&#x884C;&#x6307;&#x6570;&#x5316;&#x548C;&#x5F52;&#x4E00;&#x5316;;  &#x8FD9;&#x662F;&#x4E00;&#x79CD;&#x5EC9;&#x4EF7;&#x4E14;&#x4E3B;&#x8981;&#x662F;&#x5750;&#x6807;&#x7684;&#x64CD;&#x4F5C;, &#x9002;&#x7528;&#x4E8E;&#x50CF;SVI&#x8FD9;&#x6837;&#x7684;&#x7B97;&#x6CD5;. &#x76F8;&#x53CD;, <code>biject_to(constraints.simplex)</code> &#x8FD4;&#x56DE;&#x4E00;&#x4E2A; <a href="#torch.distributions.transforms.StickBreakingTransform" title="torch.distributions.transforms.StickBreakingTransform"><code>StickBreakingTransform</code></a> &#x5C06;&#x5176;&#x8F93;&#x5165;&#x751F;&#x6210;&#x4E00;&#x4E2A;&#x8F83;&#x5C0F;&#x7EF4;&#x5EA6;&#x7684;&#x7A7A;&#x95F4;; &#x8FD9;&#x662F;&#x4E00;&#x79CD;&#x66F4;&#x6602;&#x8D35;&#x7684;&#x6570;&#x503C;&#x66F4;&#x5C11;&#x7684;&#x6570;&#x503C;&#x7A33;&#x5B9A;&#x7684;&#x53D8;&#x6362;, &#x4F46;&#x5BF9;&#x4E8E;&#x50CF;HM&#x200B;&#x200B;C&#x8FD9;&#x6837;&#x7684;&#x7B97;&#x6CD5;&#x662F;&#x5FC5;&#x9700;&#x7684;. </p>
<p><code>biject_to</code> &#x548C; <code>transform_to</code> &#x5BF9;&#x8C61;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x7528;&#x6237;&#x5B9A;&#x4E49;&#x7684;&#x7EA6;&#x675F;&#x8FDB;&#x884C;&#x6269;&#x5C55;, &#x5E76;&#x4F7F;&#x7528;<code>.register()</code>&#x65B9;&#x6CD5;&#x8FDB;&#x884C;&#x8F6C;&#x6362;, &#x4F5C;&#x4E3A;&#x5355;&#x4F8B;&#x7EA6;&#x675F;&#x7684;&#x51FD;&#x6570;</p>
<pre><code class="lang-py">transform_to.register(my_constraint, my_transform)
</code></pre>
<p>&#x6216;&#x4F5C;&#x4E3A;&#x53C2;&#x6570;&#x5316;&#x7EA6;&#x675F;&#x7684;&#x88C5;&#x9970;&#x5668;:</p>
<pre><code class="lang-py"><span class="hljs-meta">@transform_to.register(MyConstraintClass)</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">my_factory</span><span class="hljs-params">(constraint)</span>:</span>
    <span class="hljs-keyword">assert</span> isinstance(constraint, MyConstraintClass)
    <span class="hljs-keyword">return</span> MyTransform(constraint.param1, constraint.param2)
</code></pre>
<p> &#x60A8;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x521B;&#x5EFA;&#x65B0;&#x7684;<a href="#torch.distributions.constraint_registry.ConstraintRegistry" title="torch.distributions.constraint_registry.ConstraintRegistry"><code>ConstraintRegistry</code></a>&#x521B;&#x5EFA;&#x81EA;&#x5DF1;&#x7684;&#x6CE8;&#x518C;&#x8868;.</p>
<pre><code class="lang-py">class torch.distributions.constraint_registry.ConstraintRegistry
</code></pre>
<p>&#x6CE8;&#x518C;&#x8868;, &#x5C06;&#x7EA6;&#x675F;&#x94FE;&#x63A5;&#x5230;&#x8F6C;&#x6362;.</p>
<pre><code class="lang-py">register(constraint, factory=<span class="hljs-keyword">None</span>)
</code></pre>
<p>&#x5728;&#x6B64;&#x6CE8;&#x518C;&#x8868;&#x6CE8;&#x518C;&#x4E00;&#x4E2A; <a href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code>Constraint</code></a> &#x5B50;&#x7C7B;. &#x7528;&#x6CD5;:</p>
<pre><code class="lang-py"><span class="hljs-meta">@my_registry.register(MyConstraintClass)</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">construct_transform</span><span class="hljs-params">(constraint)</span>:</span>
    <span class="hljs-keyword">assert</span> isinstance(constraint, MyConstraint)
    <span class="hljs-keyword">return</span> MyTransform(constraint.arg_constraints)
</code></pre>
<p>&#x53C2;&#x6570;: </p>
<ul>
<li><strong>constraint</strong> (subclass of <a href="#torch.distributions.constraints.Constraint" title="torch.distributions.constraints.Constraint"><code>Constraint</code></a>) &#x2013;  [<code>Constraint</code>]&#x7684;&#x5B50;&#x7C7B;(#torch.distributions.constraints.Constraint &quot;torch.distributions.constraints.Constraint&quot;), &#x6216;&#x8005;&#x6D3E;&#x751F;&#x7C7B;&#x7684;&#x5BF9;&#x8C61;.</li>
<li><strong>factory</strong> (<em>callable</em>) &#x2013; &#x53EF;&#x8C03;&#x7528;&#x5BF9;&#x8C61;, &#x8F93;&#x5165; constraint &#x5BF9;&#x8C61;&#x8FD4;&#x56DE; <a href="#torch.distributions.transforms.Transform" title="torch.distributions.transforms.Transform"><code>Transform</code></a> &#x5BF9;&#x8C61;.</li>
</ul>
<p><hr></p>
<div align="center">
    <p><a href="http://www.apachecn.org" target="_blank"><font face="KaiTi" size="6" color="red">&#x6211;&#x4EEC;&#x4E00;&#x76F4;&#x5728;&#x52AA;&#x529B;</font></a></p>
    <p><a href="https://github.com/apachecn/pytorch-doc-zh/" target="_blank">apachecn/pytorch-doc-zh</a></p>
    <p><iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&amp;repo=pytorch-doc-zh&amp;type=watch&amp;count=true&amp;v=2" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
    <iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&amp;repo=pytorch-doc-zh&amp;type=star&amp;count=true" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
    <iframe align="middle" src="https://ghbtns.com/github-btn.html?user=apachecn&amp;repo=pytorch-doc-zh&amp;type=fork&amp;count=true" frameborder="0" scrolling="0" width="100px" height="25px"></iframe>
    <a target="_blank" href="shang.qq.com/wpa/qunwpa"><img border="0" src="http://data.apachecn.org/img/logo/ApacheCN-group.png" alt="ML | ApacheCN" title="ML | ApacheCN"></a></p>
</div>
 <div style="text-align:center;margin:0 0 10.5px;">
     <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
     <ins class="adsbygoogle" style="display:inline-block;width:728px;height:90px" data-ad-client="ca-pub-3565452474788507" data-ad-slot="2543897000">
     </ins>
     <script>(adsbygoogle = window.adsbygoogle || []).push({});</script>

    <script>
      var _hmt = _hmt || [];
      (function() {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91";
        var s = document.getElementsByTagName("script")[0]; 
        s.parentNode.insertBefore(hm, s);
      })();
    </script>

    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-102475051-10"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-102475051-10');
    </script>
</div>

<p><meta name="google-site-verification" content="pyo9N70ZWyh8JB43bIu633mhxesJ1IcwWCZlM3jUfFo"></p>
<p><iframe src="https://www.bilibili.com/read/cv2710377" style="display:none"></iframe>
<img src="http://t.cn/AiCoDHwb" hidden="hidden"></p>
<div>
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
    <script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"></script>
    <script src="https://cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.min.js"></script>
    <div id="gitalk-container"></div>
    <script type="text/javascript">
        const gitalk = new Gitalk({
        clientID: '2e62dee5b9896e2eede6',
        clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53',
        repo: 'pytorch-doc-zh',
        owner: 'apachecn',
        admin: ['jiangzhonglian', 'wizardforcel'],
        id: md5(location.pathname),
        distractionFreeMode: false
        })
        gitalk.render('gitalk-container')
    </script>
</div>

<footer class="page-footer"><span class="copyright">Copyright &#xA9; ibooker.org.cn 2019 all right reserved&#xFF0C;&#x7531; ApacheCN &#x56E2;&#x961F;&#x63D0;&#x4F9B;&#x652F;&#x6301;</span><span class="footer-modification">&#x8BE5;&#x6587;&#x4EF6;&#x4FEE;&#x8BA2;&#x65F6;&#x95F4;&#xFF1A; 
2019-12-27 08:05:23
</span></footer>
<script>console.log("plugin-popup....");document.onclick = function(e){ e.target.tagName === "IMG" && window.open(e.target.src,e.target.src)}</script><style>img{cursor:pointer}</style>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="distributed.html" class="navigation navigation-prev " aria-label="Previous page: Distributed communication package - torch.distributed">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="jit.html" class="navigation navigation-next " aria-label="Next page: Torch Script">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Probability distributions - torch.distributions","level":"1.3.2.14","depth":3,"next":{"title":"Torch Script","level":"1.3.2.15","depth":3,"path":"jit.md","ref":"jit.md","articles":[]},"previous":{"title":"Distributed communication package - torch.distributed","level":"1.3.2.13","depth":3,"path":"distributed.md","ref":"distributed.md","articles":[]},"dir":"ltr"},"config":{"plugins":["github","github-buttons","-sharing","insert-logo","sharing-plus","back-to-top-button","code","copy-code-button","mathjax","pageview-count","edit-link","emphasize","alerts","auto-scroll-table","popup","hide-element","page-toc-button","tbfed-pagefooter","sitemap","advanced-emoji","expandable-chapters","splitter","search-pro"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"tbfed-pagefooter":{"copyright":"Copyright &copy ibooker.org.cn 2019","modify_label":"该文件修订时间： ","modify_format":"YYYY-MM-DD HH:mm:ss"},"emphasize":{},"github":{"url":"https://github.com/apachecn/pytorch-doc-zh"},"splitter":{},"search-pro":{},"search":{},"sharing-plus":{"qq":false,"all":["facebook","google","twitter","instapaper","linkedin","pocket","stumbleupon"],"douban":false,"facebook":true,"weibo":false,"instapaper":false,"whatsapp":false,"hatenaBookmark":false,"twitter":true,"messenger":false,"line":false,"vk":false,"pocket":true,"google":false,"viber":false,"stumbleupon":false,"qzone":false,"linkedin":false},"auto-scroll-table":{},"popup":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"code":{"copyButtons":true},"hide-element":{"elements":[".gitbook-link"]},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"sitemap":{"hostname":"http://pytorch.apachecn.org"},"page-toc-button":{"maxTocDepth":4,"minTocSize":4},"back-to-top-button":{},"pageview-count":{},"alerts":{},"github-buttons":{"buttons":[{"user":"apachecn","repo":"pytorch-doc-zh","type":"star","count":true,"size":"small"}]},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"copy-code-button":{},"advanced-emoji":{"embedEmojis":false},"sharing":{"qq":false,"all":["qq","douban","facebook","google","linkedin","twitter","weibo","whatsapp"],"douban":false,"facebook":false,"weibo":true,"whatsapp":false,"twitter":false,"line":false,"google":false,"qzone":true},"edit-link":{"label":"编辑本页","base":"https://github.com/apachecn/pytorch-doc-zh/blob/master/docs/1.0"},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"insert-logo":{"style":"background: none; max-height: 150px; min-height: 150px","url":"http://data.apachecn.org/img/logo.jpg"},"expandable-chapters":{}},"my_links":{"sidebar":{"Home":"https://www.baidu.com"}},"theme":"default","author":"ApacheCN","my_plugins":["donate","todo","-lunr","-search","expandable-chapters-small","chapter-fold","expandable-chapters","expandable-chapters-small","back-to-top-button","ga","baidu","sitemap","tbfed-pagefooter","advanced-emoji","sectionx","page-treeview","simple-page-toc","ancre-navigation","theme-apachecn@git+https://github.com/apachecn/theme-apachecn#HEAD","pagefooter-apachecn@git+https://github.com/apachecn/gitbook-plugin-pagefooter-apachecn#HEAD"],"my_pluginsConfig":{"page-treeview":{"copyright":"Copyright &#169; aleen42","minHeaderCount":"2","minHeaderDeep":"2"},"ignores":["node_modules"],"simple-page-toc":{"maxDepth":3,"skipFirstH1":true},"page-copyright":{"wisdom":"Designer, Frontend Developer & overall web enthusiast","noPowered":false,"copyright":"Copyright &#169; 你的名字","style":"normal","timeColor":"#666","utcOffset":"8","format":"YYYY-MM-dd hh:mm:ss","signature":"你的签名","copyrightColor":"#666","description":"modified at"},"donate":{"wechat":"微信收款的二维码URL","alipay":"支付宝收款的二维码URL","title":"","button":"赏","alipayText":"支付宝打赏","wechatText":"微信打赏"},"page-toc-button":{"maxTocDepth":2,"minTocSize":2},"github-buttons":{"buttons":[{"user":"apachecn","repo":"pytorch-doc-zh","type":"star","count":true,"size":"small"},{"user":"apachecn","width":"160","type":"follow","count":true,"size":"small"}]},"ga":{"token":"UA-102475051-10"},"baidu":{"token":"75439e2cbd22bdd813226000e9dcc12f"},"pagefooter-apachecn":{"copyright":"Copyright &copy ibooker.org.cn 2019","modify_label":"该文件修订时间： ","modify_format":"YYYY-MM-DD HH:mm:ss"}},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"Pytorch 中文文档","language":"zh-hans","gitbook":"*","description":"Pytorch 中文文档: 教程和文档"},"file":{"path":"distributions.md","mtime":"2019-12-27T08:05:23.711Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-12-27T08:07:43.252Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-github-buttons/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-insert-logo/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing-plus/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-copy-code-button/toggle.js"></script>
        
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-pageview-count/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-edit-link/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-alerts/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-auto-scroll-table/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-hide-element/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-page-toc-button/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

