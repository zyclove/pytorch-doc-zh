{"./":{"url":"./","title":"Introduction","keywords":"","body":"版本特性 PyTorch V1.2 新特性 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"PyTorch_V1.2.html":{"url":"PyTorch_V1.2.html","title":"PyTorch V1.2 新特性","keywords":"","body":"新版本: PyTorch 1.2 torchtext 0.4，torchaudio 0.3 和 torchvision 0.4 发布: 2019年8月8日 原文: PyTorch 翻译: ApacheCN 自PyTorch 1.0发布以来，我们已经看到社区扩展到添加新工具，为PyTorch Hub中可用的越来越多的模型做出贡献，并不断增加研究和生产中的使用。 从核心角度来看，PyTorch不断添加功能以支持研究和生产使用，包括通过TorchScript连接这两个世界的能力。今天，我们很高兴地宣布我们有四个新版本，包括PyTorch 1.2，torchvision 0.4，torchaudio 0.3和torchtext 0.4。您现在可以在pytorch.org上开始使用这些版本。 PyTorch 1.2 使用PyTorch 1.2，开源ML框架在生产使用方面向前迈出了一大步，增加了一个改进的，更加完善的TorchScript环境。这些改进使得更容易发布生产模型，扩展对导出ONNX格式模型的支持，并增强对 Transformers 的模块级支持。除了这些新功能之外，TensorBoard 现在不再具有实验性 - 您只需键入from torch.utils.tensorboard import SummaryWriter即可开始使用。 TORCHSCRIPT 改进 自从在PyTorch 1.0中发布以来，TorchScript已经为热切的PyTorch模型提供了生产途径。TorchScript编译器将PyTorch模型转换为静态类型的图形表示，为Python不可用的受限环境中的优化和执行提供了机会。您可以将模型逐步转换为TorchScript，将编译后的代码与Python无缝混合。 PyTorch 1.2显着扩展了TorchScript对PyTorch模型中使用的Python子集的支持，并提供了一种新的，更易于使用的API，用于将模型编译为TorchScript。有关详细信息，请参阅迁移指南 以下是新API的示例用法： import torch class MyModule(torch.nn.Module): def __init__(self, N, M): super(MyModule, self).__init__() self.weight = torch.nn.Parameter(torch.rand(N, M)) def forward(self, input): if input.sum() > 0: output = self.weight.mv(input) else: output = self.weight + input return output # Compile the model code to a static representation my_script_module = torch.jit.script(MyModule(3, 4)) # Save the compiled code and model data so it can be loaded elsewhere my_script_module.save(\"my_script_module.pt\") 要了解更多信息，请参阅我们的TorchScript简介和在C ++中加载PyTorch模型教程。 扩展了ONNX EXPORT 该ONNX社会继续以开放的成长治理结构和额外的指导委员会成员，特殊兴趣小组（SIG）和工作组（WGS）。与Microsoft合作，我们增加了对导出ONNX Opset版本7(v1.2)，8(v1.3)，9(v1.4)和10(v1.5)的全面支持。我们还增强了常量折叠传递，以支持最新版本的ONNX Opset 10。ScriptModule也得到了改进，包括支持多输出，张量工厂和元组作为输入和输出。此外，用户现在可以注册自己的符号来导出自定义操作，并在导出期间指定输入的动态尺寸。以下是所有主要改进的摘要： 支持多种Opset，包括在Opset 10中导出丢失，切片，翻转和插值的功能。 ScriptModule的改进，包括支持多输出，张量工厂和元组作为输入和输出。 支持了十几个额外的PyTorch运营商，包括导出自定义运营商的能力。 许多重大修复和测试基础改进。 您可以在这里试用最新的教程，由@ lara-hdr在Microsoft提供。非常感谢整个Microsoft团队为完成此版本所做的所有努力！ NN.TRANSFORMER 在PyTorch 1.2中，我们现在包含一个标准的nn.Transformer模块，基于“ 注意就是你所需要的 ” 这篇论文。该nn.Transformer模块完全依赖于注意机制来绘制输入和输出之间的全局依赖关系。nn.Transformer模块的各个组件经过精心设计，可以独立使用。例如，nn.TransformerEncoder可以单独使用，不需要更大nn.Transformer。新API包括： nn.Transformer nn.TransformerEncoder 和 nn.TransformerEncoderLayer nn.TransformerDecoder 和 nn.TransformerDecoderLayer 有关更多信息，请参阅Transformer Layers文档。有关完整的PyTorch 1.2发行说明，请参见此处。 域API库更新 PyTorch域库（如torchvision，torchtext和torchaudio）提供了对常用数据集，模型和变换的便捷访问，可用于快速创建最先进的基线。此外，它们还提供了常见的抽象，以减少用户可能不得不重复写入的样板代码。由于研究领域有不同的要求，围绕PyTorch出现了一个称为域API（DAPI）的专业库生态系统，以简化许多领域中新算法和现有算法的开发。我们很高兴发布三个更新的DAPI库，用于支持PyTorch 1.2核心版本的文本，音频和视觉。 TORCHAUDIO 0.3与KALDI兼容性，新变换 Torchaudio专注于机器理解音频波形。它是一个ML库，提供相关的信号处理功能（但不是一般的信号处理库）。它利用PyTorch的GPU支持为波形提供了许多工具和转换，使数据加载和标准化更容易，更易读。例如，它为使用sox的波形提供数据加载器，并为频谱图，重采样和mu-law编码和解码等转换提供数据加载器。 我们很高兴地宣布torchaudio 0.3.0的可用性，重点是标准化和复数，转换（重新采样）和两个新的功能（phase_vocoder，ISTFT），Kaldi兼容性和新教程。Torchaudio经过重新设计，是PyTorch的扩展，也是域API（DAPI）生态系统的一部分。 标准化 解决机器学习问题的重要工作是数据准备。在这个新版本中，我们更新了torchaudio的转换接口，以便围绕以下词汇和约定进行标准化。 假设张量具有通道作为第一维度，时间作为最后维度（适用时）。这使得它与PyTorch的尺寸一致。对于大小名称，使用前缀n_（例如“大小（n_freq，n_mel）的张量”），而维度名称不具有该前缀（例如“维度张量（通道，时间）”）。所有变换和函数的输入现在首先假定通道。这样做是为了与PyTorch保持一致，PyTorch具有通道，后跟样本数量。现在不推荐使用所有转换和函数的通道参数。 输出STFT是（通道，频率，时间，2），对于每个通道而言，列是特定窗口的傅里叶变换，因此当我们水平移动时，我们可以看到每列（傅里叶变换波形）随时间变化。这符合librosa的输出，使我们不再需要在我们的测试比较，转用Spectrogram，MelScale，MelSpectrogram，和MFCC。此外，由于这些新的惯例，我们弃用LC2CL并且BLC2CBL用于从一种信号形状转换到另一种形状。 作为此版本的一部分，我们还通过尺寸张量（...，2）引入对复数的支持，并提供magphase将这样的张量转换为其幅度和相位，以及类似complex_norm和angle。 README中提供了标准化的详细信息。 功能，转换和Kaldi兼容性 在标准化之前，我们将状态和计算分成了torchaudio.transforms和torchaudio.functional。 作为转换的一部分，我们在0.3.0中添加了一个新的转换：Resample。Resample可以将波形上采样或下采样到不同的频率。 作为功​​能的一部分，我们将介绍：phase_vocoder一个相位声码器，用于改变波形的速度而不改变其音调，并且ISTFT反向STFT实现与PyTorch提供的STFT兼容。这种分离允许我们使函数弱脚本化并在0.3.0中使用JIT。因此，我们有以下的转换JIT和CUDA支持：Spectrogram，AmplitudeToDB（原名SpectrogramToDB）MelScale， MelSpectrogram，MFCC，MuLawEncoding，MuLawDecoding（原名MuLawExpanding）。 我们现在还提供与Kaldi的兼容接口，以简化入门并减少用户对Kaldi的代码依赖性。我们现在有一个接口spectrogram，fbank和resample_waveform。 新教程 为了展示新的约定和转换，我们有一个新的教程，演示如何使用torchaudio预处理波形。本教程将介绍加载波形并对其应用一些可用转换的示例。 我们很高兴看到torchaudio周围的活跃社区，并渴望进一步发展和支持它。我们鼓励您继续使用本教程和可用的两个数据集进行实验：VCTK和YESNO！他们有一个界面来下载数据集并以方便的格式预处理它们。您可以在此处的发行说明中找到详细信息。 带有监督学习数据集的TORCHTEXT 0.4 torchtext的一个关键重点领域是提供有助于加速NLP研究的基本要素。这包括轻松访问常用数据集和基本预处理管道，以处理基于原始文本的数据。torchtext 0.4.0版本包括几个受欢迎的监督学习基线，带有“一个命令”的数据加载。包含一个教程，以说明如何使用新数据集进行文本分类分析。我们还添加并改进了一些函数，例如get_tokenizer和build_vocab_from_iterator，以便更容易实现未来的数据集。其他示例可以在这里找到。 文本分类是自然语言处理中的一项重要任务，具有许多应用，例如情感分析。新版本包括几个用于监督学习的流行文本分类数据集，包括： AG_NEWS SogouNews DBpedia中 YelpReviewPolarity YelpReviewFull 雅虎知识堂 AmazonReviewPolarity AmazonReviewFull 每个数据集都有两个部分（训练与测试），并且可以使用单个命令轻松加载。数据集还支持ngrams功能，以捕获有关本地字顺序的部分信息。请查看此处的教程，以了解有关如何将新数据集用于监督问题（如文本分类分析）的更多信息。 from torchtext.datasets.text_classification import DATASETS train_dataset, test_dataset = DATASETS['AG_NEWS'](ngrams=2) 除了域库之外，PyTorch还提供了许多工具来简化数据加载。用户现在可以使用一些支持良好的工具加载和预处理文本分类数据集，例如torch.utils.data.DataLoader和torch.utils.data.IterableDataset。以下是使用DataLoader包装数据的几行代码。更多例子可以在这里找到。 from torch.utils.data import DataLoader data = DataLoader(train_dataset, collate_fn=generate_batch) 查看此处的发行说明以了解更多信息并在此处试用本教程。 TORCHVISION 0.4支持视频 视频现在是torchvision的一流公民，支持数据加载，数据集，预训练模型和变换。Torch 的0.4版本包括： 用于读/写视频文件（包括音频）的高效IO原语，支持任意编码和格式。 标准视频数据集，与torch.utils.data.Dataset和兼容torch.utils.data.DataLoader。 基于Kinetics-400数据集构建的预训练模型，用于视频（包括训练脚本）的动作分类。 用于训练您自己的视频模型的参考训练脚本。 我们希望在PyTorch中处理视频数据尽可能简单，而不会影响性能。因此，我们避免了需要事先重新编码视频的步骤，因为它会涉及： 一个预处理步骤，它复制数据集以重新编码它。 时间和空间的开销，因为这种重新编码非常耗时。 通常，应使用外部脚本来执行重新编码。 此外，我们提供了诸如实用程序类之类的API，VideoClips通过创建一组视频中所有剪辑的索引，简化了在视频文件列表中枚举固定大小的所有可能剪辑的任务。它还允许您为视频指定固定的帧速率。下面提供了API的示例： from torchvision.datasets.video_utils import VideoClips class MyVideoDataset(object): def __init__(self, video_paths): self.video_clips = VideoClips(video_paths, clip_length_in_frames=16, frames_between_clips=1, frame_rate=15) def __getitem__(self, idx): video, audio, info, video_idx = self.video_clips.get_clip(idx) return video, audio def __len__(self): return self.video_clips.num_clips() 大多数面向用户的API都在Python中，类似于PyTorch，这使得它易于扩展。此外，底层实现很快 - torchvision尽可能少地从视频中解码，以便从视频中返回剪辑。 有关更多详细信息，请查看此处的torchvision 0.4 发行说明。 随着我们进一步改进和扩展PyTorch深度学习平台，我们期待继续与社区合作并听取您的反馈意见。 我们要感谢整个PyTorch团队和社区对这项工作的所有贡献！ 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"PyTorch_V1.3.html":{"url":"PyTorch_V1.3.html","title":"PyTorch V1.3 新特性","keywords":"","body":"新版本: PyTorch 1.3 添加 mobile, privacy, quantization 和 named tensors 发布: 2019年10月10日 原文: PyTorch 翻译: ApacheCN PyTorch继续获得动力，这是因为其专注于满足研究人员的需求，其简化的生产使用工作流程，并且最重要的是，由于它得到了AI社区的热情支持。正如O'Reilly所指出的那样，仅在2019年上半年，PyTorch在ArXiv上的引用就增长了194％ ，该平台的贡献者数量在去年增长了50％以上，达到近1200个。Facebook，Microsoft，Uber和其他行业的组织越来越多地将其用作最重要的机器学习（ML）研究和生产工作负载的基础。 我们现在通过PyTorch 1.3的发布进一步推进该平台的发展，该版本包括对功能的实验性支持，例如无缝模型到移动设备的部署，模型量化以在推理时获得更好的性能，以及前端改进（例如命名张量）并创建更清晰的代码，而不需要内联注释。我们还将启动许多其他工具和库，以支持模型的可解释性，并将多模式研究投入生产。 此外，我们还与Google和Salesforce合作，为Cloud Tensor处理单元增加了广泛的支持，为培训大型深度神经网络提供了显着加速的选择。阿里云还加入了Amazon Web Services，Microsoft Azure和Google Cloud，为PyTorch用户提供了受支持的云平台。您现在可以在pytorch.org 上开始使用。 PyTorch 1.3 PyTorch的1.3版本带来了重要的新功能，包括对移动设备部署的实验性支持，8位整数的快速模式量化以及张量命名能力。通过这些增强功能，我们期待PyTorch社区做出更多贡献和改进。 NAMED TENSORS（实验） 康奈尔大学的Sasha Rush认为，尽管在深度学习中无处不在，但传统的张量实现仍存在重大缺陷，例如暴露私有维度，基于绝对位置进行广播以及将类型信息保留在文档中。他提议将张量命名为替代方法。 今天，我们通过评论来命名和访问维度： # Tensor[N, C, H, W] images = torch.randn(32, 3, 56, 56) images.sum(dim=1) images.select(dim=1, index=0) 但是命名显式地导致了更具可读性和可维护性的代码： NCHW = [‘N’, ‘C’, ‘H’, ‘W’] images = torch.randn(32, 3, 56, 56, names=NCHW) images.sum('C') images.select('C', index=0) QUANTIZATION（实验） 开发ML应用程序时，有效利用服务器端和设备上的计算资源非常重要。为了支持在服务器和边缘设备上进行更有效的部署，PyTorch 1.3现在使用熟悉的急切模式Python API支持8位模型量化。量化是指用于以降低的精度执行计算和存储的技术，例如8位整数。当前处于实验状态的功能包括对训练后量化，动态量化和量化感知训练的支持。它分别针对x86和ARM CPU 利用FBGEMM和QNNPACK最新的量化内核后端，这些后端与PyTorch集成在一起，并且现在共享一个通用API。 要了解有关设计和架构的更多信息，请在此处查看API文档，并使用此处提供的教程开始使用任何受支持的技术。 PYTORCH MOBILE（实验性） 随着应用程序继续要求更低的延迟，在边缘设备上运行ML的重要性越来越重要。它也是诸如联合学习之类的隐私保护技术的基础要素。为了实现更高效的设备上ML，PyTorch 1.3现在支持从Python到在iOS和Android上部署的端到端工作流程。 这是一个早期的实验版本，针对端到端开发进行了优化。即将发布的版本将侧重于： 大小优化：根据用户应用程序所需的运算符，构建级别的优化和选择性编译（即，仅为所需的运算符支付二进制大小） 性能：进一步改善了移动CPU和GPU的性能和覆盖范围 高级API：扩展移动本机API，以涵盖将ML集成到移动应用程序中所需的常规预处理和集成任务。例如计算机视觉和自然语言处理 在此处了解更多信息或开始使用Android或iOS 。 用于模型可解释性和隐私性的新工具 资本 随着模型变得越来越复杂，开发用于模型可解释性的新方法变得越来越重要。为了满足这种需求，我们正在启动Captum，该工具可帮助在PyTorch中工作的开发人员了解为什么他们的模型生成特定输出。Captum提供了先进的工具来了解特定神经元和层的重要性如何影响模型做出的预测。Captum的算法包括积分梯度，电导，SmoothGrad和VarGrad以及DeepLift。 下例显示了如何在预先训练的ResNet模型上应用模型可解释性算法，然后通过将每个像素的属性叠加在图像上来使其可视化。 noise_tunnel = NoiseTunnel(integrated_gradients) attributions_ig_nt, delta = noise_tunnel.attribute(input, n_samples=10, nt_type='smoothgrad_sq', target=pred_label_idx) _ = viz.visualize_image_attr_multiple([\"original_image\", \"heat_map\"], [\"all\", \"positive\"], np.transpose(attributions_ig_nt.squeeze().cpu().detach().numpy(), (1,2,0)), np.transpose(transformed_img.squeeze().cpu().detach().numpy(), (1,2,0)), cmap=default_cmap, show_colorbar=True) 在captum.ai上了解有关Captum的更多信息。 CRYPTEN 通过基于云或机器学习即服务（MLaaS）平台的ML的实际应用提出了一系列安全和隐私挑战。特别是，这些平台的用户可能不希望或无法共享未加密的数据，这使他们无法充分利用ML工具。为了应对这些挑战，机器学习社区正在探索各种成熟度不同的技术方法。这些包括同态加密，安全的多方计算，受信任的执行环境，设备上计算和差异隐私。 为了更好地理解如何应用其中的某些技术，我们发布了CrypTen，这是一个新的基于社区的研究平台，用于推动隐私保护ML领域的发展。在此处了解有关CrypTen的更多信息。它可以在GitHub上这里。 多模式AI系统的工具 数字内容通常由几种形式组成，例如文本，图像，音频和视频。例如，一个公共帖子可能包含图像，正文，标题，视频和登录页面。甚至一个特定的组件也可能具有不止一种形式，例如既包含视觉信号又包含音频信号的视频，或者包含图像，文本和HTML源的登录页面。 与PyTorch配合使用的工具和库生态系统提供了增强的方法来应对构建多模式ML系统的挑战。以下是今天启动的一些最新库： DETECTRON2 对象检测和分割用于从自动驾驶汽车到内容理解（平台完整性）等任务。为了推进这项工作，Facebook AI Research（FAIR）发布了Detectron2，这是一种在PyTorch中实现的对象检测库。Detectron2提供对最新模型和任务的支持，增强的灵活性以帮助进行计算机视觉研究，并改善了可维护性和可伸缩性以支持生产用例。 Detectron2 在这里可用，您可以在这里了解更多信息。 语音扩展到 FAIRSEQ 语言翻译和音频处理是系统和应用程序（例如搜索，翻译，语音和助手）中的关键组件。由于变压器等新架构的发展以及大规模的预训练方法的发展，最近在这些领域取得了巨大的进步。我们已经扩展了Fairseq（语言翻译等序列到序列应用程序的框架），以包括对语音和音频识别任务的端到端学习的支持.fairseq的这些扩展可以加快对新语音研究的探索和原型开发。提供想法，同时提供清晰的生产路径。 在此处开始使用fairseq 。 云提供商和硬件生态系统支持 诸如Amazon Web Services，Microsoft Azure和Google Cloud之类的云提供商为希望在PyTorch上开发ML并在生产中进行部署的任何人提供了广泛的支持。我们很高兴分享Google Cloud TPU支持的全面可用性以及与阿里云的新推出的集成。我们还将扩展对硬件生态系统的支持。 Google Cloud TPU支持现已广泛可用。为了加速当今部署的最大规模的机器学习（ML）应用并实现明天的ML应用的快速发展，Google创建了称为Tensor Processing Units（TPU）的定制硅芯片。将这些TPU 组装到称为Cloud TPU Pods的多机架ML超级计算机中后，它们可以在几分钟或几小时内完成ML工作负载，而以前在其他系统上要花费几天或几周。来自Facebook，Google和Salesforce的工程师共同努力，在PyTorch中启用并试用了Cloud TPU支持，包括对Cloud TPU Pods的实验性支持。Colab还提供了对Cloud TPU的PyTorch支持。在此处了解有关如何开始使用PyTorch on Cloud TPU的更多信息。 阿里巴巴在阿里云中添加了对PyTorch的支持。最初的集成涉及PyTorch 1.x的一键式解决方案，Data Science Workshop笔记本服务，使用Gloo / NCCL进行的分布式培训以及与阿里巴巴IaaS（例如OSS，ODPS和NAS）的无缝集成。我们期待与阿里巴巴提供的工具链一起，大幅降低采用该系统所需的开销，并帮助阿里云的全球客户群利用PyTorch开发新的AI应用程序。 ML硬件生态系统得以扩展。除了主要的GPU和CPU合作伙伴之外，PyTorch生态系统还支​​持专用的ML加速器。英特尔和Habana的更新展示了PyTorch如何连接到Glow优化编译器，从而使开发人员能够利用这些针对特定市场的解决方案。 PyTorch社区的成长 作为一个开源的，社区驱动的项目，PyTorch受益于为生态系统带来新功能的众多贡献者。以下是一些最近的示例： Mila SpeechBrain旨在提供基于PyTorch的开源，多合一语音工具包。目标是开发一个单一的，灵活的，用户友好的工具包，该工具包可用于轻松开发语音识别（端到端和HMM-DNN），说话者识别，语音分离，多语言功能的最新系统-麦克风信号处理（例如，波束成形），自我监督学习以及许多其他功能。了解更多 SpaCy是一个新的包装库，具有对多个模型的一致且易于使用的界面，以便提取功能以支持NLP管道。通过spaCy的标准培训API提供支持。该库还计算对齐方式，以便可以将变压器功能部件与实际单词相关，而不仅仅是单词。了解更多 HuggingFace PyTorch-Transformers（以前称为pytorch-pretrained-bert是一个用于自然语言处理（NLP）的最新的预训练模型库。该库当前包含PyTorch实现，预训练模型权重，用法脚本和转换实用程序车型如BERT，GPT-2，罗伯塔和DistilBERT，它也在增长迅速，拥有超过13,000 GitHub的星级和广泛的用户。了解更多 PyTorch Lightning是PyTorch的类似Keras的ML库。它将核心的培训和验证逻辑留给您，并自动完成其余的工作。可重复性是许多研究领域（包括基于ML技术的领域）的关键要求。随着提交给arXiv和会议的研究论文数量激增至数以万计，缩放可重复性变得困难。了解更多。 我们最近举行了首次在线全球PyTorch夏季黑客马拉松，邀请了世界各地的研究人员和开发人员与PyTorch建立创新的新项目。近1500名开发人员参加了该项目，提交了从牲畜疾病检测到以AI为动力的财务助手等项目。获奖项目是： Torchmeta，它提供了PyTorch的扩展，以简化PyTorch中元学习算法的开发。它具有受TorchVision启发的统一界面，可解决少数镜头分类和回归问题，从而可以轻松地对多个数据集进行基准测试，以提高再现性。 Open-Unmix，使用PyTorch进行端到端音乐混合的系统。混合将单个乐器或人声轨与任何立体声录音分开。 Endless AI产生的Tees，这家商店采用AI产生的T恤设计，可在全球范围内购买和交付。该系统使用最先进的生成模型（StyleGAN），该模型由PyTorch构建，然后接受现代艺术培训。 访问pytorch.org了解更多信息，并开始使用PyTorch 1.3以及最新的库和生态系统项目。我们期待社区通过PyTorch构建的贡献，令人兴奋的研究进展以及实际应用。 我们要感谢整个PyTorch团队和社区为这项工作做出的所有贡献。 我们一直在努力 apachecn/pytorch-doc-zh (adsbygoogle = window.adsbygoogle || []).push({}); var _hmt = _hmt || []; (function() { var hm = document.createElement(\"script\"); hm.src = \"https://hm.baidu.com/hm.js?38525fdac4b5d4403900b943d4e7dd91\"; var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(hm, s); })(); window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-102475051-10'); const gitalk = new Gitalk({ clientID: '2e62dee5b9896e2eede6', clientSecret: 'ca6819a54656af0d87960af15315320f8a628a53', repo: 'pytorch-doc-zh', owner: 'apachecn', admin: ['jiangzhonglian', 'wizardforcel'], id: md5(location.pathname), distractionFreeMode: false }) gitalk.render('gitalk-container') Copyright © ibooker.org.cn 2019 all right reserved，由 ApacheCN 团队提供支持该文件修订时间： 2019-12-27 08:05:23 console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}